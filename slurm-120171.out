wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240123_021837-3rk8b0u2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-violet-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/seed-testing
wandb: üöÄ View run at https://wandb.ai/ecrl/seed-testing/runs/3rk8b0u2
Using cpu device
------------------------------------
| avg_speed          | 0.114       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.114       |
| reward             | -0.40254623 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.59e+03   |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2048        |
------------------------------------
------------------------------------------
| avg_speed                | 0.803       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.803       |
| reward                   | -0.8888517  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.85e+03   |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.003441795 |
|    clip_fraction         | 0.0262      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0974      |
|    cost_value_loss       | 0.0248      |
|    cost_values           | 0.0612      |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.00357     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 367         |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 1           |
|    value_loss            | 806         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.71         |
| reward                   | -0.9412131   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.72e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 3            |
|    time_elapsed          | 67           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0050767474 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0701       |
|    cost_value_loss       | 0.0128       |
|    cost_values           | 0.0497       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0665       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 688          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00267     |
|    std                   | 1.01         |
|    value_loss            | 1.43e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.4          |
| reward                   | -1.2093725   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.6e+03     |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 4            |
|    time_elapsed          | 89           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0034139524 |
|    clip_fraction         | 0.0141       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0506       |
|    cost_value_loss       | 0.00401      |
|    cost_values           | 0.0594       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0842       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 324          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 1            |
|    value_loss            | 677          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.724       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.724       |
| reward                   | -0.39638984 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.58e+03   |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 10240       |
| train/                   |             |
|    approx_kl             | 0.005025201 |
|    clip_fraction         | 0.0405      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0723      |
|    cost_value_loss       | 0.00346     |
|    cost_values           | 0.0814      |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.199       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 211         |
|    n_updates             | 40          |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 1           |
|    value_loss            | 443         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.81        |
| reward                   | -1.03029    |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.51e+03   |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 12288       |
| train/                   |             |
|    approx_kl             | 0.003415335 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0751      |
|    cost_value_loss       | 0.00124     |
|    cost_values           | 0.0761      |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.239       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 285         |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 1           |
|    value_loss            | 597         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.13         |
| reward                   | -1.0954587   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.47e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 7            |
|    time_elapsed          | 157          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0026495014 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0573       |
|    cost_value_loss       | 0.00169      |
|    cost_values           | 0.0598       |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.297        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 163          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 1            |
|    value_loss            | 361          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.961        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.961        |
| reward                   | -0.9047187   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.46e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 8            |
|    time_elapsed          | 180          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0028592357 |
|    clip_fraction         | 0.00688      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0679       |
|    cost_value_loss       | 0.00115      |
|    cost_values           | 0.0704       |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.18         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 194          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 1            |
|    value_loss            | 400          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.75        |
| reward                   | -1.3859735  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.41e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 18432       |
| train/                   |             |
|    approx_kl             | 0.004217918 |
|    clip_fraction         | 0.0163      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0423      |
|    cost_value_loss       | 9.89e-05    |
|    cost_values           | 0.0431      |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.187       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 271         |
|    n_updates             | 80          |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 1           |
|    value_loss            | 551         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.43        |
| reward                   | -0.87711567 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.37e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 10          |
|    time_elapsed          | 225         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.003321825 |
|    clip_fraction         | 0.0163      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.044       |
|    cost_value_loss       | 0.000321    |
|    cost_values           | 0.0445      |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.264       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 140         |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 1           |
|    value_loss            | 303         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.44         |
| reward                   | -0.31520858  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 11           |
|    time_elapsed          | 248          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0034511287 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0372       |
|    cost_value_loss       | 0.000229     |
|    cost_values           | 0.0384       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.337        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.2         |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.01         |
|    value_loss            | 205          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.425        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.425        |
| reward                   | -0.76624346  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 12           |
|    time_elapsed          | 270          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0036754052 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0249       |
|    cost_value_loss       | 0.000593     |
|    cost_values           | 0.025        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.273        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 98.8         |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 1.01         |
|    value_loss            | 235          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.203        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.203        |
| reward                   | -1.1145004   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 13           |
|    time_elapsed          | 293          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0039682807 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0236       |
|    cost_value_loss       | 0.00038      |
|    cost_values           | 0.0239       |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.474        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.4         |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 0.995        |
|    value_loss            | 97.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.86        |
| reward                   | -1.0054616  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 14          |
|    time_elapsed          | 315         |
|    total_timesteps       | 28672       |
| train/                   |             |
|    approx_kl             | 0.004283653 |
|    clip_fraction         | 0.0251      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0148      |
|    cost_value_loss       | 4.48e-05    |
|    cost_values           | 0.0152      |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.181       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 86.7        |
|    n_updates             | 130         |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.991       |
|    value_loss            | 180         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -1.1688596  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 15          |
|    time_elapsed          | 338         |
|    total_timesteps       | 30720       |
| train/                   |             |
|    approx_kl             | 0.002583314 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0254      |
|    cost_value_loss       | 0.000938    |
|    cost_values           | 0.0264      |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -0.186      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 66.8        |
|    n_updates             | 140         |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.99        |
|    value_loss            | 171         |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.46       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.46       |
| reward                   | -1.764941  |
| rollout/                 |            |
|    ep_len_mean           | 972        |
|    ep_rew_mean           | -1.14e+03  |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 16         |
|    time_elapsed          | 361        |
|    total_timesteps       | 32768      |
| train/                   |            |
|    approx_kl             | 0.00541822 |
|    clip_fraction         | 0.0377     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0212     |
|    cost_value_loss       | 0.000679   |
|    cost_values           | 0.022      |
|    entropy               | -2.83      |
|    entropy_loss          | -2.82      |
|    explained_variance    | 0.381      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 48         |
|    n_updates             | 150        |
|    policy_gradient_loss  | -0.00374   |
|    std                   | 0.994      |
|    value_loss            | 118        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 1.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.23         |
| reward                   | -1.524142    |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 17           |
|    time_elapsed          | 383          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0043001254 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000809    |
|    cost_value_loss       | 0.000142     |
|    cost_values           | -0.000702    |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.356        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.2         |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 0.996        |
|    value_loss            | 203          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.26        |
| reward                   | -1.2519505  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 18          |
|    time_elapsed          | 406         |
|    total_timesteps       | 36864       |
| train/                   |             |
|    approx_kl             | 0.004887824 |
|    clip_fraction         | 0.0269      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00129     |
|    cost_value_loss       | 3.35e-05    |
|    cost_values           | 0.00137     |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -0.051      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 172         |
|    n_updates             | 170         |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.996       |
|    value_loss            | 361         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.537        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.537        |
| reward                   | -0.92863667  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 19           |
|    time_elapsed          | 429          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0053831963 |
|    clip_fraction         | 0.0449       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00631      |
|    cost_value_loss       | 2.2e-05      |
|    cost_values           | 0.00633      |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.0849      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.1         |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 0.995        |
|    value_loss            | 191          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.2          |
| reward                   | -2.392071    |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 20           |
|    time_elapsed          | 452          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0057537975 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0144       |
|    cost_value_loss       | 0.000139     |
|    cost_values           | 0.0138       |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.348       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.5         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.99         |
|    value_loss            | 98.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -1.3917685   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 21           |
|    time_elapsed          | 474          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0044376724 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00812      |
|    cost_value_loss       | 0.000365     |
|    cost_values           | 0.00847      |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -0.433       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 89.8         |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 0.985        |
|    value_loss            | 218          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -1.585002   |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 497         |
|    total_timesteps       | 45056       |
| train/                   |             |
|    approx_kl             | 0.005408988 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0185      |
|    cost_value_loss       | 0.000173    |
|    cost_values           | 0.0186      |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | -0.175      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 80.4        |
|    n_updates             | 210         |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.984       |
|    value_loss            | 185         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0929      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0929      |
| reward                   | -0.51214886 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 520         |
|    total_timesteps       | 47104       |
| train/                   |             |
|    approx_kl             | 0.006602722 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0136      |
|    cost_value_loss       | 0.000215    |
|    cost_values           | 0.013       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.255       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 140         |
|    n_updates             | 220         |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.984       |
|    value_loss            | 314         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0425      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0425      |
| reward                   | -0.38506398 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 543         |
|    total_timesteps       | 49152       |
| train/                   |             |
|    approx_kl             | 0.004070244 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0136      |
|    cost_value_loss       | 8.82e-06    |
|    cost_values           | 0.0136      |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -0.0808     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 69.3        |
|    n_updates             | 230         |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.988       |
|    value_loss            | 148         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.51        |
| reward                   | -0.28719637 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 566         |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.008136974 |
|    clip_fraction         | 0.0611      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0121      |
|    cost_value_loss       | 8.24e-06    |
|    cost_values           | 0.0121      |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -0.044      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 148         |
|    n_updates             | 240         |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.99        |
|    value_loss            | 318         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.28        |
| reward                   | -0.4048142  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 588         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.004488489 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.01        |
|    cost_value_loss       | 2.83e-06    |
|    cost_values           | 0.0101      |
|    entropy               | -2.83       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.011       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 111         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.994       |
|    value_loss            | 259         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.03         |
| reward                   | -0.9860548   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 27           |
|    time_elapsed          | 611          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0020124537 |
|    clip_fraction         | 0.00542      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00918      |
|    cost_value_loss       | 1.96e-06     |
|    cost_values           | 0.00921      |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0255       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 128          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.998        |
|    value_loss            | 274          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.03        |
| reward                   | -0.38690606 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 633         |
|    total_timesteps       | 57344       |
| train/                   |             |
|    approx_kl             | 0.006346849 |
|    clip_fraction         | 0.0346      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00847     |
|    cost_value_loss       | 2.02e-06    |
|    cost_values           | 0.00848     |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0395      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 138         |
|    n_updates             | 270         |
|    policy_gradient_loss  | -0.0044     |
|    std                   | 0.995       |
|    value_loss            | 296         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.21         |
| reward                   | -0.48329368  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 29           |
|    time_elapsed          | 656          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0051024267 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00705      |
|    cost_value_loss       | 1.07e-06     |
|    cost_values           | 0.00707      |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0139       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 165          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 0.995        |
|    value_loss            | 329          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.33         |
| reward                   | -0.74108154  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 30           |
|    time_elapsed          | 678          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0024137455 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00518      |
|    cost_value_loss       | 1.18e-06     |
|    cost_values           | 0.0052       |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00901      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 196          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.998        |
|    value_loss            | 410          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 3.84       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.84       |
| reward                   | -1.1358051 |
| rollout/                 |            |
|    ep_len_mean           | 972        |
|    ep_rew_mean           | -1.12e+03  |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 31         |
|    time_elapsed          | 701        |
|    total_timesteps       | 63488      |
| train/                   |            |
|    approx_kl             | 0.00298836 |
|    clip_fraction         | 0.0196     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00404    |
|    cost_value_loss       | 4.58e-07   |
|    cost_values           | 0.00407    |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00841    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 353        |
|    n_updates             | 300        |
|    policy_gradient_loss  | -0.00285   |
|    std                   | 1          |
|    value_loss            | 733        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 2.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.63         |
| reward                   | -0.812074    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 32           |
|    time_elapsed          | 723          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0035836643 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00324      |
|    cost_value_loss       | 3.41e-07     |
|    cost_values           | 0.00324      |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0156       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 119          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 1.01         |
|    value_loss            | 239          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.527       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.527       |
| reward                   | -0.50174016 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 746         |
|    total_timesteps       | 67584       |
| train/                   |             |
|    approx_kl             | 0.005234633 |
|    clip_fraction         | 0.0282      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.003       |
|    cost_value_loss       | 6.69e-07    |
|    cost_values           | 0.00301     |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.00921     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 554         |
|    n_updates             | 320         |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 1.01        |
|    value_loss            | 1.13e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.821        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.821        |
| reward                   | -1.8568821   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 34           |
|    time_elapsed          | 768          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0045632543 |
|    clip_fraction         | 0.00977      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.03         |
|    cost_value_loss       | 0.00116      |
|    cost_values           | 0.0319       |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -3.81        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.9         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 1.01         |
|    value_loss            | 180          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.84         |
| reward                   | -0.8165812   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 35           |
|    time_elapsed          | 791          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0047590253 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0318       |
|    cost_value_loss       | 0.000182     |
|    cost_values           | 0.0315       |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.222       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 123          |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 1.01         |
|    value_loss            | 261          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.16         |
| reward                   | -1.8092253   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 36           |
|    time_elapsed          | 813          |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0041185413 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0257       |
|    cost_value_loss       | 9.53e-06     |
|    cost_values           | 0.0258       |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.000746    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 132          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 1.02         |
|    value_loss            | 292          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.164       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.164       |
| reward                   | -0.64637375 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 836         |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.00372527  |
|    clip_fraction         | 0.0285      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0219      |
|    cost_value_loss       | 7.24e-06    |
|    cost_values           | 0.0219      |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | -0.00219    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 224         |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 1.02        |
|    value_loss            | 466         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.22         |
| reward                   | -1.10284     |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 38           |
|    time_elapsed          | 859          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0024509057 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0183       |
|    cost_value_loss       | 6.74e-06     |
|    cost_values           | 0.0184       |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.000341    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 550          |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 1.02         |
|    value_loss            | 1.12e+03     |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.34        |
| reward                   | -1.0377774  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 882         |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.005074351 |
|    clip_fraction         | 0.0486      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0153      |
|    cost_value_loss       | 3.31e-06    |
|    cost_values           | 0.0153      |
|    entropy               | -2.89       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.00989     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 125         |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00646    |
|    std                   | 1.02        |
|    value_loss            | 263         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.6147594   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 40           |
|    time_elapsed          | 905          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0041668816 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0119       |
|    cost_value_loss       | 2.27e-06     |
|    cost_values           | 0.012        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0088       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 177          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 1.03         |
|    value_loss            | 371          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.55         |
| reward                   | -1.228709    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 41           |
|    time_elapsed          | 927          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0031414698 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00979      |
|    cost_value_loss       | 1.48e-06     |
|    cost_values           | 0.00979      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.89        |
|    explained_variance    | -9.61e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 317          |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 1.03         |
|    value_loss            | 684          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.72         |
| reward                   | -0.7732385   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 42           |
|    time_elapsed          | 950          |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0030599134 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00816      |
|    cost_value_loss       | 9.09e-07     |
|    cost_values           | 0.00817      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00732      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 93.1         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 1.03         |
|    value_loss            | 198          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.88         |
| reward                   | -0.51587796  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 43           |
|    time_elapsed          | 973          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0039353273 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00697      |
|    cost_value_loss       | 8.52e-07     |
|    cost_values           | 0.007        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0101       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 320          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1.03         |
|    value_loss            | 678          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.54         |
| reward                   | -0.69437957  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 44           |
|    time_elapsed          | 995          |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0044467864 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0056       |
|    cost_value_loss       | 4.24e-07     |
|    cost_values           | 0.00561      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0133       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.7         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00585     |
|    std                   | 1.04         |
|    value_loss            | 79.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.854       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.854       |
| reward                   | -0.23960392 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1018        |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.003634208 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00455     |
|    cost_value_loss       | 3.01e-07    |
|    cost_values           | 0.00455     |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.01        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 52.6        |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.00186    |
|    std                   | 1.05        |
|    value_loss            | 107         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.8267647   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 46           |
|    time_elapsed          | 1041         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0049119587 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00437      |
|    cost_value_loss       | 3.3e-07      |
|    cost_values           | 0.00437      |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.0161       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 1.05         |
|    value_loss            | 34.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.07        |
| reward                   | -0.90007836 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1064        |
|    total_timesteps       | 96256       |
| train/                   |             |
|    approx_kl             | 0.004355523 |
|    clip_fraction         | 0.045       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00379     |
|    cost_value_loss       | 5.29e-07    |
|    cost_values           | 0.00378     |
|    entropy               | -2.92       |
|    entropy_loss          | -2.93       |
|    explained_variance    | -0.0174     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.7        |
|    n_updates             | 460         |
|    policy_gradient_loss  | -0.00588    |
|    std                   | 1.04        |
|    value_loss            | 54.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.71         |
| reward                   | -0.73465896  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 48           |
|    time_elapsed          | 1086         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0036476096 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00352      |
|    cost_value_loss       | 1.15e-06     |
|    cost_values           | 0.00352      |
|    entropy               | -2.93        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00773      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 169          |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00811     |
|    std                   | 1.05         |
|    value_loss            | 379          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.62         |
| reward                   | -0.9914929   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 49           |
|    time_elapsed          | 1109         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0037275148 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0027       |
|    cost_value_loss       | 3.81e-07     |
|    cost_values           | 0.00271      |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | -0.0147      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.1         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 1.05         |
|    value_loss            | 62.9         |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/3rk8b0u2/model_epoch(0)
-----------------------------------
| avg_speed          | 4.38       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 4.38       |
| reward             | -0.6405982 |
| rollout/           |            |
|    ep_len_mean     | 969        |
|    ep_rew_mean     | -1.09e+03  |
| time/              |            |
|    fps             | 93         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 102400     |
-----------------------------------
------------------------------------------
| avg_speed                | 1.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.32        |
| reward                   | -0.96915096 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.09e+03   |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 104448      |
| train/                   |             |
|    approx_kl             | 0.006218376 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.013       |
|    cost_value_loss       | 2.71e-06    |
|    cost_values           | 0.013       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.000143    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.7        |
|    n_updates             | 500         |
|    policy_gradient_loss  | -0.00707    |
|    std                   | 1.05        |
|    value_loss            | 54.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.34         |
| reward                   | -1.4526696   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 3            |
|    time_elapsed          | 67           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0048185177 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0104       |
|    cost_value_loss       | 1.72e-06     |
|    cost_values           | 0.0104       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.94        |
|    explained_variance    | -0.00472     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.6         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00429     |
|    std                   | 1.06         |
|    value_loss            | 201          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.85        |
| reward                   | -0.3942789  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 4           |
|    time_elapsed          | 90          |
|    total_timesteps       | 108544      |
| train/                   |             |
|    approx_kl             | 0.006382236 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00845     |
|    cost_value_loss       | 1.24e-06    |
|    cost_values           | 0.00846     |
|    entropy               | -2.96       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 6.56e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 520         |
|    policy_gradient_loss  | -0.00546    |
|    std                   | 1.06        |
|    value_loss            | 33.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.7498577   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 5            |
|    time_elapsed          | 112          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0068283826 |
|    clip_fraction         | 0.076        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00722      |
|    cost_value_loss       | 1e-06        |
|    cost_values           | 0.00722      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.00231     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.6         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00745     |
|    std                   | 1.06         |
|    value_loss            | 60.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.53         |
| reward                   | -1.1249914   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 6            |
|    time_elapsed          | 135          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0030923483 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00578      |
|    cost_value_loss       | 6.03e-07     |
|    cost_values           | 0.0058       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | -0.000116    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.3         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 1.06         |
|    value_loss            | 107          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.18         |
| reward                   | -0.57935953  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 7            |
|    time_elapsed          | 157          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0052371486 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0048       |
|    cost_value_loss       | 4.14e-07     |
|    cost_values           | 0.0048       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | -0.00659     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.4         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 1.06         |
|    value_loss            | 112          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.89         |
| reward                   | -1.4482831   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 8            |
|    time_elapsed          | 180          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0050953557 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00384      |
|    cost_value_loss       | 2.79e-07     |
|    cost_values           | 0.00385      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | -0.00552     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 61           |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.06         |
|    value_loss            | 124          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.52         |
| reward                   | -1.1767427   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 9            |
|    time_elapsed          | 203          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0042358907 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00328      |
|    cost_value_loss       | 1.95e-07     |
|    cost_values           | 0.00329      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | -0.00371     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.1         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 1.06         |
|    value_loss            | 83.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.06         |
| reward                   | -1.2382691   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 10           |
|    time_elapsed          | 226          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0042883176 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00271      |
|    cost_value_loss       | 1.65e-07     |
|    cost_values           | 0.00271      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | -0.00282     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37           |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00457     |
|    std                   | 1.06         |
|    value_loss            | 77.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.37        |
| reward                   | -0.73634285 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 11          |
|    time_elapsed          | 248         |
|    total_timesteps       | 122880      |
| train/                   |             |
|    approx_kl             | 0.005389079 |
|    clip_fraction         | 0.0362      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00215     |
|    cost_value_loss       | 8.93e-08    |
|    cost_values           | 0.00215     |
|    entropy               | -2.96       |
|    entropy_loss          | -2.95       |
|    explained_variance    | -0.000794   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17          |
|    n_updates             | 590         |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 1.06        |
|    value_loss            | 36.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.358        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.358        |
| reward                   | -0.5758393   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 12           |
|    time_elapsed          | 271          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0035118842 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00186      |
|    cost_value_loss       | 1.16e-07     |
|    cost_values           | 0.00185      |
|    entropy               | -2.98        |
|    entropy_loss          | -2.97        |
|    explained_variance    | -0.0135      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 118          |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00521     |
|    std                   | 1.07         |
|    value_loss            | 246          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.83        |
| reward                   | -0.4144014  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 13          |
|    time_elapsed          | 294         |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.005505385 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00155     |
|    cost_value_loss       | 4.99e-08    |
|    cost_values           | 0.00155     |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.000905    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 49.7        |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.00649    |
|    std                   | 1.08        |
|    value_loss            | 110         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2279507   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 14           |
|    time_elapsed          | 317          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0050237137 |
|    clip_fraction         | 0.046        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00127      |
|    cost_value_loss       | 3.22e-08     |
|    cost_values           | 0.00127      |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.00068      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.9         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00547     |
|    std                   | 1.08         |
|    value_loss            | 79.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1713668   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 15           |
|    time_elapsed          | 340          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0067301597 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00177      |
|    cost_value_loss       | 1.82e-07     |
|    cost_values           | 0.00176      |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | -0.016       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.7         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 1.08         |
|    value_loss            | 66.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.08        |
| reward                   | -1.0794672  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 16          |
|    time_elapsed          | 362         |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.005036709 |
|    clip_fraction         | 0.0296      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00139     |
|    cost_value_loss       | 4.96e-08    |
|    cost_values           | 0.00139     |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | -0.00549    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 88.9        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.0037     |
|    std                   | 1.08        |
|    value_loss            | 189         |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.449      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.449      |
| reward                   | -1.2404119 |
| rollout/                 |            |
|    ep_len_mean           | 974        |
|    ep_rew_mean           | -1.07e+03  |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 17         |
|    time_elapsed          | 385        |
|    total_timesteps       | 135168     |
| train/                   |            |
|    approx_kl             | 0.0049778  |
|    clip_fraction         | 0.0601     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00114    |
|    cost_value_loss       | 2.71e-08   |
|    cost_values           | 0.00114    |
|    entropy               | -2.99      |
|    entropy_loss          | -2.99      |
|    explained_variance    | -0.00125   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 33.9       |
|    n_updates             | 650        |
|    policy_gradient_loss  | -0.0063    |
|    std                   | 1.08       |
|    value_loss            | 69.8       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.2951876   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 18           |
|    time_elapsed          | 408          |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0041846945 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000881     |
|    cost_value_loss       | 2.17e-08     |
|    cost_values           | 0.000884     |
|    entropy               | -3           |
|    entropy_loss          | -2.99        |
|    explained_variance    | -0.00292     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 90.5         |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 1.08         |
|    value_loss            | 192          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.6580017   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 19           |
|    time_elapsed          | 431          |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0033352394 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00081      |
|    cost_value_loss       | 1.38e-08     |
|    cost_values           | 0.000809     |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | -0.000321    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.2         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.00503     |
|    std                   | 1.08         |
|    value_loss            | 154          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -2.3912196   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 20           |
|    time_elapsed          | 454          |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0037916629 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000679     |
|    cost_value_loss       | 9.02e-09     |
|    cost_values           | 0.00068      |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.00023      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 73.5         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 1.08         |
|    value_loss            | 148          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -1.1441344  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 21          |
|    time_elapsed          | 477         |
|    total_timesteps       | 143360      |
| train/                   |             |
|    approx_kl             | 0.004962683 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000548    |
|    cost_value_loss       | 6.76e-09    |
|    cost_values           | 0.000549    |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.000151    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 168         |
|    n_updates             | 690         |
|    policy_gradient_loss  | -0.00287    |
|    std                   | 1.08        |
|    value_loss            | 361         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.83        |
| reward                   | -0.98768866 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 500         |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.003788414 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000468    |
|    cost_value_loss       | 4.88e-09    |
|    cost_values           | 0.000469    |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.000509    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 112         |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 1.08        |
|    value_loss            | 218         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.5         |
| reward                   | -2.1813202  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 522         |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.003144811 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000347    |
|    cost_value_loss       | 2.93e-09    |
|    cost_values           | 0.000347    |
|    entropy               | -2.99       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.000378    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.8        |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 1.08        |
|    value_loss            | 104         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.74         |
| reward                   | -0.55579454  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 24           |
|    time_elapsed          | 545          |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0027266773 |
|    clip_fraction         | 0.0105       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000332     |
|    cost_value_loss       | 9.05e-09     |
|    cost_values           | 0.000333     |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.000138     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 127          |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00267     |
|    std                   | 1.08         |
|    value_loss            | 261          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.55        |
| reward                   | -0.6321485  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 568         |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.004738012 |
|    clip_fraction         | 0.0377      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000249    |
|    cost_value_loss       | 2.74e-09    |
|    cost_values           | 0.000249    |
|    entropy               | -2.98       |
|    entropy_loss          | -2.99       |
|    explained_variance    | -5.32e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.2        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.0046     |
|    std                   | 1.08        |
|    value_loss            | 57.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.89        |
| reward                   | -0.74899286 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 591         |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.005366257 |
|    clip_fraction         | 0.0487      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000149    |
|    cost_value_loss       | 6.98e-10    |
|    cost_values           | 0.000149    |
|    entropy               | -2.99       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.000486    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 72.1        |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00632    |
|    std                   | 1.08        |
|    value_loss            | 151         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.32         |
| reward                   | -0.63076377  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 27           |
|    time_elapsed          | 613          |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0059416657 |
|    clip_fraction         | 0.0375       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000118     |
|    cost_value_loss       | 4.91e-10     |
|    cost_values           | 0.000118     |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.000653     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50.9         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00468     |
|    std                   | 1.08         |
|    value_loss            | 116          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.54        |
| reward                   | -0.36503407 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 635         |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.005489417 |
|    clip_fraction         | 0.0529      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000165    |
|    cost_value_loss       | 2.53e-09    |
|    cost_values           | 0.000165    |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 5.39e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 43.6        |
|    n_updates             | 760         |
|    policy_gradient_loss  | -0.00523    |
|    std                   | 1.08        |
|    value_loss            | 90.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.21         |
| reward                   | -1.6428425   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 29           |
|    time_elapsed          | 657          |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0051530492 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0002       |
|    cost_value_loss       | 6.98e-09     |
|    cost_values           | 0.0002       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.00144     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.8         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00509     |
|    std                   | 1.07         |
|    value_loss            | 46           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.07         |
| reward                   | -1.2596799   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 30           |
|    time_elapsed          | 679          |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0052333176 |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000125     |
|    cost_value_loss       | 2.93e-09     |
|    cost_values           | 0.000125     |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.000769     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.1         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00553     |
|    std                   | 1.06         |
|    value_loss            | 65.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9736233   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 31           |
|    time_elapsed          | 701          |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0061008707 |
|    clip_fraction         | 0.0658       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.25e-05     |
|    cost_value_loss       | 1.75e-09     |
|    cost_values           | 8.25e-05     |
|    entropy               | -2.95        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.000601     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.4         |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.0064      |
|    std                   | 1.06         |
|    value_loss            | 59.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -1.470615    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 32           |
|    time_elapsed          | 723          |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0042661726 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000104     |
|    cost_value_loss       | 1.31e-09     |
|    cost_values           | 0.000104     |
|    entropy               | -2.93        |
|    entropy_loss          | -2.94        |
|    explained_variance    | -0.000127    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.3         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00635     |
|    std                   | 1.05         |
|    value_loss            | 94.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.23         |
| reward                   | -0.5805564   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 33           |
|    time_elapsed          | 745          |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0032472839 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58e-05     |
|    cost_value_loss       | 6.48e-10     |
|    cost_values           | 2.55e-05     |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 1.32e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 70.6         |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 1.05         |
|    value_loss            | 142          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.99         |
| reward                   | -1.8170056   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 34           |
|    time_elapsed          | 767          |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0066695423 |
|    clip_fraction         | 0.087        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.79e-05     |
|    cost_value_loss       | 3.94e-09     |
|    cost_values           | 9.81e-05     |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00154      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.00981     |
|    std                   | 1.05         |
|    value_loss            | 28.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.72         |
| reward                   | -0.5990184   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 35           |
|    time_elapsed          | 789          |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0052224062 |
|    clip_fraction         | 0.0543       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.93e-05     |
|    cost_value_loss       | 1.42e-09     |
|    cost_values           | 7.92e-05     |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.000114     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.7         |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.00584     |
|    std                   | 1.05         |
|    value_loss            | 97           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.11         |
| reward                   | -0.53149194  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 36           |
|    time_elapsed          | 811          |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0077096242 |
|    clip_fraction         | 0.0776       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3e-05      |
|    cost_value_loss       | 7.73e-10     |
|    cost_values           | 2.28e-05     |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00142      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.3         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.00755     |
|    std                   | 1.04         |
|    value_loss            | 54.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.22        |
| reward                   | -0.6243333  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 833         |
|    total_timesteps       | 176128      |
| train/                   |             |
|    approx_kl             | 0.003323616 |
|    clip_fraction         | 0.0152      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.12e-05    |
|    cost_value_loss       | 1.58e-09    |
|    cost_values           | 5.12e-05    |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.000726    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 43.5        |
|    n_updates             | 850         |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 1.04        |
|    value_loss            | 93.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.12        |
| reward                   | -1.07378    |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 855         |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.005127582 |
|    clip_fraction         | 0.0364      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46e-05    |
|    cost_value_loss       | 9.76e-10    |
|    cost_values           | 4.48e-05    |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.00012    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27          |
|    n_updates             | 860         |
|    policy_gradient_loss  | -0.00476    |
|    std                   | 1.03        |
|    value_loss            | 55.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.34         |
| reward                   | -0.63084716  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 39           |
|    time_elapsed          | 877          |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0070417076 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21e-06     |
|    cost_value_loss       | 3.98e-10     |
|    cost_values           | 1.8e-06      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00068      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41           |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.0061      |
|    std                   | 1.03         |
|    value_loss            | 94.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.7303019   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -997         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 40           |
|    time_elapsed          | 899          |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0070413146 |
|    clip_fraction         | 0.0639       |
|    clip_range            | 0.2          |
|    cost_returns          | -1.52e-05    |
|    cost_value_loss       | 2.89e-10     |
|    cost_values           | -1.5e-05     |
|    entropy               | -2.91        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.000641     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.8         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00415     |
|    std                   | 1.03         |
|    value_loss            | 94           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -0.48757488  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 41           |
|    time_elapsed          | 921          |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0062354454 |
|    clip_fraction         | 0.0653       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26e-05     |
|    cost_value_loss       | 8.72e-10     |
|    cost_values           | 2.25e-05     |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00124      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.0088      |
|    std                   | 1.03         |
|    value_loss            | 46.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.28419417  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -999         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 42           |
|    time_elapsed          | 943          |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0055810316 |
|    clip_fraction         | 0.0447       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59e-05     |
|    cost_value_loss       | 4.16e-10     |
|    cost_values           | 1.58e-05     |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.000553     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00393     |
|    std                   | 1.03         |
|    value_loss            | 44.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.718        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.718        |
| reward                   | -0.8669252   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 43           |
|    time_elapsed          | 965          |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0080302525 |
|    clip_fraction         | 0.14         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.29e-05     |
|    cost_value_loss       | 0.000242     |
|    cost_values           | -0.000658    |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.000429    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.91         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 1.03         |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.58168185  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 44           |
|    time_elapsed          | 987          |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0122311525 |
|    clip_fraction         | 0.234        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0107      |
|    cost_value_loss       | 2.53e-06     |
|    cost_values           | -0.0104      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.00238     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.5         |
|    n_updates             | 920          |
|    policy_gradient_loss  | 0.0102       |
|    std                   | 1.03         |
|    value_loss            | 45.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.904        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.904        |
| reward                   | -1.1264377   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 45           |
|    time_elapsed          | 1009         |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0057799397 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00903     |
|    cost_value_loss       | 1.24e-06     |
|    cost_values           | -0.00909     |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00117      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.32         |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 1.04         |
|    value_loss            | 19.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.7043197  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 46          |
|    time_elapsed          | 1031        |
|    total_timesteps       | 194560      |
| train/                   |             |
|    approx_kl             | 0.005188837 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00724    |
|    cost_value_loss       | 8.24e-07    |
|    cost_values           | -0.00731    |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.000884    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 940         |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 1.04        |
|    value_loss            | 23.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.84         |
| reward                   | -1.4118943   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 47           |
|    time_elapsed          | 1053         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0061538424 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00609     |
|    cost_value_loss       | 6.2e-07      |
|    cost_values           | -0.00622     |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0012       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.7         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00535     |
|    std                   | 1.04         |
|    value_loss            | 83.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.84         |
| reward                   | -0.8028863   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 48           |
|    time_elapsed          | 1075         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0032436876 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00511     |
|    cost_value_loss       | 4.05e-07     |
|    cost_values           | -0.00518     |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.000478     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 1.04         |
|    value_loss            | 28.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.49         |
| reward                   | -0.9183242   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 49           |
|    time_elapsed          | 1097         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0058889347 |
|    clip_fraction         | 0.0554       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0041      |
|    cost_value_loss       | 2.5e-07      |
|    cost_values           | -0.00412     |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.000281     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00694     |
|    std                   | 1.05         |
|    value_loss            | 20.8         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.99       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.99       |
| reward             | -0.8755699 |
| rollout/           |            |
|    ep_len_mean     | 971        |
|    ep_rew_mean     | -1e+03     |
| time/              |            |
|    fps             | 95         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 3.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.31         |
| reward                   | -0.7318422   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 95           |
|    iterations            | 2            |
|    time_elapsed          | 42           |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0051703183 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00275     |
|    cost_value_loss       | 1.99e-05     |
|    cost_values           | -0.00251     |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0115       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.9         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00446     |
|    std                   | 1.04         |
|    value_loss            | 37.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -1.5295068  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 3           |
|    time_elapsed          | 64          |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.009165002 |
|    clip_fraction         | 0.0592      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00275    |
|    cost_value_loss       | 2.95e-06    |
|    cost_values           | -0.00267    |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.0176      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.95        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.00657    |
|    std                   | 1.04        |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.5          |
| reward                   | -1.856408    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 4            |
|    time_elapsed          | 86           |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0033820937 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0107       |
|    cost_value_loss       | 0.000533     |
|    cost_values           | 0.00833      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -5.85        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.5         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 1.04         |
|    value_loss            | 185          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.29         |
| reward                   | -1.3912745   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 5            |
|    time_elapsed          | 108          |
|    total_timesteps       | 210944       |
| train/                   |              |
|    approx_kl             | 0.0024629056 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00944      |
|    cost_value_loss       | 1.75e-05     |
|    cost_values           | 0.00921      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -0.108       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33           |
|    n_updates             | 1020         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 1.04         |
|    value_loss            | 66.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.28         |
| reward                   | -0.5606581   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 6            |
|    time_elapsed          | 130          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0030376674 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00762      |
|    cost_value_loss       | 1.11e-06     |
|    cost_values           | 0.00766      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -0.0139      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.7         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 1.04         |
|    value_loss            | 55.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.62         |
| reward                   | -0.3683236   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 152          |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0013382246 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00627      |
|    cost_value_loss       | 7.82e-07     |
|    cost_values           | 0.00643      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0024       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.1         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 1.04         |
|    value_loss            | 63.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.58         |
| reward                   | -0.8900505   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 174          |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0003405434 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00567      |
|    cost_value_loss       | 8.93e-07     |
|    cost_values           | 0.00575      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -0.0138      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.000511    |
|    std                   | 1.04         |
|    value_loss            | 210          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.81        |
| reward                   | -0.6625273  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 196         |
|    total_timesteps       | 219136      |
| train/                   |             |
|    approx_kl             | 0.000823388 |
|    clip_fraction         | 0.000195    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00458     |
|    cost_value_loss       | 3.75e-07    |
|    cost_values           | 0.00468     |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.00179     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 48.8        |
|    n_updates             | 1060        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 1.04        |
|    value_loss            | 96.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.645        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.645        |
| reward                   | -0.9525554   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 218          |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0009668486 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00383      |
|    cost_value_loss       | 2.52e-07     |
|    cost_values           | 0.00391      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00151      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.5         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 1.04         |
|    value_loss            | 130          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.8888629   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 240          |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0018142369 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00318      |
|    cost_value_loss       | 1.72e-07     |
|    cost_values           | 0.00325      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00195      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 1.04         |
|    value_loss            | 49           |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.96        |
| reward                   | -0.9122685  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 262         |
|    total_timesteps       | 225280      |
| train/                   |             |
|    approx_kl             | 0.005598383 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00268     |
|    cost_value_loss       | 1.06e-07    |
|    cost_values           | 0.00269     |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.00167     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.7        |
|    n_updates             | 1090        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 1.05        |
|    value_loss            | 41.4        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.6287285    |
| rollout/                 |               |
|    ep_len_mean           | 975           |
|    ep_rew_mean           | -1.04e+03     |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 13            |
|    time_elapsed          | 284           |
|    total_timesteps       | 227328        |
| train/                   |               |
|    approx_kl             | 0.00089217466 |
|    clip_fraction         | 0.000928      |
|    clip_range            | 0.2           |
|    cost_returns          | 0.00224       |
|    cost_value_loss       | 9.74e-08      |
|    cost_values           | 0.00229       |
|    entropy               | -2.93         |
|    entropy_loss          | -2.93         |
|    explained_variance    | 0.00237       |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 35.9          |
|    n_updates             | 1100          |
|    policy_gradient_loss  | -0.00118      |
|    std                   | 1.05          |
|    value_loss            | 73.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -1.799945    |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 306          |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0007259473 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00181      |
|    cost_value_loss       | 5.66e-08     |
|    cost_values           | 0.00183      |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.000653     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 72.4         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.000862    |
|    std                   | 1.05         |
|    value_loss            | 156          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -1.0494871   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 328          |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0011914725 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00189      |
|    cost_value_loss       | 4.88e-07     |
|    cost_values           | 0.00192      |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | -0.0789      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 96.3         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 1.05         |
|    value_loss            | 202          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.7358448   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 350          |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0014482683 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00168      |
|    cost_value_loss       | 1.09e-07     |
|    cost_values           | 0.00171      |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | -0.00938     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 1.05         |
|    value_loss            | 196          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.1209214   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 372          |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0059701195 |
|    clip_fraction         | 0.0658       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0014       |
|    cost_value_loss       | 3.35e-08     |
|    cost_values           | 0.00141      |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00342      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00685     |
|    std                   | 1.05         |
|    value_loss            | 23.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.49        |
| reward                   | -1.2214143  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 18          |
|    time_elapsed          | 394         |
|    total_timesteps       | 237568      |
| train/                   |             |
|    approx_kl             | 0.005066668 |
|    clip_fraction         | 0.0558      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00118     |
|    cost_value_loss       | 4.75e-07    |
|    cost_values           | 0.00117     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.00359     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.8        |
|    n_updates             | 1150        |
|    policy_gradient_loss  | -0.00667    |
|    std                   | 1.05        |
|    value_loss            | 72.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.54        |
| reward                   | -1.1252227  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 19          |
|    time_elapsed          | 416         |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.004884814 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000813    |
|    cost_value_loss       | 5.19e-07    |
|    cost_values           | 0.000822    |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.0283      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.51        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 1.06        |
|    value_loss            | 14.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.81        |
| reward                   | -1.3169743  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 20          |
|    time_elapsed          | 439         |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.004064625 |
|    clip_fraction         | 0.0206      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000465    |
|    cost_value_loss       | 4.57e-06    |
|    cost_values           | 0.000421    |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.0564      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 49          |
|    n_updates             | 1170        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 1.06        |
|    value_loss            | 56.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.75629365 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 21          |
|    time_elapsed          | 461         |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.009252451 |
|    clip_fraction         | 0.0796      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000306    |
|    cost_value_loss       | 1.3e-07     |
|    cost_values           | 0.000294    |
|    entropy               | -2.96       |
|    entropy_loss          | -2.95       |
|    explained_variance    | -0.00721    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.15        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.00695    |
|    std                   | 1.06        |
|    value_loss            | 14.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.65         |
| reward                   | -1.3285106   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -996         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 483          |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0033069681 |
|    clip_fraction         | 0.0601       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000389     |
|    cost_value_loss       | 3.23e-06     |
|    cost_values           | 0.000467     |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0867       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.23         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.00342     |
|    std                   | 1.06         |
|    value_loss            | 19.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.42         |
| reward                   | -0.59785926  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -998         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 23           |
|    time_elapsed          | 505          |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0074224435 |
|    clip_fraction         | 0.0412       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000418     |
|    cost_value_loss       | 5.43e-07     |
|    cost_values           | 0.000414     |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.525       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.27         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00512     |
|    std                   | 1.06         |
|    value_loss            | 17.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.45         |
| reward                   | -0.90361655  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -988         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 24           |
|    time_elapsed          | 527          |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0028486005 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000521     |
|    cost_value_loss       | 1.41e-06     |
|    cost_values           | 0.00053      |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0466       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.6         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 1.06         |
|    value_loss            | 103          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.75         |
| reward                   | -1.049155    |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -983         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 549          |
|    total_timesteps       | 251904       |
| train/                   |              |
|    approx_kl             | 0.0013514516 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000304     |
|    cost_value_loss       | 5.15e-06     |
|    cost_values           | 0.00034      |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.61        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 1220         |
|    policy_gradient_loss  | -0.000749    |
|    std                   | 1.06         |
|    value_loss            | 24.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.8053045  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -978        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 571         |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.003915162 |
|    clip_fraction         | 0.0656      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000113    |
|    cost_value_loss       | 2.13e-08    |
|    cost_values           | 0.000101    |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | -0.0149     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 1230        |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 1.07        |
|    value_loss            | 23.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.418        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.418        |
| reward                   | -1.1321657   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -975         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 593          |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0035961955 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000365     |
|    cost_value_loss       | 2.98e-07     |
|    cost_values           | 0.000447     |
|    entropy               | -2.95        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.000531    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 1.06         |
|    value_loss            | 29.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.724       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.724       |
| reward                   | -1.3260628  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -971        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 28          |
|    time_elapsed          | 615         |
|    total_timesteps       | 258048      |
| train/                   |             |
|    approx_kl             | 0.004417063 |
|    clip_fraction         | 0.00869     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000657    |
|    cost_value_loss       | 5.6e-06     |
|    cost_values           | 0.000688    |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.0862      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 1250        |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 1.06        |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.948       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.948       |
| reward                   | -0.44165263 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -977        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 29          |
|    time_elapsed          | 637         |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.005171557 |
|    clip_fraction         | 0.0394      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00106     |
|    cost_value_loss       | 0.000538    |
|    cost_values           | 0.000774    |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.217       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.37        |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.00526    |
|    std                   | 1.06        |
|    value_loss            | 25.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.55         |
| reward                   | -0.34206846  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -986         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 30           |
|    time_elapsed          | 659          |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0007122912 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0098       |
|    cost_value_loss       | 5.23e-06     |
|    cost_values           | 0.0104       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | -0.046       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.5         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.000944    |
|    std                   | 1.06         |
|    value_loss            | 89.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.36        |
| reward                   | -0.30199873 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -988        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 31          |
|    time_elapsed          | 681         |
|    total_timesteps       | 264192      |
| train/                   |             |
|    approx_kl             | 0.002703698 |
|    clip_fraction         | 0.00454     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0077      |
|    cost_value_loss       | 2.4e-05     |
|    cost_values           | 0.00776     |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.0927      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 1280        |
|    policy_gradient_loss  | -0.00144    |
|    std                   | 1.06        |
|    value_loss            | 24.4        |
------------------------------------------
--------------------------------------------
| avg_speed                | 2.44          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.44          |
| reward                   | -0.49811846   |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -991          |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 32            |
|    time_elapsed          | 703           |
|    total_timesteps       | 266240        |
| train/                   |               |
|    approx_kl             | 0.00015806669 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.0128       |
|    cost_value_loss       | 0.00708       |
|    cost_values           | -0.0199       |
|    entropy               | -2.95         |
|    entropy_loss          | -2.95         |
|    explained_variance    | 0.127         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 15.8          |
|    n_updates             | 1290          |
|    policy_gradient_loss  | -0.000329     |
|    std                   | 1.06          |
|    value_loss            | 58.1          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 4.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.51         |
| reward                   | -1.408205    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -979         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 33           |
|    time_elapsed          | 725          |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0039059066 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0154       |
|    cost_value_loss       | 0.00108      |
|    cost_values           | 0.0152       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.31         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 1.06         |
|    value_loss            | 29.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.921        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.921        |
| reward                   | -0.50668097  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -978         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 748          |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0018687972 |
|    clip_fraction         | 0.00186      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.017        |
|    cost_value_loss       | 0.00034      |
|    cost_values           | 0.0163       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.265        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.3         |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 1.06         |
|    value_loss            | 61.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -1.4664563    |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -965          |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 35            |
|    time_elapsed          | 770           |
|    total_timesteps       | 272384        |
| train/                   |               |
|    approx_kl             | 0.00013359875 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.0854       |
|    cost_value_loss       | 0.00292       |
|    cost_values           | -0.112        |
|    entropy               | -2.95         |
|    entropy_loss          | -2.95         |
|    explained_variance    | -14.3         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13.7          |
|    n_updates             | 1320          |
|    policy_gradient_loss  | 0.000306      |
|    std                   | 1.06          |
|    value_loss            | 124           |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.69          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.69          |
| reward                   | -1.745698     |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -964          |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 36            |
|    time_elapsed          | 792           |
|    total_timesteps       | 274432        |
| train/                   |               |
|    approx_kl             | 6.2484556e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.0918       |
|    cost_value_loss       | 0.0016        |
|    cost_values           | -0.103        |
|    entropy               | -2.95         |
|    entropy_loss          | -2.95         |
|    explained_variance    | -2.9          |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.71          |
|    n_updates             | 1330          |
|    policy_gradient_loss  | -0.00018      |
|    std                   | 1.06          |
|    value_loss            | 33.6          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.49          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.49          |
| reward                   | -0.9642329    |
| rollout/                 |               |
|    ep_len_mean           | 958           |
|    ep_rew_mean           | -946          |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 37            |
|    time_elapsed          | 814           |
|    total_timesteps       | 276480        |
| train/                   |               |
|    approx_kl             | 0.00029234544 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.064        |
|    cost_value_loss       | 0.00496       |
|    cost_values           | -0.0753       |
|    entropy               | -2.95         |
|    entropy_loss          | -2.95         |
|    explained_variance    | 0.58          |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 2.63          |
|    n_updates             | 1340          |
|    policy_gradient_loss  | -0.000513     |
|    std                   | 1.06          |
|    value_loss            | 21.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.32         |
| reward                   | -0.53347766  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -950         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 38           |
|    time_elapsed          | 836          |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0006699113 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0268      |
|    cost_value_loss       | 0.000873     |
|    cost_values           | -0.0276      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.41         |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 1.06         |
|    value_loss            | 22.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.2254921    |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -948          |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 39            |
|    time_elapsed          | 858           |
|    total_timesteps       | 280576        |
| train/                   |               |
|    approx_kl             | 0.00021584568 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.0471       |
|    cost_value_loss       | 0.001         |
|    cost_values           | -0.0494       |
|    entropy               | -2.95         |
|    entropy_loss          | -2.95         |
|    explained_variance    | 0.958         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.12          |
|    n_updates             | 1360          |
|    policy_gradient_loss  | -0.000309     |
|    std                   | 1.06          |
|    value_loss            | 8.27          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1093578   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -938         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 880          |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0045164493 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0449       |
|    cost_value_loss       | 0.000692     |
|    cost_values           | 0.0444       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.746        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 1.06         |
|    value_loss            | 25.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.14         |
| reward                   | -1.3015015   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -937         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 902          |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0015982799 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00868     |
|    cost_value_loss       | 0.00065      |
|    cost_values           | -0.00855     |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.946        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 1.06         |
|    value_loss            | 21           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8903964   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -936         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 926          |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0044613136 |
|    clip_fraction         | 0.0533       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0366       |
|    cost_value_loss       | 1.95e-05     |
|    cost_values           | 0.0368       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.000965     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.7         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00472     |
|    std                   | 1.06         |
|    value_loss            | 31.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.03         |
| reward                   | -0.50707644  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -937         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 950          |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0040241103 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0298       |
|    cost_value_loss       | 1.36e-05     |
|    cost_values           | 0.03         |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.00123      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 1.06         |
|    value_loss            | 20.8         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.06          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.06          |
| reward                   | -1.5582651    |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -928          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 44            |
|    time_elapsed          | 973           |
|    total_timesteps       | 290816        |
| train/                   |               |
|    approx_kl             | 0.00063487445 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | -0.0291       |
|    cost_value_loss       | 0.00071       |
|    cost_values           | -0.0333       |
|    entropy               | -2.95         |
|    entropy_loss          | -2.95         |
|    explained_variance    | 0.838         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.64          |
|    n_updates             | 1410          |
|    policy_gradient_loss  | -0.0013       |
|    std                   | 1.06          |
|    value_loss            | 18.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 2.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.7          |
| reward                   | -0.8321981   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -926         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 997          |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0019026736 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0292      |
|    cost_value_loss       | 0.00128      |
|    cost_values           | -0.031       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.8          |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 1.06         |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.849        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.849        |
| reward                   | -1.3664509   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -920         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0029605278 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00329      |
|    cost_value_loss       | 0.000331     |
|    cost_values           | 0.00355      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.903        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.5          |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 1.06         |
|    value_loss            | 21.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.38         |
| reward                   | -0.5474928   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -905         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1044         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0031684365 |
|    clip_fraction         | 0.00366      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0178      |
|    cost_value_loss       | 0.000861     |
|    cost_values           | -0.0176      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.94         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 1.06         |
|    value_loss            | 15.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.81          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.81          |
| reward                   | -0.9250784    |
| rollout/                 |               |
|    ep_len_mean           | 935           |
|    ep_rew_mean           | -902          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 48            |
|    time_elapsed          | 1067          |
|    total_timesteps       | 299008        |
| train/                   |               |
|    approx_kl             | 0.00044056444 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.00525       |
|    cost_value_loss       | 0.000795      |
|    cost_values           | 0.00353       |
|    entropy               | -2.94         |
|    entropy_loss          | -2.94         |
|    explained_variance    | 0.37          |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 58.5          |
|    n_updates             | 1450          |
|    policy_gradient_loss  | -0.000493     |
|    std                   | 1.06          |
|    value_loss            | 139           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.4145504   |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -886         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 49           |
|    time_elapsed          | 1090         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0024700186 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0123      |
|    cost_value_loss       | 0.00108      |
|    cost_values           | -0.0155      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.491        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.3          |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 1.06         |
|    value_loss            | 11.2         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.43       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.43       |
| reward             | -1.3034437 |
| rollout/           |            |
|    ep_len_mean     | 926        |
|    ep_rew_mean     | -887       |
| time/              |            |
|    fps             | 87         |
|    iterations      | 1          |
|    time_elapsed    | 23         |
|    total_timesteps | 303104     |
-----------------------------------
--------------------------------------------
| avg_speed                | 2.69          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.69          |
| reward                   | -1.1988605    |
| rollout/                 |               |
|    ep_len_mean           | 918           |
|    ep_rew_mean           | -874          |
| time/                    |               |
|    fps                   | 87            |
|    iterations            | 2             |
|    time_elapsed          | 46            |
|    total_timesteps       | 305152        |
| train/                   |               |
|    approx_kl             | 0.00050400145 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0152        |
|    cost_value_loss       | 0.00141       |
|    cost_values           | 0.0106        |
|    entropy               | -2.94         |
|    entropy_loss          | -2.94         |
|    explained_variance    | 0.711         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.27          |
|    n_updates             | 1480          |
|    policy_gradient_loss  | -0.000647     |
|    std                   | 1.06          |
|    value_loss            | 39.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.77         |
| reward                   | -1.0033116   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -864         |
| time/                    |              |
|    fps                   | 87           |
|    iterations            | 3            |
|    time_elapsed          | 70           |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0041409098 |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0167       |
|    cost_value_loss       | 0.00177      |
|    cost_values           | 0.0153       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.235        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.6         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 1.06         |
|    value_loss            | 71.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.2089839   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -859         |
| time/                    |              |
|    fps                   | 87           |
|    iterations            | 4            |
|    time_elapsed          | 94           |
|    total_timesteps       | 309248       |
| train/                   |              |
|    approx_kl             | 0.0072331107 |
|    clip_fraction         | 0.0653       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0239       |
|    cost_value_loss       | 0.00118      |
|    cost_values           | 0.0232       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.000522    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.19         |
|    n_updates             | 1500         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 1.07         |
|    value_loss            | 19.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -1.433989    |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -852         |
| time/                    |              |
|    fps                   | 87           |
|    iterations            | 5            |
|    time_elapsed          | 117          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0027938862 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0177      |
|    cost_value_loss       | 0.000952     |
|    cost_values           | -0.0217      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.000733    |
|    std                   | 1.07         |
|    value_loss            | 24.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.33        |
| reward                   | -0.76239216 |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -852        |
| time/                    |             |
|    fps                   | 86          |
|    iterations            | 6           |
|    time_elapsed          | 141         |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.001090569 |
|    clip_fraction         | 9.77e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | -0.023      |
|    cost_value_loss       | 0.00245     |
|    cost_values           | -0.0177     |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 1.07        |
|    value_loss            | 28.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.3482615   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -850         |
| time/                    |              |
|    fps                   | 86           |
|    iterations            | 7            |
|    time_elapsed          | 165          |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0033716161 |
|    clip_fraction         | 0.00552      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0141      |
|    cost_value_loss       | 0.000112     |
|    cost_values           | -0.0191      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.709        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 1.07         |
|    value_loss            | 29.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.19        |
| reward                   | -0.4697243  |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -833        |
| time/                    |             |
|    fps                   | 86          |
|    iterations            | 8           |
|    time_elapsed          | 189         |
|    total_timesteps       | 317440      |
| train/                   |             |
|    approx_kl             | 0.007753095 |
|    clip_fraction         | 0.0456      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00618    |
|    cost_value_loss       | 0.000106    |
|    cost_values           | -0.00603    |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.32        |
|    n_updates             | 1540        |
|    policy_gradient_loss  | -0.00602    |
|    std                   | 1.07        |
|    value_loss            | 16.7        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.06          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.06          |
| reward                   | -0.9925016    |
| rollout/                 |               |
|    ep_len_mean           | 911           |
|    ep_rew_mean           | -819          |
| time/                    |               |
|    fps                   | 86            |
|    iterations            | 9             |
|    time_elapsed          | 213           |
|    total_timesteps       | 319488        |
| train/                   |               |
|    approx_kl             | 0.00045943673 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.00711      |
|    cost_value_loss       | 0.000165      |
|    cost_values           | -0.00664      |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | 0.855         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 18.8          |
|    n_updates             | 1550          |
|    policy_gradient_loss  | -0.000911     |
|    std                   | 1.07          |
|    value_loss            | 43.5          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -0.6911543    |
| rollout/                 |               |
|    ep_len_mean           | 911           |
|    ep_rew_mean           | -808          |
| time/                    |               |
|    fps                   | 86            |
|    iterations            | 10            |
|    time_elapsed          | 236           |
|    total_timesteps       | 321536        |
| train/                   |               |
|    approx_kl             | 0.00045782272 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.00556      |
|    cost_value_loss       | 7.71e-05      |
|    cost_values           | -0.0072       |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | 0.733         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10            |
|    n_updates             | 1560          |
|    policy_gradient_loss  | -0.000445     |
|    std                   | 1.07          |
|    value_loss            | 23.4          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 6.75          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.75          |
| reward                   | -0.7119331    |
| rollout/                 |               |
|    ep_len_mean           | 911           |
|    ep_rew_mean           | -806          |
| time/                    |               |
|    fps                   | 86            |
|    iterations            | 11            |
|    time_elapsed          | 260           |
|    total_timesteps       | 323584        |
| train/                   |               |
|    approx_kl             | 0.00032541272 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0013        |
|    cost_value_loss       | 0.000257      |
|    cost_values           | 0.000581      |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | 0.562         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 20.6          |
|    n_updates             | 1570          |
|    policy_gradient_loss  | -0.000622     |
|    std                   | 1.07          |
|    value_loss            | 52.9          |
--------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.84298456 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -794        |
| time/                    |             |
|    fps                   | 86          |
|    iterations            | 12          |
|    time_elapsed          | 283         |
|    total_timesteps       | 325632      |
| train/                   |             |
|    approx_kl             | 0.004146453 |
|    clip_fraction         | 0.0251      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00862    |
|    cost_value_loss       | 1.27e-06    |
|    cost_values           | -0.00885    |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | -0.00789    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.4        |
|    n_updates             | 1580        |
|    policy_gradient_loss  | -0.004      |
|    std                   | 1.07        |
|    value_loss            | 46.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.43         |
| reward                   | -0.5574996   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -795         |
| time/                    |              |
|    fps                   | 86           |
|    iterations            | 13           |
|    time_elapsed          | 307          |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0009038318 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0139       |
|    cost_value_loss       | 0.000418     |
|    cost_values           | 0.0136       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.84         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.1         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 1.07         |
|    value_loss            | 38.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.332399    |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 86           |
|    iterations            | 14           |
|    time_elapsed          | 331          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0031313705 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34e-05     |
|    cost_value_loss       | 0.000159     |
|    cost_values           | -0.000339    |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.698        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.5         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 1.07         |
|    value_loss            | 94.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.25        |
| reward                   | -1.9087527  |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -790        |
| time/                    |             |
|    fps                   | 86          |
|    iterations            | 15          |
|    time_elapsed          | 353         |
|    total_timesteps       | 331776      |
| train/                   |             |
|    approx_kl             | 0.004039347 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0054      |
|    cost_value_loss       | 0.000357    |
|    cost_values           | 0.00785     |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.7        |
|    n_updates             | 1610        |
|    policy_gradient_loss  | -0.00339    |
|    std                   | 1.07        |
|    value_loss            | 35.8        |
------------------------------------------
--------------------------------------------
| avg_speed                | 6.69          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.69          |
| reward                   | -1.744789     |
| rollout/                 |               |
|    ep_len_mean           | 890           |
|    ep_rew_mean           | -786          |
| time/                    |               |
|    fps                   | 87            |
|    iterations            | 16            |
|    time_elapsed          | 375           |
|    total_timesteps       | 333824        |
| train/                   |               |
|    approx_kl             | 0.00010480848 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0355        |
|    cost_value_loss       | 0.00141       |
|    cost_values           | 0.0431        |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | 0.789         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 53.6          |
|    n_updates             | 1620          |
|    policy_gradient_loss  | -0.0001       |
|    std                   | 1.07          |
|    value_loss            | 194           |
--------------------------------------------
---------------------------------------------
| avg_speed                | 4.02           |
| cost                     | 0              |
| is_success               | 0              |
| max_speed                | 4.02           |
| reward                   | -0.5760631     |
| rollout/                 |                |
|    ep_len_mean           | 890            |
|    ep_rew_mean           | -796           |
| time/                    |                |
|    fps                   | 87             |
|    iterations            | 17             |
|    time_elapsed          | 397            |
|    total_timesteps       | 335872         |
| train/                   |                |
|    approx_kl             | 0.000109432585 |
|    clip_fraction         | 0              |
|    clip_range            | 0.2            |
|    cost_returns          | 0.0621         |
|    cost_value_loss       | 0.00102        |
|    cost_values           | 0.069          |
|    entropy               | -2.97          |
|    entropy_loss          | -2.97          |
|    explained_variance    | 0.904          |
|    lagrangian_multiplier | 0              |
|    learning_rate         | 0.0003         |
|    loss                  | 31.7           |
|    n_updates             | 1630           |
|    policy_gradient_loss  | -0.000282      |
|    std                   | 1.07           |
|    value_loss            | 85.3           |
---------------------------------------------
--------------------------------------------
| avg_speed                | 5.63          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.63          |
| reward                   | -1.1265452    |
| rollout/                 |               |
|    ep_len_mean           | 890           |
|    ep_rew_mean           | -787          |
| time/                    |               |
|    fps                   | 87            |
|    iterations            | 18            |
|    time_elapsed          | 420           |
|    total_timesteps       | 337920        |
| train/                   |               |
|    approx_kl             | 0.00041187098 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0411        |
|    cost_value_loss       | 0.00105       |
|    cost_values           | 0.0376        |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | 0.906         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 72.2          |
|    n_updates             | 1640          |
|    policy_gradient_loss  | -0.000738     |
|    std                   | 1.07          |
|    value_loss            | 169           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 6.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.26         |
| reward                   | -1.5680454   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -790         |
| time/                    |              |
|    fps                   | 87           |
|    iterations            | 19           |
|    time_elapsed          | 442          |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0008057612 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0992       |
|    cost_value_loss       | 0.00351      |
|    cost_values           | 0.08         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.558        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.02         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 1.07         |
|    value_loss            | 21.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.94          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.94          |
| reward                   | -2.9698308    |
| rollout/                 |               |
|    ep_len_mean           | 890           |
|    ep_rew_mean           | -792          |
| time/                    |               |
|    fps                   | 88            |
|    iterations            | 20            |
|    time_elapsed          | 464           |
|    total_timesteps       | 342016        |
| train/                   |               |
|    approx_kl             | 0.00041839015 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0648        |
|    cost_value_loss       | 0.00322       |
|    cost_values           | 0.0422        |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | -0.00168      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.82          |
|    n_updates             | 1660          |
|    policy_gradient_loss  | -0.00089      |
|    std                   | 1.07          |
|    value_loss            | 47.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.97         |
| reward                   | -0.4662149   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 88           |
|    iterations            | 21           |
|    time_elapsed          | 486          |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0005495052 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0206       |
|    cost_value_loss       | 0.0014       |
|    cost_values           | 0.0196       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.834        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 87.7         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.000599    |
|    std                   | 1.07         |
|    value_loss            | 209          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 2.65          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.65          |
| reward                   | -0.40608892   |
| rollout/                 |               |
|    ep_len_mean           | 890           |
|    ep_rew_mean           | -807          |
| time/                    |               |
|    fps                   | 88            |
|    iterations            | 22            |
|    time_elapsed          | 508           |
|    total_timesteps       | 346112        |
| train/                   |               |
|    approx_kl             | 0.00037922812 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0071        |
|    cost_value_loss       | 0.0016        |
|    cost_values           | 0.00355       |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | 0.909         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 15.2          |
|    n_updates             | 1680          |
|    policy_gradient_loss  | -0.000565     |
|    std                   | 1.07          |
|    value_loss            | 67.4          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 1.42          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.42          |
| reward                   | -0.7567816    |
| rollout/                 |               |
|    ep_len_mean           | 867           |
|    ep_rew_mean           | -775          |
| time/                    |               |
|    fps                   | 88            |
|    iterations            | 23            |
|    time_elapsed          | 530           |
|    total_timesteps       | 348160        |
| train/                   |               |
|    approx_kl             | 0.00067899167 |
|    clip_fraction         | 9.77e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 0.00496       |
|    cost_value_loss       | 0.00203       |
|    cost_values           | 0.00485       |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | 0.902         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.65          |
|    n_updates             | 1690          |
|    policy_gradient_loss  | -0.00114      |
|    std                   | 1.07          |
|    value_loss            | 21.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -2.146675    |
| rollout/                 |              |
|    ep_len_mean           | 867          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 88           |
|    iterations            | 24           |
|    time_elapsed          | 552          |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0014603211 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0173       |
|    cost_value_loss       | 0.00261      |
|    cost_values           | 0.0195       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.8         |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 1.07         |
|    value_loss            | 73           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.3212167   |
| rollout/                 |              |
|    ep_len_mean           | 867          |
|    ep_rew_mean           | -781         |
| time/                    |              |
|    fps                   | 89           |
|    iterations            | 25           |
|    time_elapsed          | 574          |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0012484011 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0184       |
|    cost_value_loss       | 0.00214      |
|    cost_values           | 0.0127       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.7         |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 1.07         |
|    value_loss            | 44.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.73         |
| reward                   | -1.1465712   |
| rollout/                 |              |
|    ep_len_mean           | 875          |
|    ep_rew_mean           | -785         |
| time/                    |              |
|    fps                   | 89           |
|    iterations            | 26           |
|    time_elapsed          | 597          |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0011516515 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0184       |
|    cost_value_loss       | 9.44e-06     |
|    cost_values           | 0.0204       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.000454     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 77           |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.000696    |
|    std                   | 1.07         |
|    value_loss            | 161          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.35        |
| reward                   | -0.99632293 |
| rollout/                 |             |
|    ep_len_mean           | 875         |
|    ep_rew_mean           | -777        |
| time/                    |             |
|    fps                   | 89          |
|    iterations            | 27          |
|    time_elapsed          | 619         |
|    total_timesteps       | 356352      |
| train/                   |             |
|    approx_kl             | 0.006054941 |
|    clip_fraction         | 0.0465      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0148      |
|    cost_value_loss       | 3.72e-06    |
|    cost_values           | 0.0152      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.000409    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.5        |
|    n_updates             | 1730        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 1.07        |
|    value_loss            | 34.3        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.72       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.72       |
| reward                   | -1.2929375 |
| rollout/                 |            |
|    ep_len_mean           | 875        |
|    ep_rew_mean           | -774       |
| time/                    |            |
|    fps                   | 89         |
|    iterations            | 28         |
|    time_elapsed          | 641        |
|    total_timesteps       | 358400     |
| train/                   |            |
|    approx_kl             | 0.00535799 |
|    clip_fraction         | 0.0218     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0124     |
|    cost_value_loss       | 3.43e-06   |
|    cost_values           | 0.0132     |
|    entropy               | -2.97      |
|    entropy_loss          | -2.97      |
|    explained_variance    | -0.000764  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 10.5       |
|    n_updates             | 1740       |
|    policy_gradient_loss  | -0.00314   |
|    std                   | 1.07       |
|    value_loss            | 27         |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.07         |
| reward                   | -0.843126    |
| rollout/                 |              |
|    ep_len_mean           | 883          |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 89           |
|    iterations            | 29           |
|    time_elapsed          | 663          |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0052566314 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0101       |
|    cost_value_loss       | 0.000211     |
|    cost_values           | 0.011        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.871        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 1.07         |
|    value_loss            | 27.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.2759684  |
| rollout/                 |             |
|    ep_len_mean           | 883         |
|    ep_rew_mean           | -779        |
| time/                    |             |
|    fps                   | 89          |
|    iterations            | 30          |
|    time_elapsed          | 685         |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.004028722 |
|    clip_fraction         | 0.0102      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0237      |
|    cost_value_loss       | 0.00114     |
|    cost_values           | 0.0237      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.4        |
|    n_updates             | 1760        |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 1.07        |
|    value_loss            | 35          |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.53         |
| reward                   | -1.0231885   |
| rollout/                 |              |
|    ep_len_mean           | 883          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 89           |
|    iterations            | 31           |
|    time_elapsed          | 707          |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0012313433 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0522       |
|    cost_value_loss       | 0.00252      |
|    cost_values           | 0.0385       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.46         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 1.07         |
|    value_loss            | 43.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 2.38          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.38          |
| reward                   | -1.2274488    |
| rollout/                 |               |
|    ep_len_mean           | 890           |
|    ep_rew_mean           | -794          |
| time/                    |               |
|    fps                   | 89            |
|    iterations            | 32            |
|    time_elapsed          | 729           |
|    total_timesteps       | 366592        |
| train/                   |               |
|    approx_kl             | 0.00042344176 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0412        |
|    cost_value_loss       | 0.00344       |
|    cost_values           | 0.0265        |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | 0.68          |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.59          |
|    n_updates             | 1780          |
|    policy_gradient_loss  | -0.000138     |
|    std                   | 1.07          |
|    value_loss            | 78.9          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.3         |
| reward                   | -1.0053515  |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -802        |
| time/                    |             |
|    fps                   | 89          |
|    iterations            | 33          |
|    time_elapsed          | 751         |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.008250774 |
|    clip_fraction         | 0.0917      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0233      |
|    cost_value_loss       | 1.1e-05     |
|    cost_values           | 0.0242      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | -0.00365    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.55        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.00863    |
|    std                   | 1.07        |
|    value_loss            | 21.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.28         |
| reward                   | -1.0670108   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -797         |
| time/                    |              |
|    fps                   | 89           |
|    iterations            | 34           |
|    time_elapsed          | 774          |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0011679359 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00963      |
|    cost_value_loss       | 0.00167      |
|    cost_values           | 0.00833      |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.742        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.51         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.000454    |
|    std                   | 1.07         |
|    value_loss            | 32           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.25         |
| reward                   | -0.5376537   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 35           |
|    time_elapsed          | 796          |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0044398066 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0192       |
|    cost_value_loss       | 6.91e-06     |
|    cost_values           | 0.0199       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -8.81e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.00467     |
|    std                   | 1.06         |
|    value_loss            | 26.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.35         |
| reward                   | -0.3653075   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 36           |
|    time_elapsed          | 818          |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0018435173 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00491      |
|    cost_value_loss       | 0.00112      |
|    cost_values           | 0.00554      |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.682        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.000792    |
|    std                   | 1.06         |
|    value_loss            | 17.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0264      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0264      |
| reward                   | -0.40003398 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -805        |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 840         |
|    total_timesteps       | 376832      |
| train/                   |             |
|    approx_kl             | 0.005488894 |
|    clip_fraction         | 0.0483      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0149      |
|    cost_value_loss       | 3.39e-06    |
|    cost_values           | 0.0151      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 9.24e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 1830        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 1.07        |
|    value_loss            | 21.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.484        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.484        |
| reward                   | -0.62230414  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -809         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 38           |
|    time_elapsed          | 862          |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0031743946 |
|    clip_fraction         | 0.0523       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00434      |
|    cost_value_loss       | 0.000712     |
|    cost_values           | 0.0067       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.249        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.14         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.000997    |
|    std                   | 1.07         |
|    value_loss            | 27.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.93        |
| reward                   | -0.38201287 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -813        |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 884         |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.001151319 |
|    clip_fraction         | 0.000439    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0129      |
|    cost_value_loss       | 0.00111     |
|    cost_values           | 0.00976     |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.296       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 1850        |
|    policy_gradient_loss  | -0.000832   |
|    std                   | 1.07        |
|    value_loss            | 25.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.17         |
| reward                   | -0.78063685  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 40           |
|    time_elapsed          | 906          |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0005484483 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0222       |
|    cost_value_loss       | 0.0015       |
|    cost_values           | 0.0169       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.55         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.17         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.000233    |
|    std                   | 1.07         |
|    value_loss            | 38.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.39        |
| reward                   | -0.45154563 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -821        |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 929         |
|    total_timesteps       | 385024      |
| train/                   |             |
|    approx_kl             | 0.004432831 |
|    clip_fraction         | 0.00874     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0154      |
|    cost_value_loss       | 0.000836    |
|    cost_values           | 0.0176      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 1870        |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 1.07        |
|    value_loss            | 48.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.43         |
| reward                   | -0.6112141   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -833         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 42           |
|    time_elapsed          | 950          |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0033365588 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00494      |
|    cost_value_loss       | 0.000602     |
|    cost_values           | 0.00646      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.802        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.2         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00353     |
|    std                   | 1.07         |
|    value_loss            | 75.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.02         |
| reward                   | -0.6345382   |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -854         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 43           |
|    time_elapsed          | 972          |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0043900385 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00789      |
|    cost_value_loss       | 0.000577     |
|    cost_values           | 0.00854      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.689        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.1         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 1.07         |
|    value_loss            | 107          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.67         |
| reward                   | -0.85686654  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -858         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 44           |
|    time_elapsed          | 995          |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0008482005 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0101       |
|    cost_value_loss       | 0.000888     |
|    cost_values           | 0.0108       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.000768    |
|    std                   | 1.07         |
|    value_loss            | 71.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.6641756   |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -868         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 45           |
|    time_elapsed          | 1017         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0030666967 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00766      |
|    cost_value_loss       | 0.00123      |
|    cost_values           | 0.00771      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.825        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 1.07         |
|    value_loss            | 45.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.54         |
| reward                   | -0.74867415  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -877         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 46           |
|    time_elapsed          | 1039         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0006146905 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00907      |
|    cost_value_loss       | 0.000925     |
|    cost_values           | 0.00975      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.753        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 67.5         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.000982    |
|    std                   | 1.07         |
|    value_loss            | 147          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.7          |
| reward                   | -0.4294179   |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -878         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 47           |
|    time_elapsed          | 1061         |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0020614702 |
|    clip_fraction         | 0.0041       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00598      |
|    cost_value_loss       | 0.00183      |
|    cost_values           | 0.0067       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45           |
|    n_updates             | 1930         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 1.07         |
|    value_loss            | 91.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2836257   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -882         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 48           |
|    time_elapsed          | 1083         |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0035939738 |
|    clip_fraction         | 0.00605      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0117       |
|    cost_value_loss       | 0.00199      |
|    cost_values           | 0.0113       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.924        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 1940         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 1.07         |
|    value_loss            | 29.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.22         |
| reward                   | -0.92534065  |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -881         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 49           |
|    time_elapsed          | 1106         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0057412814 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00513      |
|    cost_value_loss       | 0.000468     |
|    cost_values           | 0.00535      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.904        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.92         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 1.07         |
|    value_loss            | 20.8         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.109      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.109      |
| reward             | -0.3204575 |
| rollout/           |            |
|    ep_len_mean     | 917        |
|    ep_rew_mean     | -848       |
| time/              |            |
|    fps             | 95         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 403456     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.272        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.272        |
| reward                   | -0.46996668  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -848         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0020308031 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00732      |
|    cost_value_loss       | 9.08e-05     |
|    cost_values           | 0.00898      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.536        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.4         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 1.07         |
|    value_loss            | 131          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.93         |
| reward                   | -0.59237623  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -845         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 8.295325e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.016        |
|    cost_value_loss       | 0.00186      |
|    cost_values           | 0.00924      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.487        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.78         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -8.12e-05    |
|    std                   | 1.07         |
|    value_loss            | 44.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.32         |
| reward                   | -1.0314844   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -851         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0005054231 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00871      |
|    cost_value_loss       | 0.000921     |
|    cost_values           | 0.00949      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.619        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.1          |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.000324    |
|    std                   | 1.07         |
|    value_loss            | 30.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.29         |
| reward                   | -0.39933884  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -859         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0033389868 |
|    clip_fraction         | 0.00713      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0122       |
|    cost_value_loss       | 0.00014      |
|    cost_values           | 0.0123       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.39         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 1.07         |
|    value_loss            | 18.2         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 2.54       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.54       |
| reward                   | -0.5617522 |
| rollout/                 |            |
|    ep_len_mean           | 915        |
|    ep_rew_mean           | -845       |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 6          |
|    time_elapsed          | 131        |
|    total_timesteps       | 413696     |
| train/                   |            |
|    approx_kl             | 0.00425971 |
|    clip_fraction         | 0.00898    |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00399    |
|    cost_value_loss       | 0.000403   |
|    cost_values           | 0.00838    |
|    entropy               | -2.97      |
|    entropy_loss          | -2.97      |
|    explained_variance    | 0.762      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 10.9       |
|    n_updates             | 2010       |
|    policy_gradient_loss  | -0.002     |
|    std                   | 1.07       |
|    value_loss            | 42.4       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 6.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.67         |
| reward                   | -0.5938486   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -849         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 153          |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0024151576 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000888     |
|    cost_value_loss       | 0.0001       |
|    cost_values           | 0.00111      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.868        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 1.07         |
|    value_loss            | 30.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.1393489   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -856         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0013418326 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0152       |
|    cost_value_loss       | 0.000807     |
|    cost_values           | 0.0166       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.838        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.17         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.000983    |
|    std                   | 1.07         |
|    value_loss            | 23.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.74        |
| reward                   | -0.3546113  |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -857        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.009858859 |
|    clip_fraction         | 0.0746      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0173      |
|    cost_value_loss       | 0.000898    |
|    cost_values           | 0.0195      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00914    |
|    std                   | 1.07        |
|    value_loss            | 25.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.32        |
| reward                   | -0.22287722 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -864        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 220         |
|    total_timesteps       | 421888      |
| train/                   |             |
|    approx_kl             | 0.007289449 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000233    |
|    cost_value_loss       | 0.000225    |
|    cost_values           | -0.000234   |
|    entropy               | -2.98       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.614       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.8        |
|    n_updates             | 2050        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 1.07        |
|    value_loss            | 57.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.5          |
| reward                   | -0.6701822   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -862         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0006286781 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0208       |
|    cost_value_loss       | 0.000768     |
|    cost_values           | 0.0184       |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.000524    |
|    std                   | 1.07         |
|    value_loss            | 43.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.15        |
| reward                   | -0.4119888  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -863        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.004151486 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0136      |
|    cost_value_loss       | 0.000412    |
|    cost_values           | 0.0154      |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 64.1        |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.00472    |
|    std                   | 1.08        |
|    value_loss            | 118         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.41         |
| reward                   | -1.7156506   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -868         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0035929605 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00968      |
|    cost_value_loss       | 0.000388     |
|    cost_values           | 0.00904      |
|    entropy               | -2.99        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 1.08         |
|    value_loss            | 25.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.1         |
| reward                   | -0.8435939  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -864        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 308         |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.002826111 |
|    clip_fraction         | 0.0022      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00553     |
|    cost_value_loss       | 0.000463    |
|    cost_values           | 0.00562     |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 1.08        |
|    value_loss            | 35.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.75         |
| reward                   | -1.2287744   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -862         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 330          |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0055633863 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00502      |
|    cost_value_loss       | 0.000385     |
|    cost_values           | 0.00362      |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.5         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 1.08         |
|    value_loss            | 83.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.35        |
| reward                   | -0.46340662 |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -846        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 353         |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.007073247 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00562     |
|    cost_value_loss       | 0.000375    |
|    cost_values           | 0.00762     |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 1.08        |
|    value_loss            | 29.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.7549102  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -837        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 375         |
|    total_timesteps       | 436224      |
| train/                   |             |
|    approx_kl             | 0.008663259 |
|    clip_fraction         | 0.0407      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0143      |
|    cost_value_loss       | 0.00055     |
|    cost_values           | 0.014       |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.75        |
|    n_updates             | 2120        |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 1.08        |
|    value_loss            | 17.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.72         |
| reward                   | -0.52289134  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 397          |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0018372475 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00526     |
|    cost_value_loss       | 0.000405     |
|    cost_values           | -0.00622     |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.537        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.1         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 1.08         |
|    value_loss            | 61.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.9         |
| reward                   | -0.26634142 |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -828        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 419         |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.006079398 |
|    clip_fraction         | 0.0667      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00263     |
|    cost_value_loss       | 0.000109    |
|    cost_values           | 0.00279     |
|    entropy               | -3.01       |
|    entropy_loss          | -3          |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.46        |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -0.00541    |
|    std                   | 1.09        |
|    value_loss            | 17.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.346        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.346        |
| reward                   | -0.5254064   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 441          |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0042145588 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000204    |
|    cost_value_loss       | 0.00108      |
|    cost_values           | 0.000148     |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.955        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.29         |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 1.09         |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.463        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.463        |
| reward                   | -0.3184805   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 463          |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0037354166 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0109       |
|    cost_value_loss       | 0.000486     |
|    cost_values           | 0.00612      |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.741        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.5         |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 1.09         |
|    value_loss            | 58.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.47        |
| reward                   | -0.5358483  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -821        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 486         |
|    total_timesteps       | 446464      |
| train/                   |             |
|    approx_kl             | 0.006871699 |
|    clip_fraction         | 0.0411      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0112      |
|    cost_value_loss       | 2.36e-06    |
|    cost_values           | 0.0109      |
|    entropy               | -3.01       |
|    entropy_loss          | -3          |
|    explained_variance    | -0.00086    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 2170        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 1.09        |
|    value_loss            | 28.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.45        |
| reward                   | -0.4868273  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -813        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 507         |
|    total_timesteps       | 448512      |
| train/                   |             |
|    approx_kl             | 0.006212486 |
|    clip_fraction         | 0.0447      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00926     |
|    cost_value_loss       | 1.32e-06    |
|    cost_values           | 0.0094      |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | -0.0017     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.79        |
|    n_updates             | 2180        |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 1.09        |
|    value_loss            | 24.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.99        |
| reward                   | -0.96153736 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -811        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 529         |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.005870723 |
|    clip_fraction         | 0.0303      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00447     |
|    cost_value_loss       | 0.000714    |
|    cost_values           | 0.00375     |
|    entropy               | -3          |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.731       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00353    |
|    std                   | 1.09        |
|    value_loss            | 42.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.24        |
| reward                   | -0.6572968  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -797        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 552         |
|    total_timesteps       | 452608      |
| train/                   |             |
|    approx_kl             | 0.006447208 |
|    clip_fraction         | 0.0674      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0108      |
|    cost_value_loss       | 3.34e-05    |
|    cost_values           | 0.0109      |
|    entropy               | -2.99       |
|    entropy_loss          | -3          |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.3         |
|    n_updates             | 2200        |
|    policy_gradient_loss  | -0.00631    |
|    std                   | 1.08        |
|    value_loss            | 20.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.54527074  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -795         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 574          |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0074211624 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00302      |
|    cost_value_loss       | 0.000386     |
|    cost_values           | 0.00102      |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.88         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.41         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 1.08         |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.42         |
| reward                   | -0.79718494  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 596          |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0028957818 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00548      |
|    cost_value_loss       | 0.000302     |
|    cost_values           | 0.0061       |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.32         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 1.08         |
|    value_loss            | 19           |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.11        |
| reward                   | -0.497214   |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -783        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 618         |
|    total_timesteps       | 458752      |
| train/                   |             |
|    approx_kl             | 0.005084023 |
|    clip_fraction         | 0.0391      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0143      |
|    cost_value_loss       | 3.6e-06     |
|    cost_values           | 0.014       |
|    entropy               | -2.97       |
|    entropy_loss          | -2.98       |
|    explained_variance    | -0.00498    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.8         |
|    n_updates             | 2230        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 1.07        |
|    value_loss            | 21.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.81         |
| reward                   | -0.7828037   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 640          |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0048840647 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00542      |
|    cost_value_loss       | 0.000336     |
|    cost_values           | 0.00659      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.931        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.003       |
|    std                   | 1.07         |
|    value_loss            | 13.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.452       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.452       |
| reward                   | -0.5157764  |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -772        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 662         |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.004578318 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0147      |
|    cost_value_loss       | 0.000569    |
|    cost_values           | 0.00939     |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | -0.0302     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18          |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 1.07        |
|    value_loss            | 51.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.37955472  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 684          |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0033738487 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0139       |
|    cost_value_loss       | 0.000243     |
|    cost_values           | 0.0141       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.86         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 1.06         |
|    value_loss            | 21.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.95         |
| reward                   | -1.4054978   |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 707          |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0023992425 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00471      |
|    cost_value_loss       | 0.000402     |
|    cost_values           | 0.00497      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.376        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.5         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 1.06         |
|    value_loss            | 48.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.21         |
| reward                   | -0.36656803  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 729          |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0070493007 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0145       |
|    cost_value_loss       | 2.07e-05     |
|    cost_values           | 0.0146       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.83         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -0.00637     |
|    std                   | 1.06         |
|    value_loss            | 23.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.62        |
| reward                   | -0.63926643 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -747        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 751         |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.005605062 |
|    clip_fraction         | 0.0377      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00352     |
|    cost_value_loss       | 0.000215    |
|    cost_values           | 0.00348     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.000402   |
|    std                   | 1.06        |
|    value_loss            | 6.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.38         |
| reward                   | -0.24344052  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 773          |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0060602315 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0013       |
|    cost_value_loss       | 0.000256     |
|    cost_values           | 0.00135      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.755        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.09         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 1.05         |
|    value_loss            | 5.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.03         |
| reward                   | -0.83062464  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 795          |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0042326367 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0112       |
|    cost_value_loss       | 3.13e-05     |
|    cost_values           | 0.0114       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.601        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.3         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 1.05         |
|    value_loss            | 109          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.388        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.388        |
| reward                   | -0.40290895  |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 817          |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0050802026 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00347      |
|    cost_value_loss       | 0.000212     |
|    cost_values           | 0.00326      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 1.06         |
|    value_loss            | 8.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.765        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.765        |
| reward                   | -0.30283514  |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 839          |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0051239394 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00951      |
|    cost_value_loss       | 4.68e-05     |
|    cost_values           | 0.0102       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.725        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.7         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1.06         |
|    value_loss            | 45.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.78         |
| reward                   | -0.41127238  |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 861          |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0062667853 |
|    clip_fraction         | 0.0603       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00742      |
|    cost_value_loss       | 8.95e-07     |
|    cost_values           | 0.00751      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | -3.6e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 2340         |
|    policy_gradient_loss  | -0.00494     |
|    std                   | 1.06         |
|    value_loss            | 33.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0932       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0932       |
| reward                   | -0.40958697  |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 883          |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0037944121 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00644      |
|    cost_value_loss       | 0.000202     |
|    cost_values           | 0.00685      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.48         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 1.06         |
|    value_loss            | 25.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.94         |
| reward                   | -0.9150009   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 905          |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0022962105 |
|    clip_fraction         | 0.00234      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0158       |
|    cost_value_loss       | 0.000448     |
|    cost_values           | 0.0145       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.904        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.35         |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 1.06         |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.95         |
| reward                   | -0.39364365  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -655         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 927          |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0020009214 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0141       |
|    cost_value_loss       | 0.000178     |
|    cost_values           | 0.015        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.4         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 1.06         |
|    value_loss            | 70.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.1          |
| reward                   | -0.46016753  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -649         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 950          |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0018147682 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0151       |
|    cost_value_loss       | 0.000491     |
|    cost_values           | 0.0134       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.77         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 1.06         |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.74         |
| reward                   | -0.5575273   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -647         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 972          |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0033545014 |
|    clip_fraction         | 0.00488      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0191       |
|    cost_value_loss       | 9.57e-05     |
|    cost_values           | 0.0191       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.35         |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 1.05         |
|    value_loss            | 21.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.36        |
| reward                   | -0.49670422 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -653        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 994         |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.00582835  |
|    clip_fraction         | 0.0581      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00945     |
|    cost_value_loss       | 1.33e-06    |
|    cost_values           | 0.0095      |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | -0.000376   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.23        |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.00542    |
|    std                   | 1.05        |
|    value_loss            | 11.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.96         |
| reward                   | -0.7147178   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1016         |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0035336637 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0201       |
|    cost_value_loss       | 0.000197     |
|    cost_values           | 0.0198       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.809        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.6         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 1.06         |
|    value_loss            | 35.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.17        |
| reward                   | -0.38366646 |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -652        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1038        |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.005979774 |
|    clip_fraction         | 0.0613      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0088      |
|    cost_value_loss       | 0.000132    |
|    cost_values           | 0.00892     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.74        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00564    |
|    std                   | 1.06        |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.76        |
| reward                   | -0.3488901  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -644        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1060        |
|    total_timesteps       | 499712      |
| train/                   |             |
|    approx_kl             | 0.004010004 |
|    clip_fraction         | 0.0179      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.01        |
|    cost_value_loss       | 3.71e-05    |
|    cost_values           | 0.0101      |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.93        |
|    n_updates             | 2430        |
|    policy_gradient_loss  | -0.003      |
|    std                   | 1.06        |
|    value_loss            | 6.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.41         |
| reward                   | -0.62109107  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -630         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1082         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0055524893 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00714      |
|    cost_value_loss       | 0.00011      |
|    cost_values           | 0.00708      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 1.06         |
|    value_loss            | 9.34         |
-------------------------------------------
------------------------------------
| avg_speed          | 7.98        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.98        |
| reward             | -0.90948445 |
| rollout/           |             |
|    ep_len_mean     | 908         |
|    ep_rew_mean     | -624        |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 2.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.24         |
| reward                   | -0.27091157  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -622         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0060654837 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00852      |
|    cost_value_loss       | 0.000276     |
|    cost_values           | 0.00918      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.0041      |
|    std                   | 1.06         |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.3          |
| reward                   | -0.4431627   |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -608         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0038848596 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00992      |
|    cost_value_loss       | 7.68e-05     |
|    cost_values           | 0.00944      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.789        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.5         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 1.06         |
|    value_loss            | 46.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.01         |
| reward                   | -0.5385183   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -592         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0047852276 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00756      |
|    cost_value_loss       | 4.27e-05     |
|    cost_values           | 0.00741      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.82         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 1.06         |
|    value_loss            | 12.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.849       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.849       |
| reward                   | -0.480167   |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -588        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.006209324 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00853     |
|    cost_value_loss       | 6.72e-05    |
|    cost_values           | 0.00816     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.08        |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 1.05        |
|    value_loss            | 16          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.667       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.667       |
| reward                   | -0.5833733  |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -581        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.009730939 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00438     |
|    cost_value_loss       | 3.09e-05    |
|    cost_values           | 0.00408     |
|    entropy               | -2.95       |
|    entropy_loss          | -2.94       |
|    explained_variance    | -0.000562   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.08        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.00704    |
|    std                   | 1.06        |
|    value_loss            | 16.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.92        |
| reward                   | -0.31210494 |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -577        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.004181434 |
|    clip_fraction         | 0.0365      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00183     |
|    cost_value_loss       | 2.47e-05    |
|    cost_values           | 0.00122     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.7         |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 1.06        |
|    value_loss            | 19.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.7          |
| reward                   | -0.4330236   |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -567         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 177          |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0022583664 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00358      |
|    cost_value_loss       | 4.97e-05     |
|    cost_values           | 0.00378      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.863        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.53         |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 1.05         |
|    value_loss            | 19.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.53         |
| reward                   | -0.35272712  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -564         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 199          |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0016859695 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00325      |
|    cost_value_loss       | 5.46e-05     |
|    cost_values           | 0.00332      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.96         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 1.05         |
|    value_loss            | 6.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.04        |
| reward                   | -0.51636344 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -567        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.005344826 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000696    |
|    cost_value_loss       | 1.08e-05    |
|    cost_values           | 0.000666    |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.768       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 1.05        |
|    value_loss            | 36.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.58        |
| reward                   | -0.7056481  |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -571        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.000888544 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00158     |
|    cost_value_loss       | 7.49e-05    |
|    cost_values           | 0.00218     |
|    entropy               | -2.93       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.53        |
|    n_updates             | 2550        |
|    policy_gradient_loss  | -0.000931   |
|    std                   | 1.05        |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.69        |
| reward                   | -0.369075   |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -561        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 526336      |
| train/                   |             |
|    approx_kl             | 0.006935618 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00074    |
|    cost_value_loss       | 2.89e-05    |
|    cost_values           | -0.000898   |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.73        |
|    n_updates             | 2560        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 1.05        |
|    value_loss            | 22.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.229        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.229        |
| reward                   | -0.6550922   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 287          |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0010601236 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00694      |
|    cost_value_loss       | 0.000121     |
|    cost_values           | 0.00811      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.757        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 1.05         |
|    value_loss            | 15.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.72         |
| reward                   | -0.4412561   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 309          |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0017269568 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00569     |
|    cost_value_loss       | 3.24e-05     |
|    cost_values           | -0.00573     |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.812        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 1.06         |
|    value_loss            | 44.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.46        |
| reward                   | -1.1771823  |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -548        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 331         |
|    total_timesteps       | 532480      |
| train/                   |             |
|    approx_kl             | 0.006785026 |
|    clip_fraction         | 0.0355      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00492    |
|    cost_value_loss       | 4.5e-05     |
|    cost_values           | -0.00493    |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.33        |
|    n_updates             | 2590        |
|    policy_gradient_loss  | -0.00517    |
|    std                   | 1.06        |
|    value_loss            | 16          |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.29       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.29       |
| reward                   | -0.6156136 |
| rollout/                 |            |
|    ep_len_mean           | 897        |
|    ep_rew_mean           | -550       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 16         |
|    time_elapsed          | 353        |
|    total_timesteps       | 534528     |
| train/                   |            |
|    approx_kl             | 0.00315296 |
|    clip_fraction         | 0.00376    |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00267    |
|    cost_value_loss       | 7.76e-05   |
|    cost_values           | 0.00245    |
|    entropy               | -2.94      |
|    entropy_loss          | -2.94      |
|    explained_variance    | 0.915      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.34       |
|    n_updates             | 2600       |
|    policy_gradient_loss  | -0.00207   |
|    std                   | 1.05       |
|    value_loss            | 6.83       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 6.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.57         |
| reward                   | -0.7579027   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -542         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 375          |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0027343829 |
|    clip_fraction         | 0.00576      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00386      |
|    cost_value_loss       | 6.8e-05      |
|    cost_values           | 0.00222      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.878        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.91         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 1.05         |
|    value_loss            | 14.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.55         |
| reward                   | -0.7711471   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 397          |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0005903485 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00926      |
|    cost_value_loss       | 1.92e-05     |
|    cost_values           | 0.00928      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | -0.147       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.3         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.000951    |
|    std                   | 1.05         |
|    value_loss            | 73.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.26        |
| reward                   | -0.43749288 |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -543        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 420         |
|    total_timesteps       | 540672      |
| train/                   |             |
|    approx_kl             | 0.004353886 |
|    clip_fraction         | 0.00806     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00372     |
|    cost_value_loss       | 4.43e-05    |
|    cost_values           | 0.0041      |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 2630        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 1.05        |
|    value_loss            | 6.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.806       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.806       |
| reward                   | -0.5150348  |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -544        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 442         |
|    total_timesteps       | 542720      |
| train/                   |             |
|    approx_kl             | 0.003456607 |
|    clip_fraction         | 0.0134      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00203    |
|    cost_value_loss       | 6.82e-05    |
|    cost_values           | -0.00205    |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.07        |
|    n_updates             | 2640        |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 1.06        |
|    value_loss            | 13.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.63         |
| reward                   | -0.45880413  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -549         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0068891146 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00371     |
|    cost_value_loss       | 0.000247     |
|    cost_values           | -0.00539     |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.322        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.75         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 1.06         |
|    value_loss            | 8.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.7          |
| reward                   | -0.8880718   |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 486          |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0044861063 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0132       |
|    cost_value_loss       | 0.000247     |
|    cost_values           | 0.0129       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 1.05         |
|    value_loss            | 27.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.51         |
| reward                   | -1.4703753   |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 509          |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0015800017 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00693      |
|    cost_value_loss       | 0.000235     |
|    cost_values           | 0.00724      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.645        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.3         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 1.05         |
|    value_loss            | 37.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8887943  |
| rollout/                 |             |
|    ep_len_mean           | 893         |
|    ep_rew_mean           | -547        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 531         |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.008367181 |
|    clip_fraction         | 0.0611      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00517     |
|    cost_value_loss       | 0.000193    |
|    cost_values           | 0.00536     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.8         |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00737    |
|    std                   | 1.06        |
|    value_loss            | 20.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2            |
| reward                   | -0.40277314  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 553          |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0019451886 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0047       |
|    cost_value_loss       | 7.45e-05     |
|    cost_values           | 0.00448      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.62         |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 1.06         |
|    value_loss            | 20.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.4          |
| reward                   | -0.64799464  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -535         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 575          |
|    total_timesteps       | 555008       |
| train/                   |              |
|    approx_kl             | 0.0051445486 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00632      |
|    cost_value_loss       | 0.000226     |
|    cost_values           | 0.00647      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.613        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.8         |
|    n_updates             | 2700         |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 1.06         |
|    value_loss            | 41.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.66911435  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -533         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 597          |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0058140447 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00246      |
|    cost_value_loss       | 0.000465     |
|    cost_values           | 0.00182      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.778        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.37         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 1.06         |
|    value_loss            | 4.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.74         |
| reward                   | -0.61001855  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 619          |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0011622316 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00843      |
|    cost_value_loss       | 0.000221     |
|    cost_values           | 0.00932      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.833        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.38         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.000623    |
|    std                   | 1.06         |
|    value_loss            | 7.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.82699364  |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -541         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 642          |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0024623284 |
|    clip_fraction         | 0.0022       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00762      |
|    cost_value_loss       | 0.000217     |
|    cost_values           | 0.0078       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.68         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 1.05         |
|    value_loss            | 7.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.100199   |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -547        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 664         |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.009291554 |
|    clip_fraction         | 0.0491      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00791     |
|    cost_value_loss       | 8.21e-05    |
|    cost_values           | 0.00804     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.488       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.96        |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 1.05        |
|    value_loss            | 20          |
------------------------------------------
------------------------------------------
| avg_speed                | 3.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.79        |
| reward                   | -1.1612924  |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -550        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 686         |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.004344023 |
|    clip_fraction         | 0.0253      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00818     |
|    cost_value_loss       | 0.000101    |
|    cost_values           | 0.00849     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.85        |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 1.06        |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.55         |
| reward                   | -0.34817705  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0048300857 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00673      |
|    cost_value_loss       | 3.74e-05     |
|    cost_values           | 0.00685      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.94         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 1.05         |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.434       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.434       |
| reward                   | -0.41859147 |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -538        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 730         |
|    total_timesteps       | 569344      |
| train/                   |             |
|    approx_kl             | 0.005913724 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00941     |
|    cost_value_loss       | 0.000132    |
|    cost_values           | 0.00958     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.82        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 2770        |
|    policy_gradient_loss  | -0.00654    |
|    std                   | 1.05        |
|    value_loss            | 23.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.52479595 |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 752         |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.007620315 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00353     |
|    cost_value_loss       | 4.71e-05    |
|    cost_values           | 0.00371     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.12        |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00578    |
|    std                   | 1.06        |
|    value_loss            | 17.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.29         |
| reward                   | -0.8495662   |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -535         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 775          |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0060005607 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00244      |
|    cost_value_loss       | 9.31e-08     |
|    cost_values           | 0.00246      |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | -0.000477    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.2         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 1.06         |
|    value_loss            | 37.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.95127696 |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -544        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.005777476 |
|    clip_fraction         | 0.0548      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00202     |
|    cost_value_loss       | 5.97e-08    |
|    cost_values           | 0.00203     |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | -0.000938   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.3         |
|    n_updates             | 2800        |
|    policy_gradient_loss  | -0.0062     |
|    std                   | 1.06        |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.77013236 |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -541        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 819         |
|    total_timesteps       | 577536      |
| train/                   |             |
|    approx_kl             | 0.006556623 |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00169     |
|    cost_value_loss       | 6.03e-08    |
|    cost_values           | 0.00167     |
|    entropy               | -2.93       |
|    entropy_loss          | -2.94       |
|    explained_variance    | -0.00481    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.44        |
|    n_updates             | 2810        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 1.05        |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.296        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.296        |
| reward                   | -0.5553095   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 841          |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0062767696 |
|    clip_fraction         | 0.074        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00158      |
|    cost_value_loss       | 3.95e-08     |
|    cost_values           | 0.00158      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -0.000144    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.93         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | 0.00218      |
|    std                   | 1.04         |
|    value_loss            | 13.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.581       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.581       |
| reward                   | -0.44179446 |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -543        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 863         |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.008042277 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00162     |
|    cost_value_loss       | 7.04e-05    |
|    cost_values           | 0.00164     |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.09        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.00679    |
|    std                   | 1.04        |
|    value_loss            | 4.67        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.16         |
| reward                   | -0.6118011   |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 885          |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0042974334 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00158      |
|    cost_value_loss       | 7.85e-05     |
|    cost_values           | 0.00156      |
|    entropy               | -2.91        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.89         |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 1.04         |
|    value_loss            | 7.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.938       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.938       |
| reward                   | -0.39678937 |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -544        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 908         |
|    total_timesteps       | 585728      |
| train/                   |             |
|    approx_kl             | 0.00391451  |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00477     |
|    cost_value_loss       | 4.04e-05    |
|    cost_values           | 0.00481     |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 2850        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 1.04        |
|    value_loss            | 5.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.13         |
| reward                   | -0.5517799   |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -536         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 930          |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0057968767 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00201      |
|    cost_value_loss       | 0.000184     |
|    cost_values           | 0.00157      |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.74         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 1.04         |
|    value_loss            | 5.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.94         |
| reward                   | -0.3144277   |
| rollout/                 |              |
|    ep_len_mean           | 882          |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 952          |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0041224137 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00424      |
|    cost_value_loss       | 6.43e-05     |
|    cost_values           | 0.00493      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.68         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 1.03         |
|    value_loss            | 24.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.42        |
| reward                   | -0.42438385 |
| rollout/                 |             |
|    ep_len_mean           | 866         |
|    ep_rew_mean           | -521        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 974         |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.003656406 |
|    clip_fraction         | 0.0062      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00369     |
|    cost_value_loss       | 4.99e-05    |
|    cost_values           | 0.00381     |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.00276    |
|    std                   | 1.03        |
|    value_loss            | 38.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.06         |
| reward                   | -0.20578545  |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -531         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 996          |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0039436202 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00419      |
|    cost_value_loss       | 1.66e-05     |
|    cost_values           | 0.00429      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.4         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 1.03         |
|    value_loss            | 36.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.7         |
| reward                   | -1.010622   |
| rollout/                 |             |
|    ep_len_mean           | 874         |
|    ep_rew_mean           | -528        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 595968      |
| train/                   |             |
|    approx_kl             | 0.009429559 |
|    clip_fraction         | 0.0801      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00205     |
|    cost_value_loss       | 1.28e-05    |
|    cost_values           | 0.00202     |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.62        |
|    n_updates             | 2900        |
|    policy_gradient_loss  | -0.00583    |
|    std                   | 1.03        |
|    value_loss            | 5.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.013864   |
| rollout/                 |             |
|    ep_len_mean           | 878         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 598016      |
| train/                   |             |
|    approx_kl             | 0.008106936 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00262    |
|    cost_value_loss       | 0.000358    |
|    cost_values           | -0.00915    |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.0458     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.92        |
|    n_updates             | 2910        |
|    policy_gradient_loss  | 0.0037      |
|    std                   | 1.03        |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2            |
| reward                   | -0.3667117   |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -535         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0031660749 |
|    clip_fraction         | 0.00347      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0181      |
|    cost_value_loss       | 4.13e-05     |
|    cost_values           | -0.0203      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.0638      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.79         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 1.04         |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.5          |
| reward                   | -0.43408483  |
| rollout/                 |              |
|    ep_len_mean           | 873          |
|    ep_rew_mean           | -526         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0055474206 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0116      |
|    cost_value_loss       | 4e-05        |
|    cost_values           | -0.0117      |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.864        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 1.04         |
|    value_loss            | 24.1         |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/3rk8b0u2/model_epoch(5)
-----------------------------------
| avg_speed          | 5.01       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 5.01       |
| reward             | -0.3860891 |
| rollout/           |            |
|    ep_len_mean     | 880        |
|    ep_rew_mean     | -532       |
| time/              |            |
|    fps             | 97         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 604160     |
-----------------------------------
-------------------------------------------
| avg_speed                | 4.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.67         |
| reward                   | -0.428849    |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0013176771 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0021      |
|    cost_value_loss       | 6.6e-05      |
|    cost_values           | -0.00233     |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.81         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | -0.000993    |
|    std                   | 1.04         |
|    value_loss            | 9.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.74         |
| reward                   | -0.32411548  |
| rollout/                 |              |
|    ep_len_mean           | 875          |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 608256       |
| train/                   |              |
|    approx_kl             | 0.0067477995 |
|    clip_fraction         | 0.0534       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0133      |
|    cost_value_loss       | 2.66e-06     |
|    cost_values           | -0.0134      |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.000341    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.82         |
|    n_updates             | 2960         |
|    policy_gradient_loss  | -0.00602     |
|    std                   | 1.04         |
|    value_loss            | 5.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.8500476  |
| rollout/                 |             |
|    ep_len_mean           | 875         |
|    ep_rew_mean           | -521        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.005425643 |
|    clip_fraction         | 0.0561      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00333    |
|    cost_value_loss       | 7.35e-05    |
|    cost_values           | -0.00332    |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.5         |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 1.04        |
|    value_loss            | 23.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.61         |
| reward                   | -0.593666    |
| rollout/                 |              |
|    ep_len_mean           | 875          |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0034140514 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00139     |
|    cost_value_loss       | 0.000118     |
|    cost_values           | -0.00194     |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.902        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.5          |
|    n_updates             | 2980         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 1.04         |
|    value_loss            | 7.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.89        |
| reward                   | -0.49663857 |
| rollout/                 |             |
|    ep_len_mean           | 875         |
|    ep_rew_mean           | -517        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.005015721 |
|    clip_fraction         | 0.0367      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00777    |
|    cost_value_loss       | 9.36e-07    |
|    cost_values           | -0.00776    |
|    entropy               | -2.9        |
|    entropy_loss          | -2.91       |
|    explained_variance    | -0.000261   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 2990        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 1.03        |
|    value_loss            | 6.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.8          |
| reward                   | -0.2838898   |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0040864116 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00169      |
|    cost_value_loss       | 6.63e-05     |
|    cost_values           | 0.00145      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.913        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.26         |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 1.03         |
|    value_loss            | 5.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.161        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.161        |
| reward                   | -0.23359959  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -528         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0053325174 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0051       |
|    cost_value_loss       | 0.000107     |
|    cost_values           | 0.00502      |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.506        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.586        |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.00466     |
|    std                   | 1.03         |
|    value_loss            | 1.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.604        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.604        |
| reward                   | -0.34498537  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0044210195 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00405     |
|    cost_value_loss       | 4.36e-05     |
|    cost_values           | -0.00396     |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.28         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 1.03         |
|    value_loss            | 2.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.53         |
| reward                   | -0.270622    |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0011416235 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000366    |
|    cost_value_loss       | 4.91e-05     |
|    cost_values           | -0.000584    |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.405        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.000191    |
|    std                   | 1.03         |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.35         |
| reward                   | -0.35989136  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -516         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0036002633 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00106     |
|    cost_value_loss       | 2.29e-06     |
|    cost_values           | -0.00102     |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.714        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.04         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 1.03         |
|    value_loss            | 6.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.329        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.329        |
| reward                   | -0.23993988  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 264          |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0057015168 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00236      |
|    cost_value_loss       | 8.77e-05     |
|    cost_values           | 0.00231      |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.791        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.724        |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.00322     |
|    std                   | 1.03         |
|    value_loss            | 2.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.67        |
| reward                   | -0.6031178  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -520        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 286         |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.004002698 |
|    clip_fraction         | 0.00679     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00145    |
|    cost_value_loss       | 0.000159    |
|    cost_values           | -0.00166    |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.846       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.57        |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 1.03        |
|    value_loss            | 5.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.37188336 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -518        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 308         |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.004429658 |
|    clip_fraction         | 0.00757     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00935     |
|    cost_value_loss       | 4.16e-05    |
|    cost_values           | 0.00914     |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.961       |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 1.03        |
|    value_loss            | 3.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.08        |
| reward                   | -0.5591369  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 331         |
|    total_timesteps       | 632832      |
| train/                   |             |
|    approx_kl             | 0.005614102 |
|    clip_fraction         | 0.0621      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00326     |
|    cost_value_loss       | 7.84e-07    |
|    cost_values           | 0.00328     |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -9.51e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.67        |
|    n_updates             | 3080        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 1.04        |
|    value_loss            | 18.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00986      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00986      |
| reward                   | -0.2605755   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -521         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 353          |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0056565898 |
|    clip_fraction         | 0.0685       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000621     |
|    cost_value_loss       | 3.16e-07     |
|    cost_values           | 0.000678     |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.000198    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 1.03         |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.03         |
| reward                   | -0.2700274   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -515         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 375          |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0034281714 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00103      |
|    cost_value_loss       | 4.08e-08     |
|    cost_values           | 0.00106      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.00019     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.66         |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.000838    |
|    std                   | 1.03         |
|    value_loss            | 5.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.34770754 |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -513        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 397         |
|    total_timesteps       | 638976      |
| train/                   |             |
|    approx_kl             | 0.002379307 |
|    clip_fraction         | 0.0102      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000816    |
|    cost_value_loss       | 1.03e-08    |
|    cost_values           | 0.000813    |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.000119   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.99        |
|    n_updates             | 3110        |
|    policy_gradient_loss  | -0.00186    |
|    std                   | 1.03        |
|    value_loss            | 7.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.347        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.347        |
| reward                   | -0.3914565   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 419          |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0043209903 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00235      |
|    cost_value_loss       | 4.1e-05      |
|    cost_values           | 0.0026       |
|    entropy               | -2.89        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.766        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 1.03         |
|    value_loss            | 14.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.6          |
| reward                   | -0.74303967  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -502         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 442          |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0045366744 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000363     |
|    cost_value_loss       | 1.11e-05     |
|    cost_values           | 0.000332     |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.81         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 1.03         |
|    value_loss            | 4.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.12         |
| reward                   | -0.3483855   |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -514         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0019409502 |
|    clip_fraction         | 0.00313      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00231      |
|    cost_value_loss       | 6.79e-05     |
|    cost_values           | 0.00232      |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.863        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.02         |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 1.03         |
|    value_loss            | 9.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.99         |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 4.99         |
| reward                   | -0.106175885 |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 486          |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0024430929 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000673     |
|    cost_value_loss       | 3.66e-05     |
|    cost_values           | -1.7e-05     |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.297       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.03         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 1.03         |
|    value_loss            | 9.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.772        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.772        |
| reward                   | -0.6114519   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 508          |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0016767741 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000689     |
|    cost_value_loss       | 3.39e-05     |
|    cost_values           | 0.00128      |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.516        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19           |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 1.03         |
|    value_loss            | 36.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.52        |
| reward                   | -0.3462005  |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 531         |
|    total_timesteps       | 651264      |
| train/                   |             |
|    approx_kl             | 0.002034112 |
|    clip_fraction         | 0.00298     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00736     |
|    cost_value_loss       | 4.29e-05    |
|    cost_values           | 0.00723     |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 3170        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 1.03        |
|    value_loss            | 6.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.483        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.483        |
| reward                   | -0.46056288  |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 553          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0074555725 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000474     |
|    cost_value_loss       | 2.45e-06     |
|    cost_values           | 0.000471     |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.646        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.72         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 1.02         |
|    value_loss            | 5.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.36        |
| reward                   | -0.48964226 |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 575         |
|    total_timesteps       | 655360      |
| train/                   |             |
|    approx_kl             | 0.005958749 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00205    |
|    cost_value_loss       | 5.86e-05    |
|    cost_values           | -0.00177    |
|    entropy               | -2.85       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -0.0663     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 3190        |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 1.01        |
|    value_loss            | 41.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.14        |
| reward                   | -2.0824747  |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 598         |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.006146668 |
|    clip_fraction         | 0.0316      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00443    |
|    cost_value_loss       | 2.98e-07    |
|    cost_values           | -0.00444    |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 7.87e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.582       |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00459    |
|    std                   | 1.01        |
|    value_loss            | 1.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.2003435   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 620          |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0027370425 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000564    |
|    cost_value_loss       | 9.84e-06     |
|    cost_values           | -0.000726    |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.302        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.000473    |
|    std                   | 1.01         |
|    value_loss            | 44.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.33         |
| reward                   | -0.7866514   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 642          |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0018502413 |
|    clip_fraction         | 0.00708      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000769     |
|    cost_value_loss       | 1.66e-05     |
|    cost_values           | 0.000741     |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.215        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 67.6         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 1.01         |
|    value_loss            | 150          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.522        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.522        |
| reward                   | -0.29201478  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 664          |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0029963837 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00134     |
|    cost_value_loss       | 2.6e-08      |
|    cost_values           | -0.00135     |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.00177     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.6         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 1.01         |
|    value_loss            | 75.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.48        |
| reward                   | -0.5601264  |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -504        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 686         |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.004424876 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00186     |
|    cost_value_loss       | 2.43e-05    |
|    cost_values           | 0.00182     |
|    entropy               | -2.84       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0139      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 3240        |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 1           |
|    value_loss            | 20.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.259        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.259        |
| reward                   | -0.43943343  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0050460394 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0126       |
|    cost_value_loss       | 8.78e-05     |
|    cost_values           | 0.0127       |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.791        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.17         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 1            |
|    value_loss            | 4.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.91         |
| reward                   | -0.6655242   |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 731          |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0026022969 |
|    clip_fraction         | 0.00352      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00434     |
|    cost_value_loss       | 7.29e-05     |
|    cost_values           | -0.00483     |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.191       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.882        |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 1            |
|    value_loss            | 4.1          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.21        |
| reward                   | -0.3319458  |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -498        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 753         |
|    total_timesteps       | 671744      |
| train/                   |             |
|    approx_kl             | 0.003273025 |
|    clip_fraction         | 0.0115      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000617   |
|    cost_value_loss       | 9.65e-06    |
|    cost_values           | -0.000583   |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.624       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.12        |
|    n_updates             | 3270        |
|    policy_gradient_loss  | -0.00374    |
|    std                   | 1           |
|    value_loss            | 3.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.17         |
| reward                   | -0.5777723   |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 775          |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0034212985 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0103       |
|    cost_value_loss       | 4.46e-05     |
|    cost_values           | 0.0102       |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.434        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.67         |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 1            |
|    value_loss            | 8.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.7         |
| reward                   | -0.25811365 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -494        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.001066364 |
|    clip_fraction         | 0.000684    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00769     |
|    cost_value_loss       | 1.59e-05    |
|    cost_values           | 0.0077      |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -0.37       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.97        |
|    n_updates             | 3290        |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 1           |
|    value_loss            | 21.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.296        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.296        |
| reward                   | -0.60554904  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 819          |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0074377744 |
|    clip_fraction         | 0.0726       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00685      |
|    cost_value_loss       | 1.16e-05     |
|    cost_values           | 0.00685      |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.165        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.51         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | -0.00725     |
|    std                   | 1.01         |
|    value_loss            | 8.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.756        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.756        |
| reward                   | -0.522796    |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 841          |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0040431884 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00243      |
|    cost_value_loss       | 2.72e-05     |
|    cost_values           | 0.00264      |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0276       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.9          |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 1            |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.85         |
| reward                   | -0.7696201   |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 863          |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0036683364 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000709     |
|    cost_value_loss       | 5.04e-05     |
|    cost_values           | 0.000518     |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0122       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 1            |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.39         |
| reward                   | -0.5750338   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 885          |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0052305786 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000797    |
|    cost_value_loss       | 3.66e-05     |
|    cost_values           | -0.000706    |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0939       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.976        |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 1            |
|    value_loss            | 3.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.46         |
| reward                   | -0.83747226  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -510         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 908          |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0042548296 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000847    |
|    cost_value_loss       | 2.96e-06     |
|    cost_values           | -0.000748    |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0548       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.996        |
|    value_loss            | 10.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.348        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.348        |
| reward                   | -0.4340928   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 930          |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0037079188 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000468    |
|    cost_value_loss       | 6.76e-05     |
|    cost_values           | -0.000163    |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.175        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.17         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.994        |
|    value_loss            | 20.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.663       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.663       |
| reward                   | -0.4285847  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -509        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 952         |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.003664739 |
|    clip_fraction         | 0.0194      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00406    |
|    cost_value_loss       | 1.08e-06    |
|    cost_values           | -0.00408    |
|    entropy               | -2.83       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -0.147      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.6         |
|    n_updates             | 3360        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.996       |
|    value_loss            | 8.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.572        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.572        |
| reward                   | -0.36010757  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 974          |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0050036656 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00172      |
|    cost_value_loss       | 4.01e-05     |
|    cost_values           | 0.00273      |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.57e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.91         |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.997        |
|    value_loss            | 7.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.25         |
| reward                   | -0.67003924  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 996          |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0009841274 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00266      |
|    cost_value_loss       | 3.99e-07     |
|    cost_values           | 0.00274      |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -2.63e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.455        |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.000485    |
|    std                   | 0.994        |
|    value_loss            | 1.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.23         |
| reward                   | -0.7385816   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1018         |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0036893038 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00906      |
|    cost_value_loss       | 1.81e-05     |
|    cost_values           | 0.00909      |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.296       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.13         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.995        |
|    value_loss            | 2.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.08         |
| reward                   | -0.38903716  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -510         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1040         |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0021897948 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0109       |
|    cost_value_loss       | 2.37e-05     |
|    cost_values           | 0.0107       |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.0722      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.77         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.000403    |
|    std                   | 0.996        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.03         |
| reward                   | -1.1477231   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0056050615 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00715      |
|    cost_value_loss       | 5.5e-06      |
|    cost_values           | 0.00678      |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.0521      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.89         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 1            |
|    value_loss            | 17.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.34         |
| reward                   | -0.36557207  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1084         |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0053884005 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0215       |
|    cost_value_loss       | 0.000184     |
|    cost_values           | 0.0225       |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0827       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.3          |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.0046      |
|    std                   | 1            |
|    value_loss            | 10.8         |
-------------------------------------------
-----------------------------------
| avg_speed          | 4.06       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 4.06       |
| reward             | -1.0472676 |
| rollout/           |            |
|    ep_len_mean     | 941        |
|    ep_rew_mean     | -502       |
| time/              |            |
|    fps             | 92         |
|    iterations      | 1          |
|    time_elapsed    | 22         |
|    total_timesteps | 704512     |
-----------------------------------
-------------------------------------------
| avg_speed                | 3.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.33         |
| reward                   | -0.7073848   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -502         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 2            |
|    time_elapsed          | 44           |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0069154883 |
|    clip_fraction         | 0.0544       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0115       |
|    cost_value_loss       | 2.25e-05     |
|    cost_values           | 0.0116       |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0672       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.04         |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.00675     |
|    std                   | 0.998        |
|    value_loss            | 22.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.262       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.262       |
| reward                   | -0.51085883 |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -501        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 708608      |
| train/                   |             |
|    approx_kl             | 0.008254366 |
|    clip_fraction         | 0.0408      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0104      |
|    cost_value_loss       | 2.32e-05    |
|    cost_values           | 0.0104      |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.376       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.14        |
|    n_updates             | 3450        |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 0.994       |
|    value_loss            | 4.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.6961992   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0046417383 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00631      |
|    cost_value_loss       | 4.11e-05     |
|    cost_values           | 0.00621      |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.349        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.476        |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 0.993        |
|    value_loss            | 1.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.872       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.872       |
| reward                   | -0.472761   |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -499        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.003430448 |
|    clip_fraction         | 0.0063      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000383   |
|    cost_value_loss       | 6.24e-05    |
|    cost_values           | 0.000132    |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.488       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.991       |
|    value_loss            | 12          |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.64         |
| reward                   | -0.47891724  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 133          |
|    total_timesteps       | 714752       |
| train/                   |              |
|    approx_kl             | 0.0043190084 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00085      |
|    cost_value_loss       | 7.51e-06     |
|    cost_values           | 0.000674     |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.721        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 3480         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.991        |
|    value_loss            | 22.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.11        |
| reward                   | -0.29918247 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 155         |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.006702539 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00524     |
|    cost_value_loss       | 2.46e-05    |
|    cost_values           | 0.00539     |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0526      |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.00309    |
|    std                   | 0.996       |
|    value_loss            | 0.263       |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.36         |
| reward                   | -0.5885215   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -502         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 177          |
|    total_timesteps       | 718848       |
| train/                   |              |
|    approx_kl             | 0.0044551315 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00102     |
|    cost_value_loss       | 8.42e-08     |
|    cost_values           | -0.00106     |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -3.49e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.1          |
|    n_updates             | 3500         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 1            |
|    value_loss            | 7.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.701       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.701       |
| reward                   | -0.48797837 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -500        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 720896      |
| train/                   |             |
|    approx_kl             | 0.005133186 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00256     |
|    cost_value_loss       | 2.52e-05    |
|    cost_values           | 0.00248     |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.45        |
|    n_updates             | 3510        |
|    policy_gradient_loss  | -0.00537    |
|    std                   | 0.996       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.75        |
| reward                   | -0.29359514 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -495        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.005643842 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00633     |
|    cost_value_loss       | 2.89e-05    |
|    cost_values           | 0.00543     |
|    entropy               | -2.81       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.786       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.509       |
|    n_updates             | 3520        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.992       |
|    value_loss            | 1.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.849       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.849       |
| reward                   | -0.21996139 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 724992      |
| train/                   |             |
|    approx_kl             | 0.002901758 |
|    clip_fraction         | 0.00396     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00296     |
|    cost_value_loss       | 2.26e-05    |
|    cost_values           | 0.00306     |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.791       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.62        |
|    n_updates             | 3530        |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.991       |
|    value_loss            | 8.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.12        |
| reward                   | -0.38679686 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 266         |
|    total_timesteps       | 727040      |
| train/                   |             |
|    approx_kl             | 0.005377065 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00335     |
|    cost_value_loss       | 0.000139    |
|    cost_values           | 0.00361     |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.142       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.85        |
|    n_updates             | 3540        |
|    policy_gradient_loss  | -0.0053     |
|    std                   | 0.991       |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.323        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.323        |
| reward                   | -0.52003235  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 288          |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0051860455 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00832     |
|    cost_value_loss       | 0.000326     |
|    cost_values           | -0.00789     |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -0.165       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.28         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.991        |
|    value_loss            | 11.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.23         |
| reward                   | -0.41683787  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 310          |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0030957758 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0166      |
|    cost_value_loss       | 9.93e-05     |
|    cost_values           | -0.0163      |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.684        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.99         |
|    value_loss            | 13.2         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -1.1066552 |
| rollout/                 |            |
|    ep_len_mean           | 917        |
|    ep_rew_mean           | -478       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 15         |
|    time_elapsed          | 332        |
|    total_timesteps       | 733184     |
| train/                   |            |
|    approx_kl             | 0.00830778 |
|    clip_fraction         | 0.0355     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00696   |
|    cost_value_loss       | 8.13e-05   |
|    cost_values           | -0.0072    |
|    entropy               | -2.81      |
|    entropy_loss          | -2.81      |
|    explained_variance    | -0.158     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.812      |
|    n_updates             | 3570       |
|    policy_gradient_loss  | -0.00428   |
|    std                   | 0.99       |
|    value_loss            | 3.99       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.6840883  |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 354         |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.005752965 |
|    clip_fraction         | 0.0412      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00359    |
|    cost_value_loss       | 2.99e-05    |
|    cost_values           | -0.00363    |
|    entropy               | -2.83       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.77        |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00594    |
|    std                   | 1           |
|    value_loss            | 6.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.09        |
| reward                   | -0.7708474  |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -476        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 376         |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.009546828 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000503    |
|    cost_value_loss       | 0.000124    |
|    cost_values           | -0.000172   |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -5.82e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.07        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.00507    |
|    std                   | 1           |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.57484293  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 399          |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0071062525 |
|    clip_fraction         | 0.0795       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00509     |
|    cost_value_loss       | 5.19e-07     |
|    cost_values           | -0.00512     |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.000142    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.19         |
|    n_updates             | 3600         |
|    policy_gradient_loss  | -0.00758     |
|    std                   | 1            |
|    value_loss            | 4.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0447       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0447       |
| reward                   | -0.31167802  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 421          |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0027284115 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000851    |
|    cost_value_loss       | 0.000477     |
|    cost_values           | -0.000666    |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.485        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.87         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | 0.000967     |
|    std                   | 1            |
|    value_loss            | 16.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.9         |
| reward                   | -0.6367418  |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -488        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 443         |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.004631804 |
|    clip_fraction         | 0.0484      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00814    |
|    cost_value_loss       | 6.86e-06    |
|    cost_values           | -0.00822    |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -0.0403     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.0056     |
|    std                   | 0.998       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.714       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.714       |
| reward                   | -0.30492032 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 465         |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.004048956 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0051      |
|    cost_value_loss       | 4.97e-05    |
|    cost_values           | 0.00496     |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.777       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.05        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 0.994       |
|    value_loss            | 2.57        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.43         |
| reward                   | -0.54551625  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 488          |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0022031618 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000642     |
|    cost_value_loss       | 4.25e-05     |
|    cost_values           | 7.71e-05     |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.802        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.97         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.994        |
|    value_loss            | 5.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.45         |
| reward                   | -0.3945956   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 510          |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0022877697 |
|    clip_fraction         | 0.00488      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000285    |
|    cost_value_loss       | 2.64e-05     |
|    cost_values           | -0.000307    |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.265        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.993        |
|    value_loss            | 29.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.08         |
| reward                   | -0.45280635  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 532          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0033414639 |
|    clip_fraction         | 0.00518      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00308     |
|    cost_value_loss       | 2.58e-05     |
|    cost_values           | -0.00337     |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -0.603       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.77         |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.991        |
|    value_loss            | 7.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.86         |
| reward                   | -0.45152605  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 554          |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0018871536 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | -7.3e-05     |
|    cost_value_loss       | 2.05e-10     |
|    cost_values           | -7.65e-05    |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -9.3e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.000929    |
|    std                   | 0.991        |
|    value_loss            | 15.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.28         |
| reward                   | -0.9838534   |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 576          |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0039088307 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | -5.72e-05    |
|    cost_value_loss       | 4.78e-11     |
|    cost_values           | -5.77e-05    |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -6.79e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.6          |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.993        |
|    value_loss            | 3.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.965       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.965       |
| reward                   | -0.30551028 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 598         |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.00484861  |
|    clip_fraction         | 0.0431      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000633   |
|    cost_value_loss       | 2.93e-05    |
|    cost_values           | -0.000597   |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.233       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.993       |
|    value_loss            | 30.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.05          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.05          |
| reward                   | -0.32539108   |
| rollout/                 |               |
|    ep_len_mean           | 917           |
|    ep_rew_mean           | -468          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 28            |
|    time_elapsed          | 620           |
|    total_timesteps       | 759808        |
| train/                   |               |
|    approx_kl             | 0.00068904966 |
|    clip_fraction         | 9.77e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | -0.000766     |
|    cost_value_loss       | 6.42e-06      |
|    cost_values           | -0.000752     |
|    entropy               | -2.81         |
|    entropy_loss          | -2.82         |
|    explained_variance    | 0.433         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.1          |
|    n_updates             | 3700          |
|    policy_gradient_loss  | -0.00086      |
|    std                   | 0.993         |
|    value_loss            | 27.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 2.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.23         |
| reward                   | -0.4933629   |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 643          |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0053079706 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000762    |
|    cost_value_loss       | 2.92e-05     |
|    cost_values           | -0.000459    |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.404        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7            |
|    n_updates             | 3710         |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 0.992        |
|    value_loss            | 21.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.69        |
| reward                   | -0.48928565 |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 665         |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.005221162 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00148     |
|    cost_value_loss       | 9.57e-06    |
|    cost_values           | 0.00132     |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.674       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 0.992       |
|    value_loss            | 24.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.07         |
| reward                   | -0.34983367  |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 687          |
|    total_timesteps       | 765952       |
| train/                   |              |
|    approx_kl             | 0.0028262015 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000383     |
|    cost_value_loss       | 1.05e-05     |
|    cost_values           | 0.000309     |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.18         |
|    n_updates             | 3730         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.992        |
|    value_loss            | 8.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6084366   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 709          |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0006216536 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.84e-05     |
|    cost_value_loss       | 9.49e-06     |
|    cost_values           | 0.000534     |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.771        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.993        |
|    value_loss            | 28.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.05        |
| reward                   | -0.26855808 |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 731         |
|    total_timesteps       | 770048      |
| train/                   |             |
|    approx_kl             | 0.004873717 |
|    clip_fraction         | 0.0124      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00171     |
|    cost_value_loss       | 2.27e-05    |
|    cost_values           | 0.00204     |
|    entropy               | -2.82       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.37        |
|    n_updates             | 3750        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.993       |
|    value_loss            | 3.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.39         |
| reward                   | -0.4638282   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 753          |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0054494375 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00187     |
|    cost_value_loss       | 8.05e-08     |
|    cost_values           | -0.00185     |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -1.59e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.22         |
|    n_updates             | 3760         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.995        |
|    value_loss            | 7.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.78         |
| reward                   | -0.31168947  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 776          |
|    total_timesteps       | 774144       |
| train/                   |              |
|    approx_kl             | 0.0050406763 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00148     |
|    cost_value_loss       | 3.96e-08     |
|    cost_values           | -0.00146     |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.000161    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.09         |
|    n_updates             | 3770         |
|    policy_gradient_loss  | -0.0065      |
|    std                   | 0.996        |
|    value_loss            | 13           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0254       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0254       |
| reward                   | -0.29507783  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 798          |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0025853151 |
|    clip_fraction         | 0.00566      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000461    |
|    cost_value_loss       | 3.8e-05      |
|    cost_values           | -0.000307    |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.694        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.77         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.995        |
|    value_loss            | 19.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.82         |
| reward                   | -0.33165208  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 820          |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0050697513 |
|    clip_fraction         | 0.0248       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00238      |
|    cost_value_loss       | 2.79e-05     |
|    cost_values           | 0.00259      |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.91         |
|    n_updates             | 3790         |
|    policy_gradient_loss  | -0.00498     |
|    std                   | 0.995        |
|    value_loss            | 4.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.34         |
| reward                   | -0.27699402  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 842          |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0073424303 |
|    clip_fraction         | 0.0674       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00153      |
|    cost_value_loss       | 8.04e-06     |
|    cost_values           | 0.00155      |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.784        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.12         |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.00782     |
|    std                   | 1.01         |
|    value_loss            | 9.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.55800647  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 864          |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0023471909 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000832     |
|    cost_value_loss       | 5.16e-06     |
|    cost_values           | 0.000779     |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.914        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.14         |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.00038     |
|    std                   | 1.01         |
|    value_loss            | 3.58         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.3         |
| reward                   | -0.58953077 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 887         |
|    total_timesteps       | 784384      |
| train/                   |             |
|    approx_kl             | 0.005095265 |
|    clip_fraction         | 0.0138      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00183    |
|    cost_value_loss       | 1.8e-05     |
|    cost_values           | -0.00202    |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.467       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 3820        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 1.01        |
|    value_loss            | 21          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5213188   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 909          |
|    total_timesteps       | 786432       |
| train/                   |              |
|    approx_kl             | 0.0017835719 |
|    clip_fraction         | 0.00225      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00178     |
|    cost_value_loss       | 9.75e-06     |
|    cost_values           | -0.00172     |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.51         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 3830         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 1.01         |
|    value_loss            | 13.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.298         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.298         |
| reward                   | -0.6236265    |
| rollout/                 |               |
|    ep_len_mean           | 904           |
|    ep_rew_mean           | -461          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 42            |
|    time_elapsed          | 931           |
|    total_timesteps       | 788480        |
| train/                   |               |
|    approx_kl             | 0.00023565473 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.00202      |
|    cost_value_loss       | 1.13e-05      |
|    cost_values           | -0.00214      |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | 0.587         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21.2          |
|    n_updates             | 3840          |
|    policy_gradient_loss  | -0.000305     |
|    std                   | 1.01          |
|    value_loss            | 47.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.45         |
| reward                   | -0.34042883  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 953          |
|    total_timesteps       | 790528       |
| train/                   |              |
|    approx_kl             | 0.0029714387 |
|    clip_fraction         | 0.00845      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00295     |
|    cost_value_loss       | 1.24e-05     |
|    cost_values           | -0.0029      |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.629        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.57         |
|    n_updates             | 3850         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 1.01         |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.296        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.296        |
| reward                   | -0.43423676  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 975          |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0041431743 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00213     |
|    cost_value_loss       | 7.97e-06     |
|    cost_values           | -0.00209     |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.318        |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 1            |
|    value_loss            | 0.838        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.373        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.373        |
| reward                   | -0.49649364  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 997          |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0059920605 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00414     |
|    cost_value_loss       | 2.84e-05     |
|    cost_values           | -0.00388     |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.495        |
|    n_updates             | 3870         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 1            |
|    value_loss            | 2.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.3         |
| reward                   | -0.3405417  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 796672      |
| train/                   |             |
|    approx_kl             | 0.004199584 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00154    |
|    cost_value_loss       | 5.36e-08    |
|    cost_values           | -0.00158    |
|    entropy               | -2.84       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -8.4e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.64        |
|    n_updates             | 3880        |
|    policy_gradient_loss  | -0.00437    |
|    std                   | 1.01        |
|    value_loss            | 5.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.188       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.188       |
| reward                   | -0.55364364 |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1042        |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.006472844 |
|    clip_fraction         | 0.055       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000956   |
|    cost_value_loss       | 2.91e-05    |
|    cost_values           | -0.000986   |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.19        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00473    |
|    std                   | 0.999       |
|    value_loss            | 0.415       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.723       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.723       |
| reward                   | -0.29550737 |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.003243992 |
|    clip_fraction         | 0.00625     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000336   |
|    cost_value_loss       | 5.05e-05    |
|    cost_values           | -0.00125    |
|    entropy               | -2.81       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.45        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.995       |
|    value_loss            | 9.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.42         |
| reward                   | -0.53595465  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1086         |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0045651877 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000279     |
|    cost_value_loss       | 2.7e-05      |
|    cost_values           | 0.000227     |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.119       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.04         |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.997        |
|    value_loss            | 2.39         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.286      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.286      |
| reward             | -0.4695951 |
| rollout/           |            |
|    ep_len_mean     | 921        |
|    ep_rew_mean     | -464       |
| time/              |            |
|    fps             | 94         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 804864     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9037556   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0016678418 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.001       |
|    cost_value_loss       | 1.35e-05     |
|    cost_values           | -0.000984    |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.921        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.156        |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.000873    |
|    std                   | 1            |
|    value_loss            | 0.984        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.66         |
| reward                   | -0.45355073  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0047842218 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0043      |
|    cost_value_loss       | 5.49e-06     |
|    cost_values           | -0.00446     |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.794        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.14         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 1            |
|    value_loss            | 3.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.28         |
| reward                   | -0.58442324  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 811008       |
| train/                   |              |
|    approx_kl             | 0.0016675512 |
|    clip_fraction         | 0.00332      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00275     |
|    cost_value_loss       | 4.65e-06     |
|    cost_values           | -0.00278     |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.8          |
|    n_updates             | 3950         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.999        |
|    value_loss            | 5.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.06        |
| reward                   | -0.86615276 |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.006368869 |
|    clip_fraction         | 0.0441      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0026     |
|    cost_value_loss       | 3.18e-05    |
|    cost_values           | -0.00261    |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.198       |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00651    |
|    std                   | 0.992       |
|    value_loss            | 0.406       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0276       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0276       |
| reward                   | -0.5079956   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0046950364 |
|    clip_fraction         | 0.0405       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00103     |
|    cost_value_loss       | 3.55e-06     |
|    cost_values           | -0.00102     |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.323        |
|    n_updates             | 3970         |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 0.987        |
|    value_loss            | 0.773        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0856      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0856      |
| reward                   | -0.31273913 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 817152      |
| train/                   |             |
|    approx_kl             | 0.005355416 |
|    clip_fraction         | 0.014       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000713   |
|    cost_value_loss       | 6.12e-06    |
|    cost_values           | -0.000793   |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.251       |
|    n_updates             | 3980        |
|    policy_gradient_loss  | -0.00238    |
|    std                   | 0.983       |
|    value_loss            | 1.07        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.769      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.769      |
| reward                   | -0.3220605 |
| rollout/                 |            |
|    ep_len_mean           | 939        |
|    ep_rew_mean           | -480       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 8          |
|    time_elapsed          | 176        |
|    total_timesteps       | 819200     |
| train/                   |            |
|    approx_kl             | 0.00373187 |
|    clip_fraction         | 0.029      |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00014    |
|    cost_value_loss       | 8.33e-06   |
|    cost_values           | 0.000285   |
|    entropy               | -2.79      |
|    entropy_loss          | -2.79      |
|    explained_variance    | 0.896      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.323      |
|    n_updates             | 3990       |
|    policy_gradient_loss  | -0.00289   |
|    std                   | 0.982      |
|    value_loss            | 0.854      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0124       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0124       |
| reward                   | -0.3742961   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0023283819 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.02e-05     |
|    cost_value_loss       | 2.96e-05     |
|    cost_values           | 0.00106      |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.269        |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.000989    |
|    std                   | 0.981        |
|    value_loss            | 2.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.48        |
| reward                   | -0.44882432 |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 220         |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.003110949 |
|    clip_fraction         | 0.004       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000653   |
|    cost_value_loss       | 4.84e-06    |
|    cost_values           | -0.000601   |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.558       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.07        |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.000817   |
|    std                   | 0.981       |
|    value_loss            | 2.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.761        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.761        |
| reward                   | -0.24578212  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0045703794 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000914     |
|    cost_value_loss       | 1.22e-08     |
|    cost_values           | 0.000918     |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -5.48e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.858        |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.981        |
|    value_loss            | 2.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.389       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.389       |
| reward                   | -0.5716185  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.006408239 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00073     |
|    cost_value_loss       | 6.46e-08    |
|    cost_values           | 0.000744    |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 4.89e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.95        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.978       |
|    value_loss            | 6.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0995      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0995      |
| reward                   | -0.21517973 |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 288         |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.004439425 |
|    clip_fraction         | 0.0431      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000357   |
|    cost_value_loss       | 4.28e-06    |
|    cost_values           | -0.000527   |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.3         |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00476    |
|    std                   | 0.977       |
|    value_loss            | 4.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0413      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0413      |
| reward                   | -0.3376582  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.004383199 |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | -7.57e-05   |
|    cost_value_loss       | 3.74e-06    |
|    cost_values           | -8.28e-05   |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.89        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 0.978       |
|    value_loss            | 3.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0402       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0402       |
| reward                   | -0.4881492   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 332          |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0047002304 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00029      |
|    cost_value_loss       | 4.31e-06     |
|    cost_values           | 0.000395     |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.38         |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 0.978        |
|    value_loss            | 3.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.73         |
| reward                   | -0.4343083   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0060948096 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000546     |
|    cost_value_loss       | 5.48e-06     |
|    cost_values           | 0.000863     |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -0.18        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.824        |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.975        |
|    value_loss            | 1.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.39        |
| reward                   | -0.7972743  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 837632      |
| train/                   |             |
|    approx_kl             | 0.009208867 |
|    clip_fraction         | 0.0351      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00559    |
|    cost_value_loss       | 1.81e-05    |
|    cost_values           | -0.00573    |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.9         |
|    n_updates             | 4080        |
|    policy_gradient_loss  | -0.00413    |
|    std                   | 0.971       |
|    value_loss            | 2.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.99         |
| reward                   | -0.45969462  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 399          |
|    total_timesteps       | 839680       |
| train/                   |              |
|    approx_kl             | 0.0019134781 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00969     |
|    cost_value_loss       | 5.56e-05     |
|    cost_values           | -0.0105      |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.781        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.25         |
|    n_updates             | 4090         |
|    policy_gradient_loss  | -0.000861    |
|    std                   | 0.969        |
|    value_loss            | 5.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0903       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0903       |
| reward                   | -0.36128747  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 421          |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0038754118 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00697     |
|    cost_value_loss       | 2.31e-05     |
|    cost_values           | -0.0068      |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.795        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.969        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.37         |
| reward                   | -0.68408763  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0039957277 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00778     |
|    cost_value_loss       | 2.78e-06     |
|    cost_values           | -0.0077      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.82         |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -0.00547     |
|    std                   | 0.972        |
|    value_loss            | 5.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.11        |
| reward                   | -0.37653175 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 466         |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.007035748 |
|    clip_fraction         | 0.0699      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00477    |
|    cost_value_loss       | 6.08e-06    |
|    cost_values           | -0.00489    |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.513       |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.00825    |
|    std                   | 0.974       |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.583        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.583        |
| reward                   | -0.3893639   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 487          |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0077640023 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00254     |
|    cost_value_loss       | 4.64e-06     |
|    cost_values           | -0.00234     |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.57         |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.00525     |
|    std                   | 0.972        |
|    value_loss            | 3.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.233       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.233       |
| reward                   | -0.5037013  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 509         |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.006328635 |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00295    |
|    cost_value_loss       | 4.89e-06    |
|    cost_values           | -0.00302    |
|    entropy               | -2.75       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.128       |
|    n_updates             | 4140        |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 0.962       |
|    value_loss            | 0.308       |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.5          |
| reward                   | -0.556662    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 532          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0054556415 |
|    clip_fraction         | 0.0512       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00275     |
|    cost_value_loss       | 9.13e-06     |
|    cost_values           | -0.00273     |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0357       |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.961        |
|    value_loss            | 0.223        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.97         |
| reward                   | -0.27424645  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 554          |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 0.0034666508 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00369     |
|    cost_value_loss       | 2.91e-07     |
|    cost_values           | -0.00369     |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -1.19e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.333        |
|    n_updates             | 4160         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 0.964        |
|    value_loss            | 0.701        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.424        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.424        |
| reward                   | -0.24824238  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 576          |
|    total_timesteps       | 856064       |
| train/                   |              |
|    approx_kl             | 0.0031774985 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00368     |
|    cost_value_loss       | 3.41e-06     |
|    cost_values           | -0.00392     |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.246        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.89         |
|    n_updates             | 4170         |
|    policy_gradient_loss  | -0.000879    |
|    std                   | 0.964        |
|    value_loss            | 7.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.402        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.402        |
| reward                   | -0.39011508  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 598          |
|    total_timesteps       | 858112       |
| train/                   |              |
|    approx_kl             | 0.0013727103 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0027      |
|    cost_value_loss       | 6.95e-07     |
|    cost_values           | -0.0027      |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.325        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.62         |
|    n_updates             | 4180         |
|    policy_gradient_loss  | -0.000966    |
|    std                   | 0.964        |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.29         |
| reward                   | -0.708857    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 620          |
|    total_timesteps       | 860160       |
| train/                   |              |
|    approx_kl             | 0.0038971305 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000687    |
|    cost_value_loss       | 9.05e-06     |
|    cost_values           | -0.000697    |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.582        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.37         |
|    n_updates             | 4190         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.959        |
|    value_loss            | 3.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.589        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.589        |
| reward                   | -0.3118947   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 643          |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0056129415 |
|    clip_fraction         | 0.0524       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00281     |
|    cost_value_loss       | 2.75e-05     |
|    cost_values           | -0.00378     |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.64         |
|    n_updates             | 4200         |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 0.961        |
|    value_loss            | 14.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.17        |
| reward                   | -0.56518316 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 665         |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.003229846 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0173      |
|    cost_value_loss       | 0.000878    |
|    cost_values           | 0.0265      |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.403       |
|    n_updates             | 4210        |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.96        |
|    value_loss            | 1.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0328       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0328       |
| reward                   | -0.4481144   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 687          |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0044634202 |
|    clip_fraction         | 0.0248       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0182       |
|    cost_value_loss       | 4.01e-05     |
|    cost_values           | 0.0197       |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.162        |
|    n_updates             | 4220         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.961        |
|    value_loss            | 0.601        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.879       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.879       |
| reward                   | -0.31045166 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 709         |
|    total_timesteps       | 868352      |
| train/                   |             |
|    approx_kl             | 0.00416463  |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0127      |
|    cost_value_loss       | 2.61e-06    |
|    cost_values           | 0.0126      |
|    entropy               | -2.75       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 1.05e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.2        |
|    n_updates             | 4230        |
|    policy_gradient_loss  | -0.00572    |
|    std                   | 0.962       |
|    value_loss            | 26.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.666        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.666        |
| reward                   | -0.3423378   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 731          |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0016470604 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0123       |
|    cost_value_loss       | 5.08e-06     |
|    cost_values           | 0.0123       |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.741        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.74         |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.962        |
|    value_loss            | 6.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.957        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.957        |
| reward                   | -0.45972508  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 754          |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0057422305 |
|    clip_fraction         | 0.0599       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00992      |
|    cost_value_loss       | 4.96e-06     |
|    cost_values           | 0.0101       |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0627       |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.00598     |
|    std                   | 0.963        |
|    value_loss            | 0.569        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.999       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.999       |
| reward                   | -0.52210516 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 776         |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.005337725 |
|    clip_fraction         | 0.0574      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00894     |
|    cost_value_loss       | 4.5e-06     |
|    cost_values           | 0.00904     |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0483      |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -0.00766    |
|    std                   | 0.959       |
|    value_loss            | 0.231       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.219       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.219       |
| reward                   | -0.27133718 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 798         |
|    total_timesteps       | 876544      |
| train/                   |             |
|    approx_kl             | 0.004949497 |
|    clip_fraction         | 0.0129      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00788     |
|    cost_value_loss       | 1.06e-05    |
|    cost_values           | 0.00811     |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.577       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 4270        |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 0.957       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.31         |
| reward                   | -0.41664985  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 820          |
|    total_timesteps       | 878592       |
| train/                   |              |
|    approx_kl             | 0.0035029908 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00586      |
|    cost_value_loss       | 5.59e-06     |
|    cost_values           | 0.00594      |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.696        |
|    n_updates             | 4280         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.957        |
|    value_loss            | 1.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.232        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.232        |
| reward                   | -0.34217513  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 842          |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0034633293 |
|    clip_fraction         | 0.0659       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00745      |
|    cost_value_loss       | 6.64e-06     |
|    cost_values           | 0.00764      |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.337        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.521        |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 0.952        |
|    value_loss            | 1.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.38077244  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 864          |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0075311707 |
|    clip_fraction         | 0.0749       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000841     |
|    cost_value_loss       | 5.06e-06     |
|    cost_values           | 0.000756     |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.102        |
|    n_updates             | 4300         |
|    policy_gradient_loss  | -0.00609     |
|    std                   | 0.951        |
|    value_loss            | 0.492        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.346       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.346       |
| reward                   | -0.28880852 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 886         |
|    total_timesteps       | 884736      |
| train/                   |             |
|    approx_kl             | 0.003074364 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00102     |
|    cost_value_loss       | 2.33e-06    |
|    cost_values           | 0.000997    |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0682      |
|    n_updates             | 4310        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.949       |
|    value_loss            | 0.408       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.432       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.432       |
| reward                   | -0.57443535 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 908         |
|    total_timesteps       | 886784      |
| train/                   |             |
|    approx_kl             | 0.002779895 |
|    clip_fraction         | 0.00503     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00452     |
|    cost_value_loss       | 2.63e-06    |
|    cost_values           | 0.0046      |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.718       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.05        |
|    n_updates             | 4320        |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.947       |
|    value_loss            | 3.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.228       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.228       |
| reward                   | -0.32935533 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 930         |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.003896599 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00492    |
|    cost_value_loss       | 1.5e-05     |
|    cost_values           | -0.00459    |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.09        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.947       |
|    value_loss            | 2.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.444        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.444        |
| reward                   | -0.23922947  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 952          |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0009873672 |
|    clip_fraction         | 0.00381      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00443     |
|    cost_value_loss       | 2.48e-05     |
|    cost_values           | -0.00401     |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.724        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.659        |
|    n_updates             | 4340         |
|    policy_gradient_loss  | 4.55e-05     |
|    std                   | 0.946        |
|    value_loss            | 2.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.19        |
| reward                   | -0.30511168 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 975         |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.003562119 |
|    clip_fraction         | 0.00903     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00299    |
|    cost_value_loss       | 1.26e-05    |
|    cost_values           | -0.00295    |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -0.381      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.03        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.947       |
|    value_loss            | 2.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.208       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.208       |
| reward                   | -0.4658849  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 997         |
|    total_timesteps       | 894976      |
| train/                   |             |
|    approx_kl             | 0.004978827 |
|    clip_fraction         | 0.0111      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00779    |
|    cost_value_loss       | 8.24e-06    |
|    cost_values           | -0.00778    |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.496       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.09        |
|    n_updates             | 4360        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.948       |
|    value_loss            | 5.42        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.43       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.43       |
| reward                   | -0.5361448 |
| rollout/                 |            |
|    ep_len_mean           | 990        |
|    ep_rew_mean           | -447       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 46         |
|    time_elapsed          | 1019       |
|    total_timesteps       | 897024     |
| train/                   |            |
|    approx_kl             | 0.00513344 |
|    clip_fraction         | 0.0144     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00884   |
|    cost_value_loss       | 1.92e-05   |
|    cost_values           | -0.00932   |
|    entropy               | -2.72      |
|    entropy_loss          | -2.71      |
|    explained_variance    | 0.655      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.365      |
|    n_updates             | 4370       |
|    policy_gradient_loss  | -0.00155   |
|    std                   | 0.95       |
|    value_loss            | 1.13       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -1.3302505  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 899072      |
| train/                   |             |
|    approx_kl             | 0.007962576 |
|    clip_fraction         | 0.0477      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0087     |
|    cost_value_loss       | 1.18e-06    |
|    cost_values           | -0.00867    |
|    entropy               | -2.69       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -5.14e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.194       |
|    n_updates             | 4380        |
|    policy_gradient_loss  | -0.00594    |
|    std                   | 0.939       |
|    value_loss            | 0.398       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.18        |
| reward                   | -0.25615942 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -457        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.007370869 |
|    clip_fraction         | 0.0895      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00738    |
|    cost_value_loss       | 8.54e-07    |
|    cost_values           | -0.00734    |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | -0.000242   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.4        |
|    n_updates             | 4390        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.937       |
|    value_loss            | 53.4        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.139         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.139         |
| reward                   | -0.47787288   |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -454          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 49            |
|    time_elapsed          | 1085          |
|    total_timesteps       | 903168        |
| train/                   |               |
|    approx_kl             | 0.00087911385 |
|    clip_fraction         | 0.000537      |
|    clip_range            | 0.2           |
|    cost_returns          | -0.00623      |
|    cost_value_loss       | 1.6e-06       |
|    cost_values           | -0.00624      |
|    entropy               | -2.69         |
|    entropy_loss          | -2.69         |
|    explained_variance    | 0.315         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 30.8          |
|    n_updates             | 4400          |
|    policy_gradient_loss  | -0.00174      |
|    std                   | 0.937         |
|    value_loss            | 67.7          |
--------------------------------------------
-----------------------------------
| avg_speed          | 0.091      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.091      |
| reward             | -0.5338429 |
| rollout/           |            |
|    ep_len_mean     | 990        |
|    ep_rew_mean     | -454       |
| time/              |            |
|    fps             | 96         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 905216     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.304       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.304       |
| reward                   | -0.381071   |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 907264      |
| train/                   |             |
|    approx_kl             | 0.003043081 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00319    |
|    cost_value_loss       | 6.58e-06    |
|    cost_values           | -0.00344    |
|    entropy               | -2.7        |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.837       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0314      |
|    n_updates             | 4420        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.94        |
|    value_loss            | 0.294       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.134       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.134       |
| reward                   | -0.51862836 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 909312      |
| train/                   |             |
|    approx_kl             | 0.00540064  |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00467    |
|    cost_value_loss       | 6.34e-06    |
|    cost_values           | -0.00499    |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.379       |
|    n_updates             | 4430        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.942       |
|    value_loss            | 1.17        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.467         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.467         |
| reward                   | -0.45436373   |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -450          |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 4             |
|    time_elapsed          | 87            |
|    total_timesteps       | 911360        |
| train/                   |               |
|    approx_kl             | 0.00024292764 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | -0.00254      |
|    cost_value_loss       | 9.77e-08      |
|    cost_values           | -0.00256      |
|    entropy               | -2.7          |
|    entropy_loss          | -2.7          |
|    explained_variance    | 3.4e-06       |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.26          |
|    n_updates             | 4440          |
|    policy_gradient_loss  | -0.000202     |
|    std                   | 0.943         |
|    value_loss            | 3.71          |
--------------------------------------------
-----------------------------------------
| avg_speed                | 0.32       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.32       |
| reward                   | -0.5271073 |
| rollout/                 |            |
|    ep_len_mean           | 990        |
|    ep_rew_mean           | -448       |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 5          |
|    time_elapsed          | 109        |
|    total_timesteps       | 913408     |
| train/                   |            |
|    approx_kl             | 0.00631487 |
|    clip_fraction         | 0.105      |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00142   |
|    cost_value_loss       | 1.37e-06   |
|    cost_values           | -0.00142   |
|    entropy               | -2.7       |
|    entropy_loss          | -2.7       |
|    explained_variance    | 0.939      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.0793     |
|    n_updates             | 4450       |
|    policy_gradient_loss  | -0.00702   |
|    std                   | 0.941      |
|    value_loss            | 0.22       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.251        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.251        |
| reward                   | -0.49088717  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 131          |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0015239811 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00135     |
|    cost_value_loss       | 1.41e-06     |
|    cost_values           | -0.00144     |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | -0.691       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.62         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | 0.0013       |
|    std                   | 0.94         |
|    value_loss            | 6.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.131       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.131       |
| reward                   | -0.4156245  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.004571929 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00377    |
|    cost_value_loss       | 4.53e-06    |
|    cost_values           | -0.0039     |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | -0.0998     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.00376    |
|    std                   | 0.938       |
|    value_loss            | 5.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0628       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0628       |
| reward                   | -0.46009535  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 919552       |
| train/                   |              |
|    approx_kl             | 0.0019115558 |
|    clip_fraction         | 0.00259      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00169      |
|    cost_value_loss       | 1.12e-05     |
|    cost_values           | 0.00158      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -15.1        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.82         |
|    n_updates             | 4480         |
|    policy_gradient_loss  | -0.000428    |
|    std                   | 0.937        |
|    value_loss            | 4.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.264        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.264        |
| reward                   | -0.2824149   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 921600       |
| train/                   |              |
|    approx_kl             | 0.0048896354 |
|    clip_fraction         | 0.0443       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00188     |
|    cost_value_loss       | 5.37e-06     |
|    cost_values           | -0.00182     |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.798        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.161        |
|    n_updates             | 4490         |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 0.937        |
|    value_loss            | 0.469        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.44         |
| reward                   | -0.36930108  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0043476615 |
|    clip_fraction         | 0.00869      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0069       |
|    cost_value_loss       | 8.44e-07     |
|    cost_values           | 0.00699      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 6.91e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.934        |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.937        |
|    value_loss            | 2.46         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.224       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.224       |
| reward                   | -0.5516312  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 242         |
|    total_timesteps       | 925696      |
| train/                   |             |
|    approx_kl             | 0.004094345 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00345     |
|    cost_value_loss       | 5.21e-06    |
|    cost_values           | 0.00351     |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.32        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.88        |
|    n_updates             | 4510        |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 0.937       |
|    value_loss            | 4.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.354        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.354        |
| reward                   | -0.43276948  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 264          |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0061124275 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00395      |
|    cost_value_loss       | 1.68e-06     |
|    cost_values           | 0.00399      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -0.0416      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 4520         |
|    policy_gradient_loss  | -0.00491     |
|    std                   | 0.937        |
|    value_loss            | 36.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.28         |
| reward                   | -1.2340871   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 929792       |
| train/                   |              |
|    approx_kl             | 0.0020381666 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000162     |
|    cost_value_loss       | 1.15e-06     |
|    cost_values           | 0.000119     |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.111        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 100          |
|    n_updates             | 4530         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.937        |
|    value_loss            | 238          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.55         |
| reward                   | -1.8040345   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 308          |
|    total_timesteps       | 931840       |
| train/                   |              |
|    approx_kl             | 0.0011124213 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00224      |
|    cost_value_loss       | 4.33e-07     |
|    cost_values           | 0.00224      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.177        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.6          |
|    n_updates             | 4540         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.937        |
|    value_loss            | 20.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.22         |
| reward                   | -0.24080306  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 330          |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0019989477 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00239      |
|    cost_value_loss       | 3.84e-07     |
|    cost_values           | 0.00243      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.00961      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.2         |
|    n_updates             | 4550         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.937        |
|    value_loss            | 106          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.886        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.886        |
| reward                   | -0.5836505   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 353          |
|    total_timesteps       | 935936       |
| train/                   |              |
|    approx_kl             | 0.0009266512 |
|    clip_fraction         | 0.00723      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00204      |
|    cost_value_loss       | 6.56e-08     |
|    cost_values           | 0.00205      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 6.14e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.2         |
|    n_updates             | 4560         |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 0.937        |
|    value_loss            | 43.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.504       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.504       |
| reward                   | -0.52840334 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 375         |
|    total_timesteps       | 937984      |
| train/                   |             |
|    approx_kl             | 0.002198515 |
|    clip_fraction         | 0.00259     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000467   |
|    cost_value_loss       | 1.74e-06    |
|    cost_values           | -0.000423   |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.0739      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.587       |
|    n_updates             | 4570        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.936       |
|    value_loss            | 2.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.231        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.231        |
| reward                   | -0.24454935  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 397          |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0014093827 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000175    |
|    cost_value_loss       | 1.64e-08     |
|    cost_values           | -0.000214    |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.000667     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.9         |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.935        |
|    value_loss            | 114          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.13          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.13          |
| reward                   | -0.47505856   |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -487          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 19            |
|    time_elapsed          | 419           |
|    total_timesteps       | 942080        |
| train/                   |               |
|    approx_kl             | 0.00089619413 |
|    clip_fraction         | 0.00137       |
|    clip_range            | 0.2           |
|    cost_returns          | -7.06e-05     |
|    cost_value_loss       | 2.95e-07      |
|    cost_values           | -6.76e-05     |
|    entropy               | -2.68         |
|    entropy_loss          | -2.68         |
|    explained_variance    | 0.0129        |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 72.3          |
|    n_updates             | 4590          |
|    policy_gradient_loss  | -0.0015       |
|    std                   | 0.936         |
|    value_loss            | 147           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.48         |
| reward                   | -0.484946    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 441          |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0021578362 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | -3.49e-05    |
|    cost_value_loss       | 1.13e-07     |
|    cost_values           | -3.56e-05    |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.00642      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 67.9         |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.936        |
|    value_loss            | 131          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0544        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0544        |
| reward                   | -0.2516943    |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -499          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 21            |
|    time_elapsed          | 463           |
|    total_timesteps       | 946176        |
| train/                   |               |
|    approx_kl             | 0.00069433055 |
|    clip_fraction         | 0.000195      |
|    clip_range            | 0.2           |
|    cost_returns          | -4.95e-05     |
|    cost_value_loss       | 1.53e-07      |
|    cost_values           | -5.23e-05     |
|    entropy               | -2.68         |
|    entropy_loss          | -2.68         |
|    explained_variance    | 0.0123        |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 60            |
|    n_updates             | 4610          |
|    policy_gradient_loss  | -0.00102      |
|    std                   | 0.936         |
|    value_loss            | 125           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.252        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.252        |
| reward                   | -0.40100518  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 485          |
|    total_timesteps       | 948224       |
| train/                   |              |
|    approx_kl             | 0.0044527203 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000215    |
|    cost_value_loss       | 2.49e-06     |
|    cost_values           | -0.000222    |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.102        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.81         |
|    n_updates             | 4620         |
|    policy_gradient_loss  | -0.00512     |
|    std                   | 0.939        |
|    value_loss            | 5.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.121        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.121        |
| reward                   | -0.3170895   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 507          |
|    total_timesteps       | 950272       |
| train/                   |              |
|    approx_kl             | 0.0031356832 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000856     |
|    cost_value_loss       | 0.000132     |
|    cost_values           | 0.00142      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.38         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 4630         |
|    policy_gradient_loss  | -0.00468     |
|    std                   | 0.941        |
|    value_loss            | 36.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.71         |
| reward                   | -0.45398128  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 529          |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0046951943 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00196      |
|    cost_value_loss       | 7.87e-06     |
|    cost_values           | 0.0021       |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.121        |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.939        |
|    value_loss            | 0.419        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.451        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.451        |
| reward                   | -0.32834703  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 551          |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0010179599 |
|    clip_fraction         | 0.00366      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0037       |
|    cost_value_loss       | 3.79e-05     |
|    cost_values           | 0.00435      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.421        |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.000199    |
|    std                   | 0.94         |
|    value_loss            | 1.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.384       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.384       |
| reward                   | -0.6151506  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -500        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 574         |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.005810883 |
|    clip_fraction         | 0.018       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00119    |
|    cost_value_loss       | 8.6e-06     |
|    cost_values           | -0.00121    |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | -0.00703    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.01        |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 0.941       |
|    value_loss            | 2.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.26         |
| reward                   | -0.5629843   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -502         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 596          |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0044114813 |
|    clip_fraction         | 0.00776      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00291     |
|    cost_value_loss       | 1.1e-05      |
|    cost_values           | -0.00314     |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | -4.9         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.88         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.942        |
|    value_loss            | 5.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.365        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.365        |
| reward                   | -0.28825063  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 618          |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0038099112 |
|    clip_fraction         | 0.00884      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00247     |
|    cost_value_loss       | 4.09e-06     |
|    cost_values           | -0.00252     |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | -1.08        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.26         |
|    n_updates             | 4680         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.941        |
|    value_loss            | 3.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.108        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.108        |
| reward                   | -0.58281595  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 640          |
|    total_timesteps       | 962560       |
| train/                   |              |
|    approx_kl             | 0.0043461737 |
|    clip_fraction         | 0.0061       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00683     |
|    cost_value_loss       | 9.77e-06     |
|    cost_values           | -0.00688     |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.58         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.439        |
|    n_updates             | 4690         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.94         |
|    value_loss            | 2.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.97553915 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 662         |
|    total_timesteps       | 964608      |
| train/                   |             |
|    approx_kl             | 0.004313578 |
|    clip_fraction         | 0.00952     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0043     |
|    cost_value_loss       | 3.81e-05    |
|    cost_values           | -0.00396    |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.717       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.412       |
|    n_updates             | 4700        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.939       |
|    value_loss            | 1.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.24         |
| reward                   | -0.4863463   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 684          |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0022794022 |
|    clip_fraction         | 0.00347      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00444      |
|    cost_value_loss       | 7.81e-07     |
|    cost_values           | 0.00429      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -7.01e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.939        |
|    value_loss            | 25.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0434      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0434      |
| reward                   | -0.54144377 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 706         |
|    total_timesteps       | 968704      |
| train/                   |             |
|    approx_kl             | 0.00814919  |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00222    |
|    cost_value_loss       | 4.56e-06    |
|    cost_values           | -0.00209    |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.704       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.63        |
|    n_updates             | 4720        |
|    policy_gradient_loss  | -0.00808    |
|    std                   | 0.939       |
|    value_loss            | 11.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.0914179   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 728          |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0023588995 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00151      |
|    cost_value_loss       | 3.58e-06     |
|    cost_values           | 0.0015       |
|    entropy               | -2.68        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0521       |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.000896    |
|    std                   | 0.933        |
|    value_loss            | 0.282        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -1.7559341  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -516        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 751         |
|    total_timesteps       | 972800      |
| train/                   |             |
|    approx_kl             | 0.007823179 |
|    clip_fraction         | 0.0741      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000863    |
|    cost_value_loss       | 8.91e-05    |
|    cost_values           | 0.000986    |
|    entropy               | -2.66       |
|    entropy_loss          | -2.67       |
|    explained_variance    | -5.08e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.42        |
|    n_updates             | 4740        |
|    policy_gradient_loss  | -0.00577    |
|    std                   | 0.928       |
|    value_loss            | 6.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0943      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0943      |
| reward                   | -0.5246726  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -525        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 773         |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.038299315 |
|    clip_fraction         | 0.304       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0181      |
|    cost_value_loss       | 0.000549    |
|    cost_values           | 0.0378      |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 1.25e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67.1        |
|    n_updates             | 4750        |
|    policy_gradient_loss  | 0.0155      |
|    std                   | 0.927       |
|    value_loss            | 141         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.212        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.212        |
| reward                   | -0.42283875  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 795          |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0024981033 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0105       |
|    cost_value_loss       | 6.81e-06     |
|    cost_values           | 0.00982      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.541        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.7         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 0.926        |
|    value_loss            | 37.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0867        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0867        |
| reward                   | -0.45003304   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -524          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 37            |
|    time_elapsed          | 817           |
|    total_timesteps       | 978944        |
| train/                   |               |
|    approx_kl             | 0.00070747104 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0136        |
|    cost_value_loss       | 3.12e-06      |
|    cost_values           | 0.014         |
|    entropy               | -2.66         |
|    entropy_loss          | -2.66         |
|    explained_variance    | -0.109        |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.75          |
|    n_updates             | 4770          |
|    policy_gradient_loss  | -0.00128      |
|    std                   | 0.926         |
|    value_loss            | 13.9          |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.0769      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0769      |
| reward                   | -0.29137167 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 839         |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.00476384  |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00968     |
|    cost_value_loss       | 2.55e-06    |
|    cost_values           | 0.0098      |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.139       |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.927       |
|    value_loss            | 0.748       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.509        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.509        |
| reward                   | -0.24056606  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -523         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 862          |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0016383507 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0093       |
|    cost_value_loss       | 1.37e-06     |
|    cost_values           | 0.00948      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -1.84e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.9          |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -0.000499    |
|    std                   | 0.928        |
|    value_loss            | 7.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.109       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.109       |
| reward                   | -0.5127688  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 884         |
|    total_timesteps       | 985088      |
| train/                   |             |
|    approx_kl             | 0.004560288 |
|    clip_fraction         | 0.0375      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00211     |
|    cost_value_loss       | 3.79e-05    |
|    cost_values           | 0.00218     |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0561      |
|    n_updates             | 4800        |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.929       |
|    value_loss            | 0.186       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0963       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0963       |
| reward                   | -0.55670524  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 907          |
|    total_timesteps       | 987136       |
| train/                   |              |
|    approx_kl             | 0.0019714665 |
|    clip_fraction         | 0.00649      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0205       |
|    cost_value_loss       | 0.000127     |
|    cost_values           | 0.0248       |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -1.67e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.61         |
|    n_updates             | 4810         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.928        |
|    value_loss            | 8.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.4282091   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -521         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 928          |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0035055054 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0178       |
|    cost_value_loss       | 6.36e-06     |
|    cost_values           | 0.0177       |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.0627       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.64         |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.929        |
|    value_loss            | 4.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.278        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.278        |
| reward                   | -0.37209424  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 951          |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0042551486 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00469     |
|    cost_value_loss       | 3.1e-06      |
|    cost_values           | -0.0045      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.854        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0873       |
|    n_updates             | 4830         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.925        |
|    value_loss            | 0.537        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.333        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.333        |
| reward                   | -0.49456808  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 973          |
|    total_timesteps       | 993280       |
| train/                   |              |
|    approx_kl             | 0.0019113347 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00415     |
|    cost_value_loss       | 5.17e-06     |
|    cost_values           | -0.00392     |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.438        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.882        |
|    n_updates             | 4840         |
|    policy_gradient_loss  | -0.000233    |
|    std                   | 0.924        |
|    value_loss            | 2.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.285        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.285        |
| reward                   | -0.26444268  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -523         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 996          |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0040118247 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00436     |
|    cost_value_loss       | 4.29e-07     |
|    cost_values           | -0.00439     |
|    entropy               | -2.66        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.695        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.71         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.925        |
|    value_loss            | 1.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.467       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.467       |
| reward                   | -0.32296738 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -521        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1018        |
|    total_timesteps       | 997376      |
| train/                   |             |
|    approx_kl             | 0.003490947 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00265    |
|    cost_value_loss       | 3.59e-07    |
|    cost_values           | -0.0027     |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.295       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.804       |
|    n_updates             | 4860        |
|    policy_gradient_loss  | -0.000935   |
|    std                   | 0.926       |
|    value_loss            | 2.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.142       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.142       |
| reward                   | -0.30669478 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -512        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1040        |
|    total_timesteps       | 999424      |
| train/                   |             |
|    approx_kl             | 0.005633671 |
|    clip_fraction         | 0.044       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00244    |
|    cost_value_loss       | 2.53e-07    |
|    cost_values           | -0.00244    |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | -1.54       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.25        |
|    n_updates             | 4870        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.925       |
|    value_loss            | 3.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.21         |
| reward                   | -0.73309785  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 1001472      |
| train/                   |              |
|    approx_kl             | 0.0058723376 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00239     |
|    cost_value_loss       | 9.94e-08     |
|    cost_values           | -0.00245     |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.41         |
|    n_updates             | 4880         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.924        |
|    value_loss            | 6.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.128        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.128        |
| reward                   | -0.4772507   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -508         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0049668774 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00196     |
|    cost_value_loss       | 5.55e-08     |
|    cost_values           | -0.00197     |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.64         |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.927        |
|    value_loss            | 3.61         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.0241      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0241      |
| reward             | -0.24284397 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -508        |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1005568     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.285        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.285        |
| reward                   | -0.35944584  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0024452307 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000272    |
|    cost_value_loss       | 5.52e-06     |
|    cost_values           | -0.000436    |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.139        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.1          |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.000638    |
|    std                   | 0.93         |
|    value_loss            | 3.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0674       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0674       |
| reward                   | -0.28848502  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 1009664      |
| train/                   |              |
|    approx_kl             | 0.0054033203 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00135      |
|    cost_value_loss       | 6.47e-06     |
|    cost_values           | 0.00122      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.811        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.228        |
|    n_updates             | 4920         |
|    policy_gradient_loss  | -0.00437     |
|    std                   | 0.928        |
|    value_loss            | 1.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3            |
| reward                   | -0.34784085  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 1011712      |
| train/                   |              |
|    approx_kl             | 0.0050064903 |
|    clip_fraction         | 0.0617       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000557     |
|    cost_value_loss       | 1.54e-05     |
|    cost_values           | 0.000977     |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.923        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.456        |
|    n_updates             | 4930         |
|    policy_gradient_loss  | -0.00612     |
|    std                   | 0.927        |
|    value_loss            | 1.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.34316722  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1013760      |
| train/                   |              |
|    approx_kl             | 0.0027873477 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00454      |
|    cost_value_loss       | 3.37e-07     |
|    cost_values           | 0.0046       |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -2.28e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.521        |
|    n_updates             | 4940         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.924        |
|    value_loss            | 1.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.134        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.134        |
| reward                   | -0.23266518  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 1015808      |
| train/                   |              |
|    approx_kl             | 0.0056310575 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00374      |
|    cost_value_loss       | 2.9e-07      |
|    cost_values           | 0.00373      |
|    entropy               | -2.64        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -9.3e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.44         |
|    n_updates             | 4950         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.918        |
|    value_loss            | 3.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.206        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.206        |
| reward                   | -0.5480764   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0064117154 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00126     |
|    cost_value_loss       | 6e-06        |
|    cost_values           | -0.00116     |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.256        |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.916        |
|    value_loss            | 1.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.197        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.197        |
| reward                   | -0.44472042  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 1019904      |
| train/                   |              |
|    approx_kl             | 0.0029465465 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000895     |
|    cost_value_loss       | 1.3e-06      |
|    cost_values           | 0.000881     |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.891        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.445        |
|    n_updates             | 4970         |
|    policy_gradient_loss  | -0.000425    |
|    std                   | 0.915        |
|    value_loss            | 1.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.286        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.286        |
| reward                   | -0.41507277  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0042987983 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00807     |
|    cost_value_loss       | 1.79e-05     |
|    cost_values           | -0.0079      |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.801        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.22         |
|    n_updates             | 4980         |
|    policy_gradient_loss  | -0.00267     |
|    std                   | 0.912        |
|    value_loss            | 2.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0392       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0392       |
| reward                   | -0.47517982  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -502         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 1024000      |
| train/                   |              |
|    approx_kl             | 0.0026245965 |
|    clip_fraction         | 0.00156      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00276     |
|    cost_value_loss       | 1.2e-05      |
|    cost_values           | -0.00261     |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.5          |
|    n_updates             | 4990         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.91         |
|    value_loss            | 4.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.194       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.194       |
| reward                   | -0.24974613 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -501        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 242         |
|    total_timesteps       | 1026048     |
| train/                   |             |
|    approx_kl             | 0.004548461 |
|    clip_fraction         | 0.0471      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00845    |
|    cost_value_loss       | 7.52e-06    |
|    cost_values           | -0.00905    |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | -0.107      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0515      |
|    n_updates             | 5000        |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.91        |
|    value_loss            | 1.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.27         |
| reward                   | -0.5650187   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 264          |
|    total_timesteps       | 1028096      |
| train/                   |              |
|    approx_kl             | 0.0072025675 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00462     |
|    cost_value_loss       | 6.97e-06     |
|    cost_values           | -0.00361     |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.00953      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.152        |
|    n_updates             | 5010         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.908        |
|    value_loss            | 1            |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.569       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.569       |
| reward                   | -0.30957493 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 13          |
|    time_elapsed          | 286         |
|    total_timesteps       | 1030144     |
| train/                   |             |
|    approx_kl             | 0.004475073 |
|    clip_fraction         | 0.0187      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000804    |
|    cost_value_loss       | 1.78e-06    |
|    cost_values           | 0.000905    |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0443      |
|    n_updates             | 5020        |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.902       |
|    value_loss            | 0.653       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0851       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0851       |
| reward                   | -0.4615614   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 308          |
|    total_timesteps       | 1032192      |
| train/                   |              |
|    approx_kl             | 0.0046857083 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00356      |
|    cost_value_loss       | 2.43e-07     |
|    cost_values           | 0.00362      |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 9.41e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.47         |
|    n_updates             | 5030         |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 0.899        |
|    value_loss            | 5.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.84         |
| reward                   | -0.5851317   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 330          |
|    total_timesteps       | 1034240      |
| train/                   |              |
|    approx_kl             | 0.0013859881 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00244      |
|    cost_value_loss       | 3.44e-07     |
|    cost_values           | 0.00247      |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.503        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.28         |
|    n_updates             | 5040         |
|    policy_gradient_loss  | -0.000661    |
|    std                   | 0.899        |
|    value_loss            | 8.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.25        |
| reward                   | -0.6025866  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 352         |
|    total_timesteps       | 1036288     |
| train/                   |             |
|    approx_kl             | 0.002285782 |
|    clip_fraction         | 0.00527     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000663   |
|    cost_value_loss       | 4e-06       |
|    cost_values           | -0.000438   |
|    entropy               | -2.6        |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.166       |
|    n_updates             | 5050        |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.9         |
|    value_loss            | 1.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.501        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.501        |
| reward                   | -0.44112083  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 374          |
|    total_timesteps       | 1038336      |
| train/                   |              |
|    approx_kl             | 0.0025708168 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00203      |
|    cost_value_loss       | 9.91e-08     |
|    cost_values           | 0.00211      |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 8.21e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 5060         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.9          |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.287        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.287        |
| reward                   | -0.23545142  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 396          |
|    total_timesteps       | 1040384      |
| train/                   |              |
|    approx_kl             | 0.0024090982 |
|    clip_fraction         | 0.00708      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00162      |
|    cost_value_loss       | 3.91e-08     |
|    cost_values           | 0.00162      |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 1.28e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.925        |
|    n_updates             | 5070         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.899        |
|    value_loss            | 2.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0723      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0723      |
| reward                   | -0.5512834  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 419         |
|    total_timesteps       | 1042432     |
| train/                   |             |
|    approx_kl             | 0.002963656 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00132     |
|    cost_value_loss       | 2.52e-08    |
|    cost_values           | 0.00132     |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | -4.78e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.701       |
|    n_updates             | 5080        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.901       |
|    value_loss            | 1.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.234        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.234        |
| reward                   | -0.3163354   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 441          |
|    total_timesteps       | 1044480      |
| train/                   |              |
|    approx_kl             | 0.0008267114 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00377     |
|    cost_value_loss       | 3.46e-06     |
|    cost_values           | -0.00391     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.648        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.88         |
|    n_updates             | 5090         |
|    policy_gradient_loss  | -0.000169    |
|    std                   | 0.9          |
|    value_loss            | 4.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.273        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.273        |
| reward                   | -0.3895297   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 462          |
|    total_timesteps       | 1046528      |
| train/                   |              |
|    approx_kl             | 0.0043692687 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000477     |
|    cost_value_loss       | 4.31e-07     |
|    cost_values           | 0.000498     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.853        |
|    n_updates             | 5100         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.896        |
|    value_loss            | 1.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.173       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.173       |
| reward                   | -0.49055046 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 484         |
|    total_timesteps       | 1048576     |
| train/                   |             |
|    approx_kl             | 0.004896165 |
|    clip_fraction         | 0.0288      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000339    |
|    cost_value_loss       | 3.45e-07    |
|    cost_values           | 0.000345    |
|    entropy               | -2.57       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.029       |
|    n_updates             | 5110        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.892       |
|    value_loss            | 0.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.143       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.143       |
| reward                   | -0.40040824 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 506         |
|    total_timesteps       | 1050624     |
| train/                   |             |
|    approx_kl             | 0.003665756 |
|    clip_fraction         | 0.0228      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000605    |
|    cost_value_loss       | 1.86e-05    |
|    cost_values           | 0.000331    |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.71        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0958      |
|    n_updates             | 5120        |
|    policy_gradient_loss  | -0.00216    |
|    std                   | 0.892       |
|    value_loss            | 0.833       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.165       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.165       |
| reward                   | -0.31771407 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 1052672     |
| train/                   |             |
|    approx_kl             | 0.004827436 |
|    clip_fraction         | 0.012       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000164    |
|    cost_value_loss       | 8e-06       |
|    cost_values           | 3.14e-05    |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | -1.01       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.19        |
|    n_updates             | 5130        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.893       |
|    value_loss            | 3.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.398        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.398        |
| reward                   | -0.5665912   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 549          |
|    total_timesteps       | 1054720      |
| train/                   |              |
|    approx_kl             | 0.0060491804 |
|    clip_fraction         | 0.0359       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00182      |
|    cost_value_loss       | 1.96e-05     |
|    cost_values           | 0.00169      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | -0.382       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.83         |
|    n_updates             | 5140         |
|    policy_gradient_loss  | -0.00495     |
|    std                   | 0.894        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0325       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0325       |
| reward                   | -0.43812773  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 26           |
|    time_elapsed          | 571          |
|    total_timesteps       | 1056768      |
| train/                   |              |
|    approx_kl             | 0.0012724588 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000323     |
|    cost_value_loss       | 1.01e-08     |
|    cost_values           | 0.000341     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 7.51e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.68         |
|    n_updates             | 5150         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.895        |
|    value_loss            | 4.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00189      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00189      |
| reward                   | -0.45875433  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 593          |
|    total_timesteps       | 1058816      |
| train/                   |              |
|    approx_kl             | 0.0055638915 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000265     |
|    cost_value_loss       | 1.25e-09     |
|    cost_values           | 0.000266     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 2.44e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.652        |
|    n_updates             | 5160         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.893        |
|    value_loss            | 1.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.32834476  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 615          |
|    total_timesteps       | 1060864      |
| train/                   |              |
|    approx_kl             | 0.0035672686 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00121      |
|    cost_value_loss       | 1.23e-05     |
|    cost_values           | 0.00105      |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.532        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.155        |
|    n_updates             | 5170         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.893        |
|    value_loss            | 0.657        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.219        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.219        |
| reward                   | -0.40415347  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 638          |
|    total_timesteps       | 1062912      |
| train/                   |              |
|    approx_kl             | 0.0018840156 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000506     |
|    cost_value_loss       | 5.49e-06     |
|    cost_values           | 0.000607     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.815        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.553        |
|    n_updates             | 5180         |
|    policy_gradient_loss  | -0.000887    |
|    std                   | 0.894        |
|    value_loss            | 1.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0932      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0932      |
| reward                   | -0.35881063 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 30          |
|    time_elapsed          | 660         |
|    total_timesteps       | 1064960     |
| train/                   |             |
|    approx_kl             | 0.005039012 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000102    |
|    cost_value_loss       | 5.02e-06    |
|    cost_values           | 0.000189    |
|    entropy               | -2.57       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.743       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.441       |
|    n_updates             | 5190        |
|    policy_gradient_loss  | -0.00276    |
|    std                   | 0.893       |
|    value_loss            | 1.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.23         |
| reward                   | -0.6126258   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 682          |
|    total_timesteps       | 1067008      |
| train/                   |              |
|    approx_kl             | 0.0035234839 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000358     |
|    cost_value_loss       | 5.09e-09     |
|    cost_values           | 0.000362     |
|    entropy               | -2.6         |
|    entropy_loss          | -2.59        |
|    explained_variance    | -3.58e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.688        |
|    n_updates             | 5200         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.907        |
|    value_loss            | 1.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.227        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.227        |
| reward                   | -0.20835489  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 704          |
|    total_timesteps       | 1069056      |
| train/                   |              |
|    approx_kl             | 0.0041588694 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000297     |
|    cost_value_loss       | 1.35e-09     |
|    cost_values           | 0.000297     |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 6.79e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.04         |
|    n_updates             | 5210         |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 0.907        |
|    value_loss            | 2.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.188        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.188        |
| reward                   | -0.3765336   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 727          |
|    total_timesteps       | 1071104      |
| train/                   |              |
|    approx_kl             | 0.0008561232 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0035      |
|    cost_value_loss       | 2.87e-05     |
|    cost_values           | -0.00299     |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.14         |
|    n_updates             | 5220         |
|    policy_gradient_loss  | -0.000813    |
|    std                   | 0.907        |
|    value_loss            | 3.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.241       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.241       |
| reward                   | -0.4928441  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 749         |
|    total_timesteps       | 1073152     |
| train/                   |             |
|    approx_kl             | 0.004243991 |
|    clip_fraction         | 0.00869     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00314    |
|    cost_value_loss       | 3.67e-06    |
|    cost_values           | -0.00302    |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.7         |
|    n_updates             | 5230        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.907       |
|    value_loss            | 2.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.43973964  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 771          |
|    total_timesteps       | 1075200      |
| train/                   |              |
|    approx_kl             | 0.0046549737 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00177      |
|    cost_value_loss       | 3.81e-07     |
|    cost_values           | 0.00175      |
|    entropy               | -2.61        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.434        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.889        |
|    n_updates             | 5240         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.911        |
|    value_loss            | 1.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0335       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0335       |
| reward                   | -0.47315186  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 793          |
|    total_timesteps       | 1077248      |
| train/                   |              |
|    approx_kl             | 0.0032040118 |
|    clip_fraction         | 0.00937      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00489     |
|    cost_value_loss       | 1.34e-05     |
|    cost_values           | -0.00506     |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.859        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0272       |
|    n_updates             | 5250         |
|    policy_gradient_loss  | 0.000517     |
|    std                   | 0.911        |
|    value_loss            | 0.448        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.417        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.417        |
| reward                   | -0.32333666  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 815          |
|    total_timesteps       | 1079296      |
| train/                   |              |
|    approx_kl             | 0.0046363752 |
|    clip_fraction         | 0.071        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000617    |
|    cost_value_loss       | 3.09e-06     |
|    cost_values           | -0.000598    |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.013        |
|    n_updates             | 5260         |
|    policy_gradient_loss  | -0.00485     |
|    std                   | 0.903        |
|    value_loss            | 0.056        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.293        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.293        |
| reward                   | -0.36646858  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 838          |
|    total_timesteps       | 1081344      |
| train/                   |              |
|    approx_kl             | 0.0018246019 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00143      |
|    cost_value_loss       | 4.62e-07     |
|    cost_values           | 0.00146      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.116        |
|    n_updates             | 5270         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.9          |
|    value_loss            | 0.643        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.159        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.159        |
| reward                   | -0.43585432  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 860          |
|    total_timesteps       | 1083392      |
| train/                   |              |
|    approx_kl             | 0.0042535393 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00277     |
|    cost_value_loss       | 5.13e-06     |
|    cost_values           | -0.00276     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.948        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0601       |
|    n_updates             | 5280         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.902        |
|    value_loss            | 0.237        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.22         |
| reward                   | -0.45055333  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 882          |
|    total_timesteps       | 1085440      |
| train/                   |              |
|    approx_kl             | 0.0019330234 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00213     |
|    cost_value_loss       | 7.43e-06     |
|    cost_values           | -0.00231     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.566        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.134        |
|    n_updates             | 5290         |
|    policy_gradient_loss  | -0.000551    |
|    std                   | 0.903        |
|    value_loss            | 0.831        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.115        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.115        |
| reward                   | -0.39360204  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 904          |
|    total_timesteps       | 1087488      |
| train/                   |              |
|    approx_kl             | 0.0047334973 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00426      |
|    cost_value_loss       | 9.22e-06     |
|    cost_values           | 0.00419      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.292        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.498        |
|    n_updates             | 5300         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 0.903        |
|    value_loss            | 1.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0696      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0696      |
| reward                   | -0.509416   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 926         |
|    total_timesteps       | 1089536     |
| train/                   |             |
|    approx_kl             | 0.005493312 |
|    clip_fraction         | 0.0219      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00194    |
|    cost_value_loss       | 5.91e-06    |
|    cost_values           | -0.00205    |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.791       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.296       |
|    n_updates             | 5310        |
|    policy_gradient_loss  | -0.00241    |
|    std                   | 0.901       |
|    value_loss            | 0.892       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.217        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.217        |
| reward                   | -0.46129104  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 949          |
|    total_timesteps       | 1091584      |
| train/                   |              |
|    approx_kl             | 0.0026114783 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00688     |
|    cost_value_loss       | 1.74e-06     |
|    cost_values           | -0.00679     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.346        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.566        |
|    n_updates             | 5320         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.901        |
|    value_loss            | 1.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.22         |
| reward                   | -0.48194098  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 971          |
|    total_timesteps       | 1093632      |
| train/                   |              |
|    approx_kl             | 0.0045826035 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00627     |
|    cost_value_loss       | 9.51e-07     |
|    cost_values           | -0.00638     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.319        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.17         |
|    n_updates             | 5330         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.902        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.429       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.429       |
| reward                   | -0.25767377 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 993         |
|    total_timesteps       | 1095680     |
| train/                   |             |
|    approx_kl             | 0.015045354 |
|    clip_fraction         | 0.0826      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00332     |
|    cost_value_loss       | 5.29e-06    |
|    cost_values           | 0.00319     |
|    entropy               | -2.59       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0296      |
|    n_updates             | 5340        |
|    policy_gradient_loss  | -0.00519    |
|    std                   | 0.904       |
|    value_loss            | 0.327       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.006        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.006        |
| reward                   | -0.27812177  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1016         |
|    total_timesteps       | 1097728      |
| train/                   |              |
|    approx_kl             | 0.0024972104 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00209     |
|    cost_value_loss       | 6.88e-06     |
|    cost_values           | -0.00183     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.446        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.565        |
|    n_updates             | 5350         |
|    policy_gradient_loss  | -0.000482    |
|    std                   | 0.904        |
|    value_loss            | 1.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0611       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0611       |
| reward                   | -0.46430936  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1038         |
|    total_timesteps       | 1099776      |
| train/                   |              |
|    approx_kl             | 0.0046618637 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00396      |
|    cost_value_loss       | 2.26e-05     |
|    cost_values           | 0.00412      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.155        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.13         |
|    n_updates             | 5360         |
|    policy_gradient_loss  | -0.00427     |
|    std                   | 0.902        |
|    value_loss            | 8.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.38         |
| reward                   | -0.38460988  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1060         |
|    total_timesteps       | 1101824      |
| train/                   |              |
|    approx_kl             | 0.0023910622 |
|    clip_fraction         | 0.0062       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00489      |
|    cost_value_loss       | 3.78e-06     |
|    cost_values           | 0.00491      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.305        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.2         |
|    n_updates             | 5370         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.901        |
|    value_loss            | 74.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.7712159   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1082         |
|    total_timesteps       | 1103872      |
| train/                   |              |
|    approx_kl             | 0.0023738667 |
|    clip_fraction         | 0.00869      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00401      |
|    cost_value_loss       | 1.59e-06     |
|    cost_values           | 0.00412      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.539        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 5380         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.901        |
|    value_loss            | 28           |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/3rk8b0u2/model_epoch(10)
------------------------------------
| avg_speed          | 0.336       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.336       |
| reward             | -0.34169263 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -429        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1105920     |
------------------------------------
-------------------------------------------
| avg_speed                | 7.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.42         |
| reward                   | -1.7927402   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1107968      |
| train/                   |              |
|    approx_kl             | 0.0050087124 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000219    |
|    cost_value_loss       | 7.21e-10     |
|    cost_values           | -0.000221    |
|    entropy               | -2.59        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 1.26e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 5400         |
|    policy_gradient_loss  | -0.00688     |
|    std                   | 0.904        |
|    value_loss            | 18.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.142        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.142        |
| reward                   | -0.32146803  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 1110016      |
| train/                   |              |
|    approx_kl             | 0.0017697795 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00018     |
|    cost_value_loss       | 6.15e-10     |
|    cost_values           | -0.000176    |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 1.37e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.3         |
|    n_updates             | 5410         |
|    policy_gradient_loss  | -0.000742    |
|    std                   | 0.906        |
|    value_loss            | 102          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.223        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.223        |
| reward                   | -0.39653713  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 1112064      |
| train/                   |              |
|    approx_kl             | 0.0010049809 |
|    clip_fraction         | 0.00776      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0067       |
|    cost_value_loss       | 6.96e-06     |
|    cost_values           | 0.00687      |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.406        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.8         |
|    n_updates             | 5420         |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 0.906        |
|    value_loss            | 40           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.46         |
| reward                   | -0.88290197  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 1114112      |
| train/                   |              |
|    approx_kl             | 0.0050546546 |
|    clip_fraction         | 0.0443       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0021       |
|    cost_value_loss       | 7.99e-06     |
|    cost_values           | 0.00206      |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.635        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.126        |
|    n_updates             | 5430         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.905        |
|    value_loss            | 0.261        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.24551357  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 1116160      |
| train/                   |              |
|    approx_kl             | 0.0056351405 |
|    clip_fraction         | 0.0807       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0127       |
|    cost_value_loss       | 2.41e-05     |
|    cost_values           | 0.013        |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.11         |
|    n_updates             | 5440         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.906        |
|    value_loss            | 2.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0639       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0639       |
| reward                   | -0.2518347   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1118208      |
| train/                   |              |
|    approx_kl             | 0.0009874268 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00449      |
|    cost_value_loss       | 7.5e-06      |
|    cost_values           | 0.00464      |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.766        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.19         |
|    n_updates             | 5450         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.906        |
|    value_loss            | 0.674        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0415       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0415       |
| reward                   | -0.42818642  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 1120256      |
| train/                   |              |
|    approx_kl             | 0.0012833292 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00396     |
|    cost_value_loss       | 1.24e-05     |
|    cost_values           | -0.00382     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.499        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.825        |
|    n_updates             | 5460         |
|    policy_gradient_loss  | -0.00065     |
|    std                   | 0.904        |
|    value_loss            | 2.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.314        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.314        |
| reward                   | -0.31735325  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1122304      |
| train/                   |              |
|    approx_kl             | 0.0028408843 |
|    clip_fraction         | 0.00396      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00246     |
|    cost_value_loss       | 5.14e-06     |
|    cost_values           | -0.00245     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.836        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.398        |
|    n_updates             | 5470         |
|    policy_gradient_loss  | -0.000333    |
|    std                   | 0.902        |
|    value_loss            | 1.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.147        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.147        |
| reward                   | -0.4082019   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 1124352      |
| train/                   |              |
|    approx_kl             | 0.0060598007 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00716     |
|    cost_value_loss       | 1.85e-06     |
|    cost_values           | -0.00733     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | -0.856       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.155        |
|    n_updates             | 5480         |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 0.901        |
|    value_loss            | 0.694        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.176        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.176        |
| reward                   | -0.24648371  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 243          |
|    total_timesteps       | 1126400      |
| train/                   |              |
|    approx_kl             | 0.0022246854 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00263     |
|    cost_value_loss       | 2.22e-06     |
|    cost_values           | -0.00272     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.48         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.2         |
|    n_updates             | 5490         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.9          |
|    value_loss            | 103          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00327     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00327     |
| reward                   | -0.43597656 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 1128448     |
| train/                   |             |
|    approx_kl             | 0.003970825 |
|    clip_fraction         | 0.0455      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000446   |
|    cost_value_loss       | 1.08e-06    |
|    cost_values           | -0.000457   |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.487       |
|    n_updates             | 5500        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.898       |
|    value_loss            | 0.972       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00787     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00787     |
| reward                   | -0.2772809  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1130496     |
| train/                   |             |
|    approx_kl             | 0.002251789 |
|    clip_fraction         | 0.000977    |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00183    |
|    cost_value_loss       | 5.13e-07    |
|    cost_values           | -0.00181    |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.302       |
|    n_updates             | 5510        |
|    policy_gradient_loss  | -0.000732   |
|    std                   | 0.898       |
|    value_loss            | 1.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.174        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.174        |
| reward                   | -0.4305464   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 309          |
|    total_timesteps       | 1132544      |
| train/                   |              |
|    approx_kl             | 0.0067054965 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00271     |
|    cost_value_loss       | 6.65e-05     |
|    cost_values           | -0.00301     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | -7.99e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.41         |
|    n_updates             | 5520         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.899        |
|    value_loss            | 2.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.532       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.532       |
| reward                   | -0.27314848 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 331         |
|    total_timesteps       | 1134592     |
| train/                   |             |
|    approx_kl             | 0.016199403 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000183   |
|    cost_value_loss       | 0.00123     |
|    cost_values           | -0.0331     |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | -1.63e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 371         |
|    n_updates             | 5530        |
|    policy_gradient_loss  | 0.00804     |
|    std                   | 0.899       |
|    value_loss            | 757         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0419      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0419      |
| reward                   | -0.5219229  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 353         |
|    total_timesteps       | 1136640     |
| train/                   |             |
|    approx_kl             | 0.004997315 |
|    clip_fraction         | 0.0121      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0109     |
|    cost_value_loss       | 4.24e-06    |
|    cost_values           | -0.0105     |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.03        |
|    n_updates             | 5540        |
|    policy_gradient_loss  | -0.00159    |
|    std                   | 0.899       |
|    value_loss            | 2.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.124        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.124        |
| reward                   | -0.39679873  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 375          |
|    total_timesteps       | 1138688      |
| train/                   |              |
|    approx_kl             | 0.0045281793 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00862     |
|    cost_value_loss       | 2.46e-06     |
|    cost_values           | -0.00865     |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | -0.671       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.818        |
|    n_updates             | 5550         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.898        |
|    value_loss            | 2.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.438        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.438        |
| reward                   | -0.9143659   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 397          |
|    total_timesteps       | 1140736      |
| train/                   |              |
|    approx_kl             | 0.0037336496 |
|    clip_fraction         | 0.00981      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00731     |
|    cost_value_loss       | 1.62e-06     |
|    cost_values           | -0.0074      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.196        |
|    n_updates             | 5560         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.901        |
|    value_loss            | 0.478        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.46         |
| reward                   | -3.1727183   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 419          |
|    total_timesteps       | 1142784      |
| train/                   |              |
|    approx_kl             | 0.0063430006 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0028      |
|    cost_value_loss       | 4.35e-06     |
|    cost_values           | -0.00284     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.791        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.38         |
|    n_updates             | 5570         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.903        |
|    value_loss            | 3.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0277      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0277      |
| reward                   | -0.5590466  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -494        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 441         |
|    total_timesteps       | 1144832     |
| train/                   |             |
|    approx_kl             | 0.001441622 |
|    clip_fraction         | 0.00234     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00364    |
|    cost_value_loss       | 5.56e-07    |
|    cost_values           | -0.00403    |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.346       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 147         |
|    n_updates             | 5580        |
|    policy_gradient_loss  | -0.000887   |
|    std                   | 0.903       |
|    value_loss            | 297         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.022        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.022        |
| reward                   | -0.48161918  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 1146880      |
| train/                   |              |
|    approx_kl             | 0.0012532444 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00324     |
|    cost_value_loss       | 4.06e-07     |
|    cost_values           | -0.00336     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.0501       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 204          |
|    n_updates             | 5590         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.903        |
|    value_loss            | 448          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.154        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.154        |
| reward                   | -0.57156783  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 486          |
|    total_timesteps       | 1148928      |
| train/                   |              |
|    approx_kl             | 0.0020807781 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00264     |
|    cost_value_loss       | 2.79e-07     |
|    cost_values           | -0.00301     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.0303       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 605          |
|    n_updates             | 5600         |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 0.903        |
|    value_loss            | 1.11e+03     |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0245        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0245        |
| reward                   | -0.32956916   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -569          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 23            |
|    time_elapsed          | 508           |
|    total_timesteps       | 1150976       |
| train/                   |               |
|    approx_kl             | 0.00086496706 |
|    clip_fraction         | 0.00225       |
|    clip_range            | 0.2           |
|    cost_returns          | -0.00211      |
|    cost_value_loss       | 2.53e-07      |
|    cost_values           | -0.00229      |
|    entropy               | -2.59         |
|    entropy_loss          | -2.59         |
|    explained_variance    | 0.056         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 463           |
|    n_updates             | 5610          |
|    policy_gradient_loss  | -0.00239      |
|    std                   | 0.903         |
|    value_loss            | 881           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 2.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.22         |
| reward                   | -1.0363806   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -564         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 530          |
|    total_timesteps       | 1153024      |
| train/                   |              |
|    approx_kl             | 0.0016698221 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00187     |
|    cost_value_loss       | 9.9e-08      |
|    cost_values           | -0.00201     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.0133       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 339          |
|    n_updates             | 5620         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.903        |
|    value_loss            | 684          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.368       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.368       |
| reward                   | -0.5392217  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -568        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 552         |
|    total_timesteps       | 1155072     |
| train/                   |             |
|    approx_kl             | 0.004741211 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000874   |
|    cost_value_loss       | 2.79e-06    |
|    cost_values           | -0.000841   |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.321       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 5630        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.903       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -3.7950203   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -573         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 574          |
|    total_timesteps       | 1157120      |
| train/                   |              |
|    approx_kl             | 0.0029920954 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00136     |
|    cost_value_loss       | 7.29e-08     |
|    cost_values           | -0.00135     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.22         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.32         |
|    n_updates             | 5640         |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 0.905        |
|    value_loss            | 6.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.236        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.236        |
| reward                   | -0.48949862  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -593         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 596          |
|    total_timesteps       | 1159168      |
| train/                   |              |
|    approx_kl             | 0.0018646668 |
|    clip_fraction         | 0.00557      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000687    |
|    cost_value_loss       | 1.48e-06     |
|    cost_values           | -0.00078     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.201        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 334          |
|    n_updates             | 5650         |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.905        |
|    value_loss            | 636          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.23        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.23        |
| reward                   | -0.42647076 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -593        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 618         |
|    total_timesteps       | 1161216     |
| train/                   |             |
|    approx_kl             | 0.004787422 |
|    clip_fraction         | 0.0152      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000688   |
|    cost_value_loss       | 8.77e-09    |
|    cost_values           | -0.00069    |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 7.45e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.4        |
|    n_updates             | 5660        |
|    policy_gradient_loss  | -0.0053     |
|    std                   | 0.906       |
|    value_loss            | 80.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0477      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0477      |
| reward                   | -0.35232016 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -592        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 640         |
|    total_timesteps       | 1163264     |
| train/                   |             |
|    approx_kl             | 0.005011645 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00202    |
|    cost_value_loss       | 2.49e-06    |
|    cost_values           | -0.00208    |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0627      |
|    n_updates             | 5670        |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 0.907       |
|    value_loss            | 0.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.391       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.391       |
| reward                   | -0.43375602 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -590        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 664         |
|    total_timesteps       | 1165312     |
| train/                   |             |
|    approx_kl             | 0.004466708 |
|    clip_fraction         | 0.0199      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000888    |
|    cost_value_loss       | 3.25e-06    |
|    cost_values           | 0.000928    |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.189       |
|    n_updates             | 5680        |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.906       |
|    value_loss            | 0.781       |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.51         |
| reward                   | -0.6527099   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -589         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 686          |
|    total_timesteps       | 1167360      |
| train/                   |              |
|    approx_kl             | 0.0021951995 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00285      |
|    cost_value_loss       | 6.87e-07     |
|    cost_values           | 0.00296      |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.48         |
|    n_updates             | 5690         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.905        |
|    value_loss            | 4.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0066      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0066      |
| reward                   | -0.21238533 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -624        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 708         |
|    total_timesteps       | 1169408     |
| train/                   |             |
|    approx_kl             | 0.004532515 |
|    clip_fraction         | 0.00977     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00317     |
|    cost_value_loss       | 1.54e-07    |
|    cost_values           | 0.00321     |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.000109    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.527       |
|    n_updates             | 5700        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.906       |
|    value_loss            | 1.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.287       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.287       |
| reward                   | -0.24971515 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -623        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 730         |
|    total_timesteps       | 1171456     |
| train/                   |             |
|    approx_kl             | 0.000379068 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00224     |
|    cost_value_loss       | 1.84e-07    |
|    cost_values           | 0.0024      |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.119       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 487         |
|    n_updates             | 5710        |
|    policy_gradient_loss  | -0.000974   |
|    std                   | 0.906       |
|    value_loss            | 1.04e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -2.1593308   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -621         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 753          |
|    total_timesteps       | 1173504      |
| train/                   |              |
|    approx_kl             | 0.0028948358 |
|    clip_fraction         | 0.00674      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000503     |
|    cost_value_loss       | 3.68e-06     |
|    cost_values           | 0.000549     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.571        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.84         |
|    n_updates             | 5720         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.907        |
|    value_loss            | 4.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.117       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.117       |
| reward                   | -0.23727967 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -666        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 775         |
|    total_timesteps       | 1175552     |
| train/                   |             |
|    approx_kl             | 0.005976241 |
|    clip_fraction         | 0.0305      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000242   |
|    cost_value_loss       | 3.11e-09    |
|    cost_values           | -0.000244   |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 4.36e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 5730        |
|    policy_gradient_loss  | -0.00837    |
|    std                   | 0.912       |
|    value_loss            | 28.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.168       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.168       |
| reward                   | -0.42689863 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 798         |
|    total_timesteps       | 1177600     |
| train/                   |             |
|    approx_kl             | 0.005149369 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000452   |
|    cost_value_loss       | 6.63e-08    |
|    cost_values           | -0.000454   |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.206       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 858         |
|    n_updates             | 5740        |
|    policy_gradient_loss  | 0.00101     |
|    std                   | 0.914       |
|    value_loss            | 1.74e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.44         |
| reward                   | -0.89382136  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 819          |
|    total_timesteps       | 1179648      |
| train/                   |              |
|    approx_kl             | 0.0004842664 |
|    clip_fraction         | 0.00137      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000413    |
|    cost_value_loss       | 2.8e-07      |
|    cost_values           | -0.000586    |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.268        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 512          |
|    n_updates             | 5750         |
|    policy_gradient_loss  | -0.000961    |
|    std                   | 0.914        |
|    value_loss            | 1.13e+03     |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.463         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.463         |
| reward                   | -0.3034703    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -698          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 38            |
|    time_elapsed          | 842           |
|    total_timesteps       | 1181696       |
| train/                   |               |
|    approx_kl             | 0.00089798286 |
|    clip_fraction         | 0.00112       |
|    clip_range            | 0.2           |
|    cost_returns          | -0.000696     |
|    cost_value_loss       | 2.46e-05      |
|    cost_values           | -0.00108      |
|    entropy               | -2.61         |
|    entropy_loss          | -2.61         |
|    explained_variance    | 0.876         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.22          |
|    n_updates             | 5760          |
|    policy_gradient_loss  | -0.0013       |
|    std                   | 0.915         |
|    value_loss            | 3.79          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0572       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0572       |
| reward                   | -0.6470245   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 864          |
|    total_timesteps       | 1183744      |
| train/                   |              |
|    approx_kl             | 0.0015390583 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00422      |
|    cost_value_loss       | 0.00157      |
|    cost_values           | 0.0185       |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.00621      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 126          |
|    n_updates             | 5770         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.915        |
|    value_loss            | 274          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.278       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.278       |
| reward                   | -0.28370938 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 886         |
|    total_timesteps       | 1185792     |
| train/                   |             |
|    approx_kl             | 0.006405819 |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0422     |
|    cost_value_loss       | 0.000684    |
|    cost_values           | -0.0434     |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.49        |
|    n_updates             | 5780        |
|    policy_gradient_loss  | -0.005      |
|    std                   | 0.918       |
|    value_loss            | 1.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.42783874  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 908          |
|    total_timesteps       | 1187840      |
| train/                   |              |
|    approx_kl             | 0.0046907235 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0353      |
|    cost_value_loss       | 0.000357     |
|    cost_values           | -0.0356      |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.787        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.94         |
|    n_updates             | 5790         |
|    policy_gradient_loss  | -0.00538     |
|    std                   | 0.922        |
|    value_loss            | 13           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0822       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0822       |
| reward                   | -0.40581468  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 930          |
|    total_timesteps       | 1189888      |
| train/                   |              |
|    approx_kl             | 0.0039748144 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00948     |
|    cost_value_loss       | 7.3e-05      |
|    cost_values           | -0.00915     |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.684        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.114        |
|    n_updates             | 5800         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.921        |
|    value_loss            | 0.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0884      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0884      |
| reward                   | -0.2977504  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 953         |
|    total_timesteps       | 1191936     |
| train/                   |             |
|    approx_kl             | 0.009157314 |
|    clip_fraction         | 0.0682      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.023       |
|    cost_value_loss       | 5.9e-05     |
|    cost_values           | 0.0231      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0405      |
|    n_updates             | 5810        |
|    policy_gradient_loss  | -0.00624    |
|    std                   | 0.921       |
|    value_loss            | 0.205       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0922       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0922       |
| reward                   | -0.41274312  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 975          |
|    total_timesteps       | 1193984      |
| train/                   |              |
|    approx_kl             | 0.0030171475 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0108       |
|    cost_value_loss       | 3.66e-05     |
|    cost_values           | 0.01         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.119        |
|    n_updates             | 5820         |
|    policy_gradient_loss  | -0.000777    |
|    std                   | 0.922        |
|    value_loss            | 1.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.12        |
| reward                   | -0.55802506 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 997         |
|    total_timesteps       | 1196032     |
| train/                   |             |
|    approx_kl             | 0.001568739 |
|    clip_fraction         | 0.00493     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0162      |
|    cost_value_loss       | 7.03e-05    |
|    cost_values           | 0.0161      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.303       |
|    n_updates             | 5830        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.923       |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.5174348  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 1198080     |
| train/                   |             |
|    approx_kl             | 0.004313435 |
|    clip_fraction         | 0.00874     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00161    |
|    cost_value_loss       | 0.0005      |
|    cost_values           | 0.000212    |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.49        |
|    n_updates             | 5840        |
|    policy_gradient_loss  | -0.00238    |
|    std                   | 0.922       |
|    value_loss            | 7.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.267        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.267        |
| reward                   | -0.56931376  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1041         |
|    total_timesteps       | 1200128      |
| train/                   |              |
|    approx_kl             | 0.0027056134 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00593      |
|    cost_value_loss       | 7.68e-05     |
|    cost_values           | 0.00566      |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.271        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.7         |
|    n_updates             | 5850         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.922        |
|    value_loss            | 122          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0563      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0563      |
| reward                   | -0.2583381  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 1202176     |
| train/                   |             |
|    approx_kl             | 0.001280247 |
|    clip_fraction         | 0.00435     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0394      |
|    cost_value_loss       | 0.000283    |
|    cost_values           | 0.0438      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.504       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.4        |
|    n_updates             | 5860        |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 0.922       |
|    value_loss            | 86.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -2.1601114  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -694        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 1204224     |
| train/                   |             |
|    approx_kl             | 0.004501627 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0138      |
|    cost_value_loss       | 0.000122    |
|    cost_values           | 0.0117      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.154       |
|    n_updates             | 5870        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.924       |
|    value_loss            | 1.86        |
------------------------------------------
------------------------------------
| avg_speed          | 0.2         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.2         |
| reward             | -0.22318162 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -710        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1206272     |
------------------------------------
------------------------------------------
| avg_speed                | 0.0938      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0938      |
| reward                   | -0.31106198 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 1208320     |
| train/                   |             |
|    approx_kl             | 0.001131799 |
|    clip_fraction         | 0.000439    |
|    clip_range            | 0.2         |
|    cost_returns          | -0.007      |
|    cost_value_loss       | 5.45e-05    |
|    cost_values           | -0.0077     |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.323       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 123         |
|    n_updates             | 5890        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.926       |
|    value_loss            | 240         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.107       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.107       |
| reward                   | -0.40492582 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 1210368     |
| train/                   |             |
|    approx_kl             | 0.005049091 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00229     |
|    cost_value_loss       | 0.00155     |
|    cost_values           | 0.00127     |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | -0.244      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0351      |
|    n_updates             | 5900        |
|    policy_gradient_loss  | -0.00564    |
|    std                   | 0.925       |
|    value_loss            | 0.482       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.53717685  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 1212416      |
| train/                   |              |
|    approx_kl             | 0.0054742163 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0234       |
|    cost_value_loss       | 0.000705     |
|    cost_values           | 0.0264       |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.832        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.22         |
|    n_updates             | 5910         |
|    policy_gradient_loss  | -0.000863    |
|    std                   | 0.923        |
|    value_loss            | 0.961        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.171       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.171       |
| reward                   | -0.38294566 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 1214464     |
| train/                   |             |
|    approx_kl             | 0.005114683 |
|    clip_fraction         | 0.0224      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0155      |
|    cost_value_loss       | 0.000898    |
|    cost_values           | 0.00487     |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0286      |
|    n_updates             | 5920        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.922       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0123      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0123      |
| reward                   | -0.40529242 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 1216512     |
| train/                   |             |
|    approx_kl             | 0.007289813 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0643      |
|    cost_value_loss       | 8.94e-05    |
|    cost_values           | 0.0653      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.348       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0703      |
|    n_updates             | 5930        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.922       |
|    value_loss            | 0.554       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.229        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.229        |
| reward                   | -0.4008921   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1218560      |
| train/                   |              |
|    approx_kl             | 0.0058878427 |
|    clip_fraction         | 0.0465       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0341       |
|    cost_value_loss       | 2.97e-05     |
|    cost_values           | 0.0341       |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.73         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.393        |
|    n_updates             | 5940         |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.916        |
|    value_loss            | 0.892        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00625     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00625     |
| reward                   | -0.390577   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 1220608     |
| train/                   |             |
|    approx_kl             | 0.008071447 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00688    |
|    cost_value_loss       | 0.000115    |
|    cost_values           | -0.00607    |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0193      |
|    n_updates             | 5950        |
|    policy_gradient_loss  | -0.00964    |
|    std                   | 0.915       |
|    value_loss            | 0.101       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0199      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0199      |
| reward                   | -0.47433457 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 1222656     |
| train/                   |             |
|    approx_kl             | 0.002731673 |
|    clip_fraction         | 0.0199      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0241     |
|    cost_value_loss       | 0.000276    |
|    cost_values           | -0.0285     |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.521       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.134       |
|    n_updates             | 5960        |
|    policy_gradient_loss  | 0.000257    |
|    std                   | 0.915       |
|    value_loss            | 2.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.745        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.745        |
| reward                   | -0.29839027  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 1224704      |
| train/                   |              |
|    approx_kl             | 0.0066593066 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0135       |
|    cost_value_loss       | 0.000388     |
|    cost_values           | 0.0165       |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.179        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.918        |
|    n_updates             | 5970         |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 0.912        |
|    value_loss            | 2.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.356       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.356       |
| reward                   | -0.35464463 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -689        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 1226752     |
| train/                   |             |
|    approx_kl             | 0.006065911 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00843     |
|    cost_value_loss       | 6.05e-05    |
|    cost_values           | 0.00739     |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.0339      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.14        |
|    n_updates             | 5980        |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 0.91        |
|    value_loss            | 0.922       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0417       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0417       |
| reward                   | -0.56083816  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 265          |
|    total_timesteps       | 1228800      |
| train/                   |              |
|    approx_kl             | 0.0075104237 |
|    clip_fraction         | 0.0603       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00881      |
|    cost_value_loss       | 2.1e-05      |
|    cost_values           | 0.00941      |
|    entropy               | -2.6         |
|    entropy_loss          | -2.59        |
|    explained_variance    | -0.275       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0934       |
|    n_updates             | 5990         |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 0.913        |
|    value_loss            | 0.317        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.451        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.451        |
| reward                   | -0.36365455  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 287          |
|    total_timesteps       | 1230848      |
| train/                   |              |
|    approx_kl             | 0.0040747356 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00841      |
|    cost_value_loss       | 3.57e-05     |
|    cost_values           | 0.00812      |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.312        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.38         |
|    n_updates             | 6000         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.914        |
|    value_loss            | 1.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.247        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.247        |
| reward                   | -0.41567925  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 310          |
|    total_timesteps       | 1232896      |
| train/                   |              |
|    approx_kl             | 0.0042682174 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000861     |
|    cost_value_loss       | 0.000131     |
|    cost_values           | 0.000808     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.527        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.11         |
|    n_updates             | 6010         |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 0.911        |
|    value_loss            | 0.726        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -1.1402525 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -669       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 15         |
|    time_elapsed          | 332        |
|    total_timesteps       | 1234944    |
| train/                   |            |
|    approx_kl             | 0.00886428 |
|    clip_fraction         | 0.123      |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00833   |
|    cost_value_loss       | 1.7e-05    |
|    cost_values           | -0.00847   |
|    entropy               | -2.61      |
|    entropy_loss          | -2.6       |
|    explained_variance    | 0.012      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.0629     |
|    n_updates             | 6020       |
|    policy_gradient_loss  | -0.0045    |
|    std                   | 0.916      |
|    value_loss            | 0.182      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.218        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.218        |
| reward                   | -0.374471    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 1236992      |
| train/                   |              |
|    approx_kl             | 0.0060104285 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00328     |
|    cost_value_loss       | 7e-05        |
|    cost_values           | -0.00345     |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.834        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.35         |
|    n_updates             | 6030         |
|    policy_gradient_loss  | -0.00596     |
|    std                   | 0.916        |
|    value_loss            | 4.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0429       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0429       |
| reward                   | -0.5226021   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 376          |
|    total_timesteps       | 1239040      |
| train/                   |              |
|    approx_kl             | 0.0032319308 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0229      |
|    cost_value_loss       | 5.66e-05     |
|    cost_values           | -0.0239      |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.624        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 61.1         |
|    n_updates             | 6040         |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.915        |
|    value_loss            | 132          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.228       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.228       |
| reward                   | -0.24708581 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 398         |
|    total_timesteps       | 1241088     |
| train/                   |             |
|    approx_kl             | 0.00809778  |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00537    |
|    cost_value_loss       | 2e-05       |
|    cost_values           | -0.00513    |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0622      |
|    n_updates             | 6050        |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.914       |
|    value_loss            | 0.594       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0819       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0819       |
| reward                   | -0.43084583  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 421          |
|    total_timesteps       | 1243136      |
| train/                   |              |
|    approx_kl             | 0.0046176165 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00201      |
|    cost_value_loss       | 3.62e-05     |
|    cost_values           | 0.0024       |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.759        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.264        |
|    n_updates             | 6060         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.912        |
|    value_loss            | 2.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.114        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.114        |
| reward                   | -0.56254333  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -656         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1245184      |
| train/                   |              |
|    approx_kl             | 0.0040734606 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00205      |
|    cost_value_loss       | 4.73e-05     |
|    cost_values           | 0.00228      |
|    entropy               | -2.61        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.645        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0397       |
|    n_updates             | 6070         |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.916        |
|    value_loss            | 0.256        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.074       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.074       |
| reward                   | -0.38967574 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -627        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 465         |
|    total_timesteps       | 1247232     |
| train/                   |             |
|    approx_kl             | 0.004255166 |
|    clip_fraction         | 0.0255      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0122     |
|    cost_value_loss       | 6.07e-05    |
|    cost_values           | -0.0157     |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -20.8       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.082       |
|    n_updates             | 6080        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.918       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -1.5607915  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -604        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 487         |
|    total_timesteps       | 1249280     |
| train/                   |             |
|    approx_kl             | 0.004717004 |
|    clip_fraction         | 0.0406      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0135     |
|    cost_value_loss       | 5.26e-05    |
|    cost_values           | -0.0129     |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.465       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.253       |
|    n_updates             | 6090        |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.919       |
|    value_loss            | 1.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0971       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0971       |
| reward                   | -0.51212555  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -591         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 510          |
|    total_timesteps       | 1251328      |
| train/                   |              |
|    approx_kl             | 0.0036978978 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0436      |
|    cost_value_loss       | 7.91e-05     |
|    cost_values           | -0.0454      |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.798        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 6100         |
|    policy_gradient_loss  | -0.00382     |
|    std                   | 0.919        |
|    value_loss            | 41.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0895      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0895      |
| reward                   | -0.26112953 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -590        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 532         |
|    total_timesteps       | 1253376     |
| train/                   |             |
|    approx_kl             | 0.004868965 |
|    clip_fraction         | 0.0833      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0127     |
|    cost_value_loss       | 1.44e-05    |
|    cost_values           | -0.0133     |
|    entropy               | -2.63       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.765       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0199      |
|    n_updates             | 6110        |
|    policy_gradient_loss  | -0.00768    |
|    std                   | 0.928       |
|    value_loss            | 0.252       |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.138         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.138         |
| reward                   | -0.3329787    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -587          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 25            |
|    time_elapsed          | 553           |
|    total_timesteps       | 1255424       |
| train/                   |               |
|    approx_kl             | 0.00041423072 |
|    clip_fraction         | 0.103         |
|    clip_range            | 0.2           |
|    cost_returns          | -0.0193       |
|    cost_value_loss       | 1.6e-05       |
|    cost_values           | -0.0197       |
|    entropy               | -2.63         |
|    entropy_loss          | -2.63         |
|    explained_variance    | 0.678         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.278         |
|    n_updates             | 6120          |
|    policy_gradient_loss  | -0.000985     |
|    std                   | 0.928         |
|    value_loss            | 0.834         |
--------------------------------------------
------------------------------------------
| avg_speed                | 4.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.86        |
| reward                   | -0.6042385  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -562        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 575         |
|    total_timesteps       | 1257472     |
| train/                   |             |
|    approx_kl             | 0.005441664 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0112     |
|    cost_value_loss       | 2.89e-05    |
|    cost_values           | -0.0115     |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0705      |
|    n_updates             | 6130        |
|    policy_gradient_loss  | -0.000809   |
|    std                   | 0.926       |
|    value_loss            | 0.411       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0229       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0229       |
| reward                   | -0.2281885   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -570         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 598          |
|    total_timesteps       | 1259520      |
| train/                   |              |
|    approx_kl             | 0.0060619544 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0184      |
|    cost_value_loss       | 6.31e-05     |
|    cost_values           | -0.0193      |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.646        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.33         |
|    n_updates             | 6140         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.927        |
|    value_loss            | 3.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.207        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.207        |
| reward                   | -0.28381932  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -574         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 620          |
|    total_timesteps       | 1261568      |
| train/                   |              |
|    approx_kl             | 0.0020766428 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0436      |
|    cost_value_loss       | 0.000206     |
|    cost_values           | -0.0477      |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.692        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.3         |
|    n_updates             | 6150         |
|    policy_gradient_loss  | -0.000474    |
|    std                   | 0.927        |
|    value_loss            | 99.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.33        |
| reward                   | -0.36274195 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -571        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 642         |
|    total_timesteps       | 1263616     |
| train/                   |             |
|    approx_kl             | 0.002730076 |
|    clip_fraction         | 0.0175      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0173     |
|    cost_value_loss       | 0.000136    |
|    cost_values           | -0.0173     |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.767       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 6160        |
|    policy_gradient_loss  | -0.00526    |
|    std                   | 0.928       |
|    value_loss            | 23.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0747      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0747      |
| reward                   | -0.5000528  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -572        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 664         |
|    total_timesteps       | 1265664     |
| train/                   |             |
|    approx_kl             | 0.009351002 |
|    clip_fraction         | 0.0633      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0144      |
|    cost_value_loss       | 1.27e-05    |
|    cost_values           | 0.0145      |
|    entropy               | -2.64       |
|    entropy_loss          | -2.63       |
|    explained_variance    | -1.71       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0902      |
|    n_updates             | 6170        |
|    policy_gradient_loss  | -0.00671    |
|    std                   | 0.934       |
|    value_loss            | 0.395       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.419        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.419        |
| reward                   | -0.5189035   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -576         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 686          |
|    total_timesteps       | 1267712      |
| train/                   |              |
|    approx_kl             | 0.0037356697 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0036       |
|    cost_value_loss       | 6.42e-06     |
|    cost_values           | 0.00337      |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.602        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.421        |
|    n_updates             | 6180         |
|    policy_gradient_loss  | -0.000965    |
|    std                   | 0.938        |
|    value_loss            | 1.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.481       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.481       |
| reward                   | -0.29509923 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -546        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 708         |
|    total_timesteps       | 1269760     |
| train/                   |             |
|    approx_kl             | 0.004621733 |
|    clip_fraction         | 0.0179      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0165     |
|    cost_value_loss       | 8.58e-05    |
|    cost_values           | -0.0181     |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.73        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.3        |
|    n_updates             | 6190        |
|    policy_gradient_loss  | -0.00422    |
|    std                   | 0.939       |
|    value_loss            | 53.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0457       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0457       |
| reward                   | -0.35069472  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 730          |
|    total_timesteps       | 1271808      |
| train/                   |              |
|    approx_kl             | 0.0027564857 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0112       |
|    cost_value_loss       | 5.96e-06     |
|    cost_values           | 0.0113       |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.357        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.513        |
|    n_updates             | 6200         |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 0.938        |
|    value_loss            | 2.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.157       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.157       |
| reward                   | -0.44127253 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -547        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 752         |
|    total_timesteps       | 1273856     |
| train/                   |             |
|    approx_kl             | 0.00455949  |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.005       |
|    cost_value_loss       | 1.26e-05    |
|    cost_values           | 0.00479     |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.641       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.202       |
|    n_updates             | 6210        |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.941       |
|    value_loss            | 0.608       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.199       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.199       |
| reward                   | -0.28970206 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 774         |
|    total_timesteps       | 1275904     |
| train/                   |             |
|    approx_kl             | 0.003541318 |
|    clip_fraction         | 0.0271      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0236     |
|    cost_value_loss       | 6.54e-05    |
|    cost_values           | -0.0232     |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | -1.25       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.137       |
|    n_updates             | 6220        |
|    policy_gradient_loss  | -0.00109    |
|    std                   | 0.945       |
|    value_loss            | 0.419       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0718      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0718      |
| reward                   | -0.5275969  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 796         |
|    total_timesteps       | 1277952     |
| train/                   |             |
|    approx_kl             | 0.007020627 |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0135     |
|    cost_value_loss       | 1.43e-05    |
|    cost_values           | -0.0129     |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.569       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.117       |
|    n_updates             | 6230        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.947       |
|    value_loss            | 1.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00932      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00932      |
| reward                   | -0.55785054  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 819          |
|    total_timesteps       | 1280000      |
| train/                   |              |
|    approx_kl             | 0.0012737577 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0417      |
|    cost_value_loss       | 0.000122     |
|    cost_values           | -0.0449      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 125          |
|    n_updates             | 6240         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.947        |
|    value_loss            | 258          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.03         |
| reward                   | -1.6878638   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 841          |
|    total_timesteps       | 1282048      |
| train/                   |              |
|    approx_kl             | 0.0072885538 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00335     |
|    cost_value_loss       | 1.03e-05     |
|    cost_values           | -0.00347     |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.884        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0991       |
|    n_updates             | 6250         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.947        |
|    value_loss            | 1.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.0861564  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -500        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 863         |
|    total_timesteps       | 1284096     |
| train/                   |             |
|    approx_kl             | 0.001405344 |
|    clip_fraction         | 0.00308     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0252     |
|    cost_value_loss       | 5.36e-05    |
|    cost_values           | -0.0251     |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.749       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28          |
|    n_updates             | 6260        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.947       |
|    value_loss            | 62.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0263       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0263       |
| reward                   | -0.40702742  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 885          |
|    total_timesteps       | 1286144      |
| train/                   |              |
|    approx_kl             | 0.0017776056 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0293      |
|    cost_value_loss       | 8.29e-05     |
|    cost_values           | -0.0306      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.723        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65.8         |
|    n_updates             | 6270         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.948        |
|    value_loss            | 133          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.136       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.136       |
| reward                   | -0.52573544 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 907         |
|    total_timesteps       | 1288192     |
| train/                   |             |
|    approx_kl             | 0.002766043 |
|    clip_fraction         | 0.0119      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00237     |
|    cost_value_loss       | 2.92e-05    |
|    cost_values           | 0.00196     |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.5        |
|    n_updates             | 6280        |
|    policy_gradient_loss  | -0.00627    |
|    std                   | 0.947       |
|    value_loss            | 61.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.141       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.141       |
| reward                   | -0.27782467 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -509        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 930         |
|    total_timesteps       | 1290240     |
| train/                   |             |
|    approx_kl             | 0.003961038 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0116      |
|    cost_value_loss       | 6.91e-06    |
|    cost_values           | 0.0118      |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.369       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.211       |
|    n_updates             | 6290        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.948       |
|    value_loss            | 1.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -2.4113107   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -508         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 952          |
|    total_timesteps       | 1292288      |
| train/                   |              |
|    approx_kl             | 0.0013520839 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0065       |
|    cost_value_loss       | 1.48e-05     |
|    cost_values           | 0.00536      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.709        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.405        |
|    n_updates             | 6300         |
|    policy_gradient_loss  | -0.000419    |
|    std                   | 0.947        |
|    value_loss            | 3.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.51547503  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 973          |
|    total_timesteps       | 1294336      |
| train/                   |              |
|    approx_kl             | 0.0017017248 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.009       |
|    cost_value_loss       | 3.02e-05     |
|    cost_values           | -0.00736     |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 115          |
|    n_updates             | 6310         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.946        |
|    value_loss            | 209          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00526     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00526     |
| reward                   | -0.48701182 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -520        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 995         |
|    total_timesteps       | 1296384     |
| train/                   |             |
|    approx_kl             | 0.008164473 |
|    clip_fraction         | 0.0389      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00131    |
|    cost_value_loss       | 0.000138    |
|    cost_values           | -0.00172    |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.697       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.27        |
|    n_updates             | 6320        |
|    policy_gradient_loss  | -0.0118     |
|    std                   | 0.946       |
|    value_loss            | 8.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.5451033  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1017        |
|    total_timesteps       | 1298432     |
| train/                   |             |
|    approx_kl             | 0.007755232 |
|    clip_fraction         | 0.0613      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00117     |
|    cost_value_loss       | 4.21e-05    |
|    cost_values           | 0.00115     |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0462      |
|    n_updates             | 6330        |
|    policy_gradient_loss  | -0.00412    |
|    std                   | 0.951       |
|    value_loss            | 0.142       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0187       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0187       |
| reward                   | -0.55548614  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1039         |
|    total_timesteps       | 1300480      |
| train/                   |              |
|    approx_kl             | 0.0037883623 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0259      |
|    cost_value_loss       | 9.41e-05     |
|    cost_values           | -0.0278      |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.0277      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.253        |
|    n_updates             | 6340         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.948        |
|    value_loss            | 0.737        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.21622342  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1061         |
|    total_timesteps       | 1302528      |
| train/                   |              |
|    approx_kl             | 0.0020009743 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0023      |
|    cost_value_loss       | 2.39e-05     |
|    cost_values           | -0.00267     |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.434        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 272          |
|    n_updates             | 6350         |
|    policy_gradient_loss  | 0.000631     |
|    std                   | 0.946        |
|    value_loss            | 567          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0914       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0914       |
| reward                   | -0.5101875   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -533         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1084         |
|    total_timesteps       | 1304576      |
| train/                   |              |
|    approx_kl             | 0.0030169326 |
|    clip_fraction         | 0.00571      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0384       |
|    cost_value_loss       | 4.24e-05     |
|    cost_values           | 0.0396       |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.825        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.561        |
|    n_updates             | 6360         |
|    policy_gradient_loss  | -0.000781    |
|    std                   | 0.945        |
|    value_loss            | 1.63         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.246       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.246       |
| reward             | -0.21816882 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -522        |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1306624     |
------------------------------------
--------------------------------------------
| avg_speed                | 0.0201        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0201        |
| reward                   | -0.4456858    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -540          |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 2             |
|    time_elapsed          | 43            |
|    total_timesteps       | 1308672       |
| train/                   |               |
|    approx_kl             | 3.2375858e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0267        |
|    cost_value_loss       | 0.000255      |
|    cost_values           | 0.021         |
|    entropy               | -2.65         |
|    entropy_loss          | -2.65         |
|    explained_variance    | 0.699         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.275         |
|    n_updates             | 6380          |
|    policy_gradient_loss  | 2.77e-05      |
|    std                   | 0.945         |
|    value_loss            | 4.43          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.28168255  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -539         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 1310720      |
| train/                   |              |
|    approx_kl             | 0.0010792151 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0431       |
|    cost_value_loss       | 0.000451     |
|    cost_values           | 0.0605       |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.629        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 160          |
|    n_updates             | 6390         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.945        |
|    value_loss            | 343          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0417       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0417       |
| reward                   | -0.48378938  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 1312768      |
| train/                   |              |
|    approx_kl             | 0.0007350526 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0391       |
|    cost_value_loss       | 3.13e-05     |
|    cost_values           | 0.0392       |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.767        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.875        |
|    n_updates             | 6400         |
|    policy_gradient_loss  | 4.93e-06     |
|    std                   | 0.945        |
|    value_loss            | 2.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0788       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0788       |
| reward                   | -0.52981436  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1314816      |
| train/                   |              |
|    approx_kl             | 0.0039230613 |
|    clip_fraction         | 0.0295       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0261       |
|    cost_value_loss       | 0.000108     |
|    cost_values           | 0.0269       |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.124        |
|    n_updates             | 6410         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.945        |
|    value_loss            | 0.576        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.24094467  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -539         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 1316864      |
| train/                   |              |
|    approx_kl             | 0.0053771893 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0452       |
|    cost_value_loss       | 9.16e-05     |
|    cost_values           | 0.0449       |
|    entropy               | -2.64        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.056        |
|    n_updates             | 6420         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.942        |
|    value_loss            | 0.702        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.171       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.171       |
| reward                   | -0.5317967  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -539        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 155         |
|    total_timesteps       | 1318912     |
| train/                   |             |
|    approx_kl             | 0.006547011 |
|    clip_fraction         | 0.0375      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0434      |
|    cost_value_loss       | 3.53e-05    |
|    cost_values           | 0.0438      |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.07        |
|    n_updates             | 6430        |
|    policy_gradient_loss  | -0.00278    |
|    std                   | 0.941       |
|    value_loss            | 2.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.237        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.237        |
| reward                   | -0.46264642  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -541         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 177          |
|    total_timesteps       | 1320960      |
| train/                   |              |
|    approx_kl             | 0.0025010216 |
|    clip_fraction         | 0.00313      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0316       |
|    cost_value_loss       | 2.52e-05     |
|    cost_values           | 0.0322       |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | -0.163       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.85         |
|    n_updates             | 6440         |
|    policy_gradient_loss  | -0.000176    |
|    std                   | 0.94         |
|    value_loss            | 4.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.225        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.225        |
| reward                   | -0.21493202  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -557         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 199          |
|    total_timesteps       | 1323008      |
| train/                   |              |
|    approx_kl             | 0.0041165673 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0015      |
|    cost_value_loss       | 2.41e-05     |
|    cost_values           | -0.00126     |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.329        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.274        |
|    n_updates             | 6450         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.938        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.9694899   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -555         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 1325056      |
| train/                   |              |
|    approx_kl             | 0.0025849156 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0122       |
|    cost_value_loss       | 4.15e-05     |
|    cost_values           | 0.0112       |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.698        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 109          |
|    n_updates             | 6460         |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.937        |
|    value_loss            | 233          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0888      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0888      |
| reward                   | -0.30263835 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -568        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 1327104     |
| train/                   |             |
|    approx_kl             | 0.002560952 |
|    clip_fraction         | 0.0115      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00902     |
|    cost_value_loss       | 4.15e-05    |
|    cost_values           | 0.00856     |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.762       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38.2        |
|    n_updates             | 6470        |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 0.937       |
|    value_loss            | 83.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.0708706   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -581         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 264          |
|    total_timesteps       | 1329152      |
| train/                   |              |
|    approx_kl             | 0.0016458594 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.027       |
|    cost_value_loss       | 0.000209     |
|    cost_values           | -0.0283      |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.754        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.3         |
|    n_updates             | 6480         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.937        |
|    value_loss            | 71.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.23032847  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -590         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 1331200      |
| train/                   |              |
|    approx_kl             | 0.0009853044 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00654     |
|    cost_value_loss       | 0.00014      |
|    cost_values           | -0.00348     |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.714        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 152          |
|    n_updates             | 6490         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.937        |
|    value_loss            | 317          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0815       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0815       |
| reward                   | -0.5132675   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -589         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 309          |
|    total_timesteps       | 1333248      |
| train/                   |              |
|    approx_kl             | 0.0022294584 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0033      |
|    cost_value_loss       | 0.000276     |
|    cost_values           | -0.005       |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.716        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.7         |
|    n_updates             | 6500         |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 0.937        |
|    value_loss            | 62.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0389      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0389      |
| reward                   | -0.5447017  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -591        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 331         |
|    total_timesteps       | 1335296     |
| train/                   |             |
|    approx_kl             | 0.009558479 |
|    clip_fraction         | 0.0605      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00953    |
|    cost_value_loss       | 6.81e-05    |
|    cost_values           | -0.01       |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0362      |
|    n_updates             | 6510        |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 0.939       |
|    value_loss            | 0.349       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.202        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.202        |
| reward                   | -0.30772382  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -579         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 1337344      |
| train/                   |              |
|    approx_kl             | 0.0028132051 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00268      |
|    cost_value_loss       | 4.5e-05      |
|    cost_values           | 0.00185      |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.655        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0293       |
|    n_updates             | 6520         |
|    policy_gradient_loss  | 0.000334     |
|    std                   | 0.939        |
|    value_loss            | 0.257        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0136       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0136       |
| reward                   | -0.5156365   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -577         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 376          |
|    total_timesteps       | 1339392      |
| train/                   |              |
|    approx_kl             | 0.0017894651 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0109      |
|    cost_value_loss       | 2.07e-05     |
|    cost_values           | -0.012       |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.569        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.49         |
|    n_updates             | 6530         |
|    policy_gradient_loss  | 0.000366     |
|    std                   | 0.939        |
|    value_loss            | 1.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0499       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0499       |
| reward                   | -0.23271827  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -580         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 398          |
|    total_timesteps       | 1341440      |
| train/                   |              |
|    approx_kl             | 0.0067669814 |
|    clip_fraction         | 0.065        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0219       |
|    cost_value_loss       | 6.44e-05     |
|    cost_values           | 0.021        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0202       |
|    n_updates             | 6540         |
|    policy_gradient_loss  | -0.00452     |
|    std                   | 0.944        |
|    value_loss            | 0.0932       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.359        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.359        |
| reward                   | -0.52101034  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -577         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 420          |
|    total_timesteps       | 1343488      |
| train/                   |              |
|    approx_kl             | 0.0057895132 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00415     |
|    cost_value_loss       | 4.43e-05     |
|    cost_values           | -0.00471     |
|    entropy               | -2.64        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.779        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0649       |
|    n_updates             | 6550         |
|    policy_gradient_loss  | -0.000953    |
|    std                   | 0.943        |
|    value_loss            | 0.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.2960041   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -588         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 442          |
|    total_timesteps       | 1345536      |
| train/                   |              |
|    approx_kl             | 0.0028213726 |
|    clip_fraction         | 0.0503       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0054       |
|    cost_value_loss       | 5.04e-05     |
|    cost_values           | 0.00639      |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.811        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.453        |
|    n_updates             | 6560         |
|    policy_gradient_loss  | -0.000731    |
|    std                   | 0.942        |
|    value_loss            | 4.09         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.00994       |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.00994       |
| reward                   | -0.54989237   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -590          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 21            |
|    time_elapsed          | 465           |
|    total_timesteps       | 1347584       |
| train/                   |               |
|    approx_kl             | 0.00080971466 |
|    clip_fraction         | 0.000879      |
|    clip_range            | 0.2           |
|    cost_returns          | 0.0516        |
|    cost_value_loss       | 0.000546      |
|    cost_values           | 0.0598        |
|    entropy               | -2.64         |
|    entropy_loss          | -2.64         |
|    explained_variance    | 0.781         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 76.2          |
|    n_updates             | 6570          |
|    policy_gradient_loss  | -0.00203      |
|    std                   | 0.942         |
|    value_loss            | 154           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0112       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0112       |
| reward                   | -0.30234158  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -586         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 487          |
|    total_timesteps       | 1349632      |
| train/                   |              |
|    approx_kl             | 0.0041337656 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0122       |
|    cost_value_loss       | 5.23e-05     |
|    cost_values           | 0.0124       |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.666        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.45         |
|    n_updates             | 6580         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.941        |
|    value_loss            | 3.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.175        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.175        |
| reward                   | -0.51982343  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -585         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 509          |
|    total_timesteps       | 1351680      |
| train/                   |              |
|    approx_kl             | 0.0031228182 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0513       |
|    cost_value_loss       | 0.00027      |
|    cost_values           | 0.0526       |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0928       |
|    n_updates             | 6590         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.941        |
|    value_loss            | 0.618        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0202       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0202       |
| reward                   | -0.5489049   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -583         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 531          |
|    total_timesteps       | 1353728      |
| train/                   |              |
|    approx_kl             | 0.0031971526 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0688       |
|    cost_value_loss       | 0.00037      |
|    cost_values           | 0.069        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0996       |
|    n_updates             | 6600         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.941        |
|    value_loss            | 0.494        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0125      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0125      |
| reward                   | -0.35653967 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -584        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 553         |
|    total_timesteps       | 1355776     |
| train/                   |             |
|    approx_kl             | 0.003377105 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0388      |
|    cost_value_loss       | 0.000352    |
|    cost_values           | 0.0399      |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0601      |
|    n_updates             | 6610        |
|    policy_gradient_loss  | -0.000141   |
|    std                   | 0.939       |
|    value_loss            | 1.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.4752444  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -584        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 576         |
|    total_timesteps       | 1357824     |
| train/                   |             |
|    approx_kl             | 0.005189472 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0519      |
|    cost_value_loss       | 0.000184    |
|    cost_values           | 0.0527      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.075       |
|    n_updates             | 6620        |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.935       |
|    value_loss            | 0.289       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.023       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.023       |
| reward                   | -0.36761945 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -577        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 598         |
|    total_timesteps       | 1359872     |
| train/                   |             |
|    approx_kl             | 0.004086203 |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0248     |
|    cost_value_loss       | 0.000126    |
|    cost_values           | -0.0266     |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0179      |
|    n_updates             | 6630        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.934       |
|    value_loss            | 0.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0138      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0138      |
| reward                   | -0.41496423 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -575        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 620         |
|    total_timesteps       | 1361920     |
| train/                   |             |
|    approx_kl             | 0.01150552  |
|    clip_fraction         | 0.0926      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0165     |
|    cost_value_loss       | 8.23e-05    |
|    cost_values           | -0.0162     |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0837      |
|    n_updates             | 6640        |
|    policy_gradient_loss  | -0.00556    |
|    std                   | 0.932       |
|    value_loss            | 0.197       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0197      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0197      |
| reward                   | -0.5554717  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -576        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 642         |
|    total_timesteps       | 1363968     |
| train/                   |             |
|    approx_kl             | 0.006060723 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.013      |
|    cost_value_loss       | 8.32e-05    |
|    cost_values           | -0.0132     |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0176      |
|    n_updates             | 6650        |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.93        |
|    value_loss            | 0.111       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.106       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.106       |
| reward                   | -0.33017576 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -578        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 664         |
|    total_timesteps       | 1366016     |
| train/                   |             |
|    approx_kl             | 0.007890996 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00567    |
|    cost_value_loss       | 4.5e-05     |
|    cost_values           | -0.00474    |
|    entropy               | -2.61       |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.014       |
|    n_updates             | 6660        |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.939       |
|    value_loss            | 0.0862      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.125       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.125       |
| reward                   | -0.447578   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -573        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 686         |
|    total_timesteps       | 1368064     |
| train/                   |             |
|    approx_kl             | 0.006646526 |
|    clip_fraction         | 0.0499      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00903    |
|    cost_value_loss       | 3.15e-05    |
|    cost_values           | -0.00891    |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0294      |
|    n_updates             | 6670        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.935       |
|    value_loss            | 0.259       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0205      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0205      |
| reward                   | -0.2780154  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -572        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 708         |
|    total_timesteps       | 1370112     |
| train/                   |             |
|    approx_kl             | 0.004705092 |
|    clip_fraction         | 0.0477      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0393      |
|    cost_value_loss       | 5.11e-05    |
|    cost_values           | 0.0395      |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.108       |
|    n_updates             | 6680        |
|    policy_gradient_loss  | -0.000381   |
|    std                   | 0.93        |
|    value_loss            | 0.502       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0113       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0113       |
| reward                   | -0.44063804  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -570         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 731          |
|    total_timesteps       | 1372160      |
| train/                   |              |
|    approx_kl             | 0.0034327484 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0577       |
|    cost_value_loss       | 0.000143     |
|    cost_values           | 0.0585       |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0635       |
|    n_updates             | 6690         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.93         |
|    value_loss            | 0.784        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.199        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.199        |
| reward                   | -0.54644775  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -570         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 753          |
|    total_timesteps       | 1374208      |
| train/                   |              |
|    approx_kl             | 0.0058103465 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.021        |
|    cost_value_loss       | 7.93e-05     |
|    cost_values           | 0.0223       |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0501       |
|    n_updates             | 6700         |
|    policy_gradient_loss  | -0.00464     |
|    std                   | 0.93         |
|    value_loss            | 0.801        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0763       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0763       |
| reward                   | -0.38859814  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -571         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 775          |
|    total_timesteps       | 1376256      |
| train/                   |              |
|    approx_kl             | 0.0035421061 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00611     |
|    cost_value_loss       | 0.000171     |
|    cost_values           | -0.00702     |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0194       |
|    n_updates             | 6710         |
|    policy_gradient_loss  | -0.000351    |
|    std                   | 0.93         |
|    value_loss            | 0.262        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.134       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.134       |
| reward                   | -0.51112723 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -558        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 1378304     |
| train/                   |             |
|    approx_kl             | 0.008802812 |
|    clip_fraction         | 0.0962      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0136      |
|    cost_value_loss       | 3.03e-05    |
|    cost_values           | 0.0141      |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0081      |
|    n_updates             | 6720        |
|    policy_gradient_loss  | -0.00669    |
|    std                   | 0.93        |
|    value_loss            | 0.0623      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0275      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0275      |
| reward                   | -0.45943636 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -557        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 819         |
|    total_timesteps       | 1380352     |
| train/                   |             |
|    approx_kl             | 0.007731839 |
|    clip_fraction         | 0.0571      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000514   |
|    cost_value_loss       | 1.91e-05    |
|    cost_values           | 0.000532    |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0224      |
|    n_updates             | 6730        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.928       |
|    value_loss            | 0.164       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0593      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0593      |
| reward                   | -0.37106463 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -554        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 842         |
|    total_timesteps       | 1382400     |
| train/                   |             |
|    approx_kl             | 0.002999933 |
|    clip_fraction         | 0.044       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00466     |
|    cost_value_loss       | 0.000135    |
|    cost_values           | 0.00556     |
|    entropy               | -2.58       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.1         |
|    n_updates             | 6740        |
|    policy_gradient_loss  | -0.000441   |
|    std                   | 0.926       |
|    value_loss            | 0.999       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.097        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.097        |
| reward                   | -0.47678846  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -533         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 864          |
|    total_timesteps       | 1384448      |
| train/                   |              |
|    approx_kl             | 0.0054789805 |
|    clip_fraction         | 0.0905       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00289      |
|    cost_value_loss       | 2.25e-05     |
|    cost_values           | 0.00305      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | -4.89        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00623      |
|    n_updates             | 6750         |
|    policy_gradient_loss  | -0.00537     |
|    std                   | 0.925        |
|    value_loss            | 0.0918       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.119        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.119        |
| reward                   | -0.428666    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 886          |
|    total_timesteps       | 1386496      |
| train/                   |              |
|    approx_kl             | 0.0017067301 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00119      |
|    cost_value_loss       | 2.56e-05     |
|    cost_values           | 0.00047      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.575        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0516       |
|    n_updates             | 6760         |
|    policy_gradient_loss  | -0.000644    |
|    std                   | 0.926        |
|    value_loss            | 0.521        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.312        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.312        |
| reward                   | -0.3279781   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 908          |
|    total_timesteps       | 1388544      |
| train/                   |              |
|    approx_kl             | 0.0028749695 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00118     |
|    cost_value_loss       | 3.58e-05     |
|    cost_values           | -0.000649    |
|    entropy               | -2.59        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.062        |
|    n_updates             | 6770         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.927        |
|    value_loss            | 0.836        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0683       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0683       |
| reward                   | -0.47418055  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -533         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 930          |
|    total_timesteps       | 1390592      |
| train/                   |              |
|    approx_kl             | 0.0016812426 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0424       |
|    cost_value_loss       | 7.18e-05     |
|    cost_values           | 0.0415       |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.4          |
|    n_updates             | 6780         |
|    policy_gradient_loss  | 1.51e-05     |
|    std                   | 0.928        |
|    value_loss            | 2.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0954       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0954       |
| reward                   | -0.37027714  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 952          |
|    total_timesteps       | 1392640      |
| train/                   |              |
|    approx_kl             | 0.0034220743 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00584      |
|    cost_value_loss       | 1.44e-05     |
|    cost_values           | 0.00592      |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00507      |
|    n_updates             | 6790         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.927        |
|    value_loss            | 0.112        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0058       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0058       |
| reward                   | -0.32934073  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 975          |
|    total_timesteps       | 1394688      |
| train/                   |              |
|    approx_kl             | 0.0041352436 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00383      |
|    cost_value_loss       | 0.000116     |
|    cost_values           | 0.00399      |
|    entropy               | -2.57        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00543      |
|    n_updates             | 6800         |
|    policy_gradient_loss  | -0.000792    |
|    std                   | 0.925        |
|    value_loss            | 0.0571       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.5517463   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 997          |
|    total_timesteps       | 1396736      |
| train/                   |              |
|    approx_kl             | 0.0019755075 |
|    clip_fraction         | 0.00654      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00978      |
|    cost_value_loss       | 0.000575     |
|    cost_values           | 0.0167       |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | -12.9        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0421       |
|    n_updates             | 6810         |
|    policy_gradient_loss  | -0.000365    |
|    std                   | 0.923        |
|    value_loss            | 0.698        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.37784138  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -519         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1019         |
|    total_timesteps       | 1398784      |
| train/                   |              |
|    approx_kl             | 0.0024137716 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00727     |
|    cost_value_loss       | 0.000205     |
|    cost_values           | 0.000752     |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.815        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.148        |
|    n_updates             | 6820         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.922        |
|    value_loss            | 2.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0062       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0062       |
| reward                   | -0.55180424  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1041         |
|    total_timesteps       | 1400832      |
| train/                   |              |
|    approx_kl             | 0.0015462181 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0182       |
|    cost_value_loss       | 3.26e-05     |
|    cost_values           | 0.0179       |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.743        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.029        |
|    n_updates             | 6830         |
|    policy_gradient_loss  | -0.000173    |
|    std                   | 0.924        |
|    value_loss            | 0.871        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0203      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0203      |
| reward                   | -0.5569985  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 1402880     |
| train/                   |             |
|    approx_kl             | 0.005965784 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0213      |
|    cost_value_loss       | 5.36e-05    |
|    cost_values           | 0.0221      |
|    entropy               | -2.58       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00473     |
|    n_updates             | 6840        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.925       |
|    value_loss            | 0.331       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0064       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0064       |
| reward                   | -0.5059292   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 1404928      |
| train/                   |              |
|    approx_kl             | 0.0026538242 |
|    clip_fraction         | 0.0496       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0444       |
|    cost_value_loss       | 0.00233      |
|    cost_values           | 0.0495       |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00817      |
|    n_updates             | 6850         |
|    policy_gradient_loss  | 0.000326     |
|    std                   | 0.922        |
|    value_loss            | 0.104        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.021       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.021       |
| reward             | -0.31378907 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -494        |
| time/              |             |
|    fps             | 96          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1406976     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.154        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.154        |
| reward                   | -0.36819977  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1409024      |
| train/                   |              |
|    approx_kl             | 0.0040107155 |
|    clip_fraction         | 0.00679      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.036       |
|    cost_value_loss       | 0.000408     |
|    cost_values           | -0.0291      |
|    entropy               | -2.57        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -1.15        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.634        |
|    n_updates             | 6870         |
|    policy_gradient_loss  | -0.00058     |
|    std                   | 0.92         |
|    value_loss            | 2.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.5380855   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 1411072      |
| train/                   |              |
|    approx_kl             | 0.0025472909 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0508      |
|    cost_value_loss       | 7.7e-05      |
|    cost_values           | -0.0499      |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0139       |
|    n_updates             | 6880         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.918        |
|    value_loss            | 0.193        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.162        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.162        |
| reward                   | -0.51748616  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 1413120      |
| train/                   |              |
|    approx_kl             | 0.0044356924 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00119     |
|    cost_value_loss       | 4.5e-05      |
|    cost_values           | -0.00146     |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.3          |
|    n_updates             | 6890         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.917        |
|    value_loss            | 1.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0477       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0477       |
| reward                   | -0.5205203   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1415168      |
| train/                   |              |
|    approx_kl             | 0.0032023655 |
|    clip_fraction         | 0.00308      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0158      |
|    cost_value_loss       | 4.88e-05     |
|    cost_values           | -0.0177      |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.067        |
|    n_updates             | 6900         |
|    policy_gradient_loss  | -0.000528    |
|    std                   | 0.917        |
|    value_loss            | 0.648        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.082        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.082        |
| reward                   | -0.38352823  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 131          |
|    total_timesteps       | 1417216      |
| train/                   |              |
|    approx_kl             | 0.0046270927 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0102       |
|    cost_value_loss       | 8.32e-05     |
|    cost_values           | 0.0132       |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.257        |
|    n_updates             | 6910         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.916        |
|    value_loss            | 2.58         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0277      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0277      |
| reward                   | -0.42194015 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -482        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 1419264     |
| train/                   |             |
|    approx_kl             | 0.003760619 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00723     |
|    cost_value_loss       | 4.57e-06    |
|    cost_values           | 0.00769     |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0136      |
|    n_updates             | 6920        |
|    policy_gradient_loss  | -0.000564   |
|    std                   | 0.916       |
|    value_loss            | 0.135       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.204        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.204        |
| reward                   | -0.51516217  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 1421312      |
| train/                   |              |
|    approx_kl             | 0.0051254285 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0161      |
|    cost_value_loss       | 2.31e-05     |
|    cost_values           | -0.0162      |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.388        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0113       |
|    n_updates             | 6930         |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 0.916        |
|    value_loss            | 0.113        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0884      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0884      |
| reward                   | -0.24368753 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.004185467 |
|    clip_fraction         | 0.0102      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00335    |
|    cost_value_loss       | 2.24e-05    |
|    cost_values           | -0.00473    |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.7         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0308      |
|    n_updates             | 6940        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.915       |
|    value_loss            | 0.475       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0563      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0563      |
| reward                   | -0.37563786 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 220         |
|    total_timesteps       | 1425408     |
| train/                   |             |
|    approx_kl             | 0.001842578 |
|    clip_fraction         | 0.00605     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0108      |
|    cost_value_loss       | 1.97e-05    |
|    cost_values           | 0.0106      |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.367       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 6950        |
|    policy_gradient_loss  | -0.000194   |
|    std                   | 0.913       |
|    value_loss            | 5.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.4833551   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 1427456      |
| train/                   |              |
|    approx_kl             | 0.0024388484 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0163       |
|    cost_value_loss       | 7.61e-05     |
|    cost_values           | 0.0181       |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -0.0654      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.533        |
|    n_updates             | 6960         |
|    policy_gradient_loss  | -0.000369    |
|    std                   | 0.91         |
|    value_loss            | 1.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.224       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.224       |
| reward                   | -0.32849517 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 1429504     |
| train/                   |             |
|    approx_kl             | 0.002529948 |
|    clip_fraction         | 0.0101      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0139     |
|    cost_value_loss       | 2.23e-05    |
|    cost_values           | -0.0138     |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00824     |
|    n_updates             | 6970        |
|    policy_gradient_loss  | -0.000603   |
|    std                   | 0.91        |
|    value_loss            | 0.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0745       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0745       |
| reward                   | -0.305414    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 1431552      |
| train/                   |              |
|    approx_kl             | 0.0043154703 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00455     |
|    cost_value_loss       | 4.83e-05     |
|    cost_values           | -0.00416     |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0621       |
|    n_updates             | 6980         |
|    policy_gradient_loss  | -0.000368    |
|    std                   | 0.91         |
|    value_loss            | 1.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0795      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0795      |
| reward                   | -0.54646736 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 308         |
|    total_timesteps       | 1433600     |
| train/                   |             |
|    approx_kl             | 0.006960199 |
|    clip_fraction         | 0.0567      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00435    |
|    cost_value_loss       | 4.09e-05    |
|    cost_values           | -0.00448    |
|    entropy               | -2.55       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.116       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.065       |
|    n_updates             | 6990        |
|    policy_gradient_loss  | -0.00489    |
|    std                   | 0.91        |
|    value_loss            | 0.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00141      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00141      |
| reward                   | -0.41388616  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 331          |
|    total_timesteps       | 1435648      |
| train/                   |              |
|    approx_kl             | 0.0022424103 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00693     |
|    cost_value_loss       | 0.00012      |
|    cost_values           | -0.00778     |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -1.53        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.614        |
|    n_updates             | 7000         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.909        |
|    value_loss            | 2.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.225       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.225       |
| reward                   | -0.37178564 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 353         |
|    total_timesteps       | 1437696     |
| train/                   |             |
|    approx_kl             | 0.005118372 |
|    clip_fraction         | 0.00718     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0134     |
|    cost_value_loss       | 3.62e-05    |
|    cost_values           | -0.0124     |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.58        |
|    n_updates             | 7010        |
|    policy_gradient_loss  | -0.000666   |
|    std                   | 0.907       |
|    value_loss            | 2.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00447      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00447      |
| reward                   | -0.5211481   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 375          |
|    total_timesteps       | 1439744      |
| train/                   |              |
|    approx_kl             | 0.0061463583 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00083     |
|    cost_value_loss       | 5.13e-05     |
|    cost_values           | -0.00285     |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0285       |
|    n_updates             | 7020         |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 0.906        |
|    value_loss            | 0.369        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0534       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0534       |
| reward                   | -0.4376716   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 397          |
|    total_timesteps       | 1441792      |
| train/                   |              |
|    approx_kl             | 0.0034705293 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0026      |
|    cost_value_loss       | 6.93e-06     |
|    cost_values           | -0.00258     |
|    entropy               | -2.53        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0141       |
|    n_updates             | 7030         |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.903        |
|    value_loss            | 0.238        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.216       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.216       |
| reward                   | -0.55675447 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 419         |
|    total_timesteps       | 1443840     |
| train/                   |             |
|    approx_kl             | 0.009984278 |
|    clip_fraction         | 0.0729      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00665     |
|    cost_value_loss       | 5.79e-05    |
|    cost_values           | 0.00781     |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00422     |
|    n_updates             | 7040        |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 0.903       |
|    value_loss            | 0.264       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.000128    |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.000128    |
| reward                   | -0.369038   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 441         |
|    total_timesteps       | 1445888     |
| train/                   |             |
|    approx_kl             | 0.004869812 |
|    clip_fraction         | 0.018       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00311     |
|    cost_value_loss       | 7.53e-06    |
|    cost_values           | 0.00302     |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.303       |
|    n_updates             | 7050        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.903       |
|    value_loss            | 1.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.41753307  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 1447936      |
| train/                   |              |
|    approx_kl             | 0.0036299594 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00285      |
|    cost_value_loss       | 3.56e-06     |
|    cost_values           | 0.00303      |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0107       |
|    n_updates             | 7060         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.901        |
|    value_loss            | 0.128        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.205        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.205        |
| reward                   | -0.26820594  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 486          |
|    total_timesteps       | 1449984      |
| train/                   |              |
|    approx_kl             | 0.0011904553 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00175     |
|    cost_value_loss       | 2.15e-06     |
|    cost_values           | -0.00174     |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0555       |
|    n_updates             | 7070         |
|    policy_gradient_loss  | -0.000358    |
|    std                   | 0.901        |
|    value_loss            | 0.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0754      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0754      |
| reward                   | -0.5050054  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 508         |
|    total_timesteps       | 1452032     |
| train/                   |             |
|    approx_kl             | 0.004716198 |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.004      |
|    cost_value_loss       | 1.41e-06    |
|    cost_values           | -0.00373    |
|    entropy               | -2.51       |
|    entropy_loss          | -2.52       |
|    explained_variance    | -1.8        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.252       |
|    n_updates             | 7080        |
|    policy_gradient_loss  | -0.000867   |
|    std                   | 0.894       |
|    value_loss            | 0.875       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0826       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0826       |
| reward                   | -0.3088937   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 530          |
|    total_timesteps       | 1454080      |
| train/                   |              |
|    approx_kl             | 0.0030475329 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00432     |
|    cost_value_loss       | 6.47e-05     |
|    cost_values           | -0.00781     |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.525        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.901        |
|    n_updates             | 7090         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.889        |
|    value_loss            | 2.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0719       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0719       |
| reward                   | -0.41780323  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 552          |
|    total_timesteps       | 1456128      |
| train/                   |              |
|    approx_kl             | 0.0032664682 |
|    clip_fraction         | 0.0455       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00029     |
|    cost_value_loss       | 8.16e-06     |
|    cost_values           | -0.000318    |
|    entropy               | -2.51        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.743        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.588        |
|    n_updates             | 7100         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.895        |
|    value_loss            | 1.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0721      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0721      |
| reward                   | -0.52264595 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 575         |
|    total_timesteps       | 1458176     |
| train/                   |             |
|    approx_kl             | 0.010241157 |
|    clip_fraction         | 0.0528      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00234    |
|    cost_value_loss       | 1.13e-05    |
|    cost_values           | -0.00334    |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.211       |
|    n_updates             | 7110        |
|    policy_gradient_loss  | -0.000899   |
|    std                   | 0.9         |
|    value_loss            | 0.767       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0023       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0023       |
| reward                   | -0.39485058  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 597          |
|    total_timesteps       | 1460224      |
| train/                   |              |
|    approx_kl             | 0.0045805797 |
|    clip_fraction         | 0.0495       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0161      |
|    cost_value_loss       | 1.89e-05     |
|    cost_values           | -0.0161      |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0365       |
|    n_updates             | 7120         |
|    policy_gradient_loss  | -0.000188    |
|    std                   | 0.902        |
|    value_loss            | 0.784        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0466       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0466       |
| reward                   | -0.5099272   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 619          |
|    total_timesteps       | 1462272      |
| train/                   |              |
|    approx_kl             | 0.0036039588 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00237     |
|    cost_value_loss       | 9.02e-07     |
|    cost_values           | -0.00231     |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.65         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.526        |
|    n_updates             | 7130         |
|    policy_gradient_loss  | -0.000712    |
|    std                   | 0.9          |
|    value_loss            | 2.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0698      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0698      |
| reward                   | -0.27573457 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 641         |
|    total_timesteps       | 1464320     |
| train/                   |             |
|    approx_kl             | 0.009407048 |
|    clip_fraction         | 0.0438      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0159     |
|    cost_value_loss       | 1.25e-05    |
|    cost_values           | -0.0162     |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000797    |
|    n_updates             | 7140        |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.9         |
|    value_loss            | 0.0922      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.145        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.145        |
| reward                   | -0.54258025  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 663          |
|    total_timesteps       | 1466368      |
| train/                   |              |
|    approx_kl             | 0.0037636142 |
|    clip_fraction         | 0.0477       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00107      |
|    cost_value_loss       | 2.81e-05     |
|    cost_values           | 0.00224      |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.187        |
|    n_updates             | 7150         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.9          |
|    value_loss            | 1.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.139       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.139       |
| reward                   | -0.325494   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 685         |
|    total_timesteps       | 1468416     |
| train/                   |             |
|    approx_kl             | 0.003239418 |
|    clip_fraction         | 0.00576     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00403    |
|    cost_value_loss       | 5.52e-07    |
|    cost_values           | -0.00418    |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | -0.439      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.31        |
|    n_updates             | 7160        |
|    policy_gradient_loss  | -0.000632   |
|    std                   | 0.901       |
|    value_loss            | 3.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0413       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0413       |
| reward                   | -0.22126418  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 1470464      |
| train/                   |              |
|    approx_kl             | 0.0034040075 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00362     |
|    cost_value_loss       | 2.59e-07     |
|    cost_values           | -0.00367     |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.107        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.873        |
|    n_updates             | 7170         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.901        |
|    value_loss            | 2.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0996       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0996       |
| reward                   | -0.31311652  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 730          |
|    total_timesteps       | 1472512      |
| train/                   |              |
|    approx_kl             | 0.0012297034 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0011       |
|    cost_value_loss       | 7.94e-05     |
|    cost_values           | 0.00486      |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.291        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.127        |
|    n_updates             | 7180         |
|    policy_gradient_loss  | 8.62e-05     |
|    std                   | 0.9          |
|    value_loss            | 1.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.131        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.131        |
| reward                   | -0.47939596  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 752          |
|    total_timesteps       | 1474560      |
| train/                   |              |
|    approx_kl             | 0.0014630521 |
|    clip_fraction         | 0.00479      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00103     |
|    cost_value_loss       | 6.96e-05     |
|    cost_values           | 0.00349      |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.517        |
|    n_updates             | 7190         |
|    policy_gradient_loss  | -2.85e-05    |
|    std                   | 0.899        |
|    value_loss            | 3.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.1          |
| reward                   | -0.41774118  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 774          |
|    total_timesteps       | 1476608      |
| train/                   |              |
|    approx_kl             | 0.0037849988 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00223     |
|    cost_value_loss       | 8.9e-07      |
|    cost_values           | -0.00226     |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.505        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0667       |
|    n_updates             | 7200         |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.899        |
|    value_loss            | 0.589        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.3115904  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 1478656     |
| train/                   |             |
|    approx_kl             | 0.003906429 |
|    clip_fraction         | 0.00303     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0106     |
|    cost_value_loss       | 7.07e-05    |
|    cost_values           | -0.00955    |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.682       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.162       |
|    n_updates             | 7210        |
|    policy_gradient_loss  | -0.000578   |
|    std                   | 0.9         |
|    value_loss            | 1.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.156        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.156        |
| reward                   | -0.5525286   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 818          |
|    total_timesteps       | 1480704      |
| train/                   |              |
|    approx_kl             | 0.0044287187 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00658     |
|    cost_value_loss       | 0.000144     |
|    cost_values           | -0.00954     |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.017        |
|    n_updates             | 7220         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.9          |
|    value_loss            | 0.349        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.267        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.267        |
| reward                   | -0.43013412  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 840          |
|    total_timesteps       | 1482752      |
| train/                   |              |
|    approx_kl             | 0.0019433883 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00543     |
|    cost_value_loss       | 6.22e-05     |
|    cost_values           | -0.00635     |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.821        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0261       |
|    n_updates             | 7230         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.894        |
|    value_loss            | 0.253        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.21         |
| reward                   | -0.5054654   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 863          |
|    total_timesteps       | 1484800      |
| train/                   |              |
|    approx_kl             | 0.0026374932 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0153      |
|    cost_value_loss       | 5.99e-05     |
|    cost_values           | -0.0185      |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0209       |
|    n_updates             | 7240         |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.891        |
|    value_loss            | 0.771        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.148        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.148        |
| reward                   | -0.5568478   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 885          |
|    total_timesteps       | 1486848      |
| train/                   |              |
|    approx_kl             | 0.0030079205 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00317     |
|    cost_value_loss       | 7.77e-07     |
|    cost_values           | -0.00331     |
|    entropy               | -2.49        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.72         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.405        |
|    n_updates             | 7250         |
|    policy_gradient_loss  | -0.000803    |
|    std                   | 0.888        |
|    value_loss            | 1.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0642      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0642      |
| reward                   | -0.52672905 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 907         |
|    total_timesteps       | 1488896     |
| train/                   |             |
|    approx_kl             | 0.004651241 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00369    |
|    cost_value_loss       | 9.87e-06    |
|    cost_values           | -0.00334    |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.467       |
|    n_updates             | 7260        |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 0.886       |
|    value_loss            | 1.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.53874075  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 929          |
|    total_timesteps       | 1490944      |
| train/                   |              |
|    approx_kl             | 0.0012547091 |
|    clip_fraction         | 0.00474      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00562     |
|    cost_value_loss       | 1.64e-06     |
|    cost_values           | -0.00574     |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.649        |
|    n_updates             | 7270         |
|    policy_gradient_loss  | -0.000607    |
|    std                   | 0.885        |
|    value_loss            | 2.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0519       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0519       |
| reward                   | -0.3344084   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 951          |
|    total_timesteps       | 1492992      |
| train/                   |              |
|    approx_kl             | 0.0022554756 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00772     |
|    cost_value_loss       | 2.52e-05     |
|    cost_values           | -0.00951     |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.184        |
|    n_updates             | 7280         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.887        |
|    value_loss            | 1.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0716       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0716       |
| reward                   | -0.3186834   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 973          |
|    total_timesteps       | 1495040      |
| train/                   |              |
|    approx_kl             | 0.0047263466 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00818     |
|    cost_value_loss       | 6.91e-06     |
|    cost_values           | -0.00867     |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.905        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0669       |
|    n_updates             | 7290         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.887        |
|    value_loss            | 0.593        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.37610465  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 996          |
|    total_timesteps       | 1497088      |
| train/                   |              |
|    approx_kl             | 0.0032014905 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00563     |
|    cost_value_loss       | 1.22e-05     |
|    cost_values           | -0.00532     |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0117       |
|    n_updates             | 7300         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 0.887        |
|    value_loss            | 0.411        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0825       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0825       |
| reward                   | -0.4838596   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1018         |
|    total_timesteps       | 1499136      |
| train/                   |              |
|    approx_kl             | 0.0044763833 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00971     |
|    cost_value_loss       | 5.41e-05     |
|    cost_values           | -0.00976     |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.135        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.685        |
|    n_updates             | 7310         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.885        |
|    value_loss            | 1.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0884       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0884       |
| reward                   | -0.36881867  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1040         |
|    total_timesteps       | 1501184      |
| train/                   |              |
|    approx_kl             | 0.0051456103 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00408      |
|    cost_value_loss       | 4.77e-06     |
|    cost_values           | 0.00425      |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0159       |
|    n_updates             | 7320         |
|    policy_gradient_loss  | -0.000501    |
|    std                   | 0.883        |
|    value_loss            | 0.338        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0643       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0643       |
| reward                   | -0.37049186  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 1503232      |
| train/                   |              |
|    approx_kl             | 0.0078045498 |
|    clip_fraction         | 0.0725       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000124     |
|    cost_value_loss       | 4.45e-05     |
|    cost_values           | -0.000881    |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0121       |
|    n_updates             | 7330         |
|    policy_gradient_loss  | 0.000421     |
|    std                   | 0.883        |
|    value_loss            | 0.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0332       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0332       |
| reward                   | -0.39228672  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 1505280      |
| train/                   |              |
|    approx_kl             | 0.0047483584 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00682     |
|    cost_value_loss       | 1.21e-05     |
|    cost_values           | -0.00644     |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00211      |
|    n_updates             | 7340         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.878        |
|    value_loss            | 0.0524       |
-------------------------------------------
------------------------------------
| avg_speed          | 0.0416      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0416      |
| reward             | -0.30961293 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -412        |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1507328     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.0751       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0751       |
| reward                   | -0.30832237  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1509376      |
| train/                   |              |
|    approx_kl             | 0.0018206805 |
|    clip_fraction         | 0.0491       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0138      |
|    cost_value_loss       | 2.9e-05      |
|    cost_values           | -0.0156      |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.701        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.152        |
|    n_updates             | 7360         |
|    policy_gradient_loss  | 0.00135      |
|    std                   | 0.873        |
|    value_loss            | 1.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0822       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0822       |
| reward                   | -0.3674626   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 1511424      |
| train/                   |              |
|    approx_kl             | 0.0047997413 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00884      |
|    cost_value_loss       | 6.5e-06      |
|    cost_values           | 0.00912      |
|    entropy               | -2.45        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0125       |
|    n_updates             | 7370         |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.872        |
|    value_loss            | 0.222        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.116       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.116       |
| reward                   | -0.53640366 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 1513472     |
| train/                   |             |
|    approx_kl             | 0.002219235 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00438     |
|    cost_value_loss       | 3.07e-07    |
|    cost_values           | 0.00441     |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | -0.149      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.169       |
|    n_updates             | 7380        |
|    policy_gradient_loss  | 0.000245    |
|    std                   | 0.871       |
|    value_loss            | 0.395       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.167       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.167       |
| reward                   | -0.3124401  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 1515520     |
| train/                   |             |
|    approx_kl             | 0.005722372 |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0249     |
|    cost_value_loss       | 7.27e-06    |
|    cost_values           | -0.0254     |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.23        |
|    n_updates             | 7390        |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.87        |
|    value_loss            | 0.964       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.133       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.133       |
| reward                   | -0.32930642 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 1517568     |
| train/                   |             |
|    approx_kl             | 0.005790705 |
|    clip_fraction         | 0.0398      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00102    |
|    cost_value_loss       | 3.8e-05     |
|    cost_values           | -0.00025    |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.144       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.294       |
|    n_updates             | 7400        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.869       |
|    value_loss            | 1.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.161        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.161        |
| reward                   | -0.50677407  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1519616      |
| train/                   |              |
|    approx_kl             | 0.0026760572 |
|    clip_fraction         | 0.00596      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.012       |
|    cost_value_loss       | 1.25e-05     |
|    cost_values           | -0.0116      |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.254        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0932       |
|    n_updates             | 7410         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.869        |
|    value_loss            | 0.784        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0603      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0603      |
| reward                   | -0.5454026  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 177         |
|    total_timesteps       | 1521664     |
| train/                   |             |
|    approx_kl             | 0.004070132 |
|    clip_fraction         | 0.0198      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000526    |
|    cost_value_loss       | 4.5e-07     |
|    cost_values           | 0.000493    |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | -0.34       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.617       |
|    n_updates             | 7420        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.87        |
|    value_loss            | 1.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0206       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0206       |
| reward                   | -0.46641478  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 199          |
|    total_timesteps       | 1523712      |
| train/                   |              |
|    approx_kl             | 0.0042904336 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0306      |
|    cost_value_loss       | 1.59e-05     |
|    cost_values           | -0.0312      |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.619        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.142        |
|    n_updates             | 7430         |
|    policy_gradient_loss  | -0.000842    |
|    std                   | 0.869        |
|    value_loss            | 0.463        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.224        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.224        |
| reward                   | -0.47177646  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 222          |
|    total_timesteps       | 1525760      |
| train/                   |              |
|    approx_kl             | 0.0027216156 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000398    |
|    cost_value_loss       | 9.63e-07     |
|    cost_values           | -0.000541    |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.161        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.464        |
|    n_updates             | 7440         |
|    policy_gradient_loss  | -0.000515    |
|    std                   | 0.867        |
|    value_loss            | 1.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0784       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0784       |
| reward                   | -0.5056554   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 243          |
|    total_timesteps       | 1527808      |
| train/                   |              |
|    approx_kl             | 0.0055714916 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0063      |
|    cost_value_loss       | 4.06e-06     |
|    cost_values           | -0.00635     |
|    entropy               | -2.42        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00964     |
|    n_updates             | 7450         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.863        |
|    value_loss            | 0.0672       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.177       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.177       |
| reward                   | -0.51194894 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 266         |
|    total_timesteps       | 1529856     |
| train/                   |             |
|    approx_kl             | 0.003872489 |
|    clip_fraction         | 0.0371      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00189    |
|    cost_value_loss       | 9.23e-06    |
|    cost_values           | -0.00184    |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.492       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.106       |
|    n_updates             | 7460        |
|    policy_gradient_loss  | -0.00327    |
|    std                   | 0.865       |
|    value_loss            | 0.331       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0146       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0146       |
| reward                   | -0.52859175  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 288          |
|    total_timesteps       | 1531904      |
| train/                   |              |
|    approx_kl             | 0.0046697455 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00121      |
|    cost_value_loss       | 7.36e-06     |
|    cost_values           | 0.000783     |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.907        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.162        |
|    n_updates             | 7470         |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.866        |
|    value_loss            | 1.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.108       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.108       |
| reward                   | -0.5133468  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 1533952     |
| train/                   |             |
|    approx_kl             | 0.004596486 |
|    clip_fraction         | 0.0266      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00627    |
|    cost_value_loss       | 7.67e-06    |
|    cost_values           | -0.00641    |
|    entropy               | -2.42       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0106      |
|    n_updates             | 7480        |
|    policy_gradient_loss  | -0.00391    |
|    std                   | 0.865       |
|    value_loss            | 0.111       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0967      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0967      |
| reward                   | -0.31901246 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 1536000     |
| train/                   |             |
|    approx_kl             | 0.003680108 |
|    clip_fraction         | 0.0137      |
|    clip_range            | 0.2         |
|    cost_returns          | -5.86e-05   |
|    cost_value_loss       | 5.15e-06    |
|    cost_values           | 0.000434    |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.729       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0212      |
|    n_updates             | 7490        |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.865       |
|    value_loss            | 0.432       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00495      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00495      |
| reward                   | -0.3773465   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 1538048      |
| train/                   |              |
|    approx_kl             | 0.0020076092 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00296      |
|    cost_value_loss       | 8.95e-06     |
|    cost_values           | 0.00334      |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0103       |
|    n_updates             | 7500         |
|    policy_gradient_loss  | -0.000945    |
|    std                   | 0.866        |
|    value_loss            | 0.252        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.037       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.037       |
| reward                   | -0.541717   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 1540096     |
| train/                   |             |
|    approx_kl             | 0.008350107 |
|    clip_fraction         | 0.0452      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00254     |
|    cost_value_loss       | 3.88e-05    |
|    cost_values           | 0.00244     |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.662       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0604      |
|    n_updates             | 7510        |
|    policy_gradient_loss  | -0.000699   |
|    std                   | 0.867       |
|    value_loss            | 0.333       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.36875287 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 399         |
|    total_timesteps       | 1542144     |
| train/                   |             |
|    approx_kl             | 0.001986292 |
|    clip_fraction         | 0.0506      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000693   |
|    cost_value_loss       | 2.64e-05    |
|    cost_values           | -0.000645   |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.15        |
|    n_updates             | 7520        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.867       |
|    value_loss            | 0.671       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0408      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0408      |
| reward                   | -0.30906767 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 421         |
|    total_timesteps       | 1544192     |
| train/                   |             |
|    approx_kl             | 0.004867573 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00833    |
|    cost_value_loss       | 1.43e-05    |
|    cost_values           | -0.00858    |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.787       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0433      |
|    n_updates             | 7530        |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 0.869       |
|    value_loss            | 0.419       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0336       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0336       |
| reward                   | -0.49043083  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1546240      |
| train/                   |              |
|    approx_kl             | 0.0037373751 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0138      |
|    cost_value_loss       | 1.81e-05     |
|    cost_values           | -0.0136      |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.673        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.32         |
|    n_updates             | 7540         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.869        |
|    value_loss            | 0.933        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.152       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.152       |
| reward                   | -0.3128771  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 465         |
|    total_timesteps       | 1548288     |
| train/                   |             |
|    approx_kl             | 0.006243745 |
|    clip_fraction         | 0.0708      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00786    |
|    cost_value_loss       | 9.71e-06    |
|    cost_values           | -0.00766    |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.684       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0325      |
|    n_updates             | 7550        |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.868       |
|    value_loss            | 0.316       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0988      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0988      |
| reward                   | -0.45243052 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 488         |
|    total_timesteps       | 1550336     |
| train/                   |             |
|    approx_kl             | 0.008121079 |
|    clip_fraction         | 0.0512      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0191      |
|    cost_value_loss       | 7.66e-05    |
|    cost_values           | 0.0188      |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.798       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00495     |
|    n_updates             | 7560        |
|    policy_gradient_loss  | -0.00449    |
|    std                   | 0.867       |
|    value_loss            | 0.351       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0122       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0122       |
| reward                   | -0.53885925  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 510          |
|    total_timesteps       | 1552384      |
| train/                   |              |
|    approx_kl             | 0.0020902744 |
|    clip_fraction         | 0.0526       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00621      |
|    cost_value_loss       | 5.48e-05     |
|    cost_values           | 0.00692      |
|    entropy               | -2.41        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.127        |
|    n_updates             | 7570         |
|    policy_gradient_loss  | -0.000108    |
|    std                   | 0.856        |
|    value_loss            | 0.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0404      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0404      |
| reward                   | -0.2821541  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 532         |
|    total_timesteps       | 1554432     |
| train/                   |             |
|    approx_kl             | 0.004788988 |
|    clip_fraction         | 0.00693     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0135     |
|    cost_value_loss       | 4.49e-06    |
|    cost_values           | -0.0136     |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.307       |
|    n_updates             | 7580        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.855       |
|    value_loss            | 1.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0297      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0297      |
| reward                   | -0.52746505 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 554         |
|    total_timesteps       | 1556480     |
| train/                   |             |
|    approx_kl             | 0.0041914   |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00434    |
|    cost_value_loss       | 3.94e-06    |
|    cost_values           | -0.00455    |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.846       |
|    n_updates             | 7590        |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.854       |
|    value_loss            | 2.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0357      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0357      |
| reward                   | -0.49488747 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 577         |
|    total_timesteps       | 1558528     |
| train/                   |             |
|    approx_kl             | 0.006625397 |
|    clip_fraction         | 0.05        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000307   |
|    cost_value_loss       | 4.5e-07     |
|    cost_values           | -0.00033    |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.116       |
|    n_updates             | 7600        |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 0.854       |
|    value_loss            | 0.852       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0209       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0209       |
| reward                   | -0.49203065  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 599          |
|    total_timesteps       | 1560576      |
| train/                   |              |
|    approx_kl             | 0.0037872763 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00636     |
|    cost_value_loss       | 6.15e-07     |
|    cost_values           | -0.00649     |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.905        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0459       |
|    n_updates             | 7610         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.854        |
|    value_loss            | 0.498        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0424       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0424       |
| reward                   | -0.4326806   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 621          |
|    total_timesteps       | 1562624      |
| train/                   |              |
|    approx_kl             | 0.0070106075 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00702     |
|    cost_value_loss       | 1.47e-06     |
|    cost_values           | -0.00709     |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00325     |
|    n_updates             | 7620         |
|    policy_gradient_loss  | -0.00322     |
|    std                   | 0.855        |
|    value_loss            | 0.112        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.195       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.195       |
| reward                   | -0.42594314 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 643         |
|    total_timesteps       | 1564672     |
| train/                   |             |
|    approx_kl             | 0.004910683 |
|    clip_fraction         | 0.0377      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000733   |
|    cost_value_loss       | 6.19e-05    |
|    cost_values           | -0.000794   |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.54        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.000576   |
|    n_updates             | 7630        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.855       |
|    value_loss            | 0.159       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0196      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0196      |
| reward                   | -0.23947452 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 666         |
|    total_timesteps       | 1566720     |
| train/                   |             |
|    approx_kl             | 0.005419393 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0126     |
|    cost_value_loss       | 2.91e-05    |
|    cost_values           | -0.0126     |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0149      |
|    n_updates             | 7640        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.855       |
|    value_loss            | 0.107       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0664       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0664       |
| reward                   | -0.31260085  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 688          |
|    total_timesteps       | 1568768      |
| train/                   |              |
|    approx_kl             | 0.0041273823 |
|    clip_fraction         | 0.0461       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00324     |
|    cost_value_loss       | 1.13e-05     |
|    cost_values           | -0.00336     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.537        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0914       |
|    n_updates             | 7650         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.858        |
|    value_loss            | 0.494        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0189      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0189      |
| reward                   | -0.46643513 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 710         |
|    total_timesteps       | 1570816     |
| train/                   |             |
|    approx_kl             | 0.004489893 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0026     |
|    cost_value_loss       | 5.44e-05    |
|    cost_values           | -6.78e-05   |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | -0.355      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.104       |
|    n_updates             | 7660        |
|    policy_gradient_loss  | -0.000962   |
|    std                   | 0.86        |
|    value_loss            | 1.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.4803914   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 732          |
|    total_timesteps       | 1572864      |
| train/                   |              |
|    approx_kl             | 0.0050644698 |
|    clip_fraction         | 0.0495       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00212      |
|    cost_value_loss       | 5.39e-05     |
|    cost_values           | 0.00293      |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | -2.17        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.311        |
|    n_updates             | 7670         |
|    policy_gradient_loss  | -0.00436     |
|    std                   | 0.86         |
|    value_loss            | 1.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.129        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.129        |
| reward                   | -0.3115645   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 754          |
|    total_timesteps       | 1574912      |
| train/                   |              |
|    approx_kl             | 0.0024135867 |
|    clip_fraction         | 0.00601      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00791     |
|    cost_value_loss       | 3.66e-06     |
|    cost_values           | -0.00817     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0915       |
|    n_updates             | 7680         |
|    policy_gradient_loss  | -0.000565    |
|    std                   | 0.86         |
|    value_loss            | 0.554        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.124        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.124        |
| reward                   | -0.4199122   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 776          |
|    total_timesteps       | 1576960      |
| train/                   |              |
|    approx_kl             | 0.0040124347 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00774     |
|    cost_value_loss       | 1.78e-06     |
|    cost_values           | -0.00776     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.105        |
|    n_updates             | 7690         |
|    policy_gradient_loss  | -0.00076     |
|    std                   | 0.86         |
|    value_loss            | 0.271        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.32111135  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 799          |
|    total_timesteps       | 1579008      |
| train/                   |              |
|    approx_kl             | 0.0036360915 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00312     |
|    cost_value_loss       | 3.08e-07     |
|    cost_values           | -0.0031      |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.203        |
|    n_updates             | 7700         |
|    policy_gradient_loss  | -0.000398    |
|    std                   | 0.861        |
|    value_loss            | 0.454        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0709       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0709       |
| reward                   | -0.37034506  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 821          |
|    total_timesteps       | 1581056      |
| train/                   |              |
|    approx_kl             | 0.0038240675 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00402      |
|    cost_value_loss       | 6.6e-06      |
|    cost_values           | 0.00418      |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -8.05e-05    |
|    n_updates             | 7710         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.863        |
|    value_loss            | 0.0904       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0321       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0321       |
| reward                   | -0.3729015   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 843          |
|    total_timesteps       | 1583104      |
| train/                   |              |
|    approx_kl             | 0.0030818693 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00743      |
|    cost_value_loss       | 3.37e-05     |
|    cost_values           | 0.00773      |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.853        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0511       |
|    n_updates             | 7720         |
|    policy_gradient_loss  | -0.000561    |
|    std                   | 0.861        |
|    value_loss            | 0.143        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0627       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0627       |
| reward                   | -0.5052347   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 865          |
|    total_timesteps       | 1585152      |
| train/                   |              |
|    approx_kl             | 0.0046402765 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00505     |
|    cost_value_loss       | 7.15e-06     |
|    cost_values           | -0.00465     |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | -0.328       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.474        |
|    n_updates             | 7730         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.859        |
|    value_loss            | 1.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0847       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0847       |
| reward                   | -0.5177923   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 887          |
|    total_timesteps       | 1587200      |
| train/                   |              |
|    approx_kl             | 0.0039429716 |
|    clip_fraction         | 0.00894      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00188     |
|    cost_value_loss       | 5.76e-05     |
|    cost_values           | -0.00213     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.689        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.337        |
|    n_updates             | 7740         |
|    policy_gradient_loss  | -0.000767    |
|    std                   | 0.86         |
|    value_loss            | 1.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0359      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0359      |
| reward                   | -0.43771616 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 910         |
|    total_timesteps       | 1589248     |
| train/                   |             |
|    approx_kl             | 0.007603889 |
|    clip_fraction         | 0.0439      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00608     |
|    cost_value_loss       | 3.15e-05    |
|    cost_values           | 0.00781     |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.209       |
|    n_updates             | 7750        |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 0.861       |
|    value_loss            | 0.845       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0405      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0405      |
| reward                   | -0.5574109  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 932         |
|    total_timesteps       | 1591296     |
| train/                   |             |
|    approx_kl             | 0.004018101 |
|    clip_fraction         | 0.0379      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0136      |
|    cost_value_loss       | 3e-05       |
|    cost_values           | 0.0137      |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00188     |
|    n_updates             | 7760        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.861       |
|    value_loss            | 0.0369      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0878       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0878       |
| reward                   | -0.55944175  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 954          |
|    total_timesteps       | 1593344      |
| train/                   |              |
|    approx_kl             | 0.0021613021 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00605     |
|    cost_value_loss       | 0.000217     |
|    cost_values           | -0.00595     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00519      |
|    n_updates             | 7770         |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.861        |
|    value_loss            | 0.125        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0892       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0892       |
| reward                   | -0.5580406   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 976          |
|    total_timesteps       | 1595392      |
| train/                   |              |
|    approx_kl             | 0.0047420347 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00602     |
|    cost_value_loss       | 0.000228     |
|    cost_values           | -0.00316     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.967        |
|    n_updates             | 7780         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.859        |
|    value_loss            | 3.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.074        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.074        |
| reward                   | -0.4881568   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 998          |
|    total_timesteps       | 1597440      |
| train/                   |              |
|    approx_kl             | 0.0053781187 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00365     |
|    cost_value_loss       | 3.46e-06     |
|    cost_values           | -0.00327     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.563        |
|    n_updates             | 7790         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.86         |
|    value_loss            | 2.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0267       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0267       |
| reward                   | -0.5422571   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 1599488      |
| train/                   |              |
|    approx_kl             | 0.0032155938 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00122     |
|    cost_value_loss       | 5.23e-07     |
|    cost_values           | -0.00125     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.243        |
|    n_updates             | 7800         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.859        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0238       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0238       |
| reward                   | -0.37642363  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1043         |
|    total_timesteps       | 1601536      |
| train/                   |              |
|    approx_kl             | 0.0051409653 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00756     |
|    cost_value_loss       | 1.01e-05     |
|    cost_values           | -0.008       |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.745        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0691       |
|    n_updates             | 7810         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.859        |
|    value_loss            | 0.607        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0904      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0904      |
| reward                   | -0.55942935 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1065        |
|    total_timesteps       | 1603584     |
| train/                   |             |
|    approx_kl             | 0.005321616 |
|    clip_fraction         | 0.0133      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0498     |
|    cost_value_loss       | 5e-05       |
|    cost_values           | -0.0498     |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0277      |
|    n_updates             | 7820        |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.859       |
|    value_loss            | 0.572       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.157       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.157       |
| reward                   | -0.3355042  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1087        |
|    total_timesteps       | 1605632     |
| train/                   |             |
|    approx_kl             | 0.006974999 |
|    clip_fraction         | 0.0775      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00828    |
|    cost_value_loss       | 6.22e-05    |
|    cost_values           | -0.00857    |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00667    |
|    n_updates             | 7830        |
|    policy_gradient_loss  | -0.00728    |
|    std                   | 0.859       |
|    value_loss            | 0.00931     |
------------------------------------------
Directory created: PPOL_New/models/seed-testing/3rk8b0u2/model_epoch(15)
------------------------------------
| avg_speed          | 0.103       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.103       |
| reward             | -0.31270975 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -425        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1607680     |
------------------------------------
-----------------------------------------
| avg_speed                | 0.0582     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0582     |
| reward                   | -0.4668415 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -423       |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 2          |
|    time_elapsed          | 43         |
|    total_timesteps       | 1609728    |
| train/                   |            |
|    approx_kl             | 0.00476976 |
|    clip_fraction         | 0.0186     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.0332    |
|    cost_value_loss       | 4.01e-05   |
|    cost_values           | -0.0338    |
|    entropy               | -2.4       |
|    entropy_loss          | -2.4       |
|    explained_variance    | 0.853      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.0133     |
|    n_updates             | 7850       |
|    policy_gradient_loss  | -0.00101   |
|    std                   | 0.859      |
|    value_loss            | 0.103      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0061       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0061       |
| reward                   | -0.3781935   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 1611776      |
| train/                   |              |
|    approx_kl             | 0.0026986476 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000548     |
|    cost_value_loss       | 2.01e-06     |
|    cost_values           | -8.55e-05    |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -0.126       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.364        |
|    n_updates             | 7860         |
|    policy_gradient_loss  | -0.000817    |
|    std                   | 0.858        |
|    value_loss            | 1.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.106       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.106       |
| reward                   | -0.24290867 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 1613824     |
| train/                   |             |
|    approx_kl             | 0.001738359 |
|    clip_fraction         | 0.00547     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0478     |
|    cost_value_loss       | 0.000173    |
|    cost_values           | -0.0509     |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.148       |
|    n_updates             | 7870        |
|    policy_gradient_loss  | -0.000231   |
|    std                   | 0.857       |
|    value_loss            | 1.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.026        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.026        |
| reward                   | -0.32884285  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1615872      |
| train/                   |              |
|    approx_kl             | 0.0007985836 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00237     |
|    cost_value_loss       | 7.5e-06      |
|    cost_values           | -0.00206     |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.57         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00468      |
|    n_updates             | 7880         |
|    policy_gradient_loss  | -0.000385    |
|    std                   | 0.86         |
|    value_loss            | 0.101        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0155      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0155      |
| reward                   | -0.4300559  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 1617920     |
| train/                   |             |
|    approx_kl             | 0.002751092 |
|    clip_fraction         | 0.0219      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00719    |
|    cost_value_loss       | 3.67e-05    |
|    cost_values           | -0.00696    |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0059      |
|    n_updates             | 7890        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.863       |
|    value_loss            | 0.328       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.15         |
| reward                   | -0.545353    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1619968      |
| train/                   |              |
|    approx_kl             | 0.0049103033 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00359     |
|    cost_value_loss       | 1.33e-05     |
|    cost_values           | -0.00329     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0116       |
|    n_updates             | 7900         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.865        |
|    value_loss            | 0.133        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.268        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.268        |
| reward                   | -0.43268564  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 1622016      |
| train/                   |              |
|    approx_kl             | 0.0048629465 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0022      |
|    cost_value_loss       | 7.9e-06      |
|    cost_values           | -0.00226     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | -3.37        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.517        |
|    n_updates             | 7910         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.865        |
|    value_loss            | 1.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0266       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0266       |
| reward                   | -0.515594    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 199          |
|    total_timesteps       | 1624064      |
| train/                   |              |
|    approx_kl             | 0.0032501891 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00462     |
|    cost_value_loss       | 1.63e-05     |
|    cost_values           | -0.00416     |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.734        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.702        |
|    n_updates             | 7920         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.865        |
|    value_loss            | 2.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.062        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.062        |
| reward                   | -0.24053518  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 1626112      |
| train/                   |              |
|    approx_kl             | 0.0043471046 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0191      |
|    cost_value_loss       | 0.000108     |
|    cost_values           | -0.0201      |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0166       |
|    n_updates             | 7930         |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.864        |
|    value_loss            | 0.513        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.113       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.113       |
| reward                   | -0.38804916 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 1628160     |
| train/                   |             |
|    approx_kl             | 0.005361406 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0101     |
|    cost_value_loss       | 0.000321    |
|    cost_values           | -0.0165     |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.4         |
|    n_updates             | 7940        |
|    policy_gradient_loss  | -0.000889   |
|    std                   | 0.865       |
|    value_loss            | 1.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.014       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.014       |
| reward                   | -0.4723891  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 1630208     |
| train/                   |             |
|    approx_kl             | 0.004182731 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0114      |
|    cost_value_loss       | 2.44e-05    |
|    cost_values           | 0.0126      |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.75        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.197       |
|    n_updates             | 7950        |
|    policy_gradient_loss  | -0.0013     |
|    std                   | 0.868       |
|    value_loss            | 0.839       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.079       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.079       |
| reward                   | -0.5110211  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1632256     |
| train/                   |             |
|    approx_kl             | 0.008581036 |
|    clip_fraction         | 0.0775      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00148     |
|    cost_value_loss       | 1.65e-05    |
|    cost_values           | 0.00149     |
|    entropy               | -2.43       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00519    |
|    n_updates             | 7960        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.872       |
|    value_loss            | 0.0647      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0717       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0717       |
| reward                   | -0.3692632   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 309          |
|    total_timesteps       | 1634304      |
| train/                   |              |
|    approx_kl             | 0.0032707383 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00673      |
|    cost_value_loss       | 2.3e-05      |
|    cost_values           | 0.00528      |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0184       |
|    n_updates             | 7970         |
|    policy_gradient_loss  | -0.000652    |
|    std                   | 0.868        |
|    value_loss            | 0.546        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.3199609   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 332          |
|    total_timesteps       | 1636352      |
| train/                   |              |
|    approx_kl             | 0.0036375439 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00677      |
|    cost_value_loss       | 9.95e-06     |
|    cost_values           | 0.00729      |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00663      |
|    n_updates             | 7980         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.867        |
|    value_loss            | 0.372        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0593       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0593       |
| reward                   | -0.46542218  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 1638400      |
| train/                   |              |
|    approx_kl             | 0.0055176094 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00519      |
|    cost_value_loss       | 5.06e-06     |
|    cost_values           | 0.00503      |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | -0.311       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.316        |
|    n_updates             | 7990         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.869        |
|    value_loss            | 1.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0795      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0795      |
| reward                   | -0.5377179  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 376         |
|    total_timesteps       | 1640448     |
| train/                   |             |
|    approx_kl             | 0.002629928 |
|    clip_fraction         | 0.00605     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00869     |
|    cost_value_loss       | 2.7e-06     |
|    cost_values           | 0.00919     |
|    entropy               | -2.41       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -0.0519     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.254       |
|    n_updates             | 8000        |
|    policy_gradient_loss  | -0.000287   |
|    std                   | 0.864       |
|    value_loss            | 0.773       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0663       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0663       |
| reward                   | -0.3111341   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 398          |
|    total_timesteps       | 1642496      |
| train/                   |              |
|    approx_kl             | 0.0046099415 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0106      |
|    cost_value_loss       | 4.95e-05     |
|    cost_values           | -0.0118      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.187        |
|    n_updates             | 8010         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.862        |
|    value_loss            | 1.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.192        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.192        |
| reward                   | -0.23971081  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 420          |
|    total_timesteps       | 1644544      |
| train/                   |              |
|    approx_kl             | 0.0054751122 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00249     |
|    cost_value_loss       | 7.95e-06     |
|    cost_values           | -0.00266     |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.761        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0233       |
|    n_updates             | 8020         |
|    policy_gradient_loss  | -0.000893    |
|    std                   | 0.862        |
|    value_loss            | 0.292        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0335       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0335       |
| reward                   | -0.31210634  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1646592      |
| train/                   |              |
|    approx_kl             | 0.0046399925 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0126       |
|    cost_value_loss       | 1.84e-05     |
|    cost_values           | 0.0127       |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.896        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.129        |
|    n_updates             | 8030         |
|    policy_gradient_loss  | -0.000938    |
|    std                   | 0.863        |
|    value_loss            | 0.942        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.035        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.035        |
| reward                   | -0.5413416   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 1648640      |
| train/                   |              |
|    approx_kl             | 0.0040232264 |
|    clip_fraction         | 0.00952      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00937      |
|    cost_value_loss       | 1.94e-05     |
|    cost_values           | 0.00982      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -2.35        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0533       |
|    n_updates             | 8040         |
|    policy_gradient_loss  | -0.000454    |
|    std                   | 0.86         |
|    value_loss            | 0.382        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0387       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0387       |
| reward                   | -0.51463926  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 487          |
|    total_timesteps       | 1650688      |
| train/                   |              |
|    approx_kl             | 0.0053326655 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0112      |
|    cost_value_loss       | 2.92e-05     |
|    cost_values           | -0.012       |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0146       |
|    n_updates             | 8050         |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.858        |
|    value_loss            | 0.686        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.172        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.172        |
| reward                   | -0.50814676  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 509          |
|    total_timesteps       | 1652736      |
| train/                   |              |
|    approx_kl             | 0.0013228719 |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00548      |
|    cost_value_loss       | 6.32e-06     |
|    cost_values           | 0.00551      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0233       |
|    n_updates             | 8060         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.857        |
|    value_loss            | 0.293        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0252       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0252       |
| reward                   | -0.51654506  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 532          |
|    total_timesteps       | 1654784      |
| train/                   |              |
|    approx_kl             | 0.0050006723 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00643      |
|    cost_value_loss       | 2.9e-06      |
|    cost_values           | 0.00652      |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0964       |
|    n_updates             | 8070         |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.855        |
|    value_loss            | 0.231        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0991       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0991       |
| reward                   | -0.32051295  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 554          |
|    total_timesteps       | 1656832      |
| train/                   |              |
|    approx_kl             | 0.0033774886 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0043      |
|    cost_value_loss       | 5.09e-06     |
|    cost_values           | -0.00463     |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.708        |
|    n_updates             | 8080         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.855        |
|    value_loss            | 3.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0167      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0167      |
| reward                   | -0.31635216 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 576         |
|    total_timesteps       | 1658880     |
| train/                   |             |
|    approx_kl             | 0.009381179 |
|    clip_fraction         | 0.0262      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00436    |
|    cost_value_loss       | 1.13e-06    |
|    cost_values           | -0.00449    |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.147       |
|    n_updates             | 8090        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.855       |
|    value_loss            | 0.503       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0249       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0249       |
| reward                   | -0.42168397  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 598          |
|    total_timesteps       | 1660928      |
| train/                   |              |
|    approx_kl             | 0.0024298718 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00712      |
|    cost_value_loss       | 7.23e-06     |
|    cost_values           | 0.00816      |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | -1.62        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.522        |
|    n_updates             | 8100         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.855        |
|    value_loss            | 2.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.133       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.133       |
| reward                   | -0.25661534 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 620         |
|    total_timesteps       | 1662976     |
| train/                   |             |
|    approx_kl             | 0.002528178 |
|    clip_fraction         | 0.0063      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00342     |
|    cost_value_loss       | 7.86e-06    |
|    cost_values           | 0.00364     |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0999      |
|    n_updates             | 8110        |
|    policy_gradient_loss  | -0.000456   |
|    std                   | 0.855       |
|    value_loss            | 0.391       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0885       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0885       |
| reward                   | -0.25577104  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 642          |
|    total_timesteps       | 1665024      |
| train/                   |              |
|    approx_kl             | 0.0042577605 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0102      |
|    cost_value_loss       | 7.01e-06     |
|    cost_values           | -0.0104      |
|    entropy               | -2.38        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.026        |
|    n_updates             | 8120         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.853        |
|    value_loss            | 0.233        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00675      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00675      |
| reward                   | -0.5105051   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 664          |
|    total_timesteps       | 1667072      |
| train/                   |              |
|    approx_kl             | 0.0047872537 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00303     |
|    cost_value_loss       | 6.21e-06     |
|    cost_values           | -0.00325     |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0094       |
|    n_updates             | 8130         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.851        |
|    value_loss            | 0.365        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.044       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.044       |
| reward                   | -0.5063237  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 687         |
|    total_timesteps       | 1669120     |
| train/                   |             |
|    approx_kl             | 0.002647772 |
|    clip_fraction         | 0.00493     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0112     |
|    cost_value_loss       | 2.89e-06    |
|    cost_values           | -0.0113     |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0622      |
|    n_updates             | 8140        |
|    policy_gradient_loss  | -0.000401   |
|    std                   | 0.851       |
|    value_loss            | 0.412       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00185      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00185      |
| reward                   | -0.4325215   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 709          |
|    total_timesteps       | 1671168      |
| train/                   |              |
|    approx_kl             | 0.0049283365 |
|    clip_fraction         | 0.0574       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.01        |
|    cost_value_loss       | 2.34e-06     |
|    cost_values           | -0.0101      |
|    entropy               | -2.39        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00583     |
|    n_updates             | 8150         |
|    policy_gradient_loss  | -0.00572     |
|    std                   | 0.858        |
|    value_loss            | 0.0766       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.196       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.196       |
| reward                   | -0.31377494 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 731         |
|    total_timesteps       | 1673216     |
| train/                   |             |
|    approx_kl             | 0.00536595  |
|    clip_fraction         | 0.0435      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00354    |
|    cost_value_loss       | 2.13e-05    |
|    cost_values           | -0.00308    |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.924       |
|    n_updates             | 8160        |
|    policy_gradient_loss  | -0.00311    |
|    std                   | 0.862       |
|    value_loss            | 4.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0316       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0316       |
| reward                   | -0.37163877  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 753          |
|    total_timesteps       | 1675264      |
| train/                   |              |
|    approx_kl             | 0.0008507123 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000795     |
|    cost_value_loss       | 1.36e-05     |
|    cost_values           | 0.00118      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -1.33        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.908        |
|    n_updates             | 8170         |
|    policy_gradient_loss  | -0.000531    |
|    std                   | 0.862        |
|    value_loss            | 3.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0348       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0348       |
| reward                   | -0.24045908  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 775          |
|    total_timesteps       | 1677312      |
| train/                   |              |
|    approx_kl             | 0.0054419558 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000908     |
|    cost_value_loss       | 7.39e-06     |
|    cost_values           | 0.00107      |
|    entropy               | -2.38        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000584     |
|    n_updates             | 8180         |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 0.858        |
|    value_loss            | 0.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.37867185  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 798          |
|    total_timesteps       | 1679360      |
| train/                   |              |
|    approx_kl             | 0.0031233542 |
|    clip_fraction         | 0.00664      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000203     |
|    cost_value_loss       | 3.96e-06     |
|    cost_values           | 0.00056      |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | -6.37        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.359        |
|    n_updates             | 8190         |
|    policy_gradient_loss  | -0.000976    |
|    std                   | 0.856        |
|    value_loss            | 1.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.54630363  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 820          |
|    total_timesteps       | 1681408      |
| train/                   |              |
|    approx_kl             | 0.0036037874 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00509     |
|    cost_value_loss       | 4.93e-06     |
|    cost_values           | -0.00495     |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.821        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.2          |
|    n_updates             | 8200         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.856        |
|    value_loss            | 0.891        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00357     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00357     |
| reward                   | -0.55692506 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 842         |
|    total_timesteps       | 1683456     |
| train/                   |             |
|    approx_kl             | 0.004207279 |
|    clip_fraction         | 0.0163      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0154     |
|    cost_value_loss       | 8.17e-06    |
|    cost_values           | -0.0157     |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00299     |
|    n_updates             | 8210        |
|    policy_gradient_loss  | -0.000809   |
|    std                   | 0.857       |
|    value_loss            | 0.0946      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.2398797   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 864          |
|    total_timesteps       | 1685504      |
| train/                   |              |
|    approx_kl             | 0.0034564377 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00631     |
|    cost_value_loss       | 9.04e-06     |
|    cost_values           | -0.00651     |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.519        |
|    n_updates             | 8220         |
|    policy_gradient_loss  | -0.000785    |
|    std                   | 0.857        |
|    value_loss            | 2.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.119        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.119        |
| reward                   | -0.5457102   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 887          |
|    total_timesteps       | 1687552      |
| train/                   |              |
|    approx_kl             | 0.0045179343 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00337      |
|    cost_value_loss       | 2.82e-05     |
|    cost_values           | 0.00327      |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.08         |
|    n_updates             | 8230         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.856        |
|    value_loss            | 5            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.181        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.181        |
| reward                   | -0.4724385   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 909          |
|    total_timesteps       | 1689600      |
| train/                   |              |
|    approx_kl             | 0.0007222402 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0074      |
|    cost_value_loss       | 3.09e-06     |
|    cost_values           | -0.0082      |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.851        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.189        |
|    n_updates             | 8240         |
|    policy_gradient_loss  | -0.000261    |
|    std                   | 0.857        |
|    value_loss            | 1.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.053       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.053       |
| reward                   | -0.5076114  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 931         |
|    total_timesteps       | 1691648     |
| train/                   |             |
|    approx_kl             | 0.002624102 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00659    |
|    cost_value_loss       | 1.13e-06    |
|    cost_values           | -0.0067     |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0325      |
|    n_updates             | 8250        |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 0.858       |
|    value_loss            | 0.138       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.192       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.192       |
| reward                   | -0.45831147 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 953         |
|    total_timesteps       | 1693696     |
| train/                   |             |
|    approx_kl             | 0.009467023 |
|    clip_fraction         | 0.0376      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00874    |
|    cost_value_loss       | 1.76e-06    |
|    cost_values           | -0.00877    |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0103      |
|    n_updates             | 8260        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.862       |
|    value_loss            | 0.126       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.24017346  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 975          |
|    total_timesteps       | 1695744      |
| train/                   |              |
|    approx_kl             | 0.0037578908 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00447      |
|    cost_value_loss       | 5.1e-06      |
|    cost_values           | 0.00452      |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0198       |
|    n_updates             | 8270         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.859        |
|    value_loss            | 0.193        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.50769895  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 997          |
|    total_timesteps       | 1697792      |
| train/                   |              |
|    approx_kl             | 0.0041697086 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00469      |
|    cost_value_loss       | 7.96e-06     |
|    cost_values           | 0.00495      |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.836        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.444        |
|    n_updates             | 8280         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.856        |
|    value_loss            | 2.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0132      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0132      |
| reward                   | -0.46738288 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 1699840     |
| train/                   |             |
|    approx_kl             | 0.004136645 |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0113     |
|    cost_value_loss       | 4.22e-06    |
|    cost_values           | -0.0115     |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.385       |
|    n_updates             | 8290        |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.856       |
|    value_loss            | 1.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.16        |
| reward                   | -0.42493722 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 1701888     |
| train/                   |             |
|    approx_kl             | 0.006771196 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.001       |
|    cost_value_loss       | 6.49e-06    |
|    cost_values           | 0.00074     |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.016       |
|    n_updates             | 8300        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.854       |
|    value_loss            | 0.121       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.106        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.106        |
| reward                   | -0.46619818  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 1703936      |
| train/                   |              |
|    approx_kl             | 0.0023319218 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0042      |
|    cost_value_loss       | 3.37e-06     |
|    cost_values           | -0.00406     |
|    entropy               | -2.34        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -6.25e-05    |
|    n_updates             | 8310         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.848        |
|    value_loss            | 0.0928       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.16        |
| reward                   | -0.33085757 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1085        |
|    total_timesteps       | 1705984     |
| train/                   |             |
|    approx_kl             | 0.004955844 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000537    |
|    cost_value_loss       | 2.13e-06    |
|    cost_values           | 0.000549    |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0457      |
|    n_updates             | 8320        |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.847       |
|    value_loss            | 0.311       |
------------------------------------------
-----------------------------------
| avg_speed          | 0.0306     |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.0306     |
| reward             | -0.5452549 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -412       |
| time/              |            |
|    fps             | 96         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 1708032    |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.00143      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00143      |
| reward                   | -0.31200433  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1710080      |
| train/                   |              |
|    approx_kl             | 0.0039769514 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0172      |
|    cost_value_loss       | 1.28e-05     |
|    cost_values           | -0.0177      |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.579        |
|    n_updates             | 8340         |
|    policy_gradient_loss  | -0.000547    |
|    std                   | 0.835        |
|    value_loss            | 1.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.037       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.037       |
| reward                   | -0.5448531  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 1712128     |
| train/                   |             |
|    approx_kl             | 0.003700098 |
|    clip_fraction         | 0.0123      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00121     |
|    cost_value_loss       | 1.31e-06    |
|    cost_values           | 0.00127     |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.537       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.868       |
|    n_updates             | 8350        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.835       |
|    value_loss            | 2.4         |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.121      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.121      |
| reward                   | -0.4204179 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -417       |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 4          |
|    time_elapsed          | 87         |
|    total_timesteps       | 1714176    |
| train/                   |            |
|    approx_kl             | 0.00601979 |
|    clip_fraction         | 0.034      |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00258   |
|    cost_value_loss       | 3.27e-06   |
|    cost_values           | -0.00265   |
|    entropy               | -2.31      |
|    entropy_loss          | -2.32      |
|    explained_variance    | 0.924      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.718      |
|    n_updates             | 8360       |
|    policy_gradient_loss  | -0.0016    |
|    std                   | 0.832      |
|    value_loss            | 1.82       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0936      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0936      |
| reward                   | -0.42698976 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 1716224     |
| train/                   |             |
|    approx_kl             | 0.005492075 |
|    clip_fraction         | 0.0163      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00348     |
|    cost_value_loss       | 9.8e-07     |
|    cost_values           | 0.00361     |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.426       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.357       |
|    n_updates             | 8370        |
|    policy_gradient_loss  | -0.000799   |
|    std                   | 0.829       |
|    value_loss            | 1.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.46547538  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 131          |
|    total_timesteps       | 1718272      |
| train/                   |              |
|    approx_kl             | 0.0038454242 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00066     |
|    cost_value_loss       | 1.31e-05     |
|    cost_values           | -0.000776    |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00319     |
|    n_updates             | 8380         |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 0.828        |
|    value_loss            | 0.0798       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0143       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0143       |
| reward                   | -0.36960897  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 153          |
|    total_timesteps       | 1720320      |
| train/                   |              |
|    approx_kl             | 0.0042069545 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0029      |
|    cost_value_loss       | 4.2e-05      |
|    cost_values           | -0.00389     |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.833        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.418        |
|    n_updates             | 8390         |
|    policy_gradient_loss  | -0.000376    |
|    std                   | 0.825        |
|    value_loss            | 0.979        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.017       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.017       |
| reward                   | -0.46538037 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 1722368     |
| train/                   |             |
|    approx_kl             | 0.006202598 |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00626    |
|    cost_value_loss       | 1.65e-06    |
|    cost_values           | -0.00631    |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.484       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.732       |
|    n_updates             | 8400        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.824       |
|    value_loss            | 1.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0132      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0132      |
| reward                   | -0.389233   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 197         |
|    total_timesteps       | 1724416     |
| train/                   |             |
|    approx_kl             | 0.005911623 |
|    clip_fraction         | 0.0416      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0117     |
|    cost_value_loss       | 3.86e-06    |
|    cost_values           | -0.012      |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00913     |
|    n_updates             | 8410        |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.826       |
|    value_loss            | 0.246       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0668       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0668       |
| reward                   | -0.33135915  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 1726464      |
| train/                   |              |
|    approx_kl             | 0.0049457126 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0109      |
|    cost_value_loss       | 3.73e-06     |
|    cost_values           | -0.0108      |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0113       |
|    n_updates             | 8420         |
|    policy_gradient_loss  | -0.000369    |
|    std                   | 0.83         |
|    value_loss            | 0.0622       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0143       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0143       |
| reward                   | -0.46549484  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 241          |
|    total_timesteps       | 1728512      |
| train/                   |              |
|    approx_kl             | 0.0076636826 |
|    clip_fraction         | 0.0729       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00931     |
|    cost_value_loss       | 4.26e-06     |
|    cost_values           | -0.00939     |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0291       |
|    n_updates             | 8430         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.827        |
|    value_loss            | 0.157        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00853      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00853      |
| reward                   | -0.32265103  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 264          |
|    total_timesteps       | 1730560      |
| train/                   |              |
|    approx_kl             | 0.0046892245 |
|    clip_fraction         | 0.0412       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000955     |
|    cost_value_loss       | 1.81e-06     |
|    cost_values           | 0.000951     |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.559        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.277        |
|    n_updates             | 8440         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.829        |
|    value_loss            | 0.637        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0567       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0567       |
| reward                   | -0.37800133  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 285          |
|    total_timesteps       | 1732608      |
| train/                   |              |
|    approx_kl             | 0.0050733676 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0169      |
|    cost_value_loss       | 1.3e-05      |
|    cost_values           | -0.0166      |
|    entropy               | -2.32        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -2.33        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0525       |
|    n_updates             | 8450         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.831        |
|    value_loss            | 0.486        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.55316675  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 307          |
|    total_timesteps       | 1734656      |
| train/                   |              |
|    approx_kl             | 0.0029075942 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0121      |
|    cost_value_loss       | 1e-05        |
|    cost_values           | -0.0121      |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.0037      |
|    n_updates             | 8460         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.83         |
|    value_loss            | 0.0539       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0835      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0835      |
| reward                   | -0.46927926 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 1736704     |
| train/                   |             |
|    approx_kl             | 0.004362192 |
|    clip_fraction         | 0.0379      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0108     |
|    cost_value_loss       | 1.76e-05    |
|    cost_values           | -0.0106     |
|    entropy               | -2.3        |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00215     |
|    n_updates             | 8470        |
|    policy_gradient_loss  | -0.000764   |
|    std                   | 0.828       |
|    value_loss            | 0.0413      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0818       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0818       |
| reward                   | -0.46547058  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 1738752      |
| train/                   |              |
|    approx_kl             | 0.0050324346 |
|    clip_fraction         | 0.0508       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0123      |
|    cost_value_loss       | 5.16e-06     |
|    cost_values           | -0.0122      |
|    entropy               | -2.29        |
|    entropy_loss          | -2.3         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00349     |
|    n_updates             | 8480         |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 0.823        |
|    value_loss            | 0.00572      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0681       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0681       |
| reward                   | -0.24297434  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 374          |
|    total_timesteps       | 1740800      |
| train/                   |              |
|    approx_kl             | 0.0025249086 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00233      |
|    cost_value_loss       | 2.31e-06     |
|    cost_values           | 0.00221      |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.669        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.526        |
|    n_updates             | 8490         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.822        |
|    value_loss            | 2.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.05        |
| reward                   | -0.3191497  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 18          |
|    time_elapsed          | 396         |
|    total_timesteps       | 1742848     |
| train/                   |             |
|    approx_kl             | 0.001978388 |
|    clip_fraction         | 0.00215     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00288     |
|    cost_value_loss       | 1.42e-06    |
|    cost_values           | 0.0029      |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.333       |
|    n_updates             | 8500        |
|    policy_gradient_loss  | -0.000361   |
|    std                   | 0.821       |
|    value_loss            | 2.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00389      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00389      |
| reward                   | -0.25263897  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 418          |
|    total_timesteps       | 1744896      |
| train/                   |              |
|    approx_kl             | 0.0053435266 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00948     |
|    cost_value_loss       | 4.09e-06     |
|    cost_values           | -0.00956     |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.26         |
|    n_updates             | 8510         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.821        |
|    value_loss            | 1.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0859       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0859       |
| reward                   | -0.46900696  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 440          |
|    total_timesteps       | 1746944      |
| train/                   |              |
|    approx_kl             | 0.0041378317 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00435      |
|    cost_value_loss       | 1.21e-06     |
|    cost_values           | 0.00436      |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.132        |
|    n_updates             | 8520         |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.821        |
|    value_loss            | 0.601        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.47047454  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 462          |
|    total_timesteps       | 1748992      |
| train/                   |              |
|    approx_kl             | 0.0058156434 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000955     |
|    cost_value_loss       | 1.11e-06     |
|    cost_values           | 0.00103      |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.148        |
|    n_updates             | 8530         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.82         |
|    value_loss            | 0.904        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.3130832   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 484          |
|    total_timesteps       | 1751040      |
| train/                   |              |
|    approx_kl             | 0.0042716814 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00251      |
|    cost_value_loss       | 2.81e-05     |
|    cost_values           | 0.00327      |
|    entropy               | -2.28        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0208       |
|    n_updates             | 8540         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.819        |
|    value_loss            | 0.141        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.42096898  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 506          |
|    total_timesteps       | 1753088      |
| train/                   |              |
|    approx_kl             | 0.0062072873 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00875     |
|    cost_value_loss       | 2.71e-05     |
|    cost_values           | -0.00893     |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.048        |
|    n_updates             | 8550         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.818        |
|    value_loss            | 0.237        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0611      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0611      |
| reward                   | -0.32787022 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 1755136     |
| train/                   |             |
|    approx_kl             | 0.003995962 |
|    clip_fraction         | 0.0347      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00243     |
|    cost_value_loss       | 1.14e-05    |
|    cost_values           | 0.00187     |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.472       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.2         |
|    n_updates             | 8560        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.817       |
|    value_loss            | 2.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.072       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.072       |
| reward                   | -0.4208355  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 551         |
|    total_timesteps       | 1757184     |
| train/                   |             |
|    approx_kl             | 0.003644682 |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0103     |
|    cost_value_loss       | 3.5e-06     |
|    cost_values           | -0.0103     |
|    entropy               | -2.27       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0195      |
|    n_updates             | 8570        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.811       |
|    value_loss            | 0.132       |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.187         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.187         |
| reward                   | -0.43565625   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -426          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 26            |
|    time_elapsed          | 573           |
|    total_timesteps       | 1759232       |
| train/                   |               |
|    approx_kl             | 0.00051388744 |
|    clip_fraction         | 0.0302        |
|    clip_range            | 0.2           |
|    cost_returns          | 0.00038       |
|    cost_value_loss       | 4.19e-07      |
|    cost_values           | 0.000321      |
|    entropy               | -2.27         |
|    entropy_loss          | -2.27         |
|    explained_variance    | 0.681         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.639         |
|    n_updates             | 8580          |
|    policy_gradient_loss  | 0.000808      |
|    std                   | 0.81          |
|    value_loss            | 1.63          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0558       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0558       |
| reward                   | -0.3207348   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 595          |
|    total_timesteps       | 1761280      |
| train/                   |              |
|    approx_kl             | 0.0069829947 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.76e-05     |
|    cost_value_loss       | 1.54e-07     |
|    cost_values           | 7.69e-05     |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.78         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000866     |
|    n_updates             | 8590         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.806        |
|    value_loss            | 0.0607       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.158        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.158        |
| reward                   | -0.5090571   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 617          |
|    total_timesteps       | 1763328      |
| train/                   |              |
|    approx_kl             | 0.0075841043 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0183      |
|    cost_value_loss       | 6.51e-06     |
|    cost_values           | -0.0185      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.534        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0133       |
|    n_updates             | 8600         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.806        |
|    value_loss            | 0.218        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0162      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0162      |
| reward                   | -0.2661892  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 640         |
|    total_timesteps       | 1765376     |
| train/                   |             |
|    approx_kl             | 0.004099644 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0135     |
|    cost_value_loss       | 6.18e-06    |
|    cost_values           | -0.0139     |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.18        |
|    n_updates             | 8610        |
|    policy_gradient_loss  | -0.00048    |
|    std                   | 0.805       |
|    value_loss            | 0.675       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0633      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0633      |
| reward                   | -0.42016456 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 662         |
|    total_timesteps       | 1767424     |
| train/                   |             |
|    approx_kl             | 0.004499815 |
|    clip_fraction         | 0.0102      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00836    |
|    cost_value_loss       | 2.13e-06    |
|    cost_values           | -0.00853    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.317       |
|    n_updates             | 8620        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.805       |
|    value_loss            | 1.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0659       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0659       |
| reward                   | -0.3728272   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 684          |
|    total_timesteps       | 1769472      |
| train/                   |              |
|    approx_kl             | 0.0037925702 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0171      |
|    cost_value_loss       | 5.95e-06     |
|    cost_values           | -0.0172      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0844       |
|    n_updates             | 8630         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.805        |
|    value_loss            | 0.403        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0649      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0649      |
| reward                   | -0.23912238 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 706         |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.005257813 |
|    clip_fraction         | 0.0355      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00434    |
|    cost_value_loss       | 2.53e-05    |
|    cost_values           | -0.0042     |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00334    |
|    n_updates             | 8640        |
|    policy_gradient_loss  | -0.00229    |
|    std                   | 0.807       |
|    value_loss            | 0.0108      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0033      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0033      |
| reward                   | -0.33576995 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 729         |
|    total_timesteps       | 1773568     |
| train/                   |             |
|    approx_kl             | 0.004273946 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00103     |
|    cost_value_loss       | 3.13e-05    |
|    cost_values           | 0.000735    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.54        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 8650        |
|    policy_gradient_loss  | 0.000232    |
|    std                   | 0.807       |
|    value_loss            | 4.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.112       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.112       |
| reward                   | -0.3624502  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 751         |
|    total_timesteps       | 1775616     |
| train/                   |             |
|    approx_kl             | 0.003430686 |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00266    |
|    cost_value_loss       | 1.53e-06    |
|    cost_values           | -0.00277    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.132       |
|    n_updates             | 8660        |
|    policy_gradient_loss  | -0.000737   |
|    std                   | 0.808       |
|    value_loss            | 0.609       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.46915132  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 773          |
|    total_timesteps       | 1777664      |
| train/                   |              |
|    approx_kl             | 0.0059515126 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | -7.67e-05    |
|    cost_value_loss       | 1.05e-06     |
|    cost_values           | -0.000107    |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0642       |
|    n_updates             | 8670         |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 0.807        |
|    value_loss            | 0.539        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.227        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.227        |
| reward                   | -0.5522543   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 795          |
|    total_timesteps       | 1779712      |
| train/                   |              |
|    approx_kl             | 0.0043055154 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000427    |
|    cost_value_loss       | 1.26e-05     |
|    cost_values           | -0.00149     |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0321       |
|    n_updates             | 8680         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.804        |
|    value_loss            | 0.875        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.46301803  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 818          |
|    total_timesteps       | 1781760      |
| train/                   |              |
|    approx_kl             | 0.0048945434 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000218    |
|    cost_value_loss       | 5.19e-07     |
|    cost_values           | -0.000242    |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0616       |
|    n_updates             | 8690         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.803        |
|    value_loss            | 0.358        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0163       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0163       |
| reward                   | -0.38639826  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 840          |
|    total_timesteps       | 1783808      |
| train/                   |              |
|    approx_kl             | 0.0051372107 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00549      |
|    cost_value_loss       | 3.04e-05     |
|    cost_values           | 0.00544      |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0107       |
|    n_updates             | 8700         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.803        |
|    value_loss            | 0.158        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.146        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.146        |
| reward                   | -0.5464509   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 862          |
|    total_timesteps       | 1785856      |
| train/                   |              |
|    approx_kl             | 0.0016556303 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000353    |
|    cost_value_loss       | 8.67e-06     |
|    cost_values           | -0.000513    |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.955        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00221      |
|    n_updates             | 8710         |
|    policy_gradient_loss  | -0.000888    |
|    std                   | 0.807        |
|    value_loss            | 0.0513       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0576       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0576       |
| reward                   | -0.4786376   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 884          |
|    total_timesteps       | 1787904      |
| train/                   |              |
|    approx_kl             | 0.0021679983 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0159      |
|    cost_value_loss       | 1.28e-05     |
|    cost_values           | -0.0159      |
|    entropy               | -2.27        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0154       |
|    n_updates             | 8720         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 0.812        |
|    value_loss            | 0.0889       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.131        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.131        |
| reward                   | -0.3132934   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 907          |
|    total_timesteps       | 1789952      |
| train/                   |              |
|    approx_kl             | 0.0017908404 |
|    clip_fraction         | 0.00708      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00397      |
|    cost_value_loss       | 4.93e-05     |
|    cost_values           | 0.00613      |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.674        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0404       |
|    n_updates             | 8730         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.813        |
|    value_loss            | 1.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.012       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.012       |
| reward                   | -0.31806374 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 929         |
|    total_timesteps       | 1792000     |
| train/                   |             |
|    approx_kl             | 0.007521496 |
|    clip_fraction         | 0.0521      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0086     |
|    cost_value_loss       | 3.92e-06    |
|    cost_values           | -0.00872    |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0123      |
|    n_updates             | 8740        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.812       |
|    value_loss            | 0.0762      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.07         |
| reward                   | -0.5557201   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 951          |
|    total_timesteps       | 1794048      |
| train/                   |              |
|    approx_kl             | 0.0029473337 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00971     |
|    cost_value_loss       | 5.63e-06     |
|    cost_values           | -0.0102      |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.275        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.201        |
|    n_updates             | 8750         |
|    policy_gradient_loss  | -0.000739    |
|    std                   | 0.814        |
|    value_loss            | 1.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0135      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0135      |
| reward                   | -0.42184278 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 973         |
|    total_timesteps       | 1796096     |
| train/                   |             |
|    approx_kl             | 0.005731547 |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00596     |
|    cost_value_loss       | 7.82e-06    |
|    cost_values           | 0.00603     |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00263    |
|    n_updates             | 8760        |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.816       |
|    value_loss            | 0.0487      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0164      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0164      |
| reward                   | -0.46731585 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 995         |
|    total_timesteps       | 1798144     |
| train/                   |             |
|    approx_kl             | 0.00704233  |
|    clip_fraction         | 0.033       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0185     |
|    cost_value_loss       | 1.63e-05    |
|    cost_values           | -0.0187     |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0012     |
|    n_updates             | 8770        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.816       |
|    value_loss            | 0.0177      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.221        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.221        |
| reward                   | -0.33242205  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1017         |
|    total_timesteps       | 1800192      |
| train/                   |              |
|    approx_kl             | 0.0060168523 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3e-05      |
|    cost_value_loss       | 2.38e-06     |
|    cost_values           | 0.00011      |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00464      |
|    n_updates             | 8780         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.818        |
|    value_loss            | 0.0393       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.207        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.207        |
| reward                   | -0.25873795  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1039         |
|    total_timesteps       | 1802240      |
| train/                   |              |
|    approx_kl             | 0.0020893726 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00325     |
|    cost_value_loss       | 3.11e-06     |
|    cost_values           | -0.00363     |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0614       |
|    n_updates             | 8790         |
|    policy_gradient_loss  | -0.000848    |
|    std                   | 0.817        |
|    value_loss            | 0.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.041        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.041        |
| reward                   | -0.50891894  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 1804288      |
| train/                   |              |
|    approx_kl             | 0.0042342497 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000299    |
|    cost_value_loss       | 1.76e-06     |
|    cost_values           | -0.000539    |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.722        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.088        |
|    n_updates             | 8800         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.815        |
|    value_loss            | 0.343        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0619       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0619       |
| reward                   | -0.55410755  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1084         |
|    total_timesteps       | 1806336      |
| train/                   |              |
|    approx_kl             | 0.0035581756 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00272     |
|    cost_value_loss       | 1.23e-06     |
|    cost_values           | -0.00296     |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0406       |
|    n_updates             | 8810         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.815        |
|    value_loss            | 0.378        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.0364      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0364      |
| reward             | -0.46610692 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -417        |
| time/              |             |
|    fps             | 96          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1808384     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.0265       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0265       |
| reward                   | -0.50709605  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1810432      |
| train/                   |              |
|    approx_kl             | 0.0054484857 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0178      |
|    cost_value_loss       | 1.91e-05     |
|    cost_values           | -0.0178      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0443       |
|    n_updates             | 8830         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.813        |
|    value_loss            | 0.733        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0617       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0617       |
| reward                   | -0.5499011   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 1812480      |
| train/                   |              |
|    approx_kl             | 0.0020574257 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00502     |
|    cost_value_loss       | 2.36e-05     |
|    cost_values           | -0.00416     |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.646        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.693        |
|    n_updates             | 8840         |
|    policy_gradient_loss  | 0.000875     |
|    std                   | 0.814        |
|    value_loss            | 1.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.208        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.208        |
| reward                   | -0.50694704  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 1814528      |
| train/                   |              |
|    approx_kl             | 0.0030160495 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0157      |
|    cost_value_loss       | 2.53e-05     |
|    cost_values           | -0.0151      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0719       |
|    n_updates             | 8850         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.816        |
|    value_loss            | 0.708        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.117       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.117       |
| reward                   | -0.5069384  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 1816576     |
| train/                   |             |
|    approx_kl             | 0.002320839 |
|    clip_fraction         | 0.0119      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0168      |
|    cost_value_loss       | 5.35e-06    |
|    cost_values           | 0.0169      |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.000395   |
|    n_updates             | 8860        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.816       |
|    value_loss            | 0.127       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.142       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.142       |
| reward                   | -0.5576845  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 1818624     |
| train/                   |             |
|    approx_kl             | 0.004192911 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00164     |
|    cost_value_loss       | 5.63e-06    |
|    cost_values           | 0.00175     |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.132       |
|    n_updates             | 8870        |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.815       |
|    value_loss            | 0.874       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.232       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.232       |
| reward                   | -0.55647457 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 1820672     |
| train/                   |             |
|    approx_kl             | 0.004580045 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00891    |
|    cost_value_loss       | 5.45e-06    |
|    cost_values           | -0.00895    |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0511      |
|    n_updates             | 8880        |
|    policy_gradient_loss  | -0.00525    |
|    std                   | 0.817       |
|    value_loss            | 0.292       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.15         |
| reward                   | -0.4803479   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 1822720      |
| train/                   |              |
|    approx_kl             | 0.0023712683 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0198      |
|    cost_value_loss       | 7.83e-06     |
|    cost_values           | -0.0199      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00232      |
|    n_updates             | 8890         |
|    policy_gradient_loss  | -0.00021     |
|    std                   | 0.812        |
|    value_loss            | 0.0189       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.157       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.157       |
| reward                   | -0.50784737 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 1824768     |
| train/                   |             |
|    approx_kl             | 0.0086164   |
|    clip_fraction         | 0.0666      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00277     |
|    cost_value_loss       | 8.21e-06    |
|    cost_values           | 0.00286     |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00109     |
|    n_updates             | 8900        |
|    policy_gradient_loss  | -0.00462    |
|    std                   | 0.807       |
|    value_loss            | 0.0252      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.17        |
| reward                   | -0.50135714 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 220         |
|    total_timesteps       | 1826816     |
| train/                   |             |
|    approx_kl             | 0.004340226 |
|    clip_fraction         | 0.0297      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.67e-06    |
|    cost_value_loss       | 3.88e-07    |
|    cost_values           | 2.2e-06     |
|    entropy               | -2.26       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00433     |
|    n_updates             | 8910        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.81        |
|    value_loss            | 0.0185      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0152       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0152       |
| reward                   | -0.4268913   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 1828864      |
| train/                   |              |
|    approx_kl             | 0.0060498603 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00392     |
|    cost_value_loss       | 1.17e-06     |
|    cost_values           | -0.00393     |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00771      |
|    n_updates             | 8920         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.806        |
|    value_loss            | 0.00242      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.145        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.145        |
| reward                   | -0.32755893  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 264          |
|    total_timesteps       | 1830912      |
| train/                   |              |
|    approx_kl             | 0.0032929606 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0108      |
|    cost_value_loss       | 6.88e-06     |
|    cost_values           | -0.011       |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.748        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.667        |
|    n_updates             | 8930         |
|    policy_gradient_loss  | 0.0036       |
|    std                   | 0.805        |
|    value_loss            | 1.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.161       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.161       |
| reward                   | -0.37793314 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 286         |
|    total_timesteps       | 1832960     |
| train/                   |             |
|    approx_kl             | 0.004044916 |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00354     |
|    cost_value_loss       | 4.84e-06    |
|    cost_values           | 0.00352     |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00924    |
|    n_updates             | 8940        |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.805       |
|    value_loss            | 0.0235      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.148        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.148        |
| reward                   | -0.46727967  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 308          |
|    total_timesteps       | 1835008      |
| train/                   |              |
|    approx_kl             | 0.0050824527 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0258      |
|    cost_value_loss       | 6.55e-05     |
|    cost_values           | -0.0265      |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000842     |
|    n_updates             | 8950         |
|    policy_gradient_loss  | -0.000548    |
|    std                   | 0.801        |
|    value_loss            | 0.0583       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0571       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0571       |
| reward                   | -0.5462078   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 330          |
|    total_timesteps       | 1837056      |
| train/                   |              |
|    approx_kl             | 0.0021373825 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00186     |
|    cost_value_loss       | 1.58e-05     |
|    cost_values           | -0.00147     |
|    entropy               | -2.23        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00633      |
|    n_updates             | 8960         |
|    policy_gradient_loss  | -3.68e-05    |
|    std                   | 0.798        |
|    value_loss            | 0.0533       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00154     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00154     |
| reward                   | -0.42423    |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 353         |
|    total_timesteps       | 1839104     |
| train/                   |             |
|    approx_kl             | 0.004540112 |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0206      |
|    cost_value_loss       | 1.24e-05    |
|    cost_values           | 0.0207      |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00932     |
|    n_updates             | 8970        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.797       |
|    value_loss            | 0.0367      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.4213652   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 375          |
|    total_timesteps       | 1841152      |
| train/                   |              |
|    approx_kl             | 0.0033855573 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000756     |
|    cost_value_loss       | 1.96e-06     |
|    cost_values           | 0.000859     |
|    entropy               | -2.22        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000869    |
|    n_updates             | 8980         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.792        |
|    value_loss            | 0.0916       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.47522247  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 397          |
|    total_timesteps       | 1843200      |
| train/                   |              |
|    approx_kl             | 0.0037587164 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0382       |
|    cost_value_loss       | 3.83e-05     |
|    cost_values           | 0.0386       |
|    entropy               | -2.21        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000781     |
|    n_updates             | 8990         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.788        |
|    value_loss            | 0.0249       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.122        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.122        |
| reward                   | -0.47725022  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 419          |
|    total_timesteps       | 1845248      |
| train/                   |              |
|    approx_kl             | 0.0012327919 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.073        |
|    cost_value_loss       | 8.46e-05     |
|    cost_values           | 0.0734       |
|    entropy               | -2.2         |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.17         |
|    n_updates             | 9000         |
|    policy_gradient_loss  | -0.000111    |
|    std                   | 0.785        |
|    value_loss            | 0.439        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00119      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00119      |
| reward                   | -0.47659478  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 441          |
|    total_timesteps       | 1847296      |
| train/                   |              |
|    approx_kl             | 0.0054656873 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0249       |
|    cost_value_loss       | 5.97e-05     |
|    cost_values           | 0.0259       |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00255     |
|    n_updates             | 9010         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.783        |
|    value_loss            | 0.0221       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0618       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0618       |
| reward                   | -0.5451138   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 463          |
|    total_timesteps       | 1849344      |
| train/                   |              |
|    approx_kl             | 0.0025118159 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0475       |
|    cost_value_loss       | 5.34e-05     |
|    cost_values           | 0.0492       |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.749        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.225        |
|    n_updates             | 9020         |
|    policy_gradient_loss  | 9.38e-05     |
|    std                   | 0.784        |
|    value_loss            | 1.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.113        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.113        |
| reward                   | -0.33570722  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 485          |
|    total_timesteps       | 1851392      |
| train/                   |              |
|    approx_kl             | 0.0043740543 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00582      |
|    cost_value_loss       | 5.55e-06     |
|    cost_values           | 0.00584      |
|    entropy               | -2.19        |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0135       |
|    n_updates             | 9030         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.781        |
|    value_loss            | 0.0139       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00137     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00137     |
| reward                   | -0.55559343 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 507         |
|    total_timesteps       | 1853440     |
| train/                   |             |
|    approx_kl             | 0.006324495 |
|    clip_fraction         | 0.0326      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0315      |
|    cost_value_loss       | 8.68e-05    |
|    cost_values           | 0.0312      |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00151     |
|    n_updates             | 9040        |
|    policy_gradient_loss  | -0.00278    |
|    std                   | 0.781       |
|    value_loss            | 0.373       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0588      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0588      |
| reward                   | -0.43396142 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 529         |
|    total_timesteps       | 1855488     |
| train/                   |             |
|    approx_kl             | 0.006713227 |
|    clip_fraction         | 0.0473      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00839    |
|    cost_value_loss       | 6.99e-06    |
|    cost_values           | -0.00865    |
|    entropy               | -2.2        |
|    entropy_loss          | -2.19       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00262    |
|    n_updates             | 9050        |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 0.785       |
|    value_loss            | 0.0703      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0884       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0884       |
| reward                   | -0.24419871  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 551          |
|    total_timesteps       | 1857536      |
| train/                   |              |
|    approx_kl             | 0.0050100274 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00611     |
|    cost_value_loss       | 4.73e-06     |
|    cost_values           | -0.00604     |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000181     |
|    n_updates             | 9060         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.784        |
|    value_loss            | 0.0305       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0558       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0558       |
| reward                   | -0.4353821   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 574          |
|    total_timesteps       | 1859584      |
| train/                   |              |
|    approx_kl             | 0.0075558894 |
|    clip_fraction         | 0.0631       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0416       |
|    cost_value_loss       | 5.82e-05     |
|    cost_values           | 0.0417       |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0507       |
|    n_updates             | 9070         |
|    policy_gradient_loss  | -0.00576     |
|    std                   | 0.784        |
|    value_loss            | 0.796        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.107       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.107       |
| reward                   | -0.37391168 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 596         |
|    total_timesteps       | 1861632     |
| train/                   |             |
|    approx_kl             | 0.003087363 |
|    clip_fraction         | 0.00674     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0154      |
|    cost_value_loss       | 8.36e-05    |
|    cost_values           | 0.0156      |
|    entropy               | -2.2        |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.741       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.63        |
|    n_updates             | 9080        |
|    policy_gradient_loss  | -0.00041    |
|    std                   | 0.784       |
|    value_loss            | 1.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0777      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0777      |
| reward                   | -0.33970666 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 618         |
|    total_timesteps       | 1863680     |
| train/                   |             |
|    approx_kl             | 0.004679922 |
|    clip_fraction         | 0.0631      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0146      |
|    cost_value_loss       | 1.22e-05    |
|    cost_values           | 0.0147      |
|    entropy               | -2.18       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00542    |
|    n_updates             | 9090        |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.777       |
|    value_loss            | 0.00569     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.121       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.121       |
| reward                   | -0.5284681  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 641         |
|    total_timesteps       | 1865728     |
| train/                   |             |
|    approx_kl             | 0.007672634 |
|    clip_fraction         | 0.066       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00719     |
|    cost_value_loss       | 3.99e-06    |
|    cost_values           | 0.00722     |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0065      |
|    n_updates             | 9100        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.777       |
|    value_loss            | 0.0291      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.245        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.245        |
| reward                   | -0.2910756   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 664          |
|    total_timesteps       | 1867776      |
| train/                   |              |
|    approx_kl             | 0.0034987228 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0386       |
|    cost_value_loss       | 3.41e-05     |
|    cost_values           | 0.0397       |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.188        |
|    n_updates             | 9110         |
|    policy_gradient_loss  | -0.000546    |
|    std                   | 0.778        |
|    value_loss            | 0.893        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.1683425   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 686          |
|    total_timesteps       | 1869824      |
| train/                   |              |
|    approx_kl             | 0.0035762824 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00938      |
|    cost_value_loss       | 6.25e-05     |
|    cost_values           | 0.00813      |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0386       |
|    n_updates             | 9120         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.779        |
|    value_loss            | 1.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0986      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0986      |
| reward                   | -0.26568922 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 708         |
|    total_timesteps       | 1871872     |
| train/                   |             |
|    approx_kl             | 0.004479381 |
|    clip_fraction         | 0.0338      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00285     |
|    cost_value_loss       | 1.51e-05    |
|    cost_values           | 0.00466     |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.57        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.674       |
|    n_updates             | 9130        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.779       |
|    value_loss            | 3.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0876      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0876      |
| reward                   | -0.5518667  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 730         |
|    total_timesteps       | 1873920     |
| train/                   |             |
|    approx_kl             | 0.003382001 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0111      |
|    cost_value_loss       | 1.34e-05    |
|    cost_values           | 0.011       |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0242      |
|    n_updates             | 9140        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.781       |
|    value_loss            | 0.198       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0868      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0868      |
| reward                   | -0.2571113  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 752         |
|    total_timesteps       | 1875968     |
| train/                   |             |
|    approx_kl             | 0.008451927 |
|    clip_fraction         | 0.0663      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0357     |
|    cost_value_loss       | 2.74e-05    |
|    cost_values           | -0.0365     |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00949    |
|    n_updates             | 9150        |
|    policy_gradient_loss  | -0.00606    |
|    std                   | 0.78        |
|    value_loss            | 0.0398      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.189        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.189        |
| reward                   | -0.4240992   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 774          |
|    total_timesteps       | 1878016      |
| train/                   |              |
|    approx_kl             | 0.0050321976 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.041       |
|    cost_value_loss       | 2.9e-05      |
|    cost_values           | -0.0422      |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0171       |
|    n_updates             | 9160         |
|    policy_gradient_loss  | -0.000718    |
|    std                   | 0.779        |
|    value_loss            | 0.126        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0724      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0724      |
| reward                   | -0.3740862  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 1880064     |
| train/                   |             |
|    approx_kl             | 0.005352962 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0194     |
|    cost_value_loss       | 1.31e-05    |
|    cost_values           | -0.0197     |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0119      |
|    n_updates             | 9170        |
|    policy_gradient_loss  | -0.00361    |
|    std                   | 0.779       |
|    value_loss            | 0.599       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.136       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.136       |
| reward                   | -0.46201745 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 819         |
|    total_timesteps       | 1882112     |
| train/                   |             |
|    approx_kl             | 0.005612462 |
|    clip_fraction         | 0.0384      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00515    |
|    cost_value_loss       | 1.04e-05    |
|    cost_values           | -0.00528    |
|    entropy               | -2.17       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0122     |
|    n_updates             | 9180        |
|    policy_gradient_loss  | -0.00718    |
|    std                   | 0.776       |
|    value_loss            | 0.0201      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0623       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0623       |
| reward                   | -0.49737138  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 841          |
|    total_timesteps       | 1884160      |
| train/                   |              |
|    approx_kl             | 0.0066219703 |
|    clip_fraction         | 0.0561       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0109      |
|    cost_value_loss       | 3.47e-06     |
|    cost_values           | -0.0111      |
|    entropy               | -2.16        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.0037      |
|    n_updates             | 9190         |
|    policy_gradient_loss  | -0.00497     |
|    std                   | 0.769        |
|    value_loss            | 0.00418      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0885       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0885       |
| reward                   | -0.55314606  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 863          |
|    total_timesteps       | 1886208      |
| train/                   |              |
|    approx_kl             | 0.0062672268 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00591     |
|    cost_value_loss       | 2.64e-06     |
|    cost_values           | -0.00622     |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0762       |
|    n_updates             | 9200         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.767        |
|    value_loss            | 0.827        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.18         |
| reward                   | -0.5177814   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 885          |
|    total_timesteps       | 1888256      |
| train/                   |              |
|    approx_kl             | 0.0055183806 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00681     |
|    cost_value_loss       | 8.58e-06     |
|    cost_values           | -0.00666     |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00336     |
|    n_updates             | 9210         |
|    policy_gradient_loss  | -0.0009      |
|    std                   | 0.767        |
|    value_loss            | 0.0921       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0111       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0111       |
| reward                   | -0.39900446  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 908          |
|    total_timesteps       | 1890304      |
| train/                   |              |
|    approx_kl             | 0.0047521885 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000901     |
|    cost_value_loss       | 3.25e-06     |
|    cost_values           | 0.000651     |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00404     |
|    n_updates             | 9220         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.766        |
|    value_loss            | 0.0359       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.249       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.249       |
| reward                   | -0.26917145 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 930         |
|    total_timesteps       | 1892352     |
| train/                   |             |
|    approx_kl             | 0.004691738 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00374     |
|    cost_value_loss       | 4.13e-06    |
|    cost_values           | 0.00379     |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00133    |
|    n_updates             | 9230        |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.768       |
|    value_loss            | 0.0414      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0297      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0297      |
| reward                   | -0.24494696 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 952         |
|    total_timesteps       | 1894400     |
| train/                   |             |
|    approx_kl             | 0.00509864  |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00802    |
|    cost_value_loss       | 2.66e-05    |
|    cost_values           | -0.00781    |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.637       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.659       |
|    n_updates             | 9240        |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.767       |
|    value_loss            | 5.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0376      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0376      |
| reward                   | -0.26896334 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 975         |
|    total_timesteps       | 1896448     |
| train/                   |             |
|    approx_kl             | 0.001459099 |
|    clip_fraction         | 0.00933     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0494      |
|    cost_value_loss       | 0.000979    |
|    cost_values           | 0.0574      |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | -2.76       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 327         |
|    n_updates             | 9250        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.767       |
|    value_loss            | 1.24e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.41427633  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 997          |
|    total_timesteps       | 1898496      |
| train/                   |              |
|    approx_kl             | 0.0028159898 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0456       |
|    cost_value_loss       | 0.00151      |
|    cost_values           | 0.0601       |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | -6.82        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 587          |
|    n_updates             | 9260         |
|    policy_gradient_loss  | -0.00733     |
|    std                   | 0.767        |
|    value_loss            | 1.17e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -3.496231    |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1019         |
|    total_timesteps       | 1900544      |
| train/                   |              |
|    approx_kl             | 0.0023533234 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0206       |
|    cost_value_loss       | 7.21e-05     |
|    cost_values           | 0.021        |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.48         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.98         |
|    n_updates             | 9270         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.768        |
|    value_loss            | 3.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0299       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0299       |
| reward                   | -0.31885356  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1041         |
|    total_timesteps       | 1902592      |
| train/                   |              |
|    approx_kl             | 0.0016011209 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0571       |
|    cost_value_loss       | 0.00481      |
|    cost_values           | 0.0804       |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | -1.75        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 9280         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.768        |
|    value_loss            | 105          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -4.060351   |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -518        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 1904640     |
| train/                   |             |
|    approx_kl             | 0.005655099 |
|    clip_fraction         | 0.0394      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.194       |
|    cost_value_loss       | 0.0152      |
|    cost_values           | 0.167       |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | -5.78       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 423         |
|    n_updates             | 9290        |
|    policy_gradient_loss  | 0.00183     |
|    std                   | 0.768       |
|    value_loss            | 1.95e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0784       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0784       |
| reward                   | -0.26105106  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1086         |
|    total_timesteps       | 1906688      |
| train/                   |              |
|    approx_kl             | 0.0024558716 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00898      |
|    cost_value_loss       | 0.00048      |
|    cost_values           | 0.00947      |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | -0.568       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.7         |
|    n_updates             | 9300         |
|    policy_gradient_loss  | -0.00566     |
|    std                   | 0.768        |
|    value_loss            | 189          |
-------------------------------------------
------------------------------------
| avg_speed          | 0.00405     |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.00405     |
| reward             | -0.35251147 |
| rollout/           |             |
|    ep_len_mean     | 994         |
|    ep_rew_mean     | -545        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1908736     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.0608       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0608       |
| reward                   | -0.5570436   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -584         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1910784      |
| train/                   |              |
|    approx_kl             | 0.0021859515 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00342     |
|    cost_value_loss       | 3.15e-05     |
|    cost_values           | -0.00342     |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.609        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0686       |
|    n_updates             | 9320         |
|    policy_gradient_loss  | -0.000565    |
|    std                   | 0.768        |
|    value_loss            | 0.527        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0617      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0617      |
| reward                   | -0.47002456 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -584        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 1912832     |
| train/                   |             |
|    approx_kl             | 0.006011796 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0478      |
|    cost_value_loss       | 0.000588    |
|    cost_values           | 0.058       |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.163       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 748         |
|    n_updates             | 9330        |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 0.767       |
|    value_loss            | 1.66e+03    |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -4.115085   |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -584        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 1914880     |
| train/                   |             |
|    approx_kl             | 0.004392782 |
|    clip_fraction         | 0.0173      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00579     |
|    cost_value_loss       | 1.26e-05    |
|    cost_values           | 0.00586     |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0236      |
|    n_updates             | 9340        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.767       |
|    value_loss            | 0.536       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -4.3840647  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -608        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 1916928     |
| train/                   |             |
|    approx_kl             | 0.013465637 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0216      |
|    cost_value_loss       | 0.00111     |
|    cost_values           | 0.0243      |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.559       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 96.8        |
|    n_updates             | 9350        |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 0.767       |
|    value_loss            | 235         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.4914052   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -638         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 1918976      |
| train/                   |              |
|    approx_kl             | 0.0015528374 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0383       |
|    cost_value_loss       | 0.000437     |
|    cost_values           | 0.0309       |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.594        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 414          |
|    n_updates             | 9360         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.767        |
|    value_loss            | 1.07e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.51235133  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1921024      |
| train/                   |              |
|    approx_kl             | 0.0018076191 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0207       |
|    cost_value_loss       | 4.94e-05     |
|    cost_values           | 0.0231       |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.66         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 229          |
|    n_updates             | 9370         |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 0.767        |
|    value_loss            | 581          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -4.237147    |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 1923072      |
| train/                   |              |
|    approx_kl             | 0.0040092072 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.02         |
|    cost_value_loss       | 8.29e-05     |
|    cost_values           | 0.0213       |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.683        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 594          |
|    n_updates             | 9380         |
|    policy_gradient_loss  | -0.00552     |
|    std                   | 0.767        |
|    value_loss            | 1.24e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0078       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0078       |
| reward                   | -0.5176182   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1925120      |
| train/                   |              |
|    approx_kl             | 0.0039183563 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0073       |
|    cost_value_loss       | 5.11e-05     |
|    cost_values           | 0.00716      |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.728        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 456          |
|    n_updates             | 9390         |
|    policy_gradient_loss  | -0.00733     |
|    std                   | 0.767        |
|    value_loss            | 835          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0242       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0242       |
| reward                   | -0.48777306  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 1927168      |
| train/                   |              |
|    approx_kl             | 0.0008025224 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00133      |
|    cost_value_loss       | 2.22e-05     |
|    cost_values           | 0.00225      |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.701        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 148          |
|    n_updates             | 9400         |
|    policy_gradient_loss  | -0.00267     |
|    std                   | 0.767        |
|    value_loss            | 292          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.109       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.109       |
| reward                   | -0.43647808 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 242         |
|    total_timesteps       | 1929216     |
| train/                   |             |
|    approx_kl             | 0.004319854 |
|    clip_fraction         | 0.0324      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0167     |
|    cost_value_loss       | 2.52e-05    |
|    cost_values           | -0.0167     |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0178      |
|    n_updates             | 9410        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.768       |
|    value_loss            | 0.259       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.76        |
| reward                   | -2.1488576  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 1931264     |
| train/                   |             |
|    approx_kl             | 0.009249086 |
|    clip_fraction         | 0.0573      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0272     |
|    cost_value_loss       | 2.19e-05    |
|    cost_values           | -0.0278     |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.000897   |
|    n_updates             | 9420        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.77        |
|    value_loss            | 0.0422      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0728      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0728      |
| reward                   | -0.37413678 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -726        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 286         |
|    total_timesteps       | 1933312     |
| train/                   |             |
|    approx_kl             | 0.008554183 |
|    clip_fraction         | 0.078       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00849    |
|    cost_value_loss       | 3.59e-05    |
|    cost_values           | -0.0083     |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.3         |
|    n_updates             | 9430        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.771       |
|    value_loss            | 7.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0901      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0901      |
| reward                   | -0.5461     |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -725        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 309         |
|    total_timesteps       | 1935360     |
| train/                   |             |
|    approx_kl             | 0.003983743 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00104    |
|    cost_value_loss       | 0.000176    |
|    cost_values           | -0.00154    |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 325         |
|    n_updates             | 9440        |
|    policy_gradient_loss  | -0.00397    |
|    std                   | 0.771       |
|    value_loss            | 702         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.137        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.137        |
| reward                   | -0.31780493  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 330          |
|    total_timesteps       | 1937408      |
| train/                   |              |
|    approx_kl             | 0.0068618264 |
|    clip_fraction         | 0.0779       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0103      |
|    cost_value_loss       | 4.07e-06     |
|    cost_values           | -0.0103      |
|    entropy               | -2.17        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0131       |
|    n_updates             | 9450         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.775        |
|    value_loss            | 0.0605       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00205      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00205      |
| reward                   | -0.39944518  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 1939456      |
| train/                   |              |
|    approx_kl             | 0.0060649673 |
|    clip_fraction         | 0.0858       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00563     |
|    cost_value_loss       | 5.13e-06     |
|    cost_values           | -0.00568     |
|    entropy               | -2.16        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00617     |
|    n_updates             | 9460         |
|    policy_gradient_loss  | -0.00595     |
|    std                   | 0.773        |
|    value_loss            | 0.0419       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0422      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0422      |
| reward                   | -0.39893162 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 375         |
|    total_timesteps       | 1941504     |
| train/                   |             |
|    approx_kl             | 0.021724608 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00636     |
|    cost_value_loss       | 3.19e-05    |
|    cost_values           | 0.00664     |
|    entropy               | -2.16       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.721       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 547         |
|    n_updates             | 9470        |
|    policy_gradient_loss  | 0.0167      |
|    std                   | 0.772       |
|    value_loss            | 1.08e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.41         |
| reward                   | -2.9093275   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 397          |
|    total_timesteps       | 1943552      |
| train/                   |              |
|    approx_kl             | 0.0037984187 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0104      |
|    cost_value_loss       | 5.27e-06     |
|    cost_values           | -0.0105      |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0246       |
|    n_updates             | 9480         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.772        |
|    value_loss            | 0.879        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -3.39617     |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -785         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 419          |
|    total_timesteps       | 1945600      |
| train/                   |              |
|    approx_kl             | 0.0029668997 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.015       |
|    cost_value_loss       | 4.18e-05     |
|    cost_values           | -0.0152      |
|    entropy               | -2.17        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20           |
|    n_updates             | 9490         |
|    policy_gradient_loss  | -0.00545     |
|    std                   | 0.773        |
|    value_loss            | 35.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.32045126  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 441          |
|    total_timesteps       | 1947648      |
| train/                   |              |
|    approx_kl             | 0.0028351704 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00451     |
|    cost_value_loss       | 2.11e-05     |
|    cost_values           | -0.00466     |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.721        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 549          |
|    n_updates             | 9500         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.773        |
|    value_loss            | 1.15e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -4.0575037   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 1949696      |
| train/                   |              |
|    approx_kl             | 0.0019547418 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00354      |
|    cost_value_loss       | 2.03e-05     |
|    cost_values           | 0.00345      |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.68         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 891          |
|    n_updates             | 9510         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.773        |
|    value_loss            | 1.89e+03     |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.147       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.147       |
| reward                   | -0.266279   |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -873        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 486         |
|    total_timesteps       | 1951744     |
| train/                   |             |
|    approx_kl             | 0.003157102 |
|    clip_fraction         | 0.018       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0124     |
|    cost_value_loss       | 1.3e-05     |
|    cost_values           | -0.0124     |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.804       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 99.2        |
|    n_updates             | 9520        |
|    policy_gradient_loss  | -0.00756    |
|    std                   | 0.773       |
|    value_loss            | 232         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0967       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0967       |
| reward                   | -0.42666572  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1953792      |
| train/                   |              |
|    approx_kl             | 0.0015700589 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00767     |
|    cost_value_loss       | 9.53e-06     |
|    cost_values           | -0.00855     |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.695        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 395          |
|    n_updates             | 9530         |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 0.773        |
|    value_loss            | 887          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0485      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0485      |
| reward                   | -0.42772982 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -891        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 530         |
|    total_timesteps       | 1955840     |
| train/                   |             |
|    approx_kl             | 0.001744657 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00694    |
|    cost_value_loss       | 1.63e-05    |
|    cost_values           | -0.00724    |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.755       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 340         |
|    n_updates             | 9540        |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 0.773       |
|    value_loss            | 739         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0895      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0895      |
| reward                   | -0.22762513 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -892        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 552         |
|    total_timesteps       | 1957888     |
| train/                   |             |
|    approx_kl             | 0.004008847 |
|    clip_fraction         | 0.0293      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0152     |
|    cost_value_loss       | 3.13e-05    |
|    cost_values           | -0.0153     |
|    entropy               | -2.14       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00145     |
|    n_updates             | 9550        |
|    policy_gradient_loss  | -0.00245    |
|    std                   | 0.764       |
|    value_loss            | 0.0215      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.4153772   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -889         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 575          |
|    total_timesteps       | 1959936      |
| train/                   |              |
|    approx_kl             | 0.0030496796 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0133      |
|    cost_value_loss       | 1.28e-05     |
|    cost_values           | -0.0135      |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.814        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0251       |
|    n_updates             | 9560         |
|    policy_gradient_loss  | -0.000549    |
|    std                   | 0.763        |
|    value_loss            | 0.285        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0169      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0169      |
| reward                   | -0.4290578  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -888        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 597         |
|    total_timesteps       | 1961984     |
| train/                   |             |
|    approx_kl             | 0.007072656 |
|    clip_fraction         | 0.0319      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0108     |
|    cost_value_loss       | 1.44e-05    |
|    cost_values           | -0.0105     |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0299      |
|    n_updates             | 9570        |
|    policy_gradient_loss  | -0.000611   |
|    std                   | 0.764       |
|    value_loss            | 0.2         |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.0867        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0867        |
| reward                   | -0.5518447    |
| rollout/                 |               |
|    ep_len_mean           | 994           |
|    ep_rew_mean           | -889          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 28            |
|    time_elapsed          | 619           |
|    total_timesteps       | 1964032       |
| train/                   |               |
|    approx_kl             | 0.00081749156 |
|    clip_fraction         | 0.00249       |
|    clip_range            | 0.2           |
|    cost_returns          | 0.012         |
|    cost_value_loss       | 2.15e-05      |
|    cost_values           | 0.0122        |
|    entropy               | -2.13         |
|    entropy_loss          | -2.13         |
|    explained_variance    | 0.977         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.0364        |
|    n_updates             | 9580          |
|    policy_gradient_loss  | -0.000108     |
|    std                   | 0.76          |
|    value_loss            | 0.142         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0213       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0213       |
| reward                   | -0.27363774  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -887         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 641          |
|    total_timesteps       | 1966080      |
| train/                   |              |
|    approx_kl             | 0.0022926226 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000484     |
|    cost_value_loss       | 1.88e-05     |
|    cost_values           | 0.00093      |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.853        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0511       |
|    n_updates             | 9590         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.759        |
|    value_loss            | 0.414        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0441       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0441       |
| reward                   | -0.5159075   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -883         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 663          |
|    total_timesteps       | 1968128      |
| train/                   |              |
|    approx_kl             | 0.0002253172 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.018       |
|    cost_value_loss       | 1.18e-05     |
|    cost_values           | -0.018       |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.407        |
|    n_updates             | 9600         |
|    policy_gradient_loss  | 0.00042      |
|    std                   | 0.759        |
|    value_loss            | 2.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0534       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0534       |
| reward                   | -0.35939708  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -884         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 686          |
|    total_timesteps       | 1970176      |
| train/                   |              |
|    approx_kl             | 0.0057371706 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00536     |
|    cost_value_loss       | 1.63e-05     |
|    cost_values           | -0.00509     |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.883        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.5          |
|    n_updates             | 9610         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.759        |
|    value_loss            | 4.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0586       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0586       |
| reward                   | -0.24821506  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -917         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 1972224      |
| train/                   |              |
|    approx_kl             | 0.0066181216 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00272     |
|    cost_value_loss       | 7.21e-06     |
|    cost_values           | -0.00263     |
|    entropy               | -2.13        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0095       |
|    n_updates             | 9620         |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 0.761        |
|    value_loss            | 0.113        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0396       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0396       |
| reward                   | -0.42704767  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -915         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 730          |
|    total_timesteps       | 1974272      |
| train/                   |              |
|    approx_kl             | 0.0029192532 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00474     |
|    cost_value_loss       | 2.62e-05     |
|    cost_values           | -0.0062      |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.774        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 591          |
|    n_updates             | 9630         |
|    policy_gradient_loss  | -0.00267     |
|    std                   | 0.762        |
|    value_loss            | 1.11e+03     |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0843      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0843      |
| reward                   | -0.42774245 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -916        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 752         |
|    total_timesteps       | 1976320     |
| train/                   |             |
|    approx_kl             | 0.006875775 |
|    clip_fraction         | 0.042       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00673     |
|    cost_value_loss       | 1.56e-05    |
|    cost_values           | 0.00745     |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0433      |
|    n_updates             | 9640        |
|    policy_gradient_loss  | -0.00278    |
|    std                   | 0.76        |
|    value_loss            | 0.464       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0405      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0405      |
| reward                   | -0.45698336 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -915        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 774         |
|    total_timesteps       | 1978368     |
| train/                   |             |
|    approx_kl             | 0.006258938 |
|    clip_fraction         | 0.0554      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0127      |
|    cost_value_loss       | 8.67e-06    |
|    cost_values           | 0.0127      |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0195      |
|    n_updates             | 9650        |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 0.76        |
|    value_loss            | 0.166       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0638      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0638      |
| reward                   | -0.38959348 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -948        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 1980416     |
| train/                   |             |
|    approx_kl             | 0.005116347 |
|    clip_fraction         | 0.047       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00425    |
|    cost_value_loss       | 2.35e-05    |
|    cost_values           | -0.00444    |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0204      |
|    n_updates             | 9660        |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 0.763       |
|    value_loss            | 0.255       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.108        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.108        |
| reward                   | -0.43371013  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -943         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 818          |
|    total_timesteps       | 1982464      |
| train/                   |              |
|    approx_kl             | 0.0025731896 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0243      |
|    cost_value_loss       | 4.5e-05      |
|    cost_values           | -0.0284      |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.771        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 573          |
|    n_updates             | 9670         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.764        |
|    value_loss            | 1.13e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.51656646  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -971         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 841          |
|    total_timesteps       | 1984512      |
| train/                   |              |
|    approx_kl             | 0.0073843114 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00526     |
|    cost_value_loss       | 3.34e-05     |
|    cost_values           | -0.00442     |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.782        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.46         |
|    n_updates             | 9680         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.764        |
|    value_loss            | 4.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0942       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0942       |
| reward                   | -0.4188101   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -972         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 863          |
|    total_timesteps       | 1986560      |
| train/                   |              |
|    approx_kl             | 0.0035202084 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0142      |
|    cost_value_loss       | 0.000219     |
|    cost_values           | -0.0189      |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.761        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 478          |
|    n_updates             | 9690         |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.764        |
|    value_loss            | 979          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.062        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.062        |
| reward                   | -0.24680854  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -971         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 885          |
|    total_timesteps       | 1988608      |
| train/                   |              |
|    approx_kl             | 0.0034999978 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00539      |
|    cost_value_loss       | 2.42e-05     |
|    cost_values           | 0.0051       |
|    entropy               | -2.14        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0444       |
|    n_updates             | 9700         |
|    policy_gradient_loss  | -0.000563    |
|    std                   | 0.763        |
|    value_loss            | 0.325        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0266       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0266       |
| reward                   | -0.29913443  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -973         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 907          |
|    total_timesteps       | 1990656      |
| train/                   |              |
|    approx_kl             | 0.0027879777 |
|    clip_fraction         | 0.00718      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00471     |
|    cost_value_loss       | 1.97e-05     |
|    cost_values           | -0.00551     |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0356       |
|    n_updates             | 9710         |
|    policy_gradient_loss  | -0.000796    |
|    std                   | 0.761        |
|    value_loss            | 0.441        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0665       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0665       |
| reward                   | -0.32372418  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -950         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 930          |
|    total_timesteps       | 1992704      |
| train/                   |              |
|    approx_kl             | 0.0054302933 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0143       |
|    cost_value_loss       | 1.73e-05     |
|    cost_values           | 0.014        |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00152     |
|    n_updates             | 9720         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.761        |
|    value_loss            | 0.106        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.117       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.117       |
| reward                   | -0.42706427 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -943        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 952         |
|    total_timesteps       | 1994752     |
| train/                   |             |
|    approx_kl             | 0.00598919  |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0132      |
|    cost_value_loss       | 1.07e-05    |
|    cost_values           | 0.0133      |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00482     |
|    n_updates             | 9730        |
|    policy_gradient_loss  | -0.00186    |
|    std                   | 0.761       |
|    value_loss            | 0.0152      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00852      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00852      |
| reward                   | -0.43382484  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -948         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 974          |
|    total_timesteps       | 1996800      |
| train/                   |              |
|    approx_kl             | 0.0073636584 |
|    clip_fraction         | 0.0798       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00263     |
|    cost_value_loss       | 7.78e-05     |
|    cost_values           | 0.00139      |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.828        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 129          |
|    n_updates             | 9740         |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 0.761        |
|    value_loss            | 292          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00142      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00142      |
| reward                   | -0.33112404  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -948         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 997          |
|    total_timesteps       | 1998848      |
| train/                   |              |
|    approx_kl             | 0.0069820243 |
|    clip_fraction         | 0.0765       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00986      |
|    cost_value_loss       | 6.76e-06     |
|    cost_values           | 0.00997      |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00974      |
|    n_updates             | 9750         |
|    policy_gradient_loss  | -0.00323     |
|    std                   | 0.761        |
|    value_loss            | 0.0372       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.133       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.133       |
| reward                   | -0.48627502 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -924        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 2000896     |
| train/                   |             |
|    approx_kl             | 0.007604369 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0014      |
|    cost_value_loss       | 2.65e-05    |
|    cost_values           | 0.00131     |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.59        |
|    n_updates             | 9760        |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.757       |
|    value_loss            | 3.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -4.170675    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -968         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1041         |
|    total_timesteps       | 2002944      |
| train/                   |              |
|    approx_kl             | 0.0043469495 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00458      |
|    cost_value_loss       | 0.000163     |
|    cost_values           | 0.000876     |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.806        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 484          |
|    n_updates             | 9770         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.755        |
|    value_loss            | 1.05e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.152        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.152        |
| reward                   | -0.31384912  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -969         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1064         |
|    total_timesteps       | 2004992      |
| train/                   |              |
|    approx_kl             | 0.0024544098 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00772      |
|    cost_value_loss       | 8.51e-05     |
|    cost_values           | 0.00899      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.55         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 810          |
|    n_updates             | 9780         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.755        |
|    value_loss            | 1.74e+03     |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0751      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0751      |
| reward                   | -0.5578997  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -971        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 2007040     |
| train/                   |             |
|    approx_kl             | 0.001860651 |
|    clip_fraction         | 0.0172      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00888    |
|    cost_value_loss       | 2.09e-05    |
|    cost_values           | -0.00761    |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.805       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 326         |
|    n_updates             | 9790        |
|    policy_gradient_loss  | -0.00458    |
|    std                   | 0.755       |
|    value_loss            | 658         |
------------------------------------------
------------------------------------
| avg_speed          | 0.208       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.208       |
| reward             | -0.27171123 |
| rollout/           |             |
|    ep_len_mean     | 982         |
|    ep_rew_mean     | -934        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2009088     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -4.1700497   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 2011136      |
| train/                   |              |
|    approx_kl             | 0.0030208663 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0113      |
|    cost_value_loss       | 2.83e-05     |
|    cost_values           | -0.0117      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0482       |
|    n_updates             | 9810         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.755        |
|    value_loss            | 0.731        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0486      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0486      |
| reward                   | -0.47451112 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -964        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2013184     |
| train/                   |             |
|    approx_kl             | 0.007346395 |
|    clip_fraction         | 0.097       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00135     |
|    cost_value_loss       | 7.94e-05    |
|    cost_values           | 0.00495     |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 300         |
|    n_updates             | 9820        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.754       |
|    value_loss            | 633         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -4.13351     |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -941         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 2015232      |
| train/                   |              |
|    approx_kl             | 0.0020960015 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0195      |
|    cost_value_loss       | 5.65e-06     |
|    cost_values           | -0.0199      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.804        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 213          |
|    n_updates             | 9830         |
|    policy_gradient_loss  | -0.00561     |
|    std                   | 0.755        |
|    value_loss            | 395          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -4.0542126   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -942         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 2017280      |
| train/                   |              |
|    approx_kl             | 0.0025051963 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.021       |
|    cost_value_loss       | 2.57e-05     |
|    cost_values           | -0.022       |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.786        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 275          |
|    n_updates             | 9840         |
|    policy_gradient_loss  | -0.00546     |
|    std                   | 0.755        |
|    value_loss            | 664          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0933       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0933       |
| reward                   | -0.33389714  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -939         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 2019328      |
| train/                   |              |
|    approx_kl             | 0.0021447102 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00605      |
|    cost_value_loss       | 4.49e-05     |
|    cost_values           | 0.00668      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.798        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 450          |
|    n_updates             | 9850         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.755        |
|    value_loss            | 950          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.154       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.154       |
| reward                   | -0.40651822 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -936        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 155         |
|    total_timesteps       | 2021376     |
| train/                   |             |
|    approx_kl             | 0.002472689 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00934    |
|    cost_value_loss       | 2.12e-06    |
|    cost_values           | -0.00948    |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.83        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 111         |
|    n_updates             | 9860        |
|    policy_gradient_loss  | -0.00823    |
|    std                   | 0.755       |
|    value_loss            | 189         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -4.3654294   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -905         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 177          |
|    total_timesteps       | 2023424      |
| train/                   |              |
|    approx_kl             | 0.0026487398 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0229      |
|    cost_value_loss       | 7.34e-06     |
|    cost_values           | -0.0232      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0241       |
|    n_updates             | 9870         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.753        |
|    value_loss            | 0.252        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.244        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.244        |
| reward                   | -0.5094474   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -945         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 199          |
|    total_timesteps       | 2025472      |
| train/                   |              |
|    approx_kl             | 0.0032720342 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000849     |
|    cost_value_loss       | 2.81e-05     |
|    cost_values           | -0.000398    |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.804        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 543          |
|    n_updates             | 9880         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.752        |
|    value_loss            | 1.02e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.143        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.143        |
| reward                   | -0.32190308  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -976         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 2027520      |
| train/                   |              |
|    approx_kl             | 0.0033668769 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00728      |
|    cost_value_loss       | 6.46e-05     |
|    cost_values           | 0.00785      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.833        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 83.6         |
|    n_updates             | 9890         |
|    policy_gradient_loss  | -0.00944     |
|    std                   | 0.752        |
|    value_loss            | 184          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.01         |
| reward                   | -0.47522444  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 244          |
|    total_timesteps       | 2029568      |
| train/                   |              |
|    approx_kl             | 0.0024758785 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00187      |
|    cost_value_loss       | 7.96e-06     |
|    cost_values           | 0.00204      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.813        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 491          |
|    n_updates             | 9900         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.752        |
|    value_loss            | 966          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0767       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0767       |
| reward                   | -0.27683032  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 266          |
|    total_timesteps       | 2031616      |
| train/                   |              |
|    approx_kl             | 0.0017001276 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00638     |
|    cost_value_loss       | 1e-05        |
|    cost_values           | -0.0069      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.828        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 501          |
|    n_updates             | 9910         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.752        |
|    value_loss            | 1e+03        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0736       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0736       |
| reward                   | -0.26086992  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 288          |
|    total_timesteps       | 2033664      |
| train/                   |              |
|    approx_kl             | 0.0020957203 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00139     |
|    cost_value_loss       | 5.13e-05     |
|    cost_values           | -0.00213     |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.814        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 473          |
|    n_updates             | 9920         |
|    policy_gradient_loss  | -0.00322     |
|    std                   | 0.752        |
|    value_loss            | 972          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -3.3556588  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 311         |
|    total_timesteps       | 2035712     |
| train/                   |             |
|    approx_kl             | 0.001796443 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0254     |
|    cost_value_loss       | 3.9e-05     |
|    cost_values           | -0.0253     |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 372         |
|    n_updates             | 9930        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.752       |
|    value_loss            | 821         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0441      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0441      |
| reward                   | -0.430722   |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 2037760     |
| train/                   |             |
|    approx_kl             | 0.004077149 |
|    clip_fraction         | 0.0189      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0253     |
|    cost_value_loss       | 2.71e-05    |
|    cost_values           | -0.0255     |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.5        |
|    n_updates             | 9940        |
|    policy_gradient_loss  | -0.00748    |
|    std                   | 0.753       |
|    value_loss            | 42.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.161       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.161       |
| reward                   | -0.5422818  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2039808     |
| train/                   |             |
|    approx_kl             | 0.001999679 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0121     |
|    cost_value_loss       | 7.37e-06    |
|    cost_values           | -0.0125     |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.784       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 447         |
|    n_updates             | 9950        |
|    policy_gradient_loss  | -0.00369    |
|    std                   | 0.753       |
|    value_loss            | 972         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -3.950954   |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 378         |
|    total_timesteps       | 2041856     |
| train/                   |             |
|    approx_kl             | 0.005952334 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0141      |
|    cost_value_loss       | 1.22e-05    |
|    cost_values           | 0.0146      |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0385      |
|    n_updates             | 9960        |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.752       |
|    value_loss            | 0.301       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0463      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0463      |
| reward                   | -0.4746607  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 401         |
|    total_timesteps       | 2043904     |
| train/                   |             |
|    approx_kl             | 0.007398718 |
|    clip_fraction         | 0.0583      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00449     |
|    cost_value_loss       | 5.01e-05    |
|    cost_values           | 0.00574     |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.856       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 249         |
|    n_updates             | 9970        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.751       |
|    value_loss            | 479         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0608      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0608      |
| reward                   | -0.35850564 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 423         |
|    total_timesteps       | 2045952     |
| train/                   |             |
|    approx_kl             | 0.002249569 |
|    clip_fraction         | 0.0139      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00687    |
|    cost_value_loss       | 2.21e-06    |
|    cost_values           | -0.00664    |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 388         |
|    n_updates             | 9980        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.752       |
|    value_loss            | 757         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.174        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.174        |
| reward                   | -0.4336989   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 445          |
|    total_timesteps       | 2048000      |
| train/                   |              |
|    approx_kl             | 0.0049863374 |
|    clip_fraction         | 0.0375       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0232      |
|    cost_value_loss       | 2.77e-05     |
|    cost_values           | -0.0233      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0688       |
|    n_updates             | 9990         |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.752        |
|    value_loss            | 0.361        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0152       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0152       |
| reward                   | -0.55410415  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -972         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 467          |
|    total_timesteps       | 2050048      |
| train/                   |              |
|    approx_kl             | 0.0013007044 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0168      |
|    cost_value_loss       | 2.6e-05      |
|    cost_values           | -0.0175      |
|    entropy               | -2.09        |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00205      |
|    n_updates             | 10000        |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.746        |
|    value_loss            | 0.0657       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00862      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00862      |
| reward                   | -0.43481487  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -951         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 489          |
|    total_timesteps       | 2052096      |
| train/                   |              |
|    approx_kl             | 0.0049853297 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0219      |
|    cost_value_loss       | 0.000894     |
|    cost_values           | -0.0164      |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0818       |
|    n_updates             | 10010        |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.74         |
|    value_loss            | 0.424        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -4.0046325  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -981        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 511         |
|    total_timesteps       | 2054144     |
| train/                   |             |
|    approx_kl             | 0.004462437 |
|    clip_fraction         | 0.0449      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00877    |
|    cost_value_loss       | 0.000358    |
|    cost_values           | -0.0148     |
|    entropy               | -2.07       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0145      |
|    n_updates             | 10020       |
|    policy_gradient_loss  | -0.00469    |
|    std                   | 0.739       |
|    value_loss            | 0.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0657       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0657       |
| reward                   | -0.5443928   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 533          |
|    total_timesteps       | 2056192      |
| train/                   |              |
|    approx_kl             | 0.0036342621 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.014        |
|    cost_value_loss       | 0.000424     |
|    cost_values           | 0.0301       |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.808        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 623          |
|    n_updates             | 10030        |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.738        |
|    value_loss            | 1.23e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00526      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00526      |
| reward                   | -0.2487908   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 556          |
|    total_timesteps       | 2058240      |
| train/                   |              |
|    approx_kl             | 0.0042054835 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0327       |
|    cost_value_loss       | 8.5e-05      |
|    cost_values           | 0.0361       |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 186          |
|    n_updates             | 10040        |
|    policy_gradient_loss  | -0.00788     |
|    std                   | 0.738        |
|    value_loss            | 378          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.077        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.077        |
| reward                   | -0.5234264   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 578          |
|    total_timesteps       | 2060288      |
| train/                   |              |
|    approx_kl             | 0.0066076033 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0225       |
|    cost_value_loss       | 0.000187     |
|    cost_values           | 0.0249       |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.862        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 10050        |
|    policy_gradient_loss  | -0.00472     |
|    std                   | 0.738        |
|    value_loss            | 17.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0566       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0566       |
| reward                   | -0.31885415  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 600          |
|    total_timesteps       | 2062336      |
| train/                   |              |
|    approx_kl             | 0.0028283563 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0137       |
|    cost_value_loss       | 0.000221     |
|    cost_values           | 0.0131       |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.859        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 403          |
|    n_updates             | 10060        |
|    policy_gradient_loss  | -0.000471    |
|    std                   | 0.738        |
|    value_loss            | 813          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.47453126  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 623          |
|    total_timesteps       | 2064384      |
| train/                   |              |
|    approx_kl             | 0.0090162065 |
|    clip_fraction         | 0.0964       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00868      |
|    cost_value_loss       | 1.97e-05     |
|    cost_values           | 0.00861      |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00619      |
|    n_updates             | 10070        |
|    policy_gradient_loss  | -0.00478     |
|    std                   | 0.738        |
|    value_loss            | 0.111        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0384      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0384      |
| reward                   | -0.47386256 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 645         |
|    total_timesteps       | 2066432     |
| train/                   |             |
|    approx_kl             | 0.004976348 |
|    clip_fraction         | 0.0256      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000432   |
|    cost_value_loss       | 6.54e-05    |
|    cost_values           | 0.000168    |
|    entropy               | -2.08       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0854      |
|    n_updates             | 10080       |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 0.74        |
|    value_loss            | 0.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0534       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0534       |
| reward                   | -0.22350116  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 667          |
|    total_timesteps       | 2068480      |
| train/                   |              |
|    approx_kl             | 0.0070620826 |
|    clip_fraction         | 0.0769       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0112       |
|    cost_value_loss       | 4.86e-05     |
|    cost_values           | 0.0134       |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.851        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 408          |
|    n_updates             | 10090        |
|    policy_gradient_loss  | -0.00467     |
|    std                   | 0.742        |
|    value_loss            | 825          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.279        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.279        |
| reward                   | -0.3805479   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 689          |
|    total_timesteps       | 2070528      |
| train/                   |              |
|    approx_kl             | 0.0023803953 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0054       |
|    cost_value_loss       | 6.9e-05      |
|    cost_values           | 0.00579      |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 454          |
|    n_updates             | 10100        |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.742        |
|    value_loss            | 945          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -4.40411     |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 711          |
|    total_timesteps       | 2072576      |
| train/                   |              |
|    approx_kl             | 0.0014970175 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00306      |
|    cost_value_loss       | 3.33e-05     |
|    cost_values           | 0.00447      |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 465          |
|    n_updates             | 10110        |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.742        |
|    value_loss            | 961          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -4.2272577   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 733          |
|    total_timesteps       | 2074624      |
| train/                   |              |
|    approx_kl             | 0.0037197268 |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0087       |
|    cost_value_loss       | 1.58e-05     |
|    cost_values           | 0.0095       |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.884        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 308          |
|    n_updates             | 10120        |
|    policy_gradient_loss  | -0.00643     |
|    std                   | 0.742        |
|    value_loss            | 640          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0419      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0419      |
| reward                   | -0.5546959  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 756         |
|    total_timesteps       | 2076672     |
| train/                   |             |
|    approx_kl             | 0.002982524 |
|    clip_fraction         | 0.00601     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00316    |
|    cost_value_loss       | 2.65e-05    |
|    cost_values           | -0.00323    |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.349       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 932         |
|    n_updates             | 10130       |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.742       |
|    value_loss            | 1.86e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0445       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0445       |
| reward                   | -0.3424867   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 778          |
|    total_timesteps       | 2078720      |
| train/                   |              |
|    approx_kl             | 0.0023703093 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00408      |
|    cost_value_loss       | 8.99e-05     |
|    cost_values           | 0.00491      |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.818        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 511          |
|    n_updates             | 10140        |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.742        |
|    value_loss            | 1.1e+03      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0418       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0418       |
| reward                   | -0.51820356  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 800          |
|    total_timesteps       | 2080768      |
| train/                   |              |
|    approx_kl             | 0.0033180336 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00485      |
|    cost_value_loss       | 6.07e-06     |
|    cost_values           | 0.00477      |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.033        |
|    n_updates             | 10150        |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.744        |
|    value_loss            | 0.327        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0422      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0422      |
| reward                   | -0.51698923 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 822         |
|    total_timesteps       | 2082816     |
| train/                   |             |
|    approx_kl             | 0.007097294 |
|    clip_fraction         | 0.092       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0053      |
|    cost_value_loss       | 1.95e-05    |
|    cost_values           | 0.00663     |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 422         |
|    n_updates             | 10160       |
|    policy_gradient_loss  | 0.000199    |
|    std                   | 0.744       |
|    value_loss            | 795         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.449       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.449       |
| reward                   | -0.48896804 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 845         |
|    total_timesteps       | 2084864     |
| train/                   |             |
|    approx_kl             | 0.00336813  |
|    clip_fraction         | 0.0469      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0096      |
|    cost_value_loss       | 4.48e-06    |
|    cost_values           | 0.00987     |
|    entropy               | -2.07       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000889    |
|    n_updates             | 10170       |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 0.741       |
|    value_loss            | 0.0596      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0558       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0558       |
| reward                   | -0.33030373  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 867          |
|    total_timesteps       | 2086912      |
| train/                   |              |
|    approx_kl             | 0.0050517847 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00569      |
|    cost_value_loss       | 5.7e-06      |
|    cost_values           | 0.00595      |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0852       |
|    n_updates             | 10180        |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.739        |
|    value_loss            | 1.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.097        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.097        |
| reward                   | -0.275512    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 889          |
|    total_timesteps       | 2088960      |
| train/                   |              |
|    approx_kl             | 0.0023206742 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0112      |
|    cost_value_loss       | 7.01e-05     |
|    cost_values           | -0.011       |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 378          |
|    n_updates             | 10190        |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.738        |
|    value_loss            | 756          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.171       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.171       |
| reward                   | -0.44450003 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 912         |
|    total_timesteps       | 2091008     |
| train/                   |             |
|    approx_kl             | 0.002773716 |
|    clip_fraction         | 0.0284      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000782   |
|    cost_value_loss       | 4.5e-05     |
|    cost_values           | -0.000671   |
|    entropy               | -2.06       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.025       |
|    n_updates             | 10200       |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 0.736       |
|    value_loss            | 0.207       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.157        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.157        |
| reward                   | -0.4708256   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 934          |
|    total_timesteps       | 2093056      |
| train/                   |              |
|    approx_kl             | 0.0034668057 |
|    clip_fraction         | 0.0571       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0105       |
|    cost_value_loss       | 3.41e-05     |
|    cost_values           | 0.012        |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.133        |
|    n_updates             | 10210        |
|    policy_gradient_loss  | 0.000878     |
|    std                   | 0.734        |
|    value_loss            | 1.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.151       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.151       |
| reward                   | -0.43267226 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 956         |
|    total_timesteps       | 2095104     |
| train/                   |             |
|    approx_kl             | 0.007694957 |
|    clip_fraction         | 0.0332      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0331      |
|    cost_value_loss       | 4.53e-05    |
|    cost_values           | 0.0338      |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0162      |
|    n_updates             | 10220       |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.733       |
|    value_loss            | 0.282       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0837       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0837       |
| reward                   | -0.47534895  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 978          |
|    total_timesteps       | 2097152      |
| train/                   |              |
|    approx_kl             | 0.0028217228 |
|    clip_fraction         | 0.043        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0369       |
|    cost_value_loss       | 0.000154     |
|    cost_values           | 0.0387       |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.033        |
|    n_updates             | 10230        |
|    policy_gradient_loss  | 0.000126     |
|    std                   | 0.732        |
|    value_loss            | 0.736        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -0.47518975  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 1000         |
|    total_timesteps       | 2099200      |
| train/                   |              |
|    approx_kl             | 0.0024523805 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.019        |
|    cost_value_loss       | 1.55e-05     |
|    cost_values           | 0.0193       |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0257       |
|    n_updates             | 10240        |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.734        |
|    value_loss            | 0.0747       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0693       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0693       |
| reward                   | -0.47326532  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1022         |
|    total_timesteps       | 2101248      |
| train/                   |              |
|    approx_kl             | 0.0021978398 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0428       |
|    cost_value_loss       | 4.15e-05     |
|    cost_values           | 0.0437       |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0115       |
|    n_updates             | 10250        |
|    policy_gradient_loss  | -0.000172    |
|    std                   | 0.734        |
|    value_loss            | 0.328        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0933       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0933       |
| reward                   | -0.47312346  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1044         |
|    total_timesteps       | 2103296      |
| train/                   |              |
|    approx_kl             | 0.0054328525 |
|    clip_fraction         | 0.0559       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0175       |
|    cost_value_loss       | 1.37e-05     |
|    cost_values           | 0.0176       |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00884      |
|    n_updates             | 10260        |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 0.734        |
|    value_loss            | 0.106        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -3.88653    |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1067        |
|    total_timesteps       | 2105344     |
| train/                   |             |
|    approx_kl             | 0.004961091 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000817    |
|    cost_value_loss       | 3.94e-05    |
|    cost_values           | 0.00196     |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 331         |
|    n_updates             | 10270       |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 0.733       |
|    value_loss            | 704         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0846       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0846       |
| reward                   | -0.32525292  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 2107392      |
| train/                   |              |
|    approx_kl             | 0.0019472901 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0143       |
|    cost_value_loss       | 0.000125     |
|    cost_values           | 0.0137       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 76.6         |
|    n_updates             | 10280        |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.733        |
|    value_loss            | 159          |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/3rk8b0u2/model_epoch(20)
----------------------------------
| avg_speed          | 0.0496    |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 0.0496    |
| reward             | -0.430639 |
| rollout/           |           |
|    ep_len_mean     | 984       |
|    ep_rew_mean     | -1.17e+03 |
| time/              |           |
|    fps             | 96        |
|    iterations      | 1         |
|    time_elapsed    | 21        |
|    total_timesteps | 2109440   |
----------------------------------
-------------------------------------------
| avg_speed                | 0.148        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.148        |
| reward                   | -0.14370127  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 2111488      |
| train/                   |              |
|    approx_kl             | 0.0044087144 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00998      |
|    cost_value_loss       | 1.72e-05     |
|    cost_values           | 0.0102       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000911     |
|    n_updates             | 10300        |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.734        |
|    value_loss            | 0.141        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -3.9158823  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 2113536     |
| train/                   |             |
|    approx_kl             | 0.021664843 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0151     |
|    cost_value_loss       | 0.000112    |
|    cost_values           | -0.0125     |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 343         |
|    n_updates             | 10310       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.734       |
|    value_loss            | 664         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0194      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0194      |
| reward                   | -0.4785369  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 2115584     |
| train/                   |             |
|    approx_kl             | 0.003252136 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0102     |
|    cost_value_loss       | 7.53e-05    |
|    cost_values           | -0.00805    |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 172         |
|    n_updates             | 10320       |
|    policy_gradient_loss  | -0.00761    |
|    std                   | 0.734       |
|    value_loss            | 326         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.115        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.115        |
| reward                   | -0.3433316   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 2117632      |
| train/                   |              |
|    approx_kl             | 0.0020985773 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00116      |
|    cost_value_loss       | 9.73e-06     |
|    cost_values           | 0.000318     |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 164          |
|    n_updates             | 10330        |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 0.734        |
|    value_loss            | 308          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0584       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0584       |
| reward                   | -0.39455613  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 2119680      |
| train/                   |              |
|    approx_kl             | 0.0062968917 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0139       |
|    cost_value_loss       | 2.13e-05     |
|    cost_values           | 0.0146       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0156       |
|    n_updates             | 10340        |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.736        |
|    value_loss            | 0.426        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.106       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.106       |
| reward                   | -0.47987702 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 155         |
|    total_timesteps       | 2121728     |
| train/                   |             |
|    approx_kl             | 0.010078413 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00584    |
|    cost_value_loss       | 1.96e-05    |
|    cost_values           | -0.00614    |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 331         |
|    n_updates             | 10350       |
|    policy_gradient_loss  | 0.00691     |
|    std                   | 0.738       |
|    value_loss            | 686         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0709       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0709       |
| reward                   | -0.3992929   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 177          |
|    total_timesteps       | 2123776      |
| train/                   |              |
|    approx_kl             | 0.0012329163 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00726      |
|    cost_value_loss       | 1.83e-05     |
|    cost_values           | 0.00755      |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0727       |
|    n_updates             | 10360        |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.737        |
|    value_loss            | 0.593        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.249       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.249       |
| reward                   | -0.49286065 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 2125824     |
| train/                   |             |
|    approx_kl             | 0.015152629 |
|    clip_fraction         | 0.0605      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.019       |
|    cost_value_loss       | 2.2e-05     |
|    cost_values           | 0.0196      |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0364      |
|    n_updates             | 10370       |
|    policy_gradient_loss  | -0.000506   |
|    std                   | 0.736       |
|    value_loss            | 0.137       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0285       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0285       |
| reward                   | -0.47666502  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 2127872      |
| train/                   |              |
|    approx_kl             | 0.0048769005 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000196     |
|    cost_value_loss       | 1.25e-05     |
|    cost_values           | 0.000397     |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0872       |
|    n_updates             | 10380        |
|    policy_gradient_loss  | -0.0072      |
|    std                   | 0.737        |
|    value_loss            | 0.406        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.129        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.129        |
| reward                   | -0.4275747   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 244          |
|    total_timesteps       | 2129920      |
| train/                   |              |
|    approx_kl             | 0.0022358014 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0406       |
|    cost_value_loss       | 0.000112     |
|    cost_values           | 0.0424       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0444       |
|    n_updates             | 10390        |
|    policy_gradient_loss  | -0.000864    |
|    std                   | 0.738        |
|    value_loss            | 0.847        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.116       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.116       |
| reward                   | -0.5005083  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -998        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 266         |
|    total_timesteps       | 2131968     |
| train/                   |             |
|    approx_kl             | 0.007880176 |
|    clip_fraction         | 0.0585      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0287      |
|    cost_value_loss       | 2.13e-05    |
|    cost_values           | 0.0293      |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0197      |
|    n_updates             | 10400       |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.739       |
|    value_loss            | 0.256       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0267       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0267       |
| reward                   | -0.43164822  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 288          |
|    total_timesteps       | 2134016      |
| train/                   |              |
|    approx_kl             | 0.0040393863 |
|    clip_fraction         | 0.0796       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00836      |
|    cost_value_loss       | 9.18e-06     |
|    cost_values           | 0.00852      |
|    entropy               | -2.04        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0016       |
|    n_updates             | 10410        |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.74         |
|    value_loss            | 0.0776       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00563     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00563     |
| reward                   | -0.40337116 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -967        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 2136064     |
| train/                   |             |
|    approx_kl             | 0.008773966 |
|    clip_fraction         | 0.0771      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00893     |
|    cost_value_loss       | 9.49e-06    |
|    cost_values           | 0.00897     |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00681     |
|    n_updates             | 10420       |
|    policy_gradient_loss  | 0.00104     |
|    std                   | 0.743       |
|    value_loss            | 0.0301      |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -3.9807549 |
| rollout/                 |            |
|    ep_len_mean           | 977        |
|    ep_rew_mean           | -963       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 15         |
|    time_elapsed          | 332        |
|    total_timesteps       | 2138112    |
| train/                   |            |
|    approx_kl             | 0.0088671  |
|    clip_fraction         | 0.0628     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00481    |
|    cost_value_loss       | 2.49e-06   |
|    cost_values           | 0.00486    |
|    entropy               | -2.04      |
|    entropy_loss          | -2.05      |
|    explained_variance    | 0.997      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | -0.00981   |
|    n_updates             | 10430      |
|    policy_gradient_loss  | -0.00355   |
|    std                   | 0.741      |
|    value_loss            | 0.0202     |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0467       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0467       |
| reward                   | -0.26206     |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -971         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 2140160      |
| train/                   |              |
|    approx_kl             | 0.0086566275 |
|    clip_fraction         | 0.21         |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00962     |
|    cost_value_loss       | 3.77e-05     |
|    cost_values           | -0.00949     |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.926        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 191          |
|    n_updates             | 10440        |
|    policy_gradient_loss  | 0.00442      |
|    std                   | 0.739        |
|    value_loss            | 416          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0531       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0531       |
| reward                   | -0.23429984  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -937         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 376          |
|    total_timesteps       | 2142208      |
| train/                   |              |
|    approx_kl             | 0.0047511915 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0121      |
|    cost_value_loss       | 1.7e-05      |
|    cost_values           | -0.0122      |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.3         |
|    n_updates             | 10450        |
|    policy_gradient_loss  | -0.00692     |
|    std                   | 0.74         |
|    value_loss            | 65.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0873       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0873       |
| reward                   | -0.32075143  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -962         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 398          |
|    total_timesteps       | 2144256      |
| train/                   |              |
|    approx_kl             | 0.0031555793 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000964     |
|    cost_value_loss       | 3.46e-05     |
|    cost_values           | 0.0012       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0432       |
|    n_updates             | 10460        |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.741        |
|    value_loss            | 0.501        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.53931415  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -960         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 420          |
|    total_timesteps       | 2146304      |
| train/                   |              |
|    approx_kl             | 0.0039008346 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00837     |
|    cost_value_loss       | 8.27e-05     |
|    cost_values           | -0.0119      |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 275          |
|    n_updates             | 10470        |
|    policy_gradient_loss  | 0.000273     |
|    std                   | 0.742        |
|    value_loss            | 597          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.131        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.131        |
| reward                   | -0.25576627  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -962         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 442          |
|    total_timesteps       | 2148352      |
| train/                   |              |
|    approx_kl             | 0.0007850971 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00294      |
|    cost_value_loss       | 1.68e-05     |
|    cost_values           | 0.0031       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0143       |
|    n_updates             | 10480        |
|    policy_gradient_loss  | -6.1e-05     |
|    std                   | 0.743        |
|    value_loss            | 0.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0828       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0828       |
| reward                   | -0.37996623  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -961         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 2150400      |
| train/                   |              |
|    approx_kl             | 0.0031888015 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0138       |
|    cost_value_loss       | 0.000135     |
|    cost_values           | 0.014        |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0236       |
|    n_updates             | 10490        |
|    policy_gradient_loss  | -0.000442    |
|    std                   | 0.746        |
|    value_loss            | 0.215        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.42         |
| reward                   | -2.978932    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 487          |
|    total_timesteps       | 2152448      |
| train/                   |              |
|    approx_kl             | 0.0015354527 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000615    |
|    cost_value_loss       | 0.000104     |
|    cost_values           | -0.00256     |
|    entropy               | -2.04        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.931        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.073        |
|    n_updates             | 10500        |
|    policy_gradient_loss  | 0.000107     |
|    std                   | 0.741        |
|    value_loss            | 0.404        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0471      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0471      |
| reward                   | -0.3351971  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -916        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 508         |
|    total_timesteps       | 2154496     |
| train/                   |             |
|    approx_kl             | 0.007989842 |
|    clip_fraction         | 0.0685      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0331      |
|    cost_value_loss       | 0.00012     |
|    cost_values           | 0.0356      |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 10510       |
|    policy_gradient_loss  | -0.00537    |
|    std                   | 0.74        |
|    value_loss            | 28.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0324      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0324      |
| reward                   | -0.5505064  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -916        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 530         |
|    total_timesteps       | 2156544     |
| train/                   |             |
|    approx_kl             | 0.004090938 |
|    clip_fraction         | 0.0136      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0184      |
|    cost_value_loss       | 2.58e-05    |
|    cost_values           | 0.0189      |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 78          |
|    n_updates             | 10520       |
|    policy_gradient_loss  | -0.00413    |
|    std                   | 0.741       |
|    value_loss            | 140         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0973       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0973       |
| reward                   | -0.32215196  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -891         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 553          |
|    total_timesteps       | 2158592      |
| train/                   |              |
|    approx_kl             | 0.0037871455 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0203       |
|    cost_value_loss       | 7.52e-05     |
|    cost_values           | 0.0214       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.958        |
|    n_updates             | 10530        |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.74         |
|    value_loss            | 2.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0433       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0433       |
| reward                   | -0.5331482   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -887         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 575          |
|    total_timesteps       | 2160640      |
| train/                   |              |
|    approx_kl             | 0.0017834676 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0333       |
|    cost_value_loss       | 0.00032      |
|    cost_values           | 0.0348       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00755      |
|    n_updates             | 10540        |
|    policy_gradient_loss  | -0.000704    |
|    std                   | 0.739        |
|    value_loss            | 0.258        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00656      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00656      |
| reward                   | -0.17001651  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -891         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 597          |
|    total_timesteps       | 2162688      |
| train/                   |              |
|    approx_kl             | 0.0062735295 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00361      |
|    cost_value_loss       | 0.000305     |
|    cost_values           | -0.000353    |
|    entropy               | -2.03        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0905       |
|    n_updates             | 10550        |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.737        |
|    value_loss            | 0.604        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.101        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.101        |
| reward                   | -0.35453874  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -857         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 619          |
|    total_timesteps       | 2164736      |
| train/                   |              |
|    approx_kl             | 0.0044507408 |
|    clip_fraction         | 0.0374       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0325       |
|    cost_value_loss       | 0.000121     |
|    cost_values           | 0.0339       |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0616       |
|    n_updates             | 10560        |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.734        |
|    value_loss            | 0.405        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0847      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0847      |
| reward                   | -0.51926374 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -825        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 641         |
|    total_timesteps       | 2166784     |
| train/                   |             |
|    approx_kl             | 0.003131761 |
|    clip_fraction         | 0.00859     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0303      |
|    cost_value_loss       | 1.8e-05     |
|    cost_values           | 0.0313      |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.907       |
|    n_updates             | 10570       |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.733       |
|    value_loss            | 2.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0248      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0248      |
| reward                   | -0.53502935 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -795        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 664         |
|    total_timesteps       | 2168832     |
| train/                   |             |
|    approx_kl             | 0.004664589 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00456     |
|    cost_value_loss       | 5.06e-05    |
|    cost_values           | 0.00554     |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0153      |
|    n_updates             | 10580       |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.73        |
|    value_loss            | 0.159       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0791      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0791      |
| reward                   | -0.4932061  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -797        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 686         |
|    total_timesteps       | 2170880     |
| train/                   |             |
|    approx_kl             | 0.003274269 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0205      |
|    cost_value_loss       | 4.89e-05    |
|    cost_values           | 0.0213      |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0144      |
|    n_updates             | 10590       |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.73        |
|    value_loss            | 0.115       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0827       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0827       |
| reward                   | -0.5125003   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 2172928      |
| train/                   |              |
|    approx_kl             | 0.0053835725 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00605      |
|    cost_value_loss       | 0.000122     |
|    cost_values           | 0.00565      |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0294       |
|    n_updates             | 10600        |
|    policy_gradient_loss  | -0.000898    |
|    std                   | 0.729        |
|    value_loss            | 0.206        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0785       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0785       |
| reward                   | -0.13180895  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 730          |
|    total_timesteps       | 2174976      |
| train/                   |              |
|    approx_kl             | 0.0013624047 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0148      |
|    cost_value_loss       | 2.59e-05     |
|    cost_values           | -0.015       |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.587        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0146       |
|    n_updates             | 10610        |
|    policy_gradient_loss  | -0.000936    |
|    std                   | 0.729        |
|    value_loss            | 0.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.198        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.198        |
| reward                   | -0.25612044  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 753          |
|    total_timesteps       | 2177024      |
| train/                   |              |
|    approx_kl             | 0.0037656496 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00632     |
|    cost_value_loss       | 1.3e-05      |
|    cost_values           | -0.00646     |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.04         |
|    n_updates             | 10620        |
|    policy_gradient_loss  | -0.000977    |
|    std                   | 0.729        |
|    value_loss            | 1.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0632       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0632       |
| reward                   | -0.2612823   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -633         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 775          |
|    total_timesteps       | 2179072      |
| train/                   |              |
|    approx_kl             | 0.0026554926 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.013       |
|    cost_value_loss       | 3.67e-05     |
|    cost_values           | -0.0129      |
|    entropy               | -2.01        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.597        |
|    n_updates             | 10630        |
|    policy_gradient_loss  | -0.000481    |
|    std                   | 0.727        |
|    value_loss            | 1.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.63         |
| reward                   | -0.5761482   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -632         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 797          |
|    total_timesteps       | 2181120      |
| train/                   |              |
|    approx_kl             | 0.0040961574 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00603     |
|    cost_value_loss       | 0.000145     |
|    cost_values           | -0.00806     |
|    entropy               | -2.02        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0196       |
|    n_updates             | 10640        |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.728        |
|    value_loss            | 0.181        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0252      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0252      |
| reward                   | -0.29503214 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -602        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 819         |
|    total_timesteps       | 2183168     |
| train/                   |             |
|    approx_kl             | 0.008176611 |
|    clip_fraction         | 0.0389      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0281      |
|    cost_value_loss       | 0.00015     |
|    cost_values           | 0.0259      |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.41        |
|    n_updates             | 10650       |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.729       |
|    value_loss            | 3.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0708       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0708       |
| reward                   | -0.4036114   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -602         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 841          |
|    total_timesteps       | 2185216      |
| train/                   |              |
|    approx_kl             | 0.0015517175 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0082       |
|    cost_value_loss       | 3.85e-05     |
|    cost_values           | 0.00865      |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.828        |
|    n_updates             | 10660        |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.729        |
|    value_loss            | 2.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.072        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.072        |
| reward                   | -0.51972306  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -606         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 864          |
|    total_timesteps       | 2187264      |
| train/                   |              |
|    approx_kl             | 0.0035419306 |
|    clip_fraction         | 0.0794       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0076       |
|    cost_value_loss       | 1.64e-05     |
|    cost_values           | 0.00838      |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00888      |
|    n_updates             | 10670        |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.727        |
|    value_loss            | 0.072        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0671       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0671       |
| reward                   | -0.31857276  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -608         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 886          |
|    total_timesteps       | 2189312      |
| train/                   |              |
|    approx_kl             | 0.0017648747 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00666     |
|    cost_value_loss       | 1.36e-05     |
|    cost_values           | -0.00636     |
|    entropy               | -2.01        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0144       |
|    n_updates             | 10680        |
|    policy_gradient_loss  | -0.000368    |
|    std                   | 0.726        |
|    value_loss            | 0.123        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0494       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0494       |
| reward                   | -0.33154297  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -605         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 908          |
|    total_timesteps       | 2191360      |
| train/                   |              |
|    approx_kl             | 0.0041706497 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000756    |
|    cost_value_loss       | 2.11e-05     |
|    cost_values           | -0.00109     |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0537       |
|    n_updates             | 10690        |
|    policy_gradient_loss  | -0.00456     |
|    std                   | 0.726        |
|    value_loss            | 0.276        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0583      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0583      |
| reward                   | -0.2521217  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -602        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 930         |
|    total_timesteps       | 2193408     |
| train/                   |             |
|    approx_kl             | 0.004717875 |
|    clip_fraction         | 0.0157      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00332     |
|    cost_value_loss       | 3.01e-05    |
|    cost_values           | 0.002       |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0199      |
|    n_updates             | 10700       |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.725       |
|    value_loss            | 0.363       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0533       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0533       |
| reward                   | -0.32378468  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -599         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 952          |
|    total_timesteps       | 2195456      |
| train/                   |              |
|    approx_kl             | 0.0038048262 |
|    clip_fraction         | 0.00605      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0022      |
|    cost_value_loss       | 0.000601     |
|    cost_values           | 0.000754     |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0157       |
|    n_updates             | 10710        |
|    policy_gradient_loss  | 4.81e-05     |
|    std                   | 0.724        |
|    value_loss            | 0.129        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.121        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.121        |
| reward                   | -0.49950165  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -597         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 975          |
|    total_timesteps       | 2197504      |
| train/                   |              |
|    approx_kl             | 0.0049956124 |
|    clip_fraction         | 0.0421       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0253      |
|    cost_value_loss       | 0.00186      |
|    cost_values           | -0.0391      |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0446       |
|    n_updates             | 10720        |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.724        |
|    value_loss            | 0.169        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0521        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0521        |
| reward                   | -0.47760954   |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -597          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 45            |
|    time_elapsed          | 997           |
|    total_timesteps       | 2199552       |
| train/                   |               |
|    approx_kl             | 0.00069614884 |
|    clip_fraction         | 0.00806       |
|    clip_range            | 0.2           |
|    cost_returns          | -0.0238       |
|    cost_value_loss       | 0.000109      |
|    cost_values           | -0.0249       |
|    entropy               | -2.01         |
|    entropy_loss          | -2.01         |
|    explained_variance    | 0.986         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.0847        |
|    n_updates             | 10730         |
|    policy_gradient_loss  | -0.00087      |
|    std                   | 0.725         |
|    value_loss            | 0.526         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0668       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0668       |
| reward                   | -0.48847714  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -567         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1019         |
|    total_timesteps       | 2201600      |
| train/                   |              |
|    approx_kl             | 0.0051463856 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0276      |
|    cost_value_loss       | 2.82e-05     |
|    cost_values           | -0.0285      |
|    entropy               | -2           |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0808       |
|    n_updates             | 10740        |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.721        |
|    value_loss            | 0.479        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00307     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00307     |
| reward                   | -0.5549462  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -539        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 2203648     |
| train/                   |             |
|    approx_kl             | 0.003977321 |
|    clip_fraction         | 0.0523      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0134     |
|    cost_value_loss       | 2.06e-05    |
|    cost_values           | -0.014      |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00763     |
|    n_updates             | 10750       |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 0.72        |
|    value_loss            | 0.0448      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0839       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0839       |
| reward                   | -0.3309023   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -541         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 2205696      |
| train/                   |              |
|    approx_kl             | 0.0031279232 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00918      |
|    cost_value_loss       | 1.91e-05     |
|    cost_values           | 0.00979      |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0138       |
|    n_updates             | 10760        |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.719        |
|    value_loss            | 0.131        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0456       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0456       |
| reward                   | -0.3800452   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -540         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 2207744      |
| train/                   |              |
|    approx_kl             | 0.0030869353 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0295      |
|    cost_value_loss       | 3.19e-05     |
|    cost_values           | -0.0301      |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00387      |
|    n_updates             | 10770        |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.714        |
|    value_loss            | 0.123        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.137       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.137       |
| reward             | -0.30549857 |
| rollout/           |             |
|    ep_len_mean     | 971         |
|    ep_rew_mean     | -514        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2209792     |
------------------------------------
------------------------------------------
| avg_speed                | 0.0488      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0488      |
| reward                   | -0.5517411  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2211840     |
| train/                   |             |
|    approx_kl             | 0.004187979 |
|    clip_fraction         | 0.0948      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0259      |
|    cost_value_loss       | 1.62e-05    |
|    cost_values           | 0.0257      |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0185      |
|    n_updates             | 10790       |
|    policy_gradient_loss  | -0.00671    |
|    std                   | 0.711       |
|    value_loss            | 0.0687      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.5525394   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 2213888      |
| train/                   |              |
|    approx_kl             | 0.0038179697 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0168       |
|    cost_value_loss       | 5.13e-05     |
|    cost_values           | 0.0168       |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0254       |
|    n_updates             | 10800        |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.713        |
|    value_loss            | 0.136        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0727       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0727       |
| reward                   | -0.5164547   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 4            |
|    time_elapsed          | 89           |
|    total_timesteps       | 2215936      |
| train/                   |              |
|    approx_kl             | 0.0042889616 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00915     |
|    cost_value_loss       | 2.36e-05     |
|    cost_values           | -0.00899     |
|    entropy               | -1.97        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00627      |
|    n_updates             | 10810        |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.709        |
|    value_loss            | 0.0658       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0125      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0125      |
| reward                   | -0.16212519 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -458        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 2217984     |
| train/                   |             |
|    approx_kl             | 0.009671111 |
|    clip_fraction         | 0.0656      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00709     |
|    cost_value_loss       | 1.12e-05    |
|    cost_values           | 0.00751     |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.08        |
|    n_updates             | 10820       |
|    policy_gradient_loss  | 0.000111    |
|    std                   | 0.709       |
|    value_loss            | 1.71        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.00474       |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.00474       |
| reward                   | -0.31109148   |
| rollout/                 |               |
|    ep_len_mean           | 964           |
|    ep_rew_mean           | -452          |
| time/                    |               |
|    fps                   | 91            |
|    iterations            | 6             |
|    time_elapsed          | 133           |
|    total_timesteps       | 2220032       |
| train/                   |               |
|    approx_kl             | 0.00041734058 |
|    clip_fraction         | 0.00244       |
|    clip_range            | 0.2           |
|    cost_returns          | -0.00752      |
|    cost_value_loss       | 4.36e-05      |
|    cost_values           | -0.00908      |
|    entropy               | -1.97         |
|    entropy_loss          | -1.97         |
|    explained_variance    | 0.986         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.0263        |
|    n_updates             | 10830         |
|    policy_gradient_loss  | -4.43e-05     |
|    std                   | 0.709         |
|    value_loss            | 0.45          |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.068       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.068       |
| reward                   | -0.48011568 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 156         |
|    total_timesteps       | 2222080     |
| train/                   |             |
|    approx_kl             | 0.006628693 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00282     |
|    cost_value_loss       | 4.87e-05    |
|    cost_values           | 3.13e-05    |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.528       |
|    n_updates             | 10840       |
|    policy_gradient_loss  | -0.00241    |
|    std                   | 0.709       |
|    value_loss            | 1.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0639      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0639      |
| reward                   | -0.4750401  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 178         |
|    total_timesteps       | 2224128     |
| train/                   |             |
|    approx_kl             | 0.003561493 |
|    clip_fraction         | 0.0137      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00228    |
|    cost_value_loss       | 9.56e-06    |
|    cost_values           | -0.00362    |
|    entropy               | -1.96       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0129      |
|    n_updates             | 10850       |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.705       |
|    value_loss            | 0.133       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0624       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0624       |
| reward                   | -0.30835673  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 9            |
|    time_elapsed          | 200          |
|    total_timesteps       | 2226176      |
| train/                   |              |
|    approx_kl             | 0.0016805206 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00292      |
|    cost_value_loss       | 2.17e-06     |
|    cost_values           | 0.00301      |
|    entropy               | -1.95        |
|    entropy_loss          | -1.96        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00148     |
|    n_updates             | 10860        |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.701        |
|    value_loss            | 0.0335       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0285      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0285      |
| reward                   | -0.55270165 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 222         |
|    total_timesteps       | 2228224     |
| train/                   |             |
|    approx_kl             | 0.005000187 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.027       |
|    cost_value_loss       | 1.28e-05    |
|    cost_values           | 0.0282      |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0121      |
|    n_updates             | 10870       |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.7         |
|    value_loss            | 0.122       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.14        |
| reward                   | -0.32634318 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 244         |
|    total_timesteps       | 2230272     |
| train/                   |             |
|    approx_kl             | 0.013987367 |
|    clip_fraction         | 0.0649      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0269      |
|    cost_value_loss       | 7.68e-05    |
|    cost_values           | 0.0279      |
|    entropy               | -1.94       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.003       |
|    n_updates             | 10880       |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.697       |
|    value_loss            | 0.0903      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0753       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0753       |
| reward                   | -0.427321    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 12           |
|    time_elapsed          | 267          |
|    total_timesteps       | 2232320      |
| train/                   |              |
|    approx_kl             | 0.0077814506 |
|    clip_fraction         | 0.0425       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00207     |
|    cost_value_loss       | 2.5e-05      |
|    cost_values           | -0.0023      |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00382      |
|    n_updates             | 10890        |
|    policy_gradient_loss  | 0.00011      |
|    std                   | 0.692        |
|    value_loss            | 0.0409       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.128       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.128       |
| reward                   | -0.5123594  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 289         |
|    total_timesteps       | 2234368     |
| train/                   |             |
|    approx_kl             | 0.018577788 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00653    |
|    cost_value_loss       | 1.33e-06    |
|    cost_values           | -0.00656    |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00775    |
|    n_updates             | 10900       |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.693       |
|    value_loss            | 0.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0932       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0932       |
| reward                   | -0.50930816  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 311          |
|    total_timesteps       | 2236416      |
| train/                   |              |
|    approx_kl             | 0.0028653038 |
|    clip_fraction         | 0.204        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0145      |
|    cost_value_loss       | 9.15e-06     |
|    cost_values           | -0.0146      |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00473      |
|    n_updates             | 10910        |
|    policy_gradient_loss  | 0.00323      |
|    std                   | 0.692        |
|    value_loss            | 0.0485       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.205        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.205        |
| reward                   | -0.49715307  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 333          |
|    total_timesteps       | 2238464      |
| train/                   |              |
|    approx_kl             | 0.0035560948 |
|    clip_fraction         | 0.0593       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00616     |
|    cost_value_loss       | 9.49e-06     |
|    cost_values           | -0.00618     |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00266      |
|    n_updates             | 10920        |
|    policy_gradient_loss  | 0.00184      |
|    std                   | 0.69         |
|    value_loss            | 0.0433       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0479       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0479       |
| reward                   | -0.37858883  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 355          |
|    total_timesteps       | 2240512      |
| train/                   |              |
|    approx_kl             | 0.0050097373 |
|    clip_fraction         | 0.0581       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00673     |
|    cost_value_loss       | 8.6e-06      |
|    cost_values           | -0.00693     |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00493     |
|    n_updates             | 10930        |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.69         |
|    value_loss            | 0.045        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0982      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0982      |
| reward                   | -0.47285345 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 2242560     |
| train/                   |             |
|    approx_kl             | 0.006391166 |
|    clip_fraction         | 0.0703      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0062     |
|    cost_value_loss       | 5.17e-06    |
|    cost_values           | -0.0062     |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000359    |
|    n_updates             | 10940       |
|    policy_gradient_loss  | -0.00321    |
|    std                   | 0.69        |
|    value_loss            | 0.0599      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0482       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0482       |
| reward                   | -0.4688806   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 399          |
|    total_timesteps       | 2244608      |
| train/                   |              |
|    approx_kl             | 0.0023825027 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00109      |
|    cost_value_loss       | 1.19e-06     |
|    cost_values           | 0.00114      |
|    entropy               | -1.91        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000116     |
|    n_updates             | 10950        |
|    policy_gradient_loss  | -0.000672    |
|    std                   | 0.684        |
|    value_loss            | 0.00996      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.113       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.113       |
| reward                   | -0.38230446 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 421         |
|    total_timesteps       | 2246656     |
| train/                   |             |
|    approx_kl             | 0.004958893 |
|    clip_fraction         | 0.0393      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00506    |
|    cost_value_loss       | 1.06e-05    |
|    cost_values           | -0.0062     |
|    entropy               | -1.91       |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00874     |
|    n_updates             | 10960       |
|    policy_gradient_loss  | -0.000123   |
|    std                   | 0.683       |
|    value_loss            | 0.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.29445148  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 2248704      |
| train/                   |              |
|    approx_kl             | 0.0028572592 |
|    clip_fraction         | 0.0451       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000606    |
|    cost_value_loss       | 1.56e-05     |
|    cost_values           | -0.000721    |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0133       |
|    n_updates             | 10970        |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.684        |
|    value_loss            | 0.053        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.143        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.143        |
| reward                   | -0.5154136   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 465          |
|    total_timesteps       | 2250752      |
| train/                   |              |
|    approx_kl             | 0.0027092437 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00849      |
|    cost_value_loss       | 9.78e-06     |
|    cost_values           | 0.00886      |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.021        |
|    n_updates             | 10980        |
|    policy_gradient_loss  | -0.000799    |
|    std                   | 0.684        |
|    value_loss            | 0.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0527       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0527       |
| reward                   | -0.4763007   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 487          |
|    total_timesteps       | 2252800      |
| train/                   |              |
|    approx_kl             | 0.0052213073 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00107     |
|    cost_value_loss       | 8.08e-06     |
|    cost_values           | -0.000996    |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.22         |
|    n_updates             | 10990        |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.684        |
|    value_loss            | 1.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0643       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0643       |
| reward                   | -0.5554267   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 509          |
|    total_timesteps       | 2254848      |
| train/                   |              |
|    approx_kl             | 0.0011611867 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00233     |
|    cost_value_loss       | 2.12e-05     |
|    cost_values           | -0.00301     |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0368       |
|    n_updates             | 11000        |
|    policy_gradient_loss  | 0.000391     |
|    std                   | 0.684        |
|    value_loss            | 0.143        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00172     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00172     |
| reward                   | -0.5476379  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 531         |
|    total_timesteps       | 2256896     |
| train/                   |             |
|    approx_kl             | 0.002008908 |
|    clip_fraction         | 0.0774      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0043     |
|    cost_value_loss       | 2.28e-06    |
|    cost_values           | -0.00449    |
|    entropy               | -1.91       |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00133     |
|    n_updates             | 11010       |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.684       |
|    value_loss            | 0.019       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0513      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0513      |
| reward                   | -0.51678836 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 552         |
|    total_timesteps       | 2258944     |
| train/                   |             |
|    approx_kl             | 0.005806081 |
|    clip_fraction         | 0.0764      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000164   |
|    cost_value_loss       | 8.31e-06    |
|    cost_values           | 0.000113    |
|    entropy               | -1.91       |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00691     |
|    n_updates             | 11020       |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.684       |
|    value_loss            | 0.0966      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0679      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0679      |
| reward                   | -0.25179383 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 575         |
|    total_timesteps       | 2260992     |
| train/                   |             |
|    approx_kl             | 0.005512325 |
|    clip_fraction         | 0.0471      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0332      |
|    cost_value_loss       | 6.46e-05    |
|    cost_values           | 0.0333      |
|    entropy               | -1.9        |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00936     |
|    n_updates             | 11030       |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.682       |
|    value_loss            | 0.187       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0468       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0468       |
| reward                   | -0.52369547  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 597          |
|    total_timesteps       | 2263040      |
| train/                   |              |
|    approx_kl             | 0.0049092546 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00162     |
|    cost_value_loss       | 1.89e-06     |
|    cost_values           | -0.00169     |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00207     |
|    n_updates             | 11040        |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.68         |
|    value_loss            | 0.0295       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0498       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0498       |
| reward                   | -0.37938476  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 619          |
|    total_timesteps       | 2265088      |
| train/                   |              |
|    approx_kl             | 0.0037094252 |
|    clip_fraction         | 0.00981      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000107    |
|    cost_value_loss       | 1.04e-05     |
|    cost_values           | -0.000973    |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0403       |
|    n_updates             | 11050        |
|    policy_gradient_loss  | -0.000531    |
|    std                   | 0.68         |
|    value_loss            | 0.173        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0568      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0568      |
| reward                   | -0.47703117 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 641         |
|    total_timesteps       | 2267136     |
| train/                   |             |
|    approx_kl             | 0.004353283 |
|    clip_fraction         | 0.0485      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00225    |
|    cost_value_loss       | 1.16e-05    |
|    cost_values           | -0.00191    |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00623     |
|    n_updates             | 11060       |
|    policy_gradient_loss  | -0.00423    |
|    std                   | 0.68        |
|    value_loss            | 0.105       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0911       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0911       |
| reward                   | -0.4510155   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 663          |
|    total_timesteps       | 2269184      |
| train/                   |              |
|    approx_kl             | 0.0055020535 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000678    |
|    cost_value_loss       | 3.95e-06     |
|    cost_values           | -0.000759    |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00945      |
|    n_updates             | 11070        |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.68         |
|    value_loss            | 0.0846       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0424       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0424       |
| reward                   | -0.3188601   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 685          |
|    total_timesteps       | 2271232      |
| train/                   |              |
|    approx_kl             | 0.0050090803 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.021       |
|    cost_value_loss       | 1.74e-05     |
|    cost_values           | -0.0212      |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0158       |
|    n_updates             | 11080        |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.68         |
|    value_loss            | 0.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.028        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.028        |
| reward                   | -0.25321123  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 707          |
|    total_timesteps       | 2273280      |
| train/                   |              |
|    approx_kl             | 0.0029352822 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0147      |
|    cost_value_loss       | 1.27e-05     |
|    cost_values           | -0.015       |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00911      |
|    n_updates             | 11090        |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 0.678        |
|    value_loss            | 0.111        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.32386285  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 729          |
|    total_timesteps       | 2275328      |
| train/                   |              |
|    approx_kl             | 0.0014067827 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00163     |
|    cost_value_loss       | 8.51e-06     |
|    cost_values           | -0.00257     |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0187       |
|    n_updates             | 11100        |
|    policy_gradient_loss  | -4.25e-05    |
|    std                   | 0.678        |
|    value_loss            | 0.234        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.114       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.114       |
| reward                   | -0.5141654  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 751         |
|    total_timesteps       | 2277376     |
| train/                   |             |
|    approx_kl             | 0.006860704 |
|    clip_fraction         | 0.0478      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00237     |
|    cost_value_loss       | 7.55e-06    |
|    cost_values           | 0.00233     |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00865     |
|    n_updates             | 11110       |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.677       |
|    value_loss            | 0.0957      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0519      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0519      |
| reward                   | -0.24165127 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 773         |
|    total_timesteps       | 2279424     |
| train/                   |             |
|    approx_kl             | 0.003796382 |
|    clip_fraction         | 0.00864     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00119     |
|    cost_value_loss       | 0.00012     |
|    cost_values           | 0.00121     |
|    entropy               | -1.88       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00577     |
|    n_updates             | 11120       |
|    policy_gradient_loss  | -0.000504   |
|    std                   | 0.675       |
|    value_loss            | 0.0454      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0413       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0413       |
| reward                   | -0.25318366  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 795          |
|    total_timesteps       | 2281472      |
| train/                   |              |
|    approx_kl             | 0.0056270813 |
|    clip_fraction         | 0.0383       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0045      |
|    cost_value_loss       | 2.56e-05     |
|    cost_values           | -0.00383     |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0145       |
|    n_updates             | 11130        |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.673        |
|    value_loss            | 0.0944       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0331       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0331       |
| reward                   | -0.3793926   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 817          |
|    total_timesteps       | 2283520      |
| train/                   |              |
|    approx_kl             | 0.0055882614 |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00478     |
|    cost_value_loss       | 2.68e-05     |
|    cost_values           | -0.00545     |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0605       |
|    n_updates             | 11140        |
|    policy_gradient_loss  | -0.000741    |
|    std                   | 0.673        |
|    value_loss            | 0.249        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0231       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0231       |
| reward                   | -0.25920534  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 839          |
|    total_timesteps       | 2285568      |
| train/                   |              |
|    approx_kl             | 0.0021561314 |
|    clip_fraction         | 0.00293      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0031       |
|    cost_value_loss       | 1.74e-05     |
|    cost_values           | 0.00234      |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0025       |
|    n_updates             | 11150        |
|    policy_gradient_loss  | -0.000791    |
|    std                   | 0.672        |
|    value_loss            | 0.0855       |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.564155  |
| rollout/                 |            |
|    ep_len_mean           | 988        |
|    ep_rew_mean           | -439       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 39         |
|    time_elapsed          | 861        |
|    total_timesteps       | 2287616    |
| train/                   |            |
|    approx_kl             | 0.00638909 |
|    clip_fraction         | 0.0388     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00575    |
|    cost_value_loss       | 1.45e-05   |
|    cost_values           | 0.00646    |
|    entropy               | -1.87      |
|    entropy_loss          | -1.87      |
|    explained_variance    | 0.994      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.00332    |
|    n_updates             | 11160      |
|    policy_gradient_loss  | -0.00206   |
|    std                   | 0.672      |
|    value_loss            | 0.0379     |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0782       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0782       |
| reward                   | -0.5148926   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 883          |
|    total_timesteps       | 2289664      |
| train/                   |              |
|    approx_kl             | 0.0065757046 |
|    clip_fraction         | 0.0506       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00175      |
|    cost_value_loss       | 0.000151     |
|    cost_values           | 0.00318      |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.858        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 655          |
|    n_updates             | 11170        |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.672        |
|    value_loss            | 1.4e+03      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0745      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0745      |
| reward                   | -0.5523681  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 905         |
|    total_timesteps       | 2291712     |
| train/                   |             |
|    approx_kl             | 0.005707392 |
|    clip_fraction         | 0.0255      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00647    |
|    cost_value_loss       | 5.44e-06    |
|    cost_values           | -0.0069     |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 92.1        |
|    n_updates             | 11180       |
|    policy_gradient_loss  | -0.00693    |
|    std                   | 0.672       |
|    value_loss            | 235         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -4.5286646   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 927          |
|    total_timesteps       | 2293760      |
| train/                   |              |
|    approx_kl             | 0.0023294478 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00346     |
|    cost_value_loss       | 6.54e-06     |
|    cost_values           | -0.00341     |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00419      |
|    n_updates             | 11190        |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.672        |
|    value_loss            | 0.0666       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0482       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0482       |
| reward                   | -0.43233457  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -508         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 949          |
|    total_timesteps       | 2295808      |
| train/                   |              |
|    approx_kl             | 0.0072417054 |
|    clip_fraction         | 0.148        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00861     |
|    cost_value_loss       | 7.9e-05      |
|    cost_values           | -0.00931     |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 327          |
|    n_updates             | 11200        |
|    policy_gradient_loss  | 0.00738      |
|    std                   | 0.672        |
|    value_loss            | 643          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00123     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00123     |
| reward                   | -0.42271602 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -508        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 971         |
|    total_timesteps       | 2297856     |
| train/                   |             |
|    approx_kl             | 0.004507635 |
|    clip_fraction         | 0.0134      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0141     |
|    cost_value_loss       | 1.76e-05    |
|    cost_values           | -0.015      |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.4        |
|    n_updates             | 11210       |
|    policy_gradient_loss  | -0.00632    |
|    std                   | 0.673       |
|    value_loss            | 52.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.82         |
| reward                   | -0.75036424  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 993          |
|    total_timesteps       | 2299904      |
| train/                   |              |
|    approx_kl             | 0.0037465906 |
|    clip_fraction         | 0.0348       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00222      |
|    cost_value_loss       | 2.4e-05      |
|    cost_values           | 0.00195      |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00319     |
|    n_updates             | 11220        |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.672        |
|    value_loss            | 0.0522       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.13         |
| reward                   | -0.25866386  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -566         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1015         |
|    total_timesteps       | 2301952      |
| train/                   |              |
|    approx_kl             | 0.0055493684 |
|    clip_fraction         | 0.0483       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00054     |
|    cost_value_loss       | 0.000274     |
|    cost_values           | -0.00392     |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 322          |
|    n_updates             | 11230        |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.672        |
|    value_loss            | 670          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0224       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0224       |
| reward                   | -0.3852278   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -560         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1037         |
|    total_timesteps       | 2304000      |
| train/                   |              |
|    approx_kl             | 0.0020134742 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0568       |
|    cost_value_loss       | 0.000236     |
|    cost_values           | 0.0622       |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 288          |
|    n_updates             | 11240        |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.672        |
|    value_loss            | 622          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0234      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0234      |
| reward                   | -0.51308435 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -563        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1058        |
|    total_timesteps       | 2306048     |
| train/                   |             |
|    approx_kl             | 0.009460812 |
|    clip_fraction         | 0.0741      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00222     |
|    cost_value_loss       | 1.68e-05    |
|    cost_values           | 0.00196     |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.019       |
|    n_updates             | 11250       |
|    policy_gradient_loss  | -0.00376    |
|    std                   | 0.671       |
|    value_loss            | 0.212       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.005        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.005        |
| reward                   | -0.5506293   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -562         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1080         |
|    total_timesteps       | 2308096      |
| train/                   |              |
|    approx_kl             | 0.0047638593 |
|    clip_fraction         | 0.0833       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00861     |
|    cost_value_loss       | 4.24e-05     |
|    cost_values           | -0.00774     |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.12         |
|    n_updates             | 11260        |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 0.672        |
|    value_loss            | 4.64         |
-------------------------------------------
----------------------------------
| avg_speed          | 0.0201    |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 0.0201    |
| reward             | -0.511267 |
| rollout/           |           |
|    ep_len_mean     | 988       |
|    ep_rew_mean     | -592      |
| time/              |           |
|    fps             | 97        |
|    iterations      | 1         |
|    time_elapsed    | 21        |
|    total_timesteps | 2310144   |
----------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.4771989   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -592         |
| time/                    |              |
|    fps                   | 95           |
|    iterations            | 2            |
|    time_elapsed          | 42           |
|    total_timesteps       | 2312192      |
| train/                   |              |
|    approx_kl             | 0.0040505254 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000456    |
|    cost_value_loss       | 8.38e-05     |
|    cost_values           | -0.00102     |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 226          |
|    n_updates             | 11280        |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 0.673        |
|    value_loss            | 479          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.055       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.055       |
| reward                   | -0.55143505 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -592        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2314240     |
| train/                   |             |
|    approx_kl             | 0.004675219 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0114     |
|    cost_value_loss       | 5.49e-06    |
|    cost_values           | -0.0112     |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0426      |
|    n_updates             | 11290       |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.673       |
|    value_loss            | 0.338       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0546       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0546       |
| reward                   | -0.40360633  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -596         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 2316288      |
| train/                   |              |
|    approx_kl             | 0.0077303564 |
|    clip_fraction         | 0.0424       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00817     |
|    cost_value_loss       | 4.51e-06     |
|    cost_values           | -0.00796     |
|    entropy               | -1.87        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0251       |
|    n_updates             | 11300        |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.673        |
|    value_loss            | 0.113        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0176      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0176      |
| reward                   | -0.42896795 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -599        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 2318336     |
| train/                   |             |
|    approx_kl             | 0.008801335 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000374   |
|    cost_value_loss       | 6.71e-06    |
|    cost_values           | -0.000119   |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.011       |
|    n_updates             | 11310       |
|    policy_gradient_loss  | 0.000172    |
|    std                   | 0.672       |
|    value_loss            | 0.0565      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0104      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0104      |
| reward                   | -0.25415915 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -600        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 2320384     |
| train/                   |             |
|    approx_kl             | 0.002229514 |
|    clip_fraction         | 0.0465      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000393   |
|    cost_value_loss       | 1.72e-06    |
|    cost_values           | -0.000347   |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00664     |
|    n_updates             | 11320       |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.674       |
|    value_loss            | 0.075       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0587      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0587      |
| reward                   | -0.52279156 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -598        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 2322432     |
| train/                   |             |
|    approx_kl             | 0.00767857  |
|    clip_fraction         | 0.0461      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00216     |
|    cost_value_loss       | 4.51e-06    |
|    cost_values           | 0.00197     |
|    entropy               | -1.87       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.026       |
|    n_updates             | 11330       |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 0.673       |
|    value_loss            | 0.0842      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0462       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0462       |
| reward                   | -0.32525906  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -599         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 175          |
|    total_timesteps       | 2324480      |
| train/                   |              |
|    approx_kl             | 0.0016609891 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0148       |
|    cost_value_loss       | 3.07e-05     |
|    cost_values           | 0.0153       |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.043        |
|    n_updates             | 11340        |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.673        |
|    value_loss            | 0.389        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0261       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0261       |
| reward                   | -0.44821155  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -599         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 197          |
|    total_timesteps       | 2326528      |
| train/                   |              |
|    approx_kl             | 0.0030234999 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00405      |
|    cost_value_loss       | 4.6e-05      |
|    cost_values           | 0.00429      |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0344       |
|    n_updates             | 11350        |
|    policy_gradient_loss  | -7.65e-06    |
|    std                   | 0.672        |
|    value_loss            | 0.185        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.4837526   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -599         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 2328576      |
| train/                   |              |
|    approx_kl             | 0.0042171017 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00423     |
|    cost_value_loss       | 1.81e-06     |
|    cost_values           | -0.00424     |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00678      |
|    n_updates             | 11360        |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.672        |
|    value_loss            | 0.0536       |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.139      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.139      |
| reward                   | -0.332146  |
| rollout/                 |            |
|    ep_len_mean           | 996        |
|    ep_rew_mean           | -600       |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 11         |
|    time_elapsed          | 241        |
|    total_timesteps       | 2330624    |
| train/                   |            |
|    approx_kl             | 0.00439882 |
|    clip_fraction         | 0.0375     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00447   |
|    cost_value_loss       | 3.97e-06   |
|    cost_values           | -0.00445   |
|    entropy               | -1.86      |
|    entropy_loss          | -1.86      |
|    explained_variance    | 0.984      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.00997    |
|    n_updates             | 11370      |
|    policy_gradient_loss  | -0.00226   |
|    std                   | 0.672      |
|    value_loss            | 0.0774     |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0151       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0151       |
| reward                   | -0.47911978  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -624         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 263          |
|    total_timesteps       | 2332672      |
| train/                   |              |
|    approx_kl             | 0.0012680201 |
|    clip_fraction         | 0.139        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00218     |
|    cost_value_loss       | 7.04e-06     |
|    cost_values           | -0.00278     |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00248      |
|    n_updates             | 11380        |
|    policy_gradient_loss  | 0.00604      |
|    std                   | 0.673        |
|    value_loss            | 0.0232       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.135       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.135       |
| reward                   | -0.45267674 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -623        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 13          |
|    time_elapsed          | 285         |
|    total_timesteps       | 2334720     |
| train/                   |             |
|    approx_kl             | 0.00861093  |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000841    |
|    cost_value_loss       | 3.93e-05    |
|    cost_values           | 0.0025      |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 226         |
|    n_updates             | 11390       |
|    policy_gradient_loss  | -0.00251    |
|    std                   | 0.673       |
|    value_loss            | 546         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0204       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0204       |
| reward                   | -0.2557141   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -623         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 307          |
|    total_timesteps       | 2336768      |
| train/                   |              |
|    approx_kl             | 0.0041645374 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0165      |
|    cost_value_loss       | 1.82e-05     |
|    cost_values           | -0.0167      |
|    entropy               | -1.86        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.119        |
|    n_updates             | 11400        |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 0.671        |
|    value_loss            | 0.529        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0254      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0254      |
| reward                   | -0.44195253 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -645        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 329         |
|    total_timesteps       | 2338816     |
| train/                   |             |
|    approx_kl             | 0.00591279  |
|    clip_fraction         | 0.0445      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00467    |
|    cost_value_loss       | 1.73e-05    |
|    cost_values           | -0.0049     |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0122      |
|    n_updates             | 11410       |
|    policy_gradient_loss  | 0.000613    |
|    std                   | 0.669       |
|    value_loss            | 0.0694      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0168       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0168       |
| reward                   | -0.4397952   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -645         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 351          |
|    total_timesteps       | 2340864      |
| train/                   |              |
|    approx_kl             | 0.0049748896 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000813     |
|    cost_value_loss       | 5.96e-05     |
|    cost_values           | 0.00179      |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0.931        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 223          |
|    n_updates             | 11420        |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 0.669        |
|    value_loss            | 492          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0618       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0618       |
| reward                   | -0.26021326  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 373          |
|    total_timesteps       | 2342912      |
| train/                   |              |
|    approx_kl             | 0.0044218963 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00673     |
|    cost_value_loss       | 5.62e-06     |
|    cost_values           | -0.00675     |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0236       |
|    n_updates             | 11430        |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.668        |
|    value_loss            | 0.106        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0586       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0586       |
| reward                   | -0.41642112  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 395          |
|    total_timesteps       | 2344960      |
| train/                   |              |
|    approx_kl             | 0.0049996087 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | -5.21e-05    |
|    cost_value_loss       | 6.21e-05     |
|    cost_values           | -0.00133     |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 197          |
|    n_updates             | 11440        |
|    policy_gradient_loss  | -0.00358     |
|    std                   | 0.668        |
|    value_loss            | 431          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0354       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0354       |
| reward                   | -0.25122082  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 19           |
|    time_elapsed          | 417          |
|    total_timesteps       | 2347008      |
| train/                   |              |
|    approx_kl             | 0.0039179935 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00344      |
|    cost_value_loss       | 0.000107     |
|    cost_values           | 0.00523      |
|    entropy               | -1.85        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0288       |
|    n_updates             | 11450        |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 0.668        |
|    value_loss            | 0.294        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0127       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0127       |
| reward                   | -0.42411017  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 439          |
|    total_timesteps       | 2349056      |
| train/                   |              |
|    approx_kl             | 0.0050489414 |
|    clip_fraction         | 0.0451       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0112      |
|    cost_value_loss       | 0.000241     |
|    cost_values           | -0.0164      |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0444       |
|    n_updates             | 11460        |
|    policy_gradient_loss  | -0.00341     |
|    std                   | 0.668        |
|    value_loss            | 0.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.37893218  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 461          |
|    total_timesteps       | 2351104      |
| train/                   |              |
|    approx_kl             | 0.0063751056 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0198      |
|    cost_value_loss       | 8.4e-06      |
|    cost_values           | -0.0197      |
|    entropy               | -1.84        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00248     |
|    n_updates             | 11470        |
|    policy_gradient_loss  | -0.005       |
|    std                   | 0.661        |
|    value_loss            | 0.0462       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0929      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0929      |
| reward                   | -0.5613221  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -671        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 22          |
|    time_elapsed          | 483         |
|    total_timesteps       | 2353152     |
| train/                   |             |
|    approx_kl             | 0.008390356 |
|    clip_fraction         | 0.0937      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0104     |
|    cost_value_loss       | 4.11e-06    |
|    cost_values           | -0.0106     |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0112      |
|    n_updates             | 11480       |
|    policy_gradient_loss  | -0.00527    |
|    std                   | 0.659       |
|    value_loss            | 0.0579      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -0.37849832  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 23           |
|    time_elapsed          | 505          |
|    total_timesteps       | 2355200      |
| train/                   |              |
|    approx_kl             | 0.0063230433 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0415       |
|    cost_value_loss       | 7.2e-05      |
|    cost_values           | 0.0428       |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.04         |
|    n_updates             | 11490        |
|    policy_gradient_loss  | -0.000985    |
|    std                   | 0.66         |
|    value_loss            | 3.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.4474663   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 24           |
|    time_elapsed          | 527          |
|    total_timesteps       | 2357248      |
| train/                   |              |
|    approx_kl             | 0.0025798837 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0096      |
|    cost_value_loss       | 3.43e-05     |
|    cost_values           | -0.00932     |
|    entropy               | -1.82        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0108       |
|    n_updates             | 11500        |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.656        |
|    value_loss            | 0.0267       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.208       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.208       |
| reward                   | -0.52780867 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -668        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 25          |
|    time_elapsed          | 549         |
|    total_timesteps       | 2359296     |
| train/                   |             |
|    approx_kl             | 0.007081561 |
|    clip_fraction         | 0.0501      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0271     |
|    cost_value_loss       | 8.29e-05    |
|    cost_values           | -0.0278     |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.101       |
|    n_updates             | 11510       |
|    policy_gradient_loss  | -0.00327    |
|    std                   | 0.652       |
|    value_loss            | 0.266       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.037       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.037       |
| reward                   | -0.30384797 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -671        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 571         |
|    total_timesteps       | 2361344     |
| train/                   |             |
|    approx_kl             | 0.003073053 |
|    clip_fraction         | 0.019       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0189     |
|    cost_value_loss       | 2.7e-05     |
|    cost_values           | -0.0183     |
|    entropy               | -1.8        |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0226      |
|    n_updates             | 11520       |
|    policy_gradient_loss  | -0.00067    |
|    std                   | 0.649       |
|    value_loss            | 0.167       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.39547595  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 593          |
|    total_timesteps       | 2363392      |
| train/                   |              |
|    approx_kl             | 0.0045868484 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.016       |
|    cost_value_loss       | 6.67e-06     |
|    cost_values           | -0.0159      |
|    entropy               | -1.79        |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00354      |
|    n_updates             | 11530        |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.646        |
|    value_loss            | 0.0394       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0503       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0503       |
| reward                   | -0.32179716  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 615          |
|    total_timesteps       | 2365440      |
| train/                   |              |
|    approx_kl             | 0.0015046794 |
|    clip_fraction         | 0.0482       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0168      |
|    cost_value_loss       | 2.89e-05     |
|    cost_values           | -0.0171      |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0271       |
|    n_updates             | 11540        |
|    policy_gradient_loss  | -0.000867    |
|    std                   | 0.644        |
|    value_loss            | 0.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.137        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.137        |
| reward                   | -0.37972143  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 636          |
|    total_timesteps       | 2367488      |
| train/                   |              |
|    approx_kl             | 0.0056829555 |
|    clip_fraction         | 0.0873       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00169     |
|    cost_value_loss       | 4.36e-06     |
|    cost_values           | -0.0016      |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0174       |
|    n_updates             | 11550        |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 0.644        |
|    value_loss            | 0.0654       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0498       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0498       |
| reward                   | -0.47844896  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 30           |
|    time_elapsed          | 658          |
|    total_timesteps       | 2369536      |
| train/                   |              |
|    approx_kl             | 0.0077560805 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00707     |
|    cost_value_loss       | 5.39e-06     |
|    cost_values           | -0.00714     |
|    entropy               | -1.8         |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00327      |
|    n_updates             | 11560        |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.646        |
|    value_loss            | 0.0309       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0302       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0302       |
| reward                   | -0.29486355  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 680          |
|    total_timesteps       | 2371584      |
| train/                   |              |
|    approx_kl             | 0.0037456339 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00931     |
|    cost_value_loss       | 2.2e-06      |
|    cost_values           | -0.00942     |
|    entropy               | -1.78        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00557      |
|    n_updates             | 11570        |
|    policy_gradient_loss  | -0.000702    |
|    std                   | 0.642        |
|    value_loss            | 0.0185       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.139       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.139       |
| reward                   | -0.43335542 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -672        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 32          |
|    time_elapsed          | 702         |
|    total_timesteps       | 2373632     |
| train/                   |             |
|    approx_kl             | 0.004808317 |
|    clip_fraction         | 0.0429      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00581    |
|    cost_value_loss       | 2.92e-06    |
|    cost_values           | -0.00573    |
|    entropy               | -1.77       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00214     |
|    n_updates             | 11580       |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.635       |
|    value_loss            | 0.0237      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0422      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0422      |
| reward                   | -0.42873734 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -674        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 33          |
|    time_elapsed          | 723         |
|    total_timesteps       | 2375680     |
| train/                   |             |
|    approx_kl             | 0.005460066 |
|    clip_fraction         | 0.0707      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0115     |
|    cost_value_loss       | 3.75e-05    |
|    cost_values           | -0.0126     |
|    entropy               | -1.75       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0313      |
|    n_updates             | 11590       |
|    policy_gradient_loss  | 0.00137     |
|    std                   | 0.633       |
|    value_loss            | 0.095       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0361       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0361       |
| reward                   | -0.50162816  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 745          |
|    total_timesteps       | 2377728      |
| train/                   |              |
|    approx_kl             | 0.0023930692 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0165      |
|    cost_value_loss       | 2.23e-05     |
|    cost_values           | -0.0168      |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0223       |
|    n_updates             | 11600        |
|    policy_gradient_loss  | -0.000758    |
|    std                   | 0.632        |
|    value_loss            | 0.0842       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0232       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0232       |
| reward                   | -0.4941219   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 768          |
|    total_timesteps       | 2379776      |
| train/                   |              |
|    approx_kl             | 0.0024509907 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00515     |
|    cost_value_loss       | 5.84e-06     |
|    cost_values           | -0.00524     |
|    entropy               | -1.76        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0132       |
|    n_updates             | 11610        |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.633        |
|    value_loss            | 0.0591       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00175      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00175      |
| reward                   | -0.530405    |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 36           |
|    time_elapsed          | 790          |
|    total_timesteps       | 2381824      |
| train/                   |              |
|    approx_kl             | 0.0074866437 |
|    clip_fraction         | 0.0542       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00301     |
|    cost_value_loss       | 3.81e-06     |
|    cost_values           | -0.00303     |
|    entropy               | -1.75        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00149      |
|    n_updates             | 11620        |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 0.632        |
|    value_loss            | 0.0336       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.124        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.124        |
| reward                   | -0.44627655  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 37           |
|    time_elapsed          | 812          |
|    total_timesteps       | 2383872      |
| train/                   |              |
|    approx_kl             | 0.0063127447 |
|    clip_fraction         | 0.0524       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00921      |
|    cost_value_loss       | 1.22e-05     |
|    cost_values           | 0.00923      |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00572      |
|    n_updates             | 11630        |
|    policy_gradient_loss  | -0.000923    |
|    std                   | 0.632        |
|    value_loss            | 0.0913       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0778      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0778      |
| reward                   | -0.25471008 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -677        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 38          |
|    time_elapsed          | 834         |
|    total_timesteps       | 2385920     |
| train/                   |             |
|    approx_kl             | 0.012964344 |
|    clip_fraction         | 0.0753      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.015       |
|    cost_value_loss       | 1.34e-05    |
|    cost_values           | 0.0152      |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0228      |
|    n_updates             | 11640       |
|    policy_gradient_loss  | 0.00135     |
|    std                   | 0.633       |
|    value_loss            | 0.0639      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0559      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0559      |
| reward                   | -0.49882856 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -614        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 39          |
|    time_elapsed          | 856         |
|    total_timesteps       | 2387968     |
| train/                   |             |
|    approx_kl             | 0.004795879 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0088     |
|    cost_value_loss       | 1.43e-05    |
|    cost_values           | -0.00891    |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0196      |
|    n_updates             | 11650       |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.634       |
|    value_loss            | 0.071       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0602       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0602       |
| reward                   | -0.40338182  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -611         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 880          |
|    total_timesteps       | 2390016      |
| train/                   |              |
|    approx_kl             | 0.0043470706 |
|    clip_fraction         | 0.0605       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00891     |
|    cost_value_loss       | 1.52e-05     |
|    cost_values           | -0.00899     |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00578     |
|    n_updates             | 11660        |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 0.632        |
|    value_loss            | 0.0194       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0443       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0443       |
| reward                   | -0.38090983  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -608         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 902          |
|    total_timesteps       | 2392064      |
| train/                   |              |
|    approx_kl             | 0.0016013382 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.004        |
|    cost_value_loss       | 4.97e-06     |
|    cost_values           | 0.00393      |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0198       |
|    n_updates             | 11670        |
|    policy_gradient_loss  | -0.000678    |
|    std                   | 0.633        |
|    value_loss            | 0.0626       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0947       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0947       |
| reward                   | -0.32581836  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -597         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 924          |
|    total_timesteps       | 2394112      |
| train/                   |              |
|    approx_kl             | 0.0053064288 |
|    clip_fraction         | 0.0443       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0205       |
|    cost_value_loss       | 1.2e-05      |
|    cost_values           | 0.021        |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -2.96e-05    |
|    n_updates             | 11680        |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.633        |
|    value_loss            | 0.0158       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.142        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.142        |
| reward                   | -0.5182812   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -593         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 946          |
|    total_timesteps       | 2396160      |
| train/                   |              |
|    approx_kl             | 0.0059331725 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0124       |
|    cost_value_loss       | 0.000168     |
|    cost_values           | 0.0155       |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.2         |
|    n_updates             | 11690        |
|    policy_gradient_loss  | -0.00678     |
|    std                   | 0.633        |
|    value_loss            | 164          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0358       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0358       |
| reward                   | -0.32456267  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -613         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 44           |
|    time_elapsed          | 968          |
|    total_timesteps       | 2398208      |
| train/                   |              |
|    approx_kl             | 0.0021373676 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0071       |
|    cost_value_loss       | 8.88e-06     |
|    cost_values           | 0.00736      |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.88         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.99         |
|    n_updates             | 11700        |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.633        |
|    value_loss            | 3.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.135        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.135        |
| reward                   | -0.26911476  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 45           |
|    time_elapsed          | 990          |
|    total_timesteps       | 2400256      |
| train/                   |              |
|    approx_kl             | 0.0027156717 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00884      |
|    cost_value_loss       | 7.22e-05     |
|    cost_values           | 0.00877      |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 90           |
|    n_updates             | 11710        |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.633        |
|    value_loss            | 202          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0875      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0875      |
| reward                   | -0.41115928 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -552        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 46          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 2402304     |
| train/                   |             |
|    approx_kl             | 0.008178858 |
|    clip_fraction         | 0.0414      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00941     |
|    cost_value_loss       | 3.14e-05    |
|    cost_values           | 0.00969     |
|    entropy               | -1.72       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00345     |
|    n_updates             | 11720       |
|    policy_gradient_loss  | -0.00196    |
|    std                   | 0.625       |
|    value_loss            | 0.0345      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00538     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00538     |
| reward                   | -0.47166172 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -551        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1035        |
|    total_timesteps       | 2404352     |
| train/                   |             |
|    approx_kl             | 0.007957299 |
|    clip_fraction         | 0.311       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000154    |
|    cost_value_loss       | 0.000315    |
|    cost_values           | -0.00608    |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 11730       |
|    policy_gradient_loss  | 0.00979     |
|    std                   | 0.624       |
|    value_loss            | 4.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.41004798  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -552         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1057         |
|    total_timesteps       | 2406400      |
| train/                   |              |
|    approx_kl             | 0.0025768508 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00603      |
|    cost_value_loss       | 1.49e-05     |
|    cost_values           | 0.00621      |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00915      |
|    n_updates             | 11740        |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.622        |
|    value_loss            | 0.0722       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0192       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0192       |
| reward                   | -0.3271991   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1079         |
|    total_timesteps       | 2408448      |
| train/                   |              |
|    approx_kl             | 0.0050819423 |
|    clip_fraction         | 0.0708       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0112      |
|    cost_value_loss       | 9.69e-06     |
|    cost_values           | -0.0113      |
|    entropy               | -1.69        |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0279       |
|    n_updates             | 11750        |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 0.618        |
|    value_loss            | 0.077        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.0952      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0952      |
| reward             | -0.51582396 |
| rollout/           |             |
|    ep_len_mean     | 979         |
|    ep_rew_mean     | -523        |
| time/              |             |
|    fps             | 96          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2410496     |
------------------------------------
------------------------------------------
| avg_speed                | 0.156       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.156       |
| reward                   | -0.48457494 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 95          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2412544     |
| train/                   |             |
|    approx_kl             | 0.004313393 |
|    clip_fraction         | 0.0852      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00916     |
|    cost_value_loss       | 8.92e-06    |
|    cost_values           | 0.00909     |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00396    |
|    n_updates             | 11770       |
|    policy_gradient_loss  | -0.00622    |
|    std                   | 0.618       |
|    value_loss            | 0.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0662      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0662      |
| reward                   | -0.552488   |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2414592     |
| train/                   |             |
|    approx_kl             | 0.004592682 |
|    clip_fraction         | 0.0667      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000831   |
|    cost_value_loss       | 5.15e-06    |
|    cost_values           | -0.000592   |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00274     |
|    n_updates             | 11780       |
|    policy_gradient_loss  | -0.004      |
|    std                   | 0.621       |
|    value_loss            | 0.0727      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.51808286  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 2416640      |
| train/                   |              |
|    approx_kl             | 0.0049750255 |
|    clip_fraction         | 0.119        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0429      |
|    cost_value_loss       | 2.36e-05     |
|    cost_values           | -0.043       |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00234     |
|    n_updates             | 11790        |
|    policy_gradient_loss  | -0.0061      |
|    std                   | 0.621        |
|    value_loss            | 0.0173       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0404       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0404       |
| reward                   | -0.55276644  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -527         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 2418688      |
| train/                   |              |
|    approx_kl             | 0.0076465094 |
|    clip_fraction         | 0.0461       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0066      |
|    cost_value_loss       | 1.31e-05     |
|    cost_values           | -0.00664     |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00778      |
|    n_updates             | 11800        |
|    policy_gradient_loss  | -0.000548    |
|    std                   | 0.62         |
|    value_loss            | 0.00819      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.153        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.153        |
| reward                   | -0.34440246  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -530         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 131          |
|    total_timesteps       | 2420736      |
| train/                   |              |
|    approx_kl             | 0.0052814386 |
|    clip_fraction         | 0.122        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0203      |
|    cost_value_loss       | 5.85e-06     |
|    cost_values           | -0.0204      |
|    entropy               | -1.69        |
|    entropy_loss          | -1.7         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00418     |
|    n_updates             | 11810        |
|    policy_gradient_loss  | -0.00674     |
|    std                   | 0.617        |
|    value_loss            | 0.0109       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.121       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.121       |
| reward                   | -0.3720013  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -527        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 2422784     |
| train/                   |             |
|    approx_kl             | 0.003541994 |
|    clip_fraction         | 0.0458      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00211     |
|    cost_value_loss       | 6.88e-06    |
|    cost_values           | 0.00219     |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0055      |
|    n_updates             | 11820       |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.617       |
|    value_loss            | 0.0379      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0738       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0738       |
| reward                   | -0.37608832  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 175          |
|    total_timesteps       | 2424832      |
| train/                   |              |
|    approx_kl             | 0.0050758473 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0195       |
|    cost_value_loss       | 1.2e-05      |
|    cost_values           | 0.02         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0194       |
|    n_updates             | 11830        |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.616        |
|    value_loss            | 0.139        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.0511     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0511     |
| reward                   | -0.5429901 |
| rollout/                 |            |
|    ep_len_mean           | 979        |
|    ep_rew_mean           | -524       |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 9          |
|    time_elapsed          | 197        |
|    total_timesteps       | 2426880    |
| train/                   |            |
|    approx_kl             | 0.00445135 |
|    clip_fraction         | 0.0164     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0196     |
|    cost_value_loss       | 1.34e-05   |
|    cost_values           | 0.0192     |
|    entropy               | -1.69      |
|    entropy_loss          | -1.68      |
|    explained_variance    | 0.998      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.0248     |
|    n_updates             | 11840      |
|    policy_gradient_loss  | 0.0002     |
|    std                   | 0.616      |
|    value_loss            | 0.0856     |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0212       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0212       |
| reward                   | -0.33102176  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 2428928      |
| train/                   |              |
|    approx_kl             | 0.0033453065 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0103       |
|    cost_value_loss       | 8.63e-06     |
|    cost_values           | 0.0103       |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00848      |
|    n_updates             | 11850        |
|    policy_gradient_loss  | -0.000633    |
|    std                   | 0.614        |
|    value_loss            | 0.021        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.126       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.126       |
| reward                   | -0.34809998 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -497        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 11          |
|    time_elapsed          | 241         |
|    total_timesteps       | 2430976     |
| train/                   |             |
|    approx_kl             | 0.005898656 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.015       |
|    cost_value_loss       | 1.52e-05    |
|    cost_values           | 0.0151      |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00504     |
|    n_updates             | 11860       |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.613       |
|    value_loss            | 0.0962      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0982       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0982       |
| reward                   | -0.5175411   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -497         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 263          |
|    total_timesteps       | 2433024      |
| train/                   |              |
|    approx_kl             | 0.0030823199 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000721     |
|    cost_value_loss       | 1.86e-06     |
|    cost_values           | 0.000658     |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0087       |
|    n_updates             | 11870        |
|    policy_gradient_loss  | -0.000287    |
|    std                   | 0.614        |
|    value_loss            | 0.0494       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0863       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0863       |
| reward                   | -0.45876426  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 285          |
|    total_timesteps       | 2435072      |
| train/                   |              |
|    approx_kl             | 0.0050291186 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00464      |
|    cost_value_loss       | 3.02e-06     |
|    cost_values           | 0.00468      |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00875      |
|    n_updates             | 11880        |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.614        |
|    value_loss            | 0.0465       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0342       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0342       |
| reward                   | -0.37480426  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 307          |
|    total_timesteps       | 2437120      |
| train/                   |              |
|    approx_kl             | 0.0050060735 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0085       |
|    cost_value_loss       | 1.39e-05     |
|    cost_values           | 0.00846      |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0144       |
|    n_updates             | 11890        |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.616        |
|    value_loss            | 0.103        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.119       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.119       |
| reward                   | -0.16855751 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 329         |
|    total_timesteps       | 2439168     |
| train/                   |             |
|    approx_kl             | 0.005559192 |
|    clip_fraction         | 0.0433      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00988     |
|    cost_value_loss       | 4.52e-06    |
|    cost_values           | 0.01        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00734     |
|    n_updates             | 11900       |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.613       |
|    value_loss            | 0.0245      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.5449307   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 351          |
|    total_timesteps       | 2441216      |
| train/                   |              |
|    approx_kl             | 0.0013480065 |
|    clip_fraction         | 0.00415      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000781    |
|    cost_value_loss       | 4.74e-06     |
|    cost_values           | -0.00074     |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.031        |
|    n_updates             | 11910        |
|    policy_gradient_loss  | 7.82e-05     |
|    std                   | 0.612        |
|    value_loss            | 0.153        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0731       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0731       |
| reward                   | -0.43081263  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 374          |
|    total_timesteps       | 2443264      |
| train/                   |              |
|    approx_kl             | 0.0045969244 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00275      |
|    cost_value_loss       | 8.79e-06     |
|    cost_values           | 0.00285      |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.947        |
|    n_updates             | 11920        |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.612        |
|    value_loss            | 2.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.173        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.173        |
| reward                   | -0.3198597   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 396          |
|    total_timesteps       | 2445312      |
| train/                   |              |
|    approx_kl             | 0.0044576656 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000105    |
|    cost_value_loss       | 6.46e-06     |
|    cost_values           | -6.22e-05    |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000786     |
|    n_updates             | 11930        |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 0.61         |
|    value_loss            | 0.0126       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.114       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.114       |
| reward                   | -0.4944719  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 419         |
|    total_timesteps       | 2447360     |
| train/                   |             |
|    approx_kl             | 0.005663989 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00853    |
|    cost_value_loss       | 1.95e-05    |
|    cost_values           | -0.00823    |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0262      |
|    n_updates             | 11940       |
|    policy_gradient_loss  | -2.94e-05   |
|    std                   | 0.61        |
|    value_loss            | 0.129       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0651      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0651      |
| reward                   | -0.31478715 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 440         |
|    total_timesteps       | 2449408     |
| train/                   |             |
|    approx_kl             | 0.003193004 |
|    clip_fraction         | 0.0389      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00851    |
|    cost_value_loss       | 8.56e-06    |
|    cost_values           | -0.00888    |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0105      |
|    n_updates             | 11950       |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.61        |
|    value_loss            | 0.0697      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00897      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00897      |
| reward                   | -0.3780674   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 463          |
|    total_timesteps       | 2451456      |
| train/                   |              |
|    approx_kl             | 0.0028426168 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000776     |
|    cost_value_loss       | 8.77e-07     |
|    cost_values           | 0.00068      |
|    entropy               | -1.68        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00326     |
|    n_updates             | 11960        |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.613        |
|    value_loss            | 0.0304       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0145      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0145      |
| reward                   | -0.47333214 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 485         |
|    total_timesteps       | 2453504     |
| train/                   |             |
|    approx_kl             | 0.001618947 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00234    |
|    cost_value_loss       | 7.96e-06    |
|    cost_values           | -0.00251    |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0367      |
|    n_updates             | 11970       |
|    policy_gradient_loss  | -0.00044    |
|    std                   | 0.614       |
|    value_loss            | 0.187       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0854       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0854       |
| reward                   | -0.30564758  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 508          |
|    total_timesteps       | 2455552      |
| train/                   |              |
|    approx_kl             | 0.0041377787 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00589      |
|    cost_value_loss       | 9.39e-07     |
|    cost_values           | 0.00604      |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0158       |
|    n_updates             | 11980        |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.613        |
|    value_loss            | 0.0623       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0934       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0934       |
| reward                   | -0.47201085  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 530          |
|    total_timesteps       | 2457600      |
| train/                   |              |
|    approx_kl             | 0.0061255842 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00185      |
|    cost_value_loss       | 8.18e-06     |
|    cost_values           | 0.00166      |
|    entropy               | -1.67        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000785     |
|    n_updates             | 11990        |
|    policy_gradient_loss  | -0.000414    |
|    std                   | 0.611        |
|    value_loss            | 0.0233       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0345      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0345      |
| reward                   | -0.47228312 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 553         |
|    total_timesteps       | 2459648     |
| train/                   |             |
|    approx_kl             | 0.004952038 |
|    clip_fraction         | 0.0404      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0116     |
|    cost_value_loss       | 3.27e-05    |
|    cost_values           | -0.0123     |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.852       |
|    n_updates             | 12000       |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.611       |
|    value_loss            | 2.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.4301791   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 575          |
|    total_timesteps       | 2461696      |
| train/                   |              |
|    approx_kl             | 0.0043756803 |
|    clip_fraction         | 0.00845      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.018        |
|    cost_value_loss       | 0.000239     |
|    cost_values           | 0.0176       |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00453      |
|    n_updates             | 12010        |
|    policy_gradient_loss  | -0.000465    |
|    std                   | 0.611        |
|    value_loss            | 0.026        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00929      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00929      |
| reward                   | -0.47244087  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 597          |
|    total_timesteps       | 2463744      |
| train/                   |              |
|    approx_kl             | 0.0057970225 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0107       |
|    cost_value_loss       | 0.000136     |
|    cost_values           | 0.0126       |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0229       |
|    n_updates             | 12020        |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.611        |
|    value_loss            | 0.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0223      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0223      |
| reward                   | -0.47254586 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 620         |
|    total_timesteps       | 2465792     |
| train/                   |             |
|    approx_kl             | 0.009531238 |
|    clip_fraction         | 0.091       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0318      |
|    cost_value_loss       | 2.53e-05    |
|    cost_values           | 0.0319      |
|    entropy               | -1.66       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0123     |
|    n_updates             | 12030       |
|    policy_gradient_loss  | -0.00522    |
|    std                   | 0.607       |
|    value_loss            | 0.00748     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0268      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0268      |
| reward                   | -0.45770028 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 642         |
|    total_timesteps       | 2467840     |
| train/                   |             |
|    approx_kl             | 0.00786031  |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0231      |
|    cost_value_loss       | 5.39e-05    |
|    cost_values           | 0.0233      |
|    entropy               | -1.67       |
|    entropy_loss          | -1.66       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.011       |
|    n_updates             | 12040       |
|    policy_gradient_loss  | 0.000598    |
|    std                   | 0.61        |
|    value_loss            | 0.00436     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0437       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0437       |
| reward                   | -0.47258964  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 664          |
|    total_timesteps       | 2469888      |
| train/                   |              |
|    approx_kl             | 0.0031599733 |
|    clip_fraction         | 0.0446       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0233       |
|    cost_value_loss       | 1.5e-05      |
|    cost_values           | 0.0234       |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00528      |
|    n_updates             | 12050        |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.61         |
|    value_loss            | 0.0302       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0133      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0133      |
| reward                   | -0.5520307  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 686         |
|    total_timesteps       | 2471936     |
| train/                   |             |
|    approx_kl             | 0.010383004 |
|    clip_fraction         | 0.0944      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00672     |
|    cost_value_loss       | 6.83e-06    |
|    cost_values           | 0.00676     |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00949     |
|    n_updates             | 12060       |
|    policy_gradient_loss  | -0.0074     |
|    std                   | 0.611       |
|    value_loss            | 0.0432      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0173       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0173       |
| reward                   | -0.40084714  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 2473984      |
| train/                   |              |
|    approx_kl             | 0.0015741582 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000424    |
|    cost_value_loss       | 1.12e-05     |
|    cost_values           | -0.000447    |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00892      |
|    n_updates             | 12070        |
|    policy_gradient_loss  | -0.000323    |
|    std                   | 0.612        |
|    value_loss            | 0.0722       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.186        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.186        |
| reward                   | -0.39519495  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 731          |
|    total_timesteps       | 2476032      |
| train/                   |              |
|    approx_kl             | 0.0058523724 |
|    clip_fraction         | 0.0815       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85e-05     |
|    cost_value_loss       | 4.32e-06     |
|    cost_values           | 1.09e-05     |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0118       |
|    n_updates             | 12080        |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 0.613        |
|    value_loss            | 0.0406       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0911      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0911      |
| reward                   | -0.51330924 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 753         |
|    total_timesteps       | 2478080     |
| train/                   |             |
|    approx_kl             | 0.011356459 |
|    clip_fraction         | 0.0628      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0134      |
|    cost_value_loss       | 4.55e-06    |
|    cost_values           | 0.0135      |
|    entropy               | -1.66       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00999     |
|    n_updates             | 12090       |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.61        |
|    value_loss            | 0.0196      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.234       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.234       |
| reward                   | -0.4453621  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 775         |
|    total_timesteps       | 2480128     |
| train/                   |             |
|    approx_kl             | 0.004874795 |
|    clip_fraction         | 0.0922      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000296   |
|    cost_value_loss       | 2.86e-06    |
|    cost_values           | -0.000141   |
|    entropy               | -1.66       |
|    entropy_loss          | -1.66       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0099      |
|    n_updates             | 12100       |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.608       |
|    value_loss            | 0.0526      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.113        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.113        |
| reward                   | -0.37830186  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 797          |
|    total_timesteps       | 2482176      |
| train/                   |              |
|    approx_kl             | 0.0016740165 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00595      |
|    cost_value_loss       | 1.84e-06     |
|    cost_values           | 0.006        |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0105       |
|    n_updates             | 12110        |
|    policy_gradient_loss  | -0.000877    |
|    std                   | 0.607        |
|    value_loss            | 0.00893      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0849       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0849       |
| reward                   | -0.5511118   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 820          |
|    total_timesteps       | 2484224      |
| train/                   |              |
|    approx_kl             | 0.0059854602 |
|    clip_fraction         | 0.062        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00664      |
|    cost_value_loss       | 2.94e-06     |
|    cost_values           | 0.0065       |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.29         |
|    n_updates             | 12120        |
|    policy_gradient_loss  | 0.000842     |
|    std                   | 0.607        |
|    value_loss            | 1.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0212      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0212      |
| reward                   | -0.25079465 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 842         |
|    total_timesteps       | 2486272     |
| train/                   |             |
|    approx_kl             | 0.007790999 |
|    clip_fraction         | 0.0386      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0122      |
|    cost_value_loss       | 1.11e-05    |
|    cost_values           | 0.012       |
|    entropy               | -1.64       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00957     |
|    n_updates             | 12130       |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.604       |
|    value_loss            | 0.00509     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0341       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0341       |
| reward                   | -0.25994653  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 864          |
|    total_timesteps       | 2488320      |
| train/                   |              |
|    approx_kl             | 0.0030013376 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0021      |
|    cost_value_loss       | 3.18e-06     |
|    cost_values           | -0.00227     |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0299       |
|    n_updates             | 12140        |
|    policy_gradient_loss  | -0.000724    |
|    std                   | 0.603        |
|    value_loss            | 0.179        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0381       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0381       |
| reward                   | -0.38391128  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 886          |
|    total_timesteps       | 2490368      |
| train/                   |              |
|    approx_kl             | 0.0023326974 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00578      |
|    cost_value_loss       | 1.44e-06     |
|    cost_values           | 0.00581      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00082     |
|    n_updates             | 12150        |
|    policy_gradient_loss  | -0.000705    |
|    std                   | 0.601        |
|    value_loss            | 0.0321       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.11        |
| reward                   | -0.47342384 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 909         |
|    total_timesteps       | 2492416     |
| train/                   |             |
|    approx_kl             | 0.002326401 |
|    clip_fraction         | 0.0277      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00454    |
|    cost_value_loss       | 7.94e-06    |
|    cost_values           | -0.00524    |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0223      |
|    n_updates             | 12160       |
|    policy_gradient_loss  | -0.000233   |
|    std                   | 0.6         |
|    value_loss            | 0.195       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0169       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0169       |
| reward                   | -0.2523772   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 931          |
|    total_timesteps       | 2494464      |
| train/                   |              |
|    approx_kl             | 0.0099366605 |
|    clip_fraction         | 0.0938       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00319      |
|    cost_value_loss       | 5.4e-06      |
|    cost_values           | 0.00324      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.01        |
|    n_updates             | 12170        |
|    policy_gradient_loss  | -0.0058      |
|    std                   | 0.599        |
|    value_loss            | 0.00437      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0764       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0764       |
| reward                   | -0.47230574  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 953          |
|    total_timesteps       | 2496512      |
| train/                   |              |
|    approx_kl             | 0.0062228395 |
|    clip_fraction         | 0.0781       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00785      |
|    cost_value_loss       | 3.18e-05     |
|    cost_values           | 0.00822      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00424      |
|    n_updates             | 12180        |
|    policy_gradient_loss  | -0.00542     |
|    std                   | 0.599        |
|    value_loss            | 0.0231       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0506       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0506       |
| reward                   | -0.43037218  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 976          |
|    total_timesteps       | 2498560      |
| train/                   |              |
|    approx_kl             | 0.0031466521 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00548      |
|    cost_value_loss       | 2.46e-06     |
|    cost_values           | 0.00553      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.262        |
|    n_updates             | 12190        |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.599        |
|    value_loss            | 1.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0409       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0409       |
| reward                   | -0.3973011   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 998          |
|    total_timesteps       | 2500608      |
| train/                   |              |
|    approx_kl             | 0.0018835722 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000904     |
|    cost_value_loss       | 7.59e-06     |
|    cost_values           | 0.00101      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0254       |
|    n_updates             | 12200        |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.6          |
|    value_loss            | 0.365        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0891       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0891       |
| reward                   | -0.38068867  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 2502656      |
| train/                   |              |
|    approx_kl             | 0.0033844002 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00908      |
|    cost_value_loss       | 2.9e-06      |
|    cost_values           | 0.00921      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0102       |
|    n_updates             | 12210        |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.6          |
|    value_loss            | 0.0203       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.158       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.158       |
| reward                   | -0.36702406 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1042        |
|    total_timesteps       | 2504704     |
| train/                   |             |
|    approx_kl             | 0.004781886 |
|    clip_fraction         | 0.0199      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00573     |
|    cost_value_loss       | 5.2e-06     |
|    cost_values           | 0.00572     |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0259      |
|    n_updates             | 12220       |
|    policy_gradient_loss  | -0.00287    |
|    std                   | 0.601       |
|    value_loss            | 0.131       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0225       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0225       |
| reward                   | -0.32751882  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1064         |
|    total_timesteps       | 2506752      |
| train/                   |              |
|    approx_kl             | 0.0018539723 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00743     |
|    cost_value_loss       | 1.61e-05     |
|    cost_values           | -0.00779     |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0293       |
|    n_updates             | 12230        |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.601        |
|    value_loss            | 0.186        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0481      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0481      |
| reward                   | -0.48059434 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 2508800     |
| train/                   |             |
|    approx_kl             | 0.0079588   |
|    clip_fraction         | 0.0305      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000877    |
|    cost_value_loss       | 3.87e-06    |
|    cost_values           | 0.000791    |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0037      |
|    n_updates             | 12240       |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.601       |
|    value_loss            | 0.0892      |
------------------------------------------
------------------------------------
| avg_speed          | 0.076       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.076       |
| reward             | -0.29363412 |
| rollout/           |             |
|    ep_len_mean     | 977         |
|    ep_rew_mean     | -415        |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2510848     |
------------------------------------
------------------------------------------
| avg_speed                | 0.0333      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0333      |
| reward                   | -0.25760037 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2512896     |
| train/                   |             |
|    approx_kl             | 0.002420789 |
|    clip_fraction         | 0.0145      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00296     |
|    cost_value_loss       | 2.39e-06    |
|    cost_values           | 0.00303     |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00902     |
|    n_updates             | 12260       |
|    policy_gradient_loss  | -0.00041    |
|    std                   | 0.598       |
|    value_loss            | 0.0234      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0251      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0251      |
| reward                   | -0.43131113 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2514944     |
| train/                   |             |
|    approx_kl             | 0.006111517 |
|    clip_fraction         | 0.0365      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00587     |
|    cost_value_loss       | 6.11e-06    |
|    cost_values           | 0.00581     |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.027       |
|    n_updates             | 12270       |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.597       |
|    value_loss            | 0.159       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0867      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0867      |
| reward                   | -0.95341533 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 2516992     |
| train/                   |             |
|    approx_kl             | 0.007776019 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.011      |
|    cost_value_loss       | 3.01e-05    |
|    cost_values           | -0.0118     |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.14        |
|    n_updates             | 12280       |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.598       |
|    value_loss            | 2.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0849       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0849       |
| reward                   | -0.39512658  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 2519040      |
| train/                   |              |
|    approx_kl             | 0.0040864893 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00639     |
|    cost_value_loss       | 4.24e-05     |
|    cost_values           | -0.0065      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.164        |
|    n_updates             | 12290        |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 0.599        |
|    value_loss            | 0.691        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0129      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0129      |
| reward                   | -0.21350792 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 2521088     |
| train/                   |             |
|    approx_kl             | 0.005612773 |
|    clip_fraction         | 0.0412      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.033      |
|    cost_value_loss       | 0.000121    |
|    cost_values           | -0.0337     |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0319      |
|    n_updates             | 12300       |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.599       |
|    value_loss            | 0.249       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0089      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0089      |
| reward                   | -0.39504588 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 2523136     |
| train/                   |             |
|    approx_kl             | 0.004030262 |
|    clip_fraction         | 0.0217      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00784     |
|    cost_value_loss       | 6.16e-06    |
|    cost_values           | 0.00809     |
|    entropy               | -1.62       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00775     |
|    n_updates             | 12310       |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 0.599       |
|    value_loss            | 0.0634      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0316       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0316       |
| reward                   | -0.40273795  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 2525184      |
| train/                   |              |
|    approx_kl             | 0.0046419855 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00998      |
|    cost_value_loss       | 4.49e-06     |
|    cost_values           | 0.0101       |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00879      |
|    n_updates             | 12320        |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.598        |
|    value_loss            | 0.0723       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.128        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.128        |
| reward                   | -0.32346797  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 199          |
|    total_timesteps       | 2527232      |
| train/                   |              |
|    approx_kl             | 0.0056607695 |
|    clip_fraction         | 0.051        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00837      |
|    cost_value_loss       | 2.38e-06     |
|    cost_values           | 0.00849      |
|    entropy               | -1.61        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00114     |
|    n_updates             | 12330        |
|    policy_gradient_loss  | -0.00622     |
|    std                   | 0.595        |
|    value_loss            | 0.0569       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0633      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0633      |
| reward                   | -0.30116022 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 2529280     |
| train/                   |             |
|    approx_kl             | 0.002611419 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000388    |
|    cost_value_loss       | 1.7e-06     |
|    cost_values           | 0.000701    |
|    entropy               | -1.61       |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00321     |
|    n_updates             | 12340       |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.593       |
|    value_loss            | 0.0773      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.175       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.175       |
| reward                   | -0.25389552 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 2531328     |
| train/                   |             |
|    approx_kl             | 0.005836661 |
|    clip_fraction         | 0.0247      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000215    |
|    cost_value_loss       | 8.45e-07    |
|    cost_values           | 0.000242    |
|    entropy               | -1.6        |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0244      |
|    n_updates             | 12350       |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 0.591       |
|    value_loss            | 0.0976      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00863      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00863      |
| reward                   | -0.55152553  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 265          |
|    total_timesteps       | 2533376      |
| train/                   |              |
|    approx_kl             | 0.0044527734 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00102      |
|    cost_value_loss       | 4.04e-06     |
|    cost_values           | 0.00094      |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0.0618       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000167     |
|    n_updates             | 12360        |
|    policy_gradient_loss  | -0.00575     |
|    std                   | 0.59         |
|    value_loss            | 0.0513       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0015       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0015       |
| reward                   | -0.34153315  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 287          |
|    total_timesteps       | 2535424      |
| train/                   |              |
|    approx_kl             | 0.0070999134 |
|    clip_fraction         | 0.0546       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000122    |
|    cost_value_loss       | 2.5e-06      |
|    cost_values           | -0.000171    |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0127       |
|    n_updates             | 12370        |
|    policy_gradient_loss  | 0.00119      |
|    std                   | 0.586        |
|    value_loss            | 0.00626      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0907       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0907       |
| reward                   | -0.33231592  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 310          |
|    total_timesteps       | 2537472      |
| train/                   |              |
|    approx_kl             | 0.0018598085 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00152      |
|    cost_value_loss       | 1.93e-06     |
|    cost_values           | 0.00151      |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0011       |
|    n_updates             | 12380        |
|    policy_gradient_loss  | -0.000815    |
|    std                   | 0.584        |
|    value_loss            | 0.0202       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00819      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00819      |
| reward                   | -0.5157299   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 332          |
|    total_timesteps       | 2539520      |
| train/                   |              |
|    approx_kl             | 0.0065809092 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00464      |
|    cost_value_loss       | 2.87e-06     |
|    cost_values           | 0.00472      |
|    entropy               | -1.58        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00708      |
|    n_updates             | 12390        |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.582        |
|    value_loss            | 0.0344       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0644      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0644      |
| reward                   | -0.22655673 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2541568     |
| train/                   |             |
|    approx_kl             | 0.002366021 |
|    clip_fraction         | 0.0507      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00824     |
|    cost_value_loss       | 3.33e-06    |
|    cost_values           | 0.00854     |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00178     |
|    n_updates             | 12400       |
|    policy_gradient_loss  | -0.000149   |
|    std                   | 0.581       |
|    value_loss            | 0.0285      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.164       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.164       |
| reward                   | -0.22940631 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 2543616     |
| train/                   |             |
|    approx_kl             | 0.003982792 |
|    clip_fraction         | 0.0163      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0105      |
|    cost_value_loss       | 4.13e-06    |
|    cost_values           | 0.0107      |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0205      |
|    n_updates             | 12410       |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.581       |
|    value_loss            | 0.0872      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.147       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.147       |
| reward                   | -0.4005928  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 399         |
|    total_timesteps       | 2545664     |
| train/                   |             |
|    approx_kl             | 0.003232975 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00583     |
|    cost_value_loss       | 1.42e-06    |
|    cost_values           | 0.00611     |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0143      |
|    n_updates             | 12420       |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 0.581       |
|    value_loss            | 0.0517      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.138       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.138       |
| reward                   | -0.5499952  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 422         |
|    total_timesteps       | 2547712     |
| train/                   |             |
|    approx_kl             | 0.005414812 |
|    clip_fraction         | 0.0409      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00446     |
|    cost_value_loss       | 6.53e-07    |
|    cost_values           | 0.00451     |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.000268   |
|    n_updates             | 12430       |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.582       |
|    value_loss            | 0.0107      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0404       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0404       |
| reward                   | -0.51229584  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 444          |
|    total_timesteps       | 2549760      |
| train/                   |              |
|    approx_kl             | 0.0021102426 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000578     |
|    cost_value_loss       | 8.07e-07     |
|    cost_values           | 0.000751     |
|    entropy               | -1.56        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00276     |
|    n_updates             | 12440        |
|    policy_gradient_loss  | -0.00034     |
|    std                   | 0.577        |
|    value_loss            | 0.0187       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.123       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.123       |
| reward                   | -0.25062406 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 466         |
|    total_timesteps       | 2551808     |
| train/                   |             |
|    approx_kl             | 0.002484353 |
|    clip_fraction         | 0.0228      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00615     |
|    cost_value_loss       | 3.65e-06    |
|    cost_values           | 0.00609     |
|    entropy               | -1.54       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.000556   |
|    n_updates             | 12450       |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.572       |
|    value_loss            | 0.0178      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0163      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0163      |
| reward                   | -0.29975384 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 488         |
|    total_timesteps       | 2553856     |
| train/                   |             |
|    approx_kl             | 0.009104514 |
|    clip_fraction         | 0.089       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00346    |
|    cost_value_loss       | 1.37e-06    |
|    cost_values           | -0.00351    |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00824     |
|    n_updates             | 12460       |
|    policy_gradient_loss  | -0.000688   |
|    std                   | 0.572       |
|    value_loss            | 0.00563     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0308      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0308      |
| reward                   | -0.38506314 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 511         |
|    total_timesteps       | 2555904     |
| train/                   |             |
|    approx_kl             | 0.005129182 |
|    clip_fraction         | 0.0775      |
|    clip_range            | 0.2         |
|    cost_returns          | -4.24e-05   |
|    cost_value_loss       | 1.59e-06    |
|    cost_values           | -4.49e-05   |
|    entropy               | -1.55       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00146     |
|    n_updates             | 12470       |
|    policy_gradient_loss  | -0.00304    |
|    std                   | 0.572       |
|    value_loss            | 0.0127      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.26189178  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 533          |
|    total_timesteps       | 2557952      |
| train/                   |              |
|    approx_kl             | 0.0048054066 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00565     |
|    cost_value_loss       | 1.38e-06     |
|    cost_values           | -0.00567     |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0138       |
|    n_updates             | 12480        |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.572        |
|    value_loss            | 0.0519       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.51373994  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 555          |
|    total_timesteps       | 2560000      |
| train/                   |              |
|    approx_kl             | 0.0014752529 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00304     |
|    cost_value_loss       | 1.85e-06     |
|    cost_values           | -0.00302     |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000864     |
|    n_updates             | 12490        |
|    policy_gradient_loss  | -0.000355    |
|    std                   | 0.574        |
|    value_loss            | 0.00696      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0444       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0444       |
| reward                   | -0.25142354  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 578          |
|    total_timesteps       | 2562048      |
| train/                   |              |
|    approx_kl             | 0.0033250172 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00126     |
|    cost_value_loss       | 1.75e-05     |
|    cost_values           | -0.00103     |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00243     |
|    n_updates             | 12500        |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.573        |
|    value_loss            | 0.0176       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0837       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0837       |
| reward                   | -0.47456267  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 600          |
|    total_timesteps       | 2564096      |
| train/                   |              |
|    approx_kl             | 0.0036374184 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00128     |
|    cost_value_loss       | 4.93e-05     |
|    cost_values           | -0.00195     |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000941     |
|    n_updates             | 12510        |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.572        |
|    value_loss            | 0.0122       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00841     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00841     |
| reward                   | -0.4325901  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 622         |
|    total_timesteps       | 2566144     |
| train/                   |             |
|    approx_kl             | 0.001336962 |
|    clip_fraction         | 0.0105      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000837   |
|    cost_value_loss       | 2.24e-06    |
|    cost_values           | -0.000474   |
|    entropy               | -1.55       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0113      |
|    n_updates             | 12520       |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.572       |
|    value_loss            | 0.0524      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0434       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0434       |
| reward                   | -0.4298786   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 29           |
|    time_elapsed          | 645          |
|    total_timesteps       | 2568192      |
| train/                   |              |
|    approx_kl             | 0.0085985875 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00532      |
|    cost_value_loss       | 2.3e-05      |
|    cost_values           | 0.00505      |
|    entropy               | -1.53        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00827     |
|    n_updates             | 12530        |
|    policy_gradient_loss  | -0.00688     |
|    std                   | 0.567        |
|    value_loss            | 0.00647      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.111       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.111       |
| reward                   | -0.26053485 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 668         |
|    total_timesteps       | 2570240     |
| train/                   |             |
|    approx_kl             | 0.001735968 |
|    clip_fraction         | 0.0206      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0045      |
|    cost_value_loss       | 0.000206    |
|    cost_values           | 0.00781     |
|    entropy               | -1.52       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.937       |
|    n_updates             | 12540       |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.565       |
|    value_loss            | 1.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0622      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0622      |
| reward                   | -0.43159616 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 691         |
|    total_timesteps       | 2572288     |
| train/                   |             |
|    approx_kl             | 0.003559606 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00837     |
|    cost_value_loss       | 7.69e-06    |
|    cost_values           | 0.00892     |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000571    |
|    n_updates             | 12550       |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 0.564       |
|    value_loss            | 0.0139      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0889       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0889       |
| reward                   | -0.28103784  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 32           |
|    time_elapsed          | 713          |
|    total_timesteps       | 2574336      |
| train/                   |              |
|    approx_kl             | 0.0040316815 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00521      |
|    cost_value_loss       | 0.000231     |
|    cost_values           | 0.00293      |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00841     |
|    n_updates             | 12560        |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.564        |
|    value_loss            | 0.00781      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0498       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0498       |
| reward                   | -0.26361474  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 33           |
|    time_elapsed          | 735          |
|    total_timesteps       | 2576384      |
| train/                   |              |
|    approx_kl             | 0.0015021248 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00705     |
|    cost_value_loss       | 0.000175     |
|    cost_values           | -0.00352     |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0095       |
|    n_updates             | 12570        |
|    policy_gradient_loss  | 0.000565     |
|    std                   | 0.564        |
|    value_loss            | 0.0533       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0734      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0734      |
| reward                   | -0.3995307  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 757         |
|    total_timesteps       | 2578432     |
| train/                   |             |
|    approx_kl             | 0.006511854 |
|    clip_fraction         | 0.0542      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00907     |
|    cost_value_loss       | 4.23e-06    |
|    cost_values           | 0.00883     |
|    entropy               | -1.51       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00883     |
|    n_updates             | 12580       |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.563       |
|    value_loss            | 0.0189      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.114        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.114        |
| reward                   | -0.5507318   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 35           |
|    time_elapsed          | 779          |
|    total_timesteps       | 2580480      |
| train/                   |              |
|    approx_kl             | 0.0016927493 |
|    clip_fraction         | 0.0957       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000887     |
|    cost_value_loss       | 5.07e-06     |
|    cost_values           | 0.00121      |
|    entropy               | -1.52        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00355      |
|    n_updates             | 12590        |
|    policy_gradient_loss  | -0.00489     |
|    std                   | 0.563        |
|    value_loss            | 0.0328       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0625       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0625       |
| reward                   | -0.23408939  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 36           |
|    time_elapsed          | 802          |
|    total_timesteps       | 2582528      |
| train/                   |              |
|    approx_kl             | 0.0027825143 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00958      |
|    cost_value_loss       | 6.6e-06      |
|    cost_values           | 0.0102       |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.003        |
|    n_updates             | 12600        |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.563        |
|    value_loss            | 0.0449       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0242       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0242       |
| reward                   | -0.25220427  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 37           |
|    time_elapsed          | 824          |
|    total_timesteps       | 2584576      |
| train/                   |              |
|    approx_kl             | 0.0036661294 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0157       |
|    cost_value_loss       | 2.08e-05     |
|    cost_values           | 0.016        |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00549     |
|    n_updates             | 12610        |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.56         |
|    value_loss            | 0.0171       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0331      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0331      |
| reward                   | -0.3524902  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 846         |
|    total_timesteps       | 2586624     |
| train/                   |             |
|    approx_kl             | 0.005656507 |
|    clip_fraction         | 0.0442      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0083      |
|    cost_value_loss       | 3.88e-06    |
|    cost_values           | 0.00792     |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.808       |
|    n_updates             | 12620       |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.559       |
|    value_loss            | 1.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0776      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0776      |
| reward                   | -0.42991263 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 39          |
|    time_elapsed          | 868         |
|    total_timesteps       | 2588672     |
| train/                   |             |
|    approx_kl             | 0.009616518 |
|    clip_fraction         | 0.0805      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00183    |
|    cost_value_loss       | 2.21e-06    |
|    cost_values           | -0.00196    |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00506     |
|    n_updates             | 12630       |
|    policy_gradient_loss  | -0.00361    |
|    std                   | 0.559       |
|    value_loss            | 0.0448      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0304      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0304      |
| reward                   | -0.32369792 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 891         |
|    total_timesteps       | 2590720     |
| train/                   |             |
|    approx_kl             | 0.005327933 |
|    clip_fraction         | 0.0517      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00766     |
|    cost_value_loss       | 2.37e-06    |
|    cost_values           | 0.00804     |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000142    |
|    n_updates             | 12640       |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.559       |
|    value_loss            | 0.0168      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.55298084 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 913         |
|    total_timesteps       | 2592768     |
| train/                   |             |
|    approx_kl             | 0.005188443 |
|    clip_fraction         | 0.0561      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0103      |
|    cost_value_loss       | 3.29e-06    |
|    cost_values           | 0.0105      |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00211     |
|    n_updates             | 12650       |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.558       |
|    value_loss            | 0.0227      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00432     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00432     |
| reward                   | -0.53551185 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 935         |
|    total_timesteps       | 2594816     |
| train/                   |             |
|    approx_kl             | 0.004737688 |
|    clip_fraction         | 0.0287      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00298     |
|    cost_value_loss       | 2.63e-06    |
|    cost_values           | 0.00297     |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00282     |
|    n_updates             | 12660       |
|    policy_gradient_loss  | -0.000983   |
|    std                   | 0.555       |
|    value_loss            | 0.0129      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0139      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0139      |
| reward                   | -0.34797764 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 957         |
|    total_timesteps       | 2596864     |
| train/                   |             |
|    approx_kl             | 0.005996133 |
|    clip_fraction         | 0.0422      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000848   |
|    cost_value_loss       | 1.67e-06    |
|    cost_values           | -0.000878   |
|    entropy               | -1.48       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00116     |
|    n_updates             | 12670       |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.553       |
|    value_loss            | 0.0151      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0475       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0475       |
| reward                   | -0.40074843  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 44           |
|    time_elapsed          | 980          |
|    total_timesteps       | 2598912      |
| train/                   |              |
|    approx_kl             | 0.0050705746 |
|    clip_fraction         | 0.0973       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000742    |
|    cost_value_loss       | 1.93e-06     |
|    cost_values           | -0.000731    |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0046       |
|    n_updates             | 12680        |
|    policy_gradient_loss  | -0.00589     |
|    std                   | 0.553        |
|    value_loss            | 0.0383       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.33405158  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 45           |
|    time_elapsed          | 1003         |
|    total_timesteps       | 2600960      |
| train/                   |              |
|    approx_kl             | 0.0021965555 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00303      |
|    cost_value_loss       | 2.38e-06     |
|    cost_values           | 0.00332      |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00269     |
|    n_updates             | 12690        |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.551        |
|    value_loss            | 0.024        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0309       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0309       |
| reward                   | -0.43032295  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 46           |
|    time_elapsed          | 1025         |
|    total_timesteps       | 2603008      |
| train/                   |              |
|    approx_kl             | 0.0041576484 |
|    clip_fraction         | 0.0539       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00105     |
|    cost_value_loss       | 1.01e-06     |
|    cost_values           | -0.00101     |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00318     |
|    n_updates             | 12700        |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.55         |
|    value_loss            | 0.0111       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0724       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0724       |
| reward                   | -0.34830755  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 47           |
|    time_elapsed          | 1047         |
|    total_timesteps       | 2605056      |
| train/                   |              |
|    approx_kl             | 0.0030228395 |
|    clip_fraction         | 0.0599       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0102       |
|    cost_value_loss       | 1.9e-06      |
|    cost_values           | 0.0104       |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00186      |
|    n_updates             | 12710        |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 0.549        |
|    value_loss            | 0.0435       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0463      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0463      |
| reward                   | -0.4706703  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1069        |
|    total_timesteps       | 2607104     |
| train/                   |             |
|    approx_kl             | 0.007239341 |
|    clip_fraction         | 0.0652      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00148    |
|    cost_value_loss       | 6.98e-07    |
|    cost_values           | -0.00149    |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00305     |
|    n_updates             | 12720       |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.548       |
|    value_loss            | 0.00911     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0775       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0775       |
| reward                   | -0.5503246   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 49           |
|    time_elapsed          | 1092         |
|    total_timesteps       | 2609152      |
| train/                   |              |
|    approx_kl             | 0.0022820758 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000445    |
|    cost_value_loss       | 4.43e-07     |
|    cost_values           | -0.000348    |
|    entropy               | -1.45        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00012     |
|    n_updates             | 12730        |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 0.547        |
|    value_loss            | 0.02         |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/3rk8b0u2/model_epoch(25)
-----------------------------------
| avg_speed          | 0.109      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.109      |
| reward             | -0.4280243 |
| rollout/           |            |
|    ep_len_mean     | 986        |
|    ep_rew_mean     | -396       |
| time/              |            |
|    fps             | 94         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 2611200    |
-----------------------------------
------------------------------------------
| avg_speed                | 0.0482      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0482      |
| reward                   | -0.467038   |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2613248     |
| train/                   |             |
|    approx_kl             | 0.003310483 |
|    clip_fraction         | 0.0266      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00234     |
|    cost_value_loss       | 1.74e-06    |
|    cost_values           | 0.00234     |
|    entropy               | -1.46       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000705    |
|    n_updates             | 12750       |
|    policy_gradient_loss  | -3.44e-05   |
|    std                   | 0.549       |
|    value_loss            | 0.0108      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0777      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0777      |
| reward                   | -0.51393425 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 2615296     |
| train/                   |             |
|    approx_kl             | 0.007965462 |
|    clip_fraction         | 0.0852      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00499    |
|    cost_value_loss       | 1.65e-06    |
|    cost_values           | -0.00505    |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00204    |
|    n_updates             | 12760       |
|    policy_gradient_loss  | -0.00287    |
|    std                   | 0.548       |
|    value_loss            | 0.00791     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.113       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.113       |
| reward                   | -0.2976892  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2617344     |
| train/                   |             |
|    approx_kl             | 0.008535006 |
|    clip_fraction         | 0.0802      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00552     |
|    cost_value_loss       | 1.62e-06    |
|    cost_values           | 0.00563     |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00254    |
|    n_updates             | 12770       |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.55        |
|    value_loss            | 0.00796     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0049      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0049      |
| reward                   | -0.4302163  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 2619392     |
| train/                   |             |
|    approx_kl             | 0.007891776 |
|    clip_fraction         | 0.0774      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00535    |
|    cost_value_loss       | 2.24e-06    |
|    cost_values           | -0.00535    |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00602    |
|    n_updates             | 12780       |
|    policy_gradient_loss  | -0.00622    |
|    std                   | 0.55        |
|    value_loss            | 0.0122      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.035        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.035        |
| reward                   | -0.2510578   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 6            |
|    time_elapsed          | 134          |
|    total_timesteps       | 2621440      |
| train/                   |              |
|    approx_kl             | 0.0037160679 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00207     |
|    cost_value_loss       | 1.75e-06     |
|    cost_values           | -0.00249     |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00967      |
|    n_updates             | 12790        |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.55         |
|    value_loss            | 0.168        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0641      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0641      |
| reward                   | -0.65623236 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 156         |
|    total_timesteps       | 2623488     |
| train/                   |             |
|    approx_kl             | 0.004153426 |
|    clip_fraction         | 0.032       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000488    |
|    cost_value_loss       | 3.44e-07    |
|    cost_values           | 0.000482    |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00118     |
|    n_updates             | 12800       |
|    policy_gradient_loss  | 0.000284    |
|    std                   | 0.551       |
|    value_loss            | 0.00528     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0487       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0487       |
| reward                   | -0.28980476  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 8            |
|    time_elapsed          | 178          |
|    total_timesteps       | 2625536      |
| train/                   |              |
|    approx_kl             | 0.0051721977 |
|    clip_fraction         | 0.0757       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00199     |
|    cost_value_loss       | 3.01e-06     |
|    cost_values           | -0.00208     |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0463       |
|    n_updates             | 12810        |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.553        |
|    value_loss            | 0.147        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0451       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0451       |
| reward                   | -0.3902463   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 9            |
|    time_elapsed          | 201          |
|    total_timesteps       | 2627584      |
| train/                   |              |
|    approx_kl             | 0.0018083043 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00571     |
|    cost_value_loss       | 1.01e-05     |
|    cost_values           | -0.00576     |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0264       |
|    n_updates             | 12820        |
|    policy_gradient_loss  | 0.000547     |
|    std                   | 0.554        |
|    value_loss            | 0.245        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0245       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0245       |
| reward                   | -0.5493225   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 10           |
|    time_elapsed          | 223          |
|    total_timesteps       | 2629632      |
| train/                   |              |
|    approx_kl             | 0.0032961364 |
|    clip_fraction         | 0.0395       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00216     |
|    cost_value_loss       | 7.55e-06     |
|    cost_values           | -0.00242     |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0586       |
|    n_updates             | 12830        |
|    policy_gradient_loss  | 3.39e-05     |
|    std                   | 0.554        |
|    value_loss            | 0.225        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0578       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0578       |
| reward                   | -0.32225177  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 11           |
|    time_elapsed          | 245          |
|    total_timesteps       | 2631680      |
| train/                   |              |
|    approx_kl             | 0.0072898595 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000282    |
|    cost_value_loss       | 1.26e-06     |
|    cost_values           | -0.000171    |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00229      |
|    n_updates             | 12840        |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.555        |
|    value_loss            | 0.027        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0764       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0764       |
| reward                   | -0.3918314   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 12           |
|    time_elapsed          | 267          |
|    total_timesteps       | 2633728      |
| train/                   |              |
|    approx_kl             | 0.0045077684 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00158     |
|    cost_value_loss       | 1.47e-06     |
|    cost_values           | -0.00148     |
|    entropy               | -1.46        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00355     |
|    n_updates             | 12850        |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.554        |
|    value_loss            | 0.0127       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0476      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0476      |
| reward                   | -0.2519715  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 290         |
|    total_timesteps       | 2635776     |
| train/                   |             |
|    approx_kl             | 0.004407675 |
|    clip_fraction         | 0.0335      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00116     |
|    cost_value_loss       | 1.81e-06    |
|    cost_values           | 0.00101     |
|    entropy               | -1.47       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.000807   |
|    n_updates             | 12860       |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.556       |
|    value_loss            | 0.0141      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0151       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0151       |
| reward                   | -0.2517124   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 14           |
|    time_elapsed          | 312          |
|    total_timesteps       | 2637824      |
| train/                   |              |
|    approx_kl             | 0.0045848805 |
|    clip_fraction         | 0.0509       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00269     |
|    cost_value_loss       | 5.37e-07     |
|    cost_values           | -0.00273     |
|    entropy               | -1.46        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00258      |
|    n_updates             | 12870        |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.555        |
|    value_loss            | 0.00954      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00012      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00012      |
| reward                   | -0.2534015   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 15           |
|    time_elapsed          | 335          |
|    total_timesteps       | 2639872      |
| train/                   |              |
|    approx_kl             | 0.0059779757 |
|    clip_fraction         | 0.0922       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00109      |
|    cost_value_loss       | 2.55e-06     |
|    cost_values           | 0.0011       |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0375       |
|    n_updates             | 12880        |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.554        |
|    value_loss            | 0.107        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0245       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0245       |
| reward                   | -0.55153114  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 16           |
|    time_elapsed          | 357          |
|    total_timesteps       | 2641920      |
| train/                   |              |
|    approx_kl             | 0.0063925846 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00335     |
|    cost_value_loss       | 5.33e-07     |
|    cost_values           | -0.00333     |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000725    |
|    n_updates             | 12890        |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.554        |
|    value_loss            | 0.00925      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0923       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0923       |
| reward                   | -0.47100228  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 17           |
|    time_elapsed          | 380          |
|    total_timesteps       | 2643968      |
| train/                   |              |
|    approx_kl             | 0.0013755114 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00594     |
|    cost_value_loss       | 1.29e-06     |
|    cost_values           | -0.00598     |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00114     |
|    n_updates             | 12900        |
|    policy_gradient_loss  | -0.000489    |
|    std                   | 0.555        |
|    value_loss            | 0.0107       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0829      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0829      |
| reward                   | -0.32303426 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 402         |
|    total_timesteps       | 2646016     |
| train/                   |             |
|    approx_kl             | 0.005553586 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00744    |
|    cost_value_loss       | 2.05e-06    |
|    cost_values           | -0.00742    |
|    entropy               | -1.45       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00227    |
|    n_updates             | 12910       |
|    policy_gradient_loss  | -0.00412    |
|    std                   | 0.554       |
|    value_loss            | 0.00536     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.122        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.122        |
| reward                   | -0.5146118   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 19           |
|    time_elapsed          | 424          |
|    total_timesteps       | 2648064      |
| train/                   |              |
|    approx_kl             | 0.0012209745 |
|    clip_fraction         | 0.0141       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00295     |
|    cost_value_loss       | 5.48e-07     |
|    cost_values           | -0.00303     |
|    entropy               | -1.45        |
|    entropy_loss          | -1.45        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0045       |
|    n_updates             | 12920        |
|    policy_gradient_loss  | -3.13e-05    |
|    std                   | 0.554        |
|    value_loss            | 0.0205       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0063       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0063       |
| reward                   | -0.38010603  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 20           |
|    time_elapsed          | 447          |
|    total_timesteps       | 2650112      |
| train/                   |              |
|    approx_kl             | 0.0032154457 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00612      |
|    cost_value_loss       | 1.5e-06      |
|    cost_values           | 0.00631      |
|    entropy               | -1.45        |
|    entropy_loss          | -1.45        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00361      |
|    n_updates             | 12930        |
|    policy_gradient_loss  | -0.00383     |
|    std                   | 0.552        |
|    value_loss            | 0.041        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.214        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.214        |
| reward                   | -0.5356888   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 21           |
|    time_elapsed          | 469          |
|    total_timesteps       | 2652160      |
| train/                   |              |
|    approx_kl             | 0.0035550133 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00105      |
|    cost_value_loss       | 3.63e-07     |
|    cost_values           | 0.00105      |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00219     |
|    n_updates             | 12940        |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.549        |
|    value_loss            | 0.0121       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0516      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0516      |
| reward                   | -0.3778891  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 491         |
|    total_timesteps       | 2654208     |
| train/                   |             |
|    approx_kl             | 0.002692529 |
|    clip_fraction         | 0.064       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00163    |
|    cost_value_loss       | 4.33e-07    |
|    cost_values           | -0.00165    |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00632     |
|    n_updates             | 12950       |
|    policy_gradient_loss  | -0.00451    |
|    std                   | 0.547       |
|    value_loss            | 0.0172      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0267       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0267       |
| reward                   | -0.22782587  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 23           |
|    time_elapsed          | 514          |
|    total_timesteps       | 2656256      |
| train/                   |              |
|    approx_kl             | 0.0036495184 |
|    clip_fraction         | 0.0632       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00323     |
|    cost_value_loss       | 4.36e-06     |
|    cost_values           | -0.0032      |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00238      |
|    n_updates             | 12960        |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.547        |
|    value_loss            | 0.0431       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0743      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0743      |
| reward                   | -0.42824292 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 537         |
|    total_timesteps       | 2658304     |
| train/                   |             |
|    approx_kl             | 0.007334624 |
|    clip_fraction         | 0.0608      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000268   |
|    cost_value_loss       | 6.56e-07    |
|    cost_values           | -0.000328   |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.11        |
|    n_updates             | 12970       |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.548       |
|    value_loss            | 2.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00401      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00401      |
| reward                   | -0.4849039   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 25           |
|    time_elapsed          | 559          |
|    total_timesteps       | 2660352      |
| train/                   |              |
|    approx_kl             | 0.0035753073 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.14e-05     |
|    cost_value_loss       | 7.12e-07     |
|    cost_values           | 8.42e-05     |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00339      |
|    n_updates             | 12980        |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.547        |
|    value_loss            | 0.0277       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00128      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00128      |
| reward                   | -0.47295666  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 26           |
|    time_elapsed          | 581          |
|    total_timesteps       | 2662400      |
| train/                   |              |
|    approx_kl             | 0.0041119833 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00483     |
|    cost_value_loss       | 1.39e-06     |
|    cost_values           | -0.00496     |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00553      |
|    n_updates             | 12990        |
|    policy_gradient_loss  | 0.000396     |
|    std                   | 0.547        |
|    value_loss            | 0.00725      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0557      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0557      |
| reward                   | -0.25245798 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 603         |
|    total_timesteps       | 2664448     |
| train/                   |             |
|    approx_kl             | 0.005073105 |
|    clip_fraction         | 0.0532      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00243     |
|    cost_value_loss       | 1.45e-06    |
|    cost_values           | 0.00245     |
|    entropy               | -1.41       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00423    |
|    n_updates             | 13000       |
|    policy_gradient_loss  | -0.00424    |
|    std                   | 0.543       |
|    value_loss            | 0.00497     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.34607282  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 28           |
|    time_elapsed          | 626          |
|    total_timesteps       | 2666496      |
| train/                   |              |
|    approx_kl             | 0.0050643357 |
|    clip_fraction         | 0.0802       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000986     |
|    cost_value_loss       | 7.97e-05     |
|    cost_values           | 0.00274      |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.019       |
|    n_updates             | 13010        |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 0.541        |
|    value_loss            | 0.00791      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.012       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.012       |
| reward                   | -0.52698135 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 648         |
|    total_timesteps       | 2668544     |
| train/                   |             |
|    approx_kl             | 0.002668796 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000367   |
|    cost_value_loss       | 0.000323    |
|    cost_values           | -0.00352    |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0311      |
|    n_updates             | 13020       |
|    policy_gradient_loss  | -0.000458   |
|    std                   | 0.542       |
|    value_loss            | 0.0731      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0343      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0343      |
| reward                   | -0.42982748 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 670         |
|    total_timesteps       | 2670592     |
| train/                   |             |
|    approx_kl             | 0.002491779 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.004      |
|    cost_value_loss       | 4.77e-06    |
|    cost_values           | -0.004      |
|    entropy               | -1.41       |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.598       |
|    n_updates             | 13030       |
|    policy_gradient_loss  | -0.000576   |
|    std                   | 0.543       |
|    value_loss            | 2.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00455     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00455     |
| reward                   | -0.47106647 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 693         |
|    total_timesteps       | 2672640     |
| train/                   |             |
|    approx_kl             | 0.010039488 |
|    clip_fraction         | 0.0535      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00921    |
|    cost_value_loss       | 1.04e-05    |
|    cost_values           | -0.00917    |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0106      |
|    n_updates             | 13040       |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.543       |
|    value_loss            | 0.0703      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00335      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00335      |
| reward                   | -0.54899377  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 32           |
|    time_elapsed          | 715          |
|    total_timesteps       | 2674688      |
| train/                   |              |
|    approx_kl             | 0.0037179128 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0171      |
|    cost_value_loss       | 3.6e-06      |
|    cost_values           | -0.0172      |
|    entropy               | -1.4         |
|    entropy_loss          | -1.41        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00331      |
|    n_updates             | 13050        |
|    policy_gradient_loss  | -0.000202    |
|    std                   | 0.543        |
|    value_loss            | 0.00861      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0579       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0579       |
| reward                   | -0.32463834  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 33           |
|    time_elapsed          | 737          |
|    total_timesteps       | 2676736      |
| train/                   |              |
|    approx_kl             | 0.0071066516 |
|    clip_fraction         | 0.0416       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00676     |
|    cost_value_loss       | 2.82e-06     |
|    cost_values           | -0.00673     |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00389      |
|    n_updates             | 13060        |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.544        |
|    value_loss            | 0.0351       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0383       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0383       |
| reward                   | -0.25956425  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 34           |
|    time_elapsed          | 760          |
|    total_timesteps       | 2678784      |
| train/                   |              |
|    approx_kl             | 0.0056667747 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00719     |
|    cost_value_loss       | 4.75e-06     |
|    cost_values           | -0.00725     |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.05e-06     |
|    n_updates             | 13070        |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.545        |
|    value_loss            | 0.0254       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0181      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0181      |
| reward                   | -0.29351553 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 782         |
|    total_timesteps       | 2680832     |
| train/                   |             |
|    approx_kl             | 0.004585826 |
|    clip_fraction         | 0.0373      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.004      |
|    cost_value_loss       | 3.19e-06    |
|    cost_values           | -0.00415    |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00312     |
|    n_updates             | 13080       |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 0.544       |
|    value_loss            | 0.0424      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.05        |
| reward                   | -0.2739768  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 805         |
|    total_timesteps       | 2682880     |
| train/                   |             |
|    approx_kl             | 0.003585252 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000398   |
|    cost_value_loss       | 2.25e-06    |
|    cost_values           | -0.000641   |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0122      |
|    n_updates             | 13090       |
|    policy_gradient_loss  | -0.000707   |
|    std                   | 0.544       |
|    value_loss            | 0.0859      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.112        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.112        |
| reward                   | -0.4921267   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 37           |
|    time_elapsed          | 828          |
|    total_timesteps       | 2684928      |
| train/                   |              |
|    approx_kl             | 0.0012703114 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00101     |
|    cost_value_loss       | 3.21e-06     |
|    cost_values           | -0.00101     |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0243       |
|    n_updates             | 13100        |
|    policy_gradient_loss  | -0.000807    |
|    std                   | 0.545        |
|    value_loss            | 0.0617       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0818       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0818       |
| reward                   | -0.31957144  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 38           |
|    time_elapsed          | 850          |
|    total_timesteps       | 2686976      |
| train/                   |              |
|    approx_kl             | 0.0042306394 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000336     |
|    cost_value_loss       | 2.21e-06     |
|    cost_values           | 0.000362     |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0196       |
|    n_updates             | 13110        |
|    policy_gradient_loss  | -0.00085     |
|    std                   | 0.545        |
|    value_loss            | 0.0948       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0128       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0128       |
| reward                   | -0.42758793  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 39           |
|    time_elapsed          | 872          |
|    total_timesteps       | 2689024      |
| train/                   |              |
|    approx_kl             | 0.0060021007 |
|    clip_fraction         | 0.054        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00112     |
|    cost_value_loss       | 3.18e-06     |
|    cost_values           | -0.00115     |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00277      |
|    n_updates             | 13120        |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.545        |
|    value_loss            | 0.00999      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.047        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.047        |
| reward                   | -0.44582468  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 40           |
|    time_elapsed          | 895          |
|    total_timesteps       | 2691072      |
| train/                   |              |
|    approx_kl             | 0.0030341237 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000203    |
|    cost_value_loss       | 3.33e-06     |
|    cost_values           | -0.00021     |
|    entropy               | -1.39        |
|    entropy_loss          | -1.4         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000316    |
|    n_updates             | 13130        |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.543        |
|    value_loss            | 0.00845      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0547      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0547      |
| reward                   | -0.51822585 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 917         |
|    total_timesteps       | 2693120     |
| train/                   |             |
|    approx_kl             | 0.008689508 |
|    clip_fraction         | 0.0659      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00343     |
|    cost_value_loss       | 2.61e-06    |
|    cost_values           | 0.00336     |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.15        |
|    n_updates             | 13140       |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.542       |
|    value_loss            | 1.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0347      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0347      |
| reward                   | -0.32188874 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 939         |
|    total_timesteps       | 2695168     |
| train/                   |             |
|    approx_kl             | 0.003977719 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00187     |
|    cost_value_loss       | 2.28e-06    |
|    cost_values           | 0.00208     |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.019       |
|    n_updates             | 13150       |
|    policy_gradient_loss  | -0.00547    |
|    std                   | 0.541       |
|    value_loss            | 0.0662      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0219       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0219       |
| reward                   | -0.4287308   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 43           |
|    time_elapsed          | 962          |
|    total_timesteps       | 2697216      |
| train/                   |              |
|    approx_kl             | 0.0080687255 |
|    clip_fraction         | 0.0473       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000779     |
|    cost_value_loss       | 2.78e-06     |
|    cost_values           | 0.000852     |
|    entropy               | -1.39        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00972      |
|    n_updates             | 13160        |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.54         |
|    value_loss            | 0.0524       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0724       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0724       |
| reward                   | -0.54856336  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 44           |
|    time_elapsed          | 984          |
|    total_timesteps       | 2699264      |
| train/                   |              |
|    approx_kl             | 0.0042015444 |
|    clip_fraction         | 0.0714       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000281     |
|    cost_value_loss       | 6.63e-07     |
|    cost_values           | 0.000263     |
|    entropy               | -1.38        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00472      |
|    n_updates             | 13170        |
|    policy_gradient_loss  | 0.00114      |
|    std                   | 0.54         |
|    value_loss            | 0.00878      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0144      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0144      |
| reward                   | -0.33679348 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 45          |
|    time_elapsed          | 1007        |
|    total_timesteps       | 2701312     |
| train/                   |             |
|    approx_kl             | 0.00381952  |
|    clip_fraction         | 0.0703      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00151    |
|    cost_value_loss       | 2.49e-06    |
|    cost_values           | -0.00161    |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0116      |
|    n_updates             | 13180       |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.54        |
|    value_loss            | 0.0461      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.151       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.151       |
| reward                   | -0.49787182 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 46          |
|    time_elapsed          | 1029        |
|    total_timesteps       | 2703360     |
| train/                   |             |
|    approx_kl             | 0.007038831 |
|    clip_fraction         | 0.0528      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00356    |
|    cost_value_loss       | 1.29e-06    |
|    cost_values           | -0.00353    |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00306     |
|    n_updates             | 13190       |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.54        |
|    value_loss            | 0.0155      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0351      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0351      |
| reward                   | -0.42700034 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 47          |
|    time_elapsed          | 1051        |
|    total_timesteps       | 2705408     |
| train/                   |             |
|    approx_kl             | 0.005846289 |
|    clip_fraction         | 0.0689      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0059      |
|    cost_value_loss       | 5.58e-05    |
|    cost_values           | 0.00505     |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00557    |
|    n_updates             | 13200       |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.537       |
|    value_loss            | 0.00794     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.02        |
| reward                   | -0.2500455  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1073        |
|    total_timesteps       | 2707456     |
| train/                   |             |
|    approx_kl             | 0.005857396 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000727    |
|    cost_value_loss       | 7.73e-06    |
|    cost_values           | 0.00113     |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0082      |
|    n_updates             | 13210       |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.536       |
|    value_loss            | 0.0409      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.156        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.156        |
| reward                   | -0.47225013  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 49           |
|    time_elapsed          | 1095         |
|    total_timesteps       | 2709504      |
| train/                   |              |
|    approx_kl             | 0.0024691285 |
|    clip_fraction         | 0.0336       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000103     |
|    cost_value_loss       | 6.36e-07     |
|    cost_values           | 0.000171     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00521      |
|    n_updates             | 13220        |
|    policy_gradient_loss  | 0.000447     |
|    std                   | 0.535        |
|    value_loss            | 0.0101       |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.0187     |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.0187     |
| reward             | -0.2542312 |
| rollout/           |            |
|    ep_len_mean     | 982        |
|    ep_rew_mean     | -393       |
| time/              |            |
|    fps             | 93         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 2711552    |
-----------------------------------
------------------------------------------
| avg_speed                | 0.0222      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0222      |
| reward                   | -0.37813395 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2713600     |
| train/                   |             |
|    approx_kl             | 0.005766422 |
|    clip_fraction         | 0.0665      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00574     |
|    cost_value_loss       | 2.94e-06    |
|    cost_values           | 0.00576     |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0104      |
|    n_updates             | 13240       |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.535       |
|    value_loss            | 0.0116      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0776      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0776      |
| reward                   | -0.3234829  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2715648     |
| train/                   |             |
|    approx_kl             | 0.005362927 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00739     |
|    cost_value_loss       | 3.44e-05    |
|    cost_values           | 0.00659     |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000218    |
|    n_updates             | 13250       |
|    policy_gradient_loss  | -0.00144    |
|    std                   | 0.534       |
|    value_loss            | 0.00966     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.35438612  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 4            |
|    time_elapsed          | 89           |
|    total_timesteps       | 2717696      |
| train/                   |              |
|    approx_kl             | 0.0032099383 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00485     |
|    cost_value_loss       | 3.01e-05     |
|    cost_values           | -0.00513     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00133      |
|    n_updates             | 13260        |
|    policy_gradient_loss  | -0.000438    |
|    std                   | 0.534        |
|    value_loss            | 0.0198       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0317       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0317       |
| reward                   | -0.32069287  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -382         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 5            |
|    time_elapsed          | 111          |
|    total_timesteps       | 2719744      |
| train/                   |              |
|    approx_kl             | 0.0068614446 |
|    clip_fraction         | 0.0614       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000294     |
|    cost_value_loss       | 1.01e-06     |
|    cost_values           | 0.000209     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00574      |
|    n_updates             | 13270        |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 0.536        |
|    value_loss            | 0.00747      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.47063205  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 6            |
|    time_elapsed          | 133          |
|    total_timesteps       | 2721792      |
| train/                   |              |
|    approx_kl             | 0.0013817797 |
|    clip_fraction         | 0.041        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00416     |
|    cost_value_loss       | 3.92e-06     |
|    cost_values           | -0.00468     |
|    entropy               | -1.38        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.89         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.09         |
|    n_updates             | 13280        |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.536        |
|    value_loss            | 3.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00212      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00212      |
| reward                   | -0.5131908   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 7            |
|    time_elapsed          | 156          |
|    total_timesteps       | 2723840      |
| train/                   |              |
|    approx_kl             | 0.0033322114 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0069      |
|    cost_value_loss       | 1.86e-06     |
|    cost_values           | -0.00707     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00246     |
|    n_updates             | 13290        |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.535        |
|    value_loss            | 0.015        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0403      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0403      |
| reward                   | -0.25743547 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -380        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 178         |
|    total_timesteps       | 2725888     |
| train/                   |             |
|    approx_kl             | 0.006040913 |
|    clip_fraction         | 0.0669      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000364    |
|    cost_value_loss       | 5.8e-07     |
|    cost_values           | 0.000385    |
|    entropy               | -1.38       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00944    |
|    n_updates             | 13300       |
|    policy_gradient_loss  | -0.00524    |
|    std                   | 0.534       |
|    value_loss            | 0.00258     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0286       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0286       |
| reward                   | -0.30039138  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 9            |
|    time_elapsed          | 200          |
|    total_timesteps       | 2727936      |
| train/                   |              |
|    approx_kl             | 0.0031191856 |
|    clip_fraction         | 0.0593       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00459      |
|    cost_value_loss       | 1.95e-06     |
|    cost_values           | 0.00465      |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00602      |
|    n_updates             | 13310        |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.535        |
|    value_loss            | 0.0229       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0224       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0224       |
| reward                   | -0.37818658  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 10           |
|    time_elapsed          | 222          |
|    total_timesteps       | 2729984      |
| train/                   |              |
|    approx_kl             | 0.0051246546 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00243     |
|    cost_value_loss       | 7.75e-07     |
|    cost_values           | -0.00252     |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0126       |
|    n_updates             | 13320        |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.535        |
|    value_loss            | 0.112        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.5464201   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 11           |
|    time_elapsed          | 245          |
|    total_timesteps       | 2732032      |
| train/                   |              |
|    approx_kl             | 0.0047359564 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00297      |
|    cost_value_loss       | 3.77e-06     |
|    cost_values           | 0.00297      |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0268       |
|    n_updates             | 13330        |
|    policy_gradient_loss  | 0.000704     |
|    std                   | 0.536        |
|    value_loss            | 0.249        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0129      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0129      |
| reward                   | -0.36514223 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 267         |
|    total_timesteps       | 2734080     |
| train/                   |             |
|    approx_kl             | 0.003575346 |
|    clip_fraction         | 0.0389      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0015     |
|    cost_value_loss       | 2.41e-06    |
|    cost_values           | -0.00159    |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0118      |
|    n_updates             | 13340       |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.535       |
|    value_loss            | 0.106       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00758      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00758      |
| reward                   | -0.39226028  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 13           |
|    time_elapsed          | 289          |
|    total_timesteps       | 2736128      |
| train/                   |              |
|    approx_kl             | 0.0033809056 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00127      |
|    cost_value_loss       | 6.49e-06     |
|    cost_values           | 0.00119      |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.041        |
|    n_updates             | 13350        |
|    policy_gradient_loss  | -6.44e-06    |
|    std                   | 0.535        |
|    value_loss            | 0.203        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0745       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0745       |
| reward                   | -0.3229742   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 14           |
|    time_elapsed          | 312          |
|    total_timesteps       | 2738176      |
| train/                   |              |
|    approx_kl             | 0.0058490317 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00271      |
|    cost_value_loss       | 1e-06        |
|    cost_values           | 0.00273      |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00667      |
|    n_updates             | 13360        |
|    policy_gradient_loss  | -0.000658    |
|    std                   | 0.535        |
|    value_loss            | 0.0245       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.138       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.138       |
| reward                   | -0.3581464  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -378        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 335         |
|    total_timesteps       | 2740224     |
| train/                   |             |
|    approx_kl             | 0.005151717 |
|    clip_fraction         | 0.0384      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000881    |
|    cost_value_loss       | 3.85e-06    |
|    cost_values           | 0.000892    |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00427    |
|    n_updates             | 13370       |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.534       |
|    value_loss            | 0.0137      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0474      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0474      |
| reward                   | -0.29235947 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -375        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 357         |
|    total_timesteps       | 2742272     |
| train/                   |             |
|    approx_kl             | 0.004808926 |
|    clip_fraction         | 0.0369      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00463     |
|    cost_value_loss       | 2.87e-06    |
|    cost_values           | 0.00446     |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0304      |
|    n_updates             | 13380       |
|    policy_gradient_loss  | 5.15e-05    |
|    std                   | 0.532       |
|    value_loss            | 0.0405      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0547      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0547      |
| reward                   | -0.5131373  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -372        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 381         |
|    total_timesteps       | 2744320     |
| train/                   |             |
|    approx_kl             | 0.004236788 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00112     |
|    cost_value_loss       | 9.69e-07    |
|    cost_values           | 0.00111     |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00742     |
|    n_updates             | 13390       |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.532       |
|    value_loss            | 0.0381      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00442     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00442     |
| reward                   | -0.43622926 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -373        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 404         |
|    total_timesteps       | 2746368     |
| train/                   |             |
|    approx_kl             | 0.00998431  |
|    clip_fraction         | 0.0422      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000504   |
|    cost_value_loss       | 1.52e-06    |
|    cost_values           | -0.000653   |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.325       |
|    n_updates             | 13400       |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.531       |
|    value_loss            | 1.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0573       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0573       |
| reward                   | -0.5167862   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 19           |
|    time_elapsed          | 426          |
|    total_timesteps       | 2748416      |
| train/                   |              |
|    approx_kl             | 0.0063047037 |
|    clip_fraction         | 0.0545       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00517      |
|    cost_value_loss       | 2.97e-06     |
|    cost_values           | 0.00524      |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00147      |
|    n_updates             | 13410        |
|    policy_gradient_loss  | -0.00506     |
|    std                   | 0.532        |
|    value_loss            | 0.0249       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.119        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.119        |
| reward                   | -0.3840156   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -373         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 20           |
|    time_elapsed          | 449          |
|    total_timesteps       | 2750464      |
| train/                   |              |
|    approx_kl             | 0.0012035461 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00814      |
|    cost_value_loss       | 4.15e-06     |
|    cost_values           | 0.0082       |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.028        |
|    n_updates             | 13420        |
|    policy_gradient_loss  | -0.000719    |
|    std                   | 0.532        |
|    value_loss            | 0.158        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.111       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.111       |
| reward                   | -0.25087044 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -371        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 471         |
|    total_timesteps       | 2752512     |
| train/                   |             |
|    approx_kl             | 0.006533007 |
|    clip_fraction         | 0.0566      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00393     |
|    cost_value_loss       | 2.18e-06    |
|    cost_values           | 0.00394     |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00465     |
|    n_updates             | 13430       |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.532       |
|    value_loss            | 0.0206      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0256      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0256      |
| reward                   | -0.3970733  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -376        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 494         |
|    total_timesteps       | 2754560     |
| train/                   |             |
|    approx_kl             | 0.005084794 |
|    clip_fraction         | 0.0412      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00312     |
|    cost_value_loss       | 2.74e-06    |
|    cost_values           | 0.00308     |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00954     |
|    n_updates             | 13440       |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.532       |
|    value_loss            | 0.0276      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0155      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0155      |
| reward                   | -0.37584668 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -375        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 517         |
|    total_timesteps       | 2756608     |
| train/                   |             |
|    approx_kl             | 0.00478918  |
|    clip_fraction         | 0.0255      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0035      |
|    cost_value_loss       | 1.29e-06    |
|    cost_values           | 0.00349     |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0031     |
|    n_updates             | 13450       |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.534       |
|    value_loss            | 0.0134      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0351      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0351      |
| reward                   | -0.42193976 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -375        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 539         |
|    total_timesteps       | 2758656     |
| train/                   |             |
|    approx_kl             | 0.003669416 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000608   |
|    cost_value_loss       | 9.5e-07     |
|    cost_values           | -0.000597   |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00304    |
|    n_updates             | 13460       |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.531       |
|    value_loss            | 0.00617     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0735       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0735       |
| reward                   | -0.42815968  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 25           |
|    time_elapsed          | 562          |
|    total_timesteps       | 2760704      |
| train/                   |              |
|    approx_kl             | 0.0032600258 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00268     |
|    cost_value_loss       | 1.16e-06     |
|    cost_values           | -0.00276     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.931        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0212       |
|    n_updates             | 13470        |
|    policy_gradient_loss  | 0.000133     |
|    std                   | 0.529        |
|    value_loss            | 0.138        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00296     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00296     |
| reward                   | -0.3768312  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 584         |
|    total_timesteps       | 2762752     |
| train/                   |             |
|    approx_kl             | 0.011521663 |
|    clip_fraction         | 0.0387      |
|    clip_range            | 0.2         |
|    cost_returns          | -9e-05      |
|    cost_value_loss       | 1.39e-06    |
|    cost_values           | -0.000153   |
|    entropy               | -1.36       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00794     |
|    n_updates             | 13480       |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.528       |
|    value_loss            | 0.0162      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0234       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0234       |
| reward                   | -0.47196564  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 27           |
|    time_elapsed          | 607          |
|    total_timesteps       | 2764800      |
| train/                   |              |
|    approx_kl             | 0.0021434897 |
|    clip_fraction         | 0.0621       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00105     |
|    cost_value_loss       | 3.5e-06      |
|    cost_values           | -0.00123     |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0215       |
|    n_updates             | 13490        |
|    policy_gradient_loss  | 0.00158      |
|    std                   | 0.528        |
|    value_loss            | 0.143        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.175       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.175       |
| reward                   | -0.33003616 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 629         |
|    total_timesteps       | 2766848     |
| train/                   |             |
|    approx_kl             | 0.002936178 |
|    clip_fraction         | 0.0161      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00517    |
|    cost_value_loss       | 4.13e-06    |
|    cost_values           | -0.00515    |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00851     |
|    n_updates             | 13500       |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.528       |
|    value_loss            | 0.161       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0806       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0806       |
| reward                   | -0.36157143  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 29           |
|    time_elapsed          | 652          |
|    total_timesteps       | 2768896      |
| train/                   |              |
|    approx_kl             | 0.0068878643 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0027       |
|    cost_value_loss       | 1.09e-05     |
|    cost_values           | 0.00266      |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00217      |
|    n_updates             | 13510        |
|    policy_gradient_loss  | -0.00777     |
|    std                   | 0.529        |
|    value_loss            | 0.00767      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.008       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.008       |
| reward                   | -0.35268354 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 674         |
|    total_timesteps       | 2770944     |
| train/                   |             |
|    approx_kl             | 0.006404019 |
|    clip_fraction         | 0.0662      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000585   |
|    cost_value_loss       | 7.09e-06    |
|    cost_values           | -0.00109    |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00318    |
|    n_updates             | 13520       |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 0.528       |
|    value_loss            | 0.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.134        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.134        |
| reward                   | -0.57448983  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 31           |
|    time_elapsed          | 697          |
|    total_timesteps       | 2772992      |
| train/                   |              |
|    approx_kl             | 0.0030788737 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00216     |
|    cost_value_loss       | 9.74e-07     |
|    cost_values           | -0.00219     |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00886      |
|    n_updates             | 13530        |
|    policy_gradient_loss  | -0.000467    |
|    std                   | 0.527        |
|    value_loss            | 0.0236       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0691       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0691       |
| reward                   | -0.31905913  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 32           |
|    time_elapsed          | 719          |
|    total_timesteps       | 2775040      |
| train/                   |              |
|    approx_kl             | 0.0037194684 |
|    clip_fraction         | 0.06         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00494      |
|    cost_value_loss       | 4.47e-06     |
|    cost_values           | 0.005        |
|    entropy               | -1.37        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00657      |
|    n_updates             | 13540        |
|    policy_gradient_loss  | -0.00636     |
|    std                   | 0.53         |
|    value_loss            | 0.0299       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0404       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0404       |
| reward                   | -0.55054134  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 33           |
|    time_elapsed          | 742          |
|    total_timesteps       | 2777088      |
| train/                   |              |
|    approx_kl             | 0.0060339537 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00988     |
|    cost_value_loss       | 3.34e-06     |
|    cost_values           | -0.00997     |
|    entropy               | -1.38        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000938    |
|    n_updates             | 13550        |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.53         |
|    value_loss            | 0.0437       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0526       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0526       |
| reward                   | -0.46980342  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 34           |
|    time_elapsed          | 764          |
|    total_timesteps       | 2779136      |
| train/                   |              |
|    approx_kl             | 0.0040516015 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00514     |
|    cost_value_loss       | 8.41e-07     |
|    cost_values           | -0.00519     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00274     |
|    n_updates             | 13560        |
|    policy_gradient_loss  | -0.00039     |
|    std                   | 0.529        |
|    value_loss            | 0.00223      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0351      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0351      |
| reward                   | -0.42770413 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 787         |
|    total_timesteps       | 2781184     |
| train/                   |             |
|    approx_kl             | 0.007900455 |
|    clip_fraction         | 0.0751      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00539    |
|    cost_value_loss       | 5.34e-06    |
|    cost_values           | -0.00545    |
|    entropy               | -1.36       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00877    |
|    n_updates             | 13570       |
|    policy_gradient_loss  | -0.00637    |
|    std                   | 0.526       |
|    value_loss            | 0.00643     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.135       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.135       |
| reward                   | -0.5274051  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 809         |
|    total_timesteps       | 2783232     |
| train/                   |             |
|    approx_kl             | 0.003296922 |
|    clip_fraction         | 0.047       |
|    clip_range            | 0.2         |
|    cost_returns          | -4.74e-05   |
|    cost_value_loss       | 2.43e-06    |
|    cost_values           | -7.51e-05   |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00136    |
|    n_updates             | 13580       |
|    policy_gradient_loss  | -0.000629   |
|    std                   | 0.526       |
|    value_loss            | 0.0155      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0476       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0476       |
| reward                   | -0.47056538  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 37           |
|    time_elapsed          | 831          |
|    total_timesteps       | 2785280      |
| train/                   |              |
|    approx_kl             | 0.0027461578 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00101      |
|    cost_value_loss       | 3.28e-06     |
|    cost_values           | 0.00115      |
|    entropy               | -1.37        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00321      |
|    n_updates             | 13590        |
|    policy_gradient_loss  | -0.000618    |
|    std                   | 0.528        |
|    value_loss            | 0.0155       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0535       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0535       |
| reward                   | -0.23497826  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 38           |
|    time_elapsed          | 854          |
|    total_timesteps       | 2787328      |
| train/                   |              |
|    approx_kl             | 0.0031299684 |
|    clip_fraction         | 0.0598       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00426     |
|    cost_value_loss       | 4.87e-06     |
|    cost_values           | -0.00422     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00354      |
|    n_updates             | 13600        |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.528        |
|    value_loss            | 0.0322       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.215        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.215        |
| reward                   | -0.43564594  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 39           |
|    time_elapsed          | 876          |
|    total_timesteps       | 2789376      |
| train/                   |              |
|    approx_kl             | 0.0038991475 |
|    clip_fraction         | 0.0642       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00133     |
|    cost_value_loss       | 2.15e-06     |
|    cost_values           | -0.00147     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0359       |
|    n_updates             | 13610        |
|    policy_gradient_loss  | 0.000303     |
|    std                   | 0.527        |
|    value_loss            | 0.0949       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0551      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0551      |
| reward                   | -0.55084133 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 898         |
|    total_timesteps       | 2791424     |
| train/                   |             |
|    approx_kl             | 0.007474015 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00361    |
|    cost_value_loss       | 3.58e-06    |
|    cost_values           | -0.00367    |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.033       |
|    n_updates             | 13620       |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.527       |
|    value_loss            | 0.0784      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.072        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.072        |
| reward                   | -0.3010868   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 41           |
|    time_elapsed          | 921          |
|    total_timesteps       | 2793472      |
| train/                   |              |
|    approx_kl             | 0.0066325003 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00627     |
|    cost_value_loss       | 2.75e-06     |
|    cost_values           | -0.0064      |
|    entropy               | -1.36        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00274      |
|    n_updates             | 13630        |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.526        |
|    value_loss            | 0.0344       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0846      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0846      |
| reward                   | -0.47276813 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 943         |
|    total_timesteps       | 2795520     |
| train/                   |             |
|    approx_kl             | 0.012817345 |
|    clip_fraction         | 0.0516      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00188    |
|    cost_value_loss       | 1.89e-06    |
|    cost_values           | -0.00197    |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0172      |
|    n_updates             | 13640       |
|    policy_gradient_loss  | -0.00038    |
|    std                   | 0.525       |
|    value_loss            | 0.0404      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0653       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0653       |
| reward                   | -0.3782152   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 43           |
|    time_elapsed          | 965          |
|    total_timesteps       | 2797568      |
| train/                   |              |
|    approx_kl             | 0.0073361793 |
|    clip_fraction         | 0.0623       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00184     |
|    cost_value_loss       | 1.59e-06     |
|    cost_values           | -0.00184     |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.44e-07     |
|    n_updates             | 13650        |
|    policy_gradient_loss  | -0.000362    |
|    std                   | 0.523        |
|    value_loss            | 0.0117       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0254       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0254       |
| reward                   | -0.55086666  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 44           |
|    time_elapsed          | 987          |
|    total_timesteps       | 2799616      |
| train/                   |              |
|    approx_kl             | 0.0062306602 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0022      |
|    cost_value_loss       | 1.22e-06     |
|    cost_values           | -0.00217     |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000619    |
|    n_updates             | 13660        |
|    policy_gradient_loss  | 0.000194     |
|    std                   | 0.521        |
|    value_loss            | 0.00858      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0854      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0854      |
| reward                   | -0.47234794 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 45          |
|    time_elapsed          | 1009        |
|    total_timesteps       | 2801664     |
| train/                   |             |
|    approx_kl             | 0.007170486 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0023     |
|    cost_value_loss       | 0.000112    |
|    cost_values           | -0.00303    |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00312     |
|    n_updates             | 13670       |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.524       |
|    value_loss            | 0.00514     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.081        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.081        |
| reward                   | -0.37724435  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 46           |
|    time_elapsed          | 1031         |
|    total_timesteps       | 2803712      |
| train/                   |              |
|    approx_kl             | 0.0051786825 |
|    clip_fraction         | 0.0486       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00576     |
|    cost_value_loss       | 0.000153     |
|    cost_values           | -0.00937     |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.863        |
|    n_updates             | 13680        |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.524        |
|    value_loss            | 1.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0955       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0955       |
| reward                   | -0.32060012  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 47           |
|    time_elapsed          | 1054         |
|    total_timesteps       | 2805760      |
| train/                   |              |
|    approx_kl             | 0.0064756367 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00471     |
|    cost_value_loss       | 2.27e-06     |
|    cost_values           | -0.00481     |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00316      |
|    n_updates             | 13690        |
|    policy_gradient_loss  | -0.000245    |
|    std                   | 0.524        |
|    value_loss            | 0.00813      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0266       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0266       |
| reward                   | -0.42797446  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 48           |
|    time_elapsed          | 1076         |
|    total_timesteps       | 2807808      |
| train/                   |              |
|    approx_kl             | 0.0022410545 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00194     |
|    cost_value_loss       | 2.01e-06     |
|    cost_values           | -0.00157     |
|    entropy               | -1.36        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00102     |
|    n_updates             | 13700        |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.524        |
|    value_loss            | 0.00782      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0838      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0838      |
| reward                   | -0.4280066  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 49          |
|    time_elapsed          | 1098        |
|    total_timesteps       | 2809856     |
| train/                   |             |
|    approx_kl             | 0.004061054 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00193     |
|    cost_value_loss       | 3.81e-06    |
|    cost_values           | 0.00168     |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000749    |
|    n_updates             | 13710       |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.525       |
|    value_loss            | 0.0543      |
------------------------------------------
------------------------------------
| avg_speed          | 0.143       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.143       |
| reward             | -0.44571197 |
| rollout/           |             |
|    ep_len_mean     | 979         |
|    ep_rew_mean     | -393        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2811904     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.0746       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0746       |
| reward                   | -0.4279337   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 2813952      |
| train/                   |              |
|    approx_kl             | 0.0027326222 |
|    clip_fraction         | 0.0425       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00626      |
|    cost_value_loss       | 1.99e-06     |
|    cost_values           | 0.00639      |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000769    |
|    n_updates             | 13730        |
|    policy_gradient_loss  | -0.003       |
|    std                   | 0.525        |
|    value_loss            | 0.0175       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0766      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0766      |
| reward                   | -0.54865783 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 2816000     |
| train/                   |             |
|    approx_kl             | 0.006303023 |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00288     |
|    cost_value_loss       | 2.13e-06    |
|    cost_values           | 0.00291     |
|    entropy               | -1.35       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00601     |
|    n_updates             | 13740       |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.523       |
|    value_loss            | 0.0237      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0874       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0874       |
| reward                   | -0.35452914  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 2818048      |
| train/                   |              |
|    approx_kl             | 0.0034198253 |
|    clip_fraction         | 0.0643       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000585     |
|    cost_value_loss       | 1.78e-06     |
|    cost_values           | 0.000647     |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00553     |
|    n_updates             | 13750        |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.524        |
|    value_loss            | 0.0193       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0827       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0827       |
| reward                   | -0.46947303  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 2820096      |
| train/                   |              |
|    approx_kl             | 0.0023566168 |
|    clip_fraction         | 0.00688      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00341      |
|    cost_value_loss       | 3.08e-06     |
|    cost_values           | 0.00353      |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00772      |
|    n_updates             | 13760        |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.524        |
|    value_loss            | 0.0698       |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.122         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.122         |
| reward                   | -0.22712149   |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -406          |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 6             |
|    time_elapsed          | 133           |
|    total_timesteps       | 2822144       |
| train/                   |               |
|    approx_kl             | 0.00092532847 |
|    clip_fraction         | 0.0111        |
|    clip_range            | 0.2           |
|    cost_returns          | 0.00119       |
|    cost_value_loss       | 2.58e-06      |
|    cost_values           | 0.00118       |
|    entropy               | -1.35         |
|    entropy_loss          | -1.35         |
|    explained_variance    | 0.998         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.0107        |
|    n_updates             | 13770         |
|    policy_gradient_loss  | 5.17e-05      |
|    std                   | 0.524         |
|    value_loss            | 0.0273        |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.028        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.028        |
| reward                   | -0.36594915  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 155          |
|    total_timesteps       | 2824192      |
| train/                   |              |
|    approx_kl             | 0.0012785445 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00236      |
|    cost_value_loss       | 3.61e-06     |
|    cost_values           | 0.00237      |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0334       |
|    n_updates             | 13780        |
|    policy_gradient_loss  | -0.000161    |
|    std                   | 0.524        |
|    value_loss            | 0.101        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.123       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.123       |
| reward                   | -0.47086373 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 177         |
|    total_timesteps       | 2826240     |
| train/                   |             |
|    approx_kl             | 0.007844935 |
|    clip_fraction         | 0.0508      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00246     |
|    cost_value_loss       | 1.16e-06    |
|    cost_values           | 0.00254     |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0209      |
|    n_updates             | 13790       |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.526       |
|    value_loss            | 0.0267      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00916     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00916     |
| reward                   | -0.4704894  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 2828288     |
| train/                   |             |
|    approx_kl             | 0.004561487 |
|    clip_fraction         | 0.0925      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000379    |
|    cost_value_loss       | 1.18e-06    |
|    cost_values           | 0.00029     |
|    entropy               | -1.36       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0112     |
|    n_updates             | 13800       |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.527       |
|    value_loss            | 0.0083      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0156       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0156       |
| reward                   | -0.3775643   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 2830336      |
| train/                   |              |
|    approx_kl             | 0.0053632623 |
|    clip_fraction         | 0.0609       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000414     |
|    cost_value_loss       | 8.7e-07      |
|    cost_values           | 0.000341     |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0111       |
|    n_updates             | 13810        |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.528        |
|    value_loss            | 0.0751       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0311      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0311      |
| reward                   | -0.42748934 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 244         |
|    total_timesteps       | 2832384     |
| train/                   |             |
|    approx_kl             | 0.002270787 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000733   |
|    cost_value_loss       | 7.54e-07    |
|    cost_values           | -0.000725   |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00403    |
|    n_updates             | 13820       |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.525       |
|    value_loss            | 0.00465     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00656      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00656      |
| reward                   | -0.4213913   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 266          |
|    total_timesteps       | 2834432      |
| train/                   |              |
|    approx_kl             | 0.0066372654 |
|    clip_fraction         | 0.0516       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00335     |
|    cost_value_loss       | 4.06e-06     |
|    cost_values           | -0.00336     |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00286     |
|    n_updates             | 13830        |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.525        |
|    value_loss            | 0.0211       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0175      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0175      |
| reward                   | -0.53577614 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 289         |
|    total_timesteps       | 2836480     |
| train/                   |             |
|    approx_kl             | 0.005506184 |
|    clip_fraction         | 0.0822      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00106     |
|    cost_value_loss       | 5.7e-07     |
|    cost_values           | 0.00104     |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00209    |
|    n_updates             | 13840       |
|    policy_gradient_loss  | -0.00302    |
|    std                   | 0.525       |
|    value_loss            | 0.00507     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00388     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00388     |
| reward                   | -0.4954872  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 311         |
|    total_timesteps       | 2838528     |
| train/                   |             |
|    approx_kl             | 0.006857259 |
|    clip_fraction         | 0.042       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00549     |
|    cost_value_loss       | 4.77e-06    |
|    cost_values           | 0.00543     |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00993     |
|    n_updates             | 13850       |
|    policy_gradient_loss  | 0.000962    |
|    std                   | 0.524       |
|    value_loss            | 0.0356      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.115        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.115        |
| reward                   | -0.2870753   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 333          |
|    total_timesteps       | 2840576      |
| train/                   |              |
|    approx_kl             | 0.0032141493 |
|    clip_fraction         | 0.0512       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00679      |
|    cost_value_loss       | 4.33e-06     |
|    cost_values           | 0.00717      |
|    entropy               | -1.33        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00605      |
|    n_updates             | 13860        |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.523        |
|    value_loss            | 0.0561       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0729       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0729       |
| reward                   | -0.42635015  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 355          |
|    total_timesteps       | 2842624      |
| train/                   |              |
|    approx_kl             | 0.0064748926 |
|    clip_fraction         | 0.0455       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000106    |
|    cost_value_loss       | 3.88e-06     |
|    cost_values           | -4.75e-05    |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00603      |
|    n_updates             | 13870        |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 0.522        |
|    value_loss            | 0.0223       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.102       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.102       |
| reward                   | -0.5237344  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 378         |
|    total_timesteps       | 2844672     |
| train/                   |             |
|    approx_kl             | 0.008354668 |
|    clip_fraction         | 0.0529      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00121    |
|    cost_value_loss       | 7.47e-07    |
|    cost_values           | -0.00126    |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00669    |
|    n_updates             | 13880       |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 0.519       |
|    value_loss            | 0.0198      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0796       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0796       |
| reward                   | -0.37997842  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 400          |
|    total_timesteps       | 2846720      |
| train/                   |              |
|    approx_kl             | 0.0073263715 |
|    clip_fraction         | 0.107        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0017       |
|    cost_value_loss       | 3.39e-06     |
|    cost_values           | 0.00175      |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00206     |
|    n_updates             | 13890        |
|    policy_gradient_loss  | -0.00503     |
|    std                   | 0.516        |
|    value_loss            | 0.0146       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.061        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.061        |
| reward                   | -0.5112857   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 19           |
|    time_elapsed          | 423          |
|    total_timesteps       | 2848768      |
| train/                   |              |
|    approx_kl             | 0.0089574065 |
|    clip_fraction         | 0.0739       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000644     |
|    cost_value_loss       | 3.32e-06     |
|    cost_values           | 0.000597     |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.0003      |
|    n_updates             | 13900        |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 0.516        |
|    value_loss            | 0.0112       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.018        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.018        |
| reward                   | -0.48165306  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 20           |
|    time_elapsed          | 445          |
|    total_timesteps       | 2850816      |
| train/                   |              |
|    approx_kl             | 0.0060199574 |
|    clip_fraction         | 0.0405       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000894     |
|    cost_value_loss       | 1.02e-06     |
|    cost_values           | 0.000893     |
|    entropy               | -1.31        |
|    entropy_loss          | -1.3         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00615      |
|    n_updates             | 13910        |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.516        |
|    value_loss            | 0.0134       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0172      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0172      |
| reward                   | -0.37800217 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 467         |
|    total_timesteps       | 2852864     |
| train/                   |             |
|    approx_kl             | 0.007934729 |
|    clip_fraction         | 0.0866      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00132     |
|    cost_value_loss       | 3.69e-06    |
|    cost_values           | 0.00136     |
|    entropy               | -1.31       |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00242     |
|    n_updates             | 13920       |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.516       |
|    value_loss            | 0.0155      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0397       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0397       |
| reward                   | -0.32187414  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 22           |
|    time_elapsed          | 490          |
|    total_timesteps       | 2854912      |
| train/                   |              |
|    approx_kl             | 0.0036578756 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00144      |
|    cost_value_loss       | 1.49e-06     |
|    cost_values           | 0.00145      |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000611     |
|    n_updates             | 13930        |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.515        |
|    value_loss            | 0.0176       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.039       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.039       |
| reward                   | -0.47023875 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 512         |
|    total_timesteps       | 2856960     |
| train/                   |             |
|    approx_kl             | 0.004998429 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00031     |
|    cost_value_loss       | 1.2e-06     |
|    cost_values           | 0.0003      |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00619     |
|    n_updates             | 13940       |
|    policy_gradient_loss  | -0.000187   |
|    std                   | 0.515       |
|    value_loss            | 0.00636     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00592     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00592     |
| reward                   | -0.3780799  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 534         |
|    total_timesteps       | 2859008     |
| train/                   |             |
|    approx_kl             | 0.005156584 |
|    clip_fraction         | 0.0666      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00331     |
|    cost_value_loss       | 1.24e-06    |
|    cost_values           | 0.00337     |
|    entropy               | -1.29       |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00829     |
|    n_updates             | 13950       |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.514       |
|    value_loss            | 0.0312      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.137       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.137       |
| reward                   | -0.5131056  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 557         |
|    total_timesteps       | 2861056     |
| train/                   |             |
|    approx_kl             | 0.009904863 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00152    |
|    cost_value_loss       | 2.11e-06    |
|    cost_values           | -0.00155    |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00115    |
|    n_updates             | 13960       |
|    policy_gradient_loss  | -0.00714    |
|    std                   | 0.513       |
|    value_loss            | 0.0105      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0807      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0807      |
| reward                   | -0.54865456 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 579         |
|    total_timesteps       | 2863104     |
| train/                   |             |
|    approx_kl             | 0.010893436 |
|    clip_fraction         | 0.0756      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00359     |
|    cost_value_loss       | 1.73e-06    |
|    cost_values           | 0.00378     |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.02        |
|    n_updates             | 13970       |
|    policy_gradient_loss  | 0.000608    |
|    std                   | 0.511       |
|    value_loss            | 0.0153      |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83e-06     |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83e-06     |
| reward                   | -0.2910963   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 27           |
|    time_elapsed          | 601          |
|    total_timesteps       | 2865152      |
| train/                   |              |
|    approx_kl             | 0.0019767997 |
|    clip_fraction         | 0.0674       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00322      |
|    cost_value_loss       | 3.04e-06     |
|    cost_values           | 0.00315      |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00616     |
|    n_updates             | 13980        |
|    policy_gradient_loss  | -0.00057     |
|    std                   | 0.511        |
|    value_loss            | 0.00718      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.078        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.078        |
| reward                   | -0.25142056  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 28           |
|    time_elapsed          | 623          |
|    total_timesteps       | 2867200      |
| train/                   |              |
|    approx_kl             | 0.0069106547 |
|    clip_fraction         | 0.0854       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00334     |
|    cost_value_loss       | 2.69e-06     |
|    cost_values           | -0.00325     |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00195     |
|    n_updates             | 13990        |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 0.512        |
|    value_loss            | 0.0117       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0312      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0312      |
| reward                   | -0.3286723  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 646         |
|    total_timesteps       | 2869248     |
| train/                   |             |
|    approx_kl             | 0.004426703 |
|    clip_fraction         | 0.0369      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000635    |
|    cost_value_loss       | 9.16e-06    |
|    cost_values           | 0.000688    |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00295     |
|    n_updates             | 14000       |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.513       |
|    value_loss            | 0.0209      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0926      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0926      |
| reward                   | -0.41733304 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 668         |
|    total_timesteps       | 2871296     |
| train/                   |             |
|    approx_kl             | 0.013760356 |
|    clip_fraction         | 0.0722      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0021      |
|    cost_value_loss       | 1.23e-06    |
|    cost_values           | 0.00222     |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00938     |
|    n_updates             | 14010       |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 0.513       |
|    value_loss            | 0.0372      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0921       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0921       |
| reward                   | -0.54915136  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 31           |
|    time_elapsed          | 691          |
|    total_timesteps       | 2873344      |
| train/                   |              |
|    approx_kl             | 0.0059737815 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00125     |
|    cost_value_loss       | 1.63e-06     |
|    cost_values           | -0.00128     |
|    entropy               | -1.29        |
|    entropy_loss          | -1.3         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00656      |
|    n_updates             | 14020        |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.513        |
|    value_loss            | 0.0171       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0994       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0994       |
| reward                   | -0.2543004   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 32           |
|    time_elapsed          | 713          |
|    total_timesteps       | 2875392      |
| train/                   |              |
|    approx_kl             | 0.0076124026 |
|    clip_fraction         | 0.0646       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00191      |
|    cost_value_loss       | 3.39e-06     |
|    cost_values           | 0.00197      |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0106       |
|    n_updates             | 14030        |
|    policy_gradient_loss  | -0.00464     |
|    std                   | 0.514        |
|    value_loss            | 0.0278       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0464       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0464       |
| reward                   | -0.47169164  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 33           |
|    time_elapsed          | 736          |
|    total_timesteps       | 2877440      |
| train/                   |              |
|    approx_kl             | 0.0042314725 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00381     |
|    cost_value_loss       | 2.82e-06     |
|    cost_values           | -0.00395     |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000819    |
|    n_updates             | 14040        |
|    policy_gradient_loss  | -0.00078     |
|    std                   | 0.512        |
|    value_loss            | 0.0146       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.103       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.103       |
| reward                   | -0.45159262 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 758         |
|    total_timesteps       | 2879488     |
| train/                   |             |
|    approx_kl             | 0.005300676 |
|    clip_fraction         | 0.0254      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00142    |
|    cost_value_loss       | 1.65e-06    |
|    cost_values           | -0.00145    |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.013       |
|    n_updates             | 14050       |
|    policy_gradient_loss  | -0.000318   |
|    std                   | 0.512       |
|    value_loss            | 0.0177      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0404      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0404      |
| reward                   | -0.51265246 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 780         |
|    total_timesteps       | 2881536     |
| train/                   |             |
|    approx_kl             | 0.009781376 |
|    clip_fraction         | 0.0857      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000237   |
|    cost_value_loss       | 2.03e-06    |
|    cost_values           | -0.00024    |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00539    |
|    n_updates             | 14060       |
|    policy_gradient_loss  | -0.00565    |
|    std                   | 0.512       |
|    value_loss            | 0.0107      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0604       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0604       |
| reward                   | -0.47236556  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 36           |
|    time_elapsed          | 802          |
|    total_timesteps       | 2883584      |
| train/                   |              |
|    approx_kl             | 0.0062258923 |
|    clip_fraction         | 0.0798       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00615      |
|    cost_value_loss       | 2.29e-06     |
|    cost_values           | 0.00617      |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0174       |
|    n_updates             | 14070        |
|    policy_gradient_loss  | 0.000446     |
|    std                   | 0.512        |
|    value_loss            | 0.0331       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0322       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0322       |
| reward                   | -0.47215062  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 37           |
|    time_elapsed          | 824          |
|    total_timesteps       | 2885632      |
| train/                   |              |
|    approx_kl             | 0.0015149526 |
|    clip_fraction         | 0.0498       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00309     |
|    cost_value_loss       | 0.000229     |
|    cost_values           | -0.000796    |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00284      |
|    n_updates             | 14080        |
|    policy_gradient_loss  | -0.000499    |
|    std                   | 0.513        |
|    value_loss            | 0.00318      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0194      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0194      |
| reward                   | -0.32237166 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 847         |
|    total_timesteps       | 2887680     |
| train/                   |             |
|    approx_kl             | 0.018820252 |
|    clip_fraction         | 0.0888      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.019      |
|    cost_value_loss       | 2.77e-05    |
|    cost_values           | -0.0185     |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0231      |
|    n_updates             | 14090       |
|    policy_gradient_loss  | 0.00251     |
|    std                   | 0.512       |
|    value_loss            | 0.00479     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0767       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0767       |
| reward                   | -0.55059004  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 39           |
|    time_elapsed          | 870          |
|    total_timesteps       | 2889728      |
| train/                   |              |
|    approx_kl             | 0.0077813445 |
|    clip_fraction         | 0.0552       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00598     |
|    cost_value_loss       | 4.2e-06      |
|    cost_values           | -0.00607     |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00561      |
|    n_updates             | 14100        |
|    policy_gradient_loss  | 0.000289     |
|    std                   | 0.51         |
|    value_loss            | 0.0121       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.017        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.017        |
| reward                   | -0.42741397  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 40           |
|    time_elapsed          | 892          |
|    total_timesteps       | 2891776      |
| train/                   |              |
|    approx_kl             | 0.0026934783 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000813     |
|    cost_value_loss       | 1.55e-06     |
|    cost_values           | 0.000818     |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00116     |
|    n_updates             | 14110        |
|    policy_gradient_loss  | -0.000547    |
|    std                   | 0.51         |
|    value_loss            | 0.0058       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0703      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0703      |
| reward                   | -0.47261497 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 915         |
|    total_timesteps       | 2893824     |
| train/                   |             |
|    approx_kl             | 0.004152742 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00416    |
|    cost_value_loss       | 1.75e-06    |
|    cost_values           | -0.00418    |
|    entropy               | -1.27       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00784    |
|    n_updates             | 14120       |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.509       |
|    value_loss            | 0.00771     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00484      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00484      |
| reward                   | -0.51600295  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 42           |
|    time_elapsed          | 937          |
|    total_timesteps       | 2895872      |
| train/                   |              |
|    approx_kl             | 0.0037464723 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00189     |
|    cost_value_loss       | 1.34e-06     |
|    cost_values           | -0.00186     |
|    entropy               | -1.26        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00451     |
|    n_updates             | 14130        |
|    policy_gradient_loss  | -0.000992    |
|    std                   | 0.506        |
|    value_loss            | 0.00832      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0486      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0486      |
| reward                   | -0.37151316 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 959         |
|    total_timesteps       | 2897920     |
| train/                   |             |
|    approx_kl             | 0.007446547 |
|    clip_fraction         | 0.0547      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.006      |
|    cost_value_loss       | 4.57e-06    |
|    cost_values           | -0.00607    |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00125     |
|    n_updates             | 14140       |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.505       |
|    value_loss            | 0.0146      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.33209896  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 44           |
|    time_elapsed          | 981          |
|    total_timesteps       | 2899968      |
| train/                   |              |
|    approx_kl             | 0.0070309374 |
|    clip_fraction         | 0.0776       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00615     |
|    cost_value_loss       | 5.86e-06     |
|    cost_values           | -0.00627     |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.47         |
|    n_updates             | 14150        |
|    policy_gradient_loss  | 0.00124      |
|    std                   | 0.505        |
|    value_loss            | 1.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0464       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0464       |
| reward                   | -0.32088324  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 45           |
|    time_elapsed          | 1004         |
|    total_timesteps       | 2902016      |
| train/                   |              |
|    approx_kl             | 0.0031575044 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000102     |
|    cost_value_loss       | 2.15e-06     |
|    cost_values           | 0.000135     |
|    entropy               | -1.25        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00307      |
|    n_updates             | 14160        |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.503        |
|    value_loss            | 0.0131       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0126       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0126       |
| reward                   | -0.4276105   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 46           |
|    time_elapsed          | 1026         |
|    total_timesteps       | 2904064      |
| train/                   |              |
|    approx_kl             | 0.0033580665 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00147     |
|    cost_value_loss       | 1.44e-06     |
|    cost_values           | -0.00151     |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00155     |
|    n_updates             | 14170        |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.502        |
|    value_loss            | 0.0116       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0918      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0918      |
| reward                   | -0.47226408 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 47          |
|    time_elapsed          | 1049        |
|    total_timesteps       | 2906112     |
| train/                   |             |
|    approx_kl             | 0.003788317 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00414    |
|    cost_value_loss       | 2.33e-06    |
|    cost_values           | -0.00417    |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00889     |
|    n_updates             | 14180       |
|    policy_gradient_loss  | -0.000531   |
|    std                   | 0.502       |
|    value_loss            | 0.0221      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0333      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0333      |
| reward                   | -0.25070155 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1071        |
|    total_timesteps       | 2908160     |
| train/                   |             |
|    approx_kl             | 0.008741135 |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00233    |
|    cost_value_loss       | 5.99e-06    |
|    cost_values           | -0.00241    |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00603    |
|    n_updates             | 14190       |
|    policy_gradient_loss  | -0.00075    |
|    std                   | 0.502       |
|    value_loss            | 0.00524     |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.032        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.032        |
| reward                   | -0.4723844   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 49           |
|    time_elapsed          | 1093         |
|    total_timesteps       | 2910208      |
| train/                   |              |
|    approx_kl             | 0.0068104025 |
|    clip_fraction         | 0.0707       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00524      |
|    cost_value_loss       | 6.4e-06      |
|    cost_values           | 0.00564      |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00401      |
|    n_updates             | 14200        |
|    policy_gradient_loss  | -0.000621    |
|    std                   | 0.502        |
|    value_loss            | 0.00537      |
-------------------------------------------
------------------------------------
| avg_speed          | 0.14        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.14        |
| reward             | -0.20726606 |
| rollout/           |             |
|    ep_len_mean     | 994         |
|    ep_rew_mean     | -423        |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2912256     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.0314       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0314       |
| reward                   | -0.47065455  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 2914304      |
| train/                   |              |
|    approx_kl             | 0.0059696054 |
|    clip_fraction         | 0.0414       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0019       |
|    cost_value_loss       | 3.75e-06     |
|    cost_values           | 0.00197      |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00169      |
|    n_updates             | 14220        |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.497        |
|    value_loss            | 0.0415       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0164      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0164      |
| reward                   | -0.25124156 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 2916352     |
| train/                   |             |
|    approx_kl             | 0.00903568  |
|    clip_fraction         | 0.0755      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00241    |
|    cost_value_loss       | 4.3e-06     |
|    cost_values           | -0.00246    |
|    entropy               | -1.23       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00901     |
|    n_updates             | 14230       |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.497       |
|    value_loss            | 0.0105      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0805       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0805       |
| reward                   | -0.5131425   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 2918400      |
| train/                   |              |
|    approx_kl             | 0.0048165997 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000911     |
|    cost_value_loss       | 1.35e-06     |
|    cost_values           | 0.000962     |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00297     |
|    n_updates             | 14240        |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.496        |
|    value_loss            | 0.0101       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0539      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0539      |
| reward                   | -0.33873537 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2920448     |
| train/                   |             |
|    approx_kl             | 0.009261576 |
|    clip_fraction         | 0.0605      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00202    |
|    cost_value_loss       | 7.12e-07    |
|    cost_values           | -0.00204    |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0113     |
|    n_updates             | 14250       |
|    policy_gradient_loss  | -0.000931   |
|    std                   | 0.497       |
|    value_loss            | 0.00587     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0884      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0884      |
| reward                   | -0.38793638 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 6           |
|    time_elapsed          | 135         |
|    total_timesteps       | 2922496     |
| train/                   |             |
|    approx_kl             | 0.003584249 |
|    clip_fraction         | 0.0566      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00107    |
|    cost_value_loss       | 3.51e-06    |
|    cost_values           | -0.00108    |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0108      |
|    n_updates             | 14260       |
|    policy_gradient_loss  | 0.00154     |
|    std                   | 0.497       |
|    value_loss            | 0.0141      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0744      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0744      |
| reward                   | -0.3059596  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2924544     |
| train/                   |             |
|    approx_kl             | 0.007560085 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00344     |
|    cost_value_loss       | 3.68e-06    |
|    cost_values           | 0.00337     |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0104      |
|    n_updates             | 14270       |
|    policy_gradient_loss  | -0.000789   |
|    std                   | 0.497       |
|    value_loss            | 0.0322      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0454       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0454       |
| reward                   | -0.47042254  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 8            |
|    time_elapsed          | 179          |
|    total_timesteps       | 2926592      |
| train/                   |              |
|    approx_kl             | 0.0037943379 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00356     |
|    cost_value_loss       | 2.61e-06     |
|    cost_values           | -0.00361     |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000944     |
|    n_updates             | 14280        |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.496        |
|    value_loss            | 0.0265       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0126      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0126      |
| reward                   | -0.32012695 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2928640     |
| train/                   |             |
|    approx_kl             | 0.004033418 |
|    clip_fraction         | 0.0478      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00201     |
|    cost_value_loss       | 1.33e-06    |
|    cost_values           | 0.002       |
|    entropy               | -1.22       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00561     |
|    n_updates             | 14290       |
|    policy_gradient_loss  | -0.00352    |
|    std                   | 0.494       |
|    value_loss            | 0.0158      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.29315257  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 10           |
|    time_elapsed          | 224          |
|    total_timesteps       | 2930688      |
| train/                   |              |
|    approx_kl             | 0.0035020541 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00121     |
|    cost_value_loss       | 7.12e-07     |
|    cost_values           | -0.00126     |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0052       |
|    n_updates             | 14300        |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.494        |
|    value_loss            | 0.016        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.179       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.179       |
| reward                   | -0.39574778 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2932736     |
| train/                   |             |
|    approx_kl             | 0.00469687  |
|    clip_fraction         | 0.05        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00107    |
|    cost_value_loss       | 3.9e-07     |
|    cost_values           | -0.00108    |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00651    |
|    n_updates             | 14310       |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.493       |
|    value_loss            | 0.0154      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.121        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.121        |
| reward                   | -0.4893753   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 12           |
|    time_elapsed          | 269          |
|    total_timesteps       | 2934784      |
| train/                   |              |
|    approx_kl             | 0.0044160513 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00261      |
|    cost_value_loss       | 1.04e-06     |
|    cost_values           | 0.00259      |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00733      |
|    n_updates             | 14320        |
|    policy_gradient_loss  | -0.000102    |
|    std                   | 0.491        |
|    value_loss            | 0.0228       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0354       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0354       |
| reward                   | -0.5111154   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 13           |
|    time_elapsed          | 291          |
|    total_timesteps       | 2936832      |
| train/                   |              |
|    approx_kl             | 0.0028525307 |
|    clip_fraction         | 0.118        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00465      |
|    cost_value_loss       | 2.02e-06     |
|    cost_values           | 0.00461      |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.32         |
|    n_updates             | 14330        |
|    policy_gradient_loss  | -0.000308    |
|    std                   | 0.491        |
|    value_loss            | 1.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0579       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0579       |
| reward                   | -0.40583766  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 14           |
|    time_elapsed          | 313          |
|    total_timesteps       | 2938880      |
| train/                   |              |
|    approx_kl             | 0.0053176507 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000803     |
|    cost_value_loss       | 2.29e-06     |
|    cost_values           | 0.000887     |
|    entropy               | -1.2         |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00368      |
|    n_updates             | 14340        |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.49         |
|    value_loss            | 0.015        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0545       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0545       |
| reward                   | -0.37681973  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 15           |
|    time_elapsed          | 335          |
|    total_timesteps       | 2940928      |
| train/                   |              |
|    approx_kl             | 0.0049665775 |
|    clip_fraction         | 0.0465       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0023       |
|    cost_value_loss       | 2.79e-06     |
|    cost_values           | 0.00231      |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00811      |
|    n_updates             | 14350        |
|    policy_gradient_loss  | -0.00393     |
|    std                   | 0.49         |
|    value_loss            | 0.0344       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.215        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.215        |
| reward                   | -0.30946732  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 16           |
|    time_elapsed          | 358          |
|    total_timesteps       | 2942976      |
| train/                   |              |
|    approx_kl             | 0.0027784049 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00118     |
|    cost_value_loss       | 2.37e-06     |
|    cost_values           | -0.00113     |
|    entropy               | -1.21        |
|    entropy_loss          | -1.2         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00702      |
|    n_updates             | 14360        |
|    policy_gradient_loss  | -0.000918    |
|    std                   | 0.49         |
|    value_loss            | 0.0245       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0236      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0236      |
| reward                   | -0.4436677  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 381         |
|    total_timesteps       | 2945024     |
| train/                   |             |
|    approx_kl             | 0.003581768 |
|    clip_fraction         | 0.0271      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00147     |
|    cost_value_loss       | 4.45e-06    |
|    cost_values           | 0.00155     |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00126    |
|    n_updates             | 14370       |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.492       |
|    value_loss            | 0.0117      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00497      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00497      |
| reward                   | -0.46271795  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 18           |
|    time_elapsed          | 403          |
|    total_timesteps       | 2947072      |
| train/                   |              |
|    approx_kl             | 0.0035812655 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00256      |
|    cost_value_loss       | 8.9e-06      |
|    cost_values           | 0.0029       |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0687       |
|    n_updates             | 14380        |
|    policy_gradient_loss  | -0.000768    |
|    std                   | 0.492        |
|    value_loss            | 0.0706       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0389      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0389      |
| reward                   | -0.37736815 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 425         |
|    total_timesteps       | 2949120     |
| train/                   |             |
|    approx_kl             | 0.008726787 |
|    clip_fraction         | 0.0677      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00637     |
|    cost_value_loss       | 1.8e-06     |
|    cost_values           | 0.00627     |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00304     |
|    n_updates             | 14390       |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.491       |
|    value_loss            | 0.017       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0268       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0268       |
| reward                   | -0.3779572   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 20           |
|    time_elapsed          | 447          |
|    total_timesteps       | 2951168      |
| train/                   |              |
|    approx_kl             | 0.0045591635 |
|    clip_fraction         | 0.0468       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00682      |
|    cost_value_loss       | 2.66e-06     |
|    cost_values           | 0.00689      |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00395      |
|    n_updates             | 14400        |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.491        |
|    value_loss            | 0.0339       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0955       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0955       |
| reward                   | -0.4092232   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 21           |
|    time_elapsed          | 470          |
|    total_timesteps       | 2953216      |
| train/                   |              |
|    approx_kl             | 0.0042610867 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.005        |
|    cost_value_loss       | 1.52e-06     |
|    cost_values           | 0.00496      |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00571      |
|    n_updates             | 14410        |
|    policy_gradient_loss  | -0.000929    |
|    std                   | 0.492        |
|    value_loss            | 0.0304       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.082       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.082       |
| reward                   | -0.37688026 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 492         |
|    total_timesteps       | 2955264     |
| train/                   |             |
|    approx_kl             | 0.002008101 |
|    clip_fraction         | 0.0266      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00533     |
|    cost_value_loss       | 1.46e-06    |
|    cost_values           | 0.00537     |
|    entropy               | -1.22       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.53e-05    |
|    n_updates             | 14420       |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.493       |
|    value_loss            | 0.0131      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.37788302  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 23           |
|    time_elapsed          | 514          |
|    total_timesteps       | 2957312      |
| train/                   |              |
|    approx_kl             | 0.0043649934 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00672      |
|    cost_value_loss       | 3.5e-06      |
|    cost_values           | 0.00671      |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0.757        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000317    |
|    n_updates             | 14430        |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.493        |
|    value_loss            | 0.0136       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0727       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0727       |
| reward                   | -0.3224155   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 24           |
|    time_elapsed          | 537          |
|    total_timesteps       | 2959360      |
| train/                   |              |
|    approx_kl             | 0.0047840495 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00567      |
|    cost_value_loss       | 8.75e-07     |
|    cost_values           | 0.00571      |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00701     |
|    n_updates             | 14440        |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.496        |
|    value_loss            | 0.00821      |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.0145     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0145     |
| reward                   | -0.5487408 |
| rollout/                 |            |
|    ep_len_mean           | 987        |
|    ep_rew_mean           | -402       |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 25         |
|    time_elapsed          | 559        |
|    total_timesteps       | 2961408    |
| train/                   |            |
|    approx_kl             | 0.00423925 |
|    clip_fraction         | 0.018      |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0027     |
|    cost_value_loss       | 1.77e-06   |
|    cost_values           | 0.00272    |
|    entropy               | -1.23      |
|    entropy_loss          | -1.22      |
|    explained_variance    | 0.997      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.0128     |
|    n_updates             | 14450      |
|    policy_gradient_loss  | -0.000688  |
|    std                   | 0.499      |
|    value_loss            | 0.0152     |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.00533      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00533      |
| reward                   | -0.42599127  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 26           |
|    time_elapsed          | 581          |
|    total_timesteps       | 2963456      |
| train/                   |              |
|    approx_kl             | 0.0038842815 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00229      |
|    cost_value_loss       | 1.69e-06     |
|    cost_values           | 0.00239      |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00107     |
|    n_updates             | 14460        |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.5          |
|    value_loss            | 0.0194       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0419       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0419       |
| reward                   | -0.30808446  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 27           |
|    time_elapsed          | 603          |
|    total_timesteps       | 2965504      |
| train/                   |              |
|    approx_kl             | 0.0027138488 |
|    clip_fraction         | 0.06         |
|    clip_range            | 0.2          |
|    cost_returns          | -1.31e-05    |
|    cost_value_loss       | 0.000345     |
|    cost_values           | 0.000736     |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.009        |
|    n_updates             | 14470        |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.5          |
|    value_loss            | 0.0282       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0649      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0649      |
| reward                   | -0.45161155 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 625         |
|    total_timesteps       | 2967552     |
| train/                   |             |
|    approx_kl             | 0.005867538 |
|    clip_fraction         | 0.0532      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00097    |
|    cost_value_loss       | 8.63e-06    |
|    cost_values           | -0.000635   |
|    entropy               | -1.23       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0092      |
|    n_updates             | 14480       |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.499       |
|    value_loss            | 0.0268      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.134        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.134        |
| reward                   | -0.5047241   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 29           |
|    time_elapsed          | 648          |
|    total_timesteps       | 2969600      |
| train/                   |              |
|    approx_kl             | 0.0029692329 |
|    clip_fraction         | 0.00566      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00736      |
|    cost_value_loss       | 4.49e-06     |
|    cost_values           | 0.00738      |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0118       |
|    n_updates             | 14490        |
|    policy_gradient_loss  | -0.000983    |
|    std                   | 0.499        |
|    value_loss            | 0.0487       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0856       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0856       |
| reward                   | -0.5114039   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 30           |
|    time_elapsed          | 670          |
|    total_timesteps       | 2971648      |
| train/                   |              |
|    approx_kl             | 0.0041844826 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.012        |
|    cost_value_loss       | 6.21e-06     |
|    cost_values           | 0.012        |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00872      |
|    n_updates             | 14500        |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.499        |
|    value_loss            | 0.0156       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00531      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00531      |
| reward                   | -0.37818274  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 31           |
|    time_elapsed          | 693          |
|    total_timesteps       | 2973696      |
| train/                   |              |
|    approx_kl             | 0.0054200017 |
|    clip_fraction         | 0.0621       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00213      |
|    cost_value_loss       | 1.31e-06     |
|    cost_values           | 0.00212      |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00129      |
|    n_updates             | 14510        |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.499        |
|    value_loss            | 0.00769      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0689       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0689       |
| reward                   | -0.25936475  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 32           |
|    time_elapsed          | 715          |
|    total_timesteps       | 2975744      |
| train/                   |              |
|    approx_kl             | 0.0058393935 |
|    clip_fraction         | 0.0508       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00515     |
|    cost_value_loss       | 2.09e-06     |
|    cost_values           | -0.00516     |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00145      |
|    n_updates             | 14520        |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.5          |
|    value_loss            | 0.00346      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00247      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00247      |
| reward                   | -0.38850608  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 33           |
|    time_elapsed          | 737          |
|    total_timesteps       | 2977792      |
| train/                   |              |
|    approx_kl             | 0.0073195365 |
|    clip_fraction         | 0.0552       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000287     |
|    cost_value_loss       | 1.18e-06     |
|    cost_values           | 0.000316     |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0222       |
|    n_updates             | 14530        |
|    policy_gradient_loss  | 0.000466     |
|    std                   | 0.501        |
|    value_loss            | 0.0241       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0905       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0905       |
| reward                   | -0.5113663   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 34           |
|    time_elapsed          | 759          |
|    total_timesteps       | 2979840      |
| train/                   |              |
|    approx_kl             | 0.0049513252 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00786      |
|    cost_value_loss       | 5.96e-06     |
|    cost_values           | 0.00793      |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0262       |
|    n_updates             | 14540        |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.501        |
|    value_loss            | 0.02         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.0096     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0096     |
| reward                   | -0.4281733 |
| rollout/                 |            |
|    ep_len_mean           | 987        |
|    ep_rew_mean           | -406       |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 35         |
|    time_elapsed          | 782        |
|    total_timesteps       | 2981888    |
| train/                   |            |
|    approx_kl             | 0.00803483 |
|    clip_fraction         | 0.0373     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00362    |
|    cost_value_loss       | 3.72e-06   |
|    cost_values           | 0.00387    |
|    entropy               | -1.24      |
|    entropy_loss          | -1.24      |
|    explained_variance    | 0.998      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | -0.00118   |
|    n_updates             | 14550      |
|    policy_gradient_loss  | -0.000111  |
|    std                   | 0.503      |
|    value_loss            | 0.00786    |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0577      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0577      |
| reward                   | -0.3931573  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 804         |
|    total_timesteps       | 2983936     |
| train/                   |             |
|    approx_kl             | 0.007206227 |
|    clip_fraction         | 0.0749      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000487   |
|    cost_value_loss       | 1.7e-06     |
|    cost_values           | -0.000478   |
|    entropy               | -1.23       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00526     |
|    n_updates             | 14560       |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.5         |
|    value_loss            | 0.0127      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0144      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0144      |
| reward                   | -0.34900278 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 826         |
|    total_timesteps       | 2985984     |
| train/                   |             |
|    approx_kl             | 0.004426203 |
|    clip_fraction         | 0.0695      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000854    |
|    cost_value_loss       | 1.45e-06    |
|    cost_values           | 0.000859    |
|    entropy               | -1.22       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00736    |
|    n_updates             | 14570       |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 0.498       |
|    value_loss            | 0.00496     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0678      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0678      |
| reward                   | -0.47065723 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 848         |
|    total_timesteps       | 2988032     |
| train/                   |             |
|    approx_kl             | 0.003659113 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000848   |
|    cost_value_loss       | 1.9e-06     |
|    cost_values           | -0.00087    |
|    entropy               | -1.23       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.000241   |
|    n_updates             | 14580       |
|    policy_gradient_loss  | -0.00044    |
|    std                   | 0.499       |
|    value_loss            | 0.0151      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0785       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0785       |
| reward                   | -0.40798673  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 39           |
|    time_elapsed          | 871          |
|    total_timesteps       | 2990080      |
| train/                   |              |
|    approx_kl             | 0.0034123342 |
|    clip_fraction         | 0.0585       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0043       |
|    cost_value_loss       | 2.23e-06     |
|    cost_values           | 0.00425      |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00705      |
|    n_updates             | 14590        |
|    policy_gradient_loss  | -0.000673    |
|    std                   | 0.501        |
|    value_loss            | 0.00578      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0612       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0612       |
| reward                   | -0.54125535  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 40           |
|    time_elapsed          | 893          |
|    total_timesteps       | 2992128      |
| train/                   |              |
|    approx_kl             | 0.0030811967 |
|    clip_fraction         | 0.0616       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0013      |
|    cost_value_loss       | 3.02e-07     |
|    cost_values           | -0.00133     |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00237     |
|    n_updates             | 14600        |
|    policy_gradient_loss  | 0.000306     |
|    std                   | 0.501        |
|    value_loss            | 0.00245      |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0113      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0113      |
| reward                   | -0.37745398 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 915         |
|    total_timesteps       | 2994176     |
| train/                   |             |
|    approx_kl             | 0.003315052 |
|    clip_fraction         | 0.049       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00206     |
|    cost_value_loss       | 2.17e-06    |
|    cost_values           | 0.00205     |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00846     |
|    n_updates             | 14610       |
|    policy_gradient_loss  | -0.0022     |
|    std                   | 0.5         |
|    value_loss            | 0.0227      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0164       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0164       |
| reward                   | -0.41116273  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 42           |
|    time_elapsed          | 937          |
|    total_timesteps       | 2996224      |
| train/                   |              |
|    approx_kl             | 0.0063964557 |
|    clip_fraction         | 0.0469       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000942    |
|    cost_value_loss       | 2.35e-06     |
|    cost_values           | -0.000963    |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00216      |
|    n_updates             | 14620        |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.5          |
|    value_loss            | 0.0039       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00708      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00708      |
| reward                   | -0.2497857   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 43           |
|    time_elapsed          | 960          |
|    total_timesteps       | 2998272      |
| train/                   |              |
|    approx_kl             | 0.0031017994 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00281     |
|    cost_value_loss       | 1.33e-06     |
|    cost_values           | -0.00288     |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0117       |
|    n_updates             | 14630        |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.5          |
|    value_loss            | 0.0243       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0249      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0249      |
| reward                   | -0.5015172  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 44          |
|    time_elapsed          | 982         |
|    total_timesteps       | 3000320     |
| train/                   |             |
|    approx_kl             | 0.004872096 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00276     |
|    cost_value_loss       | 6.69e-06    |
|    cost_values           | 0.00246     |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0156      |
|    n_updates             | 14640       |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.499       |
|    value_loss            | 0.0327      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.3904253   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 45           |
|    time_elapsed          | 1005         |
|    total_timesteps       | 3002368      |
| train/                   |              |
|    approx_kl             | 0.0057748924 |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00388      |
|    cost_value_loss       | 8.19e-07     |
|    cost_values           | 0.00386      |
|    entropy               | -1.2         |
|    entropy_loss          | -1.21        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0022       |
|    n_updates             | 14650        |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.494        |
|    value_loss            | 0.00783      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0163       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0163       |
| reward                   | -0.34471226  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 46           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 3004416      |
| train/                   |              |
|    approx_kl             | 0.0065435683 |
|    clip_fraction         | 0.0492       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00215      |
|    cost_value_loss       | 2.62e-06     |
|    cost_values           | 0.00217      |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00147     |
|    n_updates             | 14660        |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.495        |
|    value_loss            | 0.0127       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0965      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0965      |
| reward                   | -0.33826616 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 47          |
|    time_elapsed          | 1049        |
|    total_timesteps       | 3006464     |
| train/                   |             |
|    approx_kl             | 0.006202929 |
|    clip_fraction         | 0.0903      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00232     |
|    cost_value_loss       | 2.54e-06    |
|    cost_values           | 0.00234     |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00838     |
|    n_updates             | 14670       |
|    policy_gradient_loss  | -0.00495    |
|    std                   | 0.495       |
|    value_loss            | 0.00665     |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0662      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0662      |
| reward                   | -0.55049604 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1072        |
|    total_timesteps       | 3008512     |
| train/                   |             |
|    approx_kl             | 0.007958087 |
|    clip_fraction         | 0.0834      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.05e-05    |
|    cost_value_loss       | 1.08e-06    |
|    cost_values           | 7.2e-05     |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00265    |
|    n_updates             | 14680       |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.496       |
|    value_loss            | 0.0117      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0674       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0674       |
| reward                   | -0.5505636   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 49           |
|    time_elapsed          | 1094         |
|    total_timesteps       | 3010560      |
| train/                   |              |
|    approx_kl             | 0.0044992496 |
|    clip_fraction         | 0.033        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0028       |
|    cost_value_loss       | 1.03e-06     |
|    cost_values           | 0.00278      |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00683     |
|    n_updates             | 14690        |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.501        |
|    value_loss            | 0.00303      |
-------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3194275498390198
Final reward: -0.3195717930793762
Final reward: -0.3196745812892914
Final reward: -0.31974318623542786
Final reward: -0.3197580873966217
Final reward: -0.31978797912597656
Final reward: -0.31988897919654846
Final reward: -0.31979456543922424
Final reward: -0.319790780544281
Final reward: -0.31966570019721985
Final reward: -0.3197380006313324
Final reward: -0.31968772411346436
Final reward: -0.31979283690452576
Final reward: -0.3198297917842865
Final reward: -0.31966185569763184
Final reward: -0.31962600350379944
Final reward: -0.3196702301502228
Final reward: -0.3197510242462158
Final reward: -0.3196942210197449
Final reward: -0.31967997550964355
Final reward: -0.3195714056491852
Final reward: -0.3196750283241272
Final reward: -0.3196588158607483
Final reward: -0.31971487402915955
Final reward: -0.3197495937347412
Final reward: -0.3197557330131531
Final reward: -0.31986722350120544
Final reward: -0.31981781125068665
Final reward: -0.31970182061195374
Final reward: -0.3197474181652069
Final reward: -0.31971198320388794
Final reward: -0.31978318095207214
Final reward: -0.3197425901889801
Final reward: -0.31975892186164856
Final reward: -0.3199331760406494
Final reward: -0.31989607214927673
Final reward: -0.31985825300216675
Final reward: -0.3199641704559326
Final reward: -0.31989794969558716
Final reward: -0.3199671804904938
Final reward: -0.3200433850288391
Final reward: -0.3199778199195862
Final reward: -0.3199102282524109
Final reward: -0.31986725330352783
Final reward: -0.31985437870025635
Final reward: -0.3198401629924774
Final reward: -0.319824755191803
Final reward: -0.31985655426979065
Final reward: -0.31988832354545593
Final reward: -0.3199281394481659
Final reward: -0.3199477195739746
Final reward: -0.3200345039367676
Final reward: -0.320000559091568
Final reward: -0.32001569867134094
Final reward: -0.320072740316391
Final reward: -0.3200426995754242
Final reward: -0.3199532628059387
Final reward: -0.3199763000011444
Final reward: -0.3198455572128296
Final reward: -0.3199579119682312
Final reward: -0.31998002529144287
Final reward: -0.3198554813861847
Final reward: -0.3199780285358429
Final reward: -0.31997692584991455
Final reward: -0.3199097216129303
Final reward: -0.31989651918411255
Final reward: -0.3200695216655731
Final reward: -0.3201076090335846
Final reward: -0.3200160264968872
Final reward: -0.3200235664844513
Final reward: -0.3199348449707031
Final reward: -0.3199789822101593
Final reward: -0.3198753893375397
Final reward: -0.31992107629776
Final reward: -0.31977546215057373
Final reward: -0.31985729932785034
Final reward: -0.3199233412742615
Final reward: -0.31994134187698364
Final reward: -0.3199080526828766
Final reward: -0.31988343596458435
Final reward: -0.31974202394485474
Final reward: -0.31976795196533203
Final reward: -0.31965169310569763
Final reward: -0.3197833001613617
Final reward: -0.3197578191757202
Final reward: -0.3197660446166992
Final reward: -0.3198123872280121
Final reward: -0.3198818564414978
Final reward: -0.31980445981025696
Final reward: -0.31969955563545227
Final reward: -0.31960147619247437
Final reward: -0.319502055644989
Final reward: -0.3196626901626587
Final reward: -0.3197459578514099
Final reward: -0.3198901414871216
Final reward: -0.3197956383228302
Final reward: -0.31982728838920593
Final reward: -0.3198637068271637
Final reward: -0.31995517015457153
Final reward: -0.3198310136795044
Final reward: -0.3197281062602997
Final reward: -0.31985533237457275
Final reward: -0.31996551156044006
Final reward: -0.3200703561306
Final reward: -0.3200487494468689
Final reward: -0.32001596689224243
Final reward: -0.3199193477630615
Final reward: -0.319807767868042
Final reward: -0.31975558400154114
Final reward: -0.31973686814308167
Final reward: -0.3196541666984558
Final reward: -0.3198632299900055
Final reward: -0.3199116587638855
Final reward: -0.3199366331100464
Final reward: -0.3200201094150543
Final reward: -0.3200017213821411
Final reward: -0.32012736797332764
Final reward: -0.3199654519557953
Final reward: -0.3198716342449188
Final reward: -0.31990236043930054
Final reward: -0.3199099600315094
Final reward: -0.31994324922561646
Final reward: -0.3198796212673187
Final reward: -0.3199373781681061
Final reward: -0.3198075294494629
Final reward: -0.31984391808509827
Final reward: -0.3197982907295227
Final reward: -0.31988394260406494
Final reward: -0.3197824954986572
Final reward: -0.3196999728679657
Final reward: -0.31975027918815613
Final reward: -0.31975752115249634
Final reward: -0.31985002756118774
Final reward: -0.3199044466018677
Final reward: -0.31988412141799927
Final reward: -0.3197471499443054
Final reward: -0.31978553533554077
Final reward: -0.3198728859424591
Final reward: -0.31996434926986694
Final reward: -0.32001739740371704
Final reward: -0.32014214992523193
Final reward: -0.32015401124954224
Final reward: -0.32015711069107056
Final reward: -0.3201637268066406
Final reward: -0.32023075222969055
Final reward: -0.3201659023761749
Final reward: -0.320285826921463
Final reward: -0.3202522099018097
Final reward: -0.3202686607837677
Final reward: -0.32033371925354004
Final reward: -0.3202768862247467
Final reward: -0.3201172351837158
Final reward: -0.3199240267276764
Final reward: -0.31994131207466125
Final reward: -0.31993985176086426
Final reward: -0.32009074091911316
Final reward: -0.3200373351573944
Final reward: -0.3200678825378418
Final reward: -0.3200179636478424
Final reward: -0.32013988494873047
Final reward: -0.3201330304145813
Final reward: -0.32018816471099854
Final reward: -0.32018664479255676
Final reward: -0.3201005160808563
Final reward: -0.3198934495449066
Final reward: -0.31993111968040466
Final reward: -0.31986916065216064
Final reward: -0.319844514131546
Final reward: -0.31989920139312744
Final reward: -0.32000526785850525
Final reward: -0.31995970010757446
Final reward: -0.32001641392707825
Final reward: -0.3200387954711914
Final reward: -0.32010746002197266
Final reward: -0.32005155086517334
Final reward: -0.3200395405292511
Final reward: -0.3202015161514282
Final reward: -0.32016265392303467
Final reward: -0.32021111249923706
Final reward: -0.3202514052391052
Final reward: -0.32027673721313477
Final reward: -0.3203904628753662
Final reward: -0.3202522397041321
Final reward: -0.32014891505241394
Final reward: -0.3201581835746765
Final reward: -0.32014647126197815
Final reward: -0.32009953260421753
Final reward: -0.32003259658813477
Final reward: -0.31999897956848145
Final reward: -0.31998899579048157
Final reward: -0.32005754113197327
Final reward: -0.32015088200569153
Final reward: -0.32012516260147095
Final reward: -0.32014816999435425
Final reward: -0.3200768232345581
Final reward: -0.3201913833618164
Final reward: -0.3201642334461212
Final reward: -0.32018446922302246
Final reward: -0.32018640637397766
Final reward: -0.3203164339065552
Final reward: -0.3202885389328003
Final reward: -0.3202586770057678
Final reward: -0.3202078938484192
Final reward: -0.32013610005378723
Final reward: -0.3200666308403015
Final reward: -0.32024702429771423
Final reward: -0.3202086091041565
Final reward: -0.3200242519378662
Final reward: -0.3200591802597046
Final reward: -0.3200664818286896
Final reward: -0.320158451795578
Final reward: -0.3200954496860504
Final reward: -0.3202032148838043
Final reward: -0.32013729214668274
Final reward: -0.3201332092285156
Final reward: -0.3201301395893097
Final reward: -0.3200889229774475
Final reward: -0.32003533840179443
Final reward: -0.31998494267463684
Final reward: -0.32005441188812256
Final reward: -0.31988105177879333
Final reward: -0.31990161538124084
Final reward: -0.3199550211429596
Final reward: -0.31991565227508545
Final reward: -0.3199266493320465
Final reward: -0.3198983371257782
Final reward: -0.31993964314460754
Final reward: -0.32008597254753113
Final reward: -0.32004329562187195
Final reward: -0.3200213611125946
Final reward: -0.32014983892440796
Final reward: -0.3201599717140198
Final reward: -0.32021406292915344
Final reward: -0.32012754678726196
Final reward: -0.32004740834236145
Final reward: -0.31998443603515625
Final reward: -0.3199648857116699
Final reward: -0.31993845105171204
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3197984993457794
Final reward: -0.31988662481307983
Final reward: -0.3199235796928406
Final reward: -0.3201281726360321
Final reward: -0.3200209438800812
Final reward: -0.31999629735946655
Final reward: -0.32014355063438416
Final reward: -0.3201528489589691
Final reward: -0.32012826204299927
Final reward: -0.32008108496665955
Final reward: -0.3200361132621765
Final reward: -0.3199230432510376
Final reward: -0.3198733627796173
Final reward: -0.3198952376842499
Final reward: -0.3198091685771942
Final reward: -0.3200010061264038
Final reward: -0.32006800174713135
Final reward: -0.320140540599823
Final reward: -0.320171594619751
Final reward: -0.32017865777015686
Final reward: -0.3202279806137085
Final reward: -0.3201822340488434
Final reward: -0.32019346952438354
Final reward: -0.3200720250606537
Final reward: -0.3201071321964264
Final reward: -0.3200904428958893
Final reward: -0.32000356912612915
Final reward: -0.32005396485328674
Final reward: -0.3201461732387543
Final reward: -0.3200990855693817
Final reward: -0.3200134336948395
Final reward: -0.32020169496536255
Final reward: -0.3202354311943054
Final reward: -0.320158988237381
Final reward: -0.3201635181903839
Final reward: -0.320207417011261
Final reward: -0.3202298879623413
Final reward: -0.3201605975627899
Final reward: -0.32029733061790466
Final reward: -0.32026275992393494
Final reward: -0.32026422023773193
Final reward: -0.32036152482032776
Final reward: -0.3204073905944824
Final reward: -0.3203651010990143
Final reward: -0.32031360268592834
Final reward: -0.3203483819961548
Final reward: -0.32028135657310486
Final reward: -0.32014137506484985
Final reward: -0.3201698362827301
Final reward: -0.32012632489204407
Final reward: -0.3201823830604553
Final reward: -0.32015031576156616
Final reward: -0.3200526237487793
Final reward: -0.3200691044330597
Final reward: -0.3200584948062897
Final reward: -0.32005059719085693
Final reward: -0.31998658180236816
Final reward: -0.3200564682483673
Final reward: -0.32006826996803284
Final reward: -0.320044606924057
Final reward: -0.32002007961273193
Final reward: -0.3198716640472412
Final reward: -0.3197890818119049
Final reward: -0.3197626769542694
Final reward: -0.3199024796485901
Final reward: -0.320013165473938
Final reward: -0.32027092576026917
Final reward: -0.3201735019683838
Final reward: -0.32006824016571045
Final reward: -0.32013821601867676
Final reward: -0.32012829184532166
Final reward: -0.3201253116130829
Final reward: -0.3201546370983124
Final reward: -0.32001593708992004
Final reward: -0.3199460804462433
Final reward: -0.3197762668132782
Final reward: -0.3198696970939636
Final reward: -0.31993478536605835
Final reward: -0.3198659420013428
Final reward: -0.3198738992214203
Final reward: -0.319918692111969
Final reward: -0.3200434148311615
Final reward: -0.32001879811286926
Final reward: -0.31997060775756836
Final reward: -0.3200998902320862
Final reward: -0.32006460428237915
Final reward: -0.32012394070625305
Final reward: -0.3199675679206848
Final reward: -0.32000717520713806
Final reward: -0.32010844349861145
Final reward: -0.3201810419559479
Final reward: -0.3202289342880249
Final reward: -0.32017797231674194
Final reward: -0.32027292251586914
Final reward: -0.32030943036079407
Final reward: -0.3203834593296051
Final reward: -0.3205646872520447
Final reward: -0.3205007016658783
Final reward: -0.32050076127052307
Final reward: -0.32053685188293457
Final reward: -0.3204578757286072
Final reward: -0.32048243284225464
Final reward: -0.3204517960548401
Final reward: -0.3202120065689087
Final reward: -0.3201238214969635
Final reward: -0.3201986253261566
Final reward: -0.3201276361942291
Final reward: -0.3199400305747986
Final reward: -0.31996992230415344
Final reward: -0.31993019580841064
Final reward: -0.3200371563434601
Final reward: -0.31997454166412354
Final reward: -0.32016390562057495
Final reward: -0.320090115070343
Final reward: -0.3199322521686554
Final reward: -0.3200976550579071
Final reward: -0.3201771378517151
Final reward: -0.320036917924881
Final reward: -0.32013213634490967
Final reward: -0.32013335824012756
Final reward: -0.3199629485607147
Final reward: -0.320013165473938
Final reward: -0.319865882396698
Final reward: -0.31984689831733704
Final reward: -0.319980263710022
Final reward: -0.31993910670280457
Final reward: -0.31990107893943787
Final reward: -0.319831907749176
Final reward: -0.32012447714805603
Final reward: -0.32027751207351685
Final reward: -0.320260614156723
Final reward: -0.32029637694358826
Final reward: -0.3202357292175293
Final reward: -0.3202773928642273
Final reward: -0.3201470375061035
Final reward: -0.32019561529159546
Final reward: -0.3200930655002594
Final reward: -0.32013997435569763
Final reward: -0.32024550437927246
Final reward: -0.320159375667572
Final reward: -0.32011300325393677
Final reward: -0.32025521993637085
Final reward: -0.3203435242176056
Final reward: -0.3203144967556
Final reward: -0.32038846611976624
Final reward: -0.3204086422920227
Final reward: -0.3204413950443268
Final reward: -0.32050347328186035
Final reward: -0.3203947842121124
Final reward: -0.3203350603580475
Final reward: -0.3203318417072296
Final reward: -0.32028916478157043
Final reward: -0.32028859853744507
Final reward: -0.3203827738761902
Final reward: -0.3205055296421051
Final reward: -0.3204432725906372
Final reward: -0.3204902112483978
Final reward: -0.32038915157318115
Final reward: -0.3203352093696594
Final reward: -0.320444792509079
Final reward: -0.32039541006088257
Final reward: -0.3203950524330139
Final reward: -0.32032138109207153
Final reward: -0.3204406499862671
Final reward: -0.3203623294830322
Final reward: -0.3203466832637787
Final reward: -0.3204120397567749
Final reward: -0.32041656970977783
Final reward: -0.3205062448978424
Final reward: -0.32038623094558716
Final reward: -0.3202836513519287
Final reward: -0.3200916051864624
Final reward: -0.3201468884944916
Final reward: -0.32008054852485657
Final reward: -0.3200801908969879
Final reward: -0.3200719654560089
Final reward: -0.3199831545352936
Final reward: -0.3201334476470947
Final reward: -0.3203772306442261
Final reward: -0.32031503319740295
Final reward: -0.32027366757392883
Final reward: -0.32027527689933777
Final reward: -0.3203043043613434
Final reward: -0.3202911913394928
Final reward: -0.3202575445175171
Final reward: -0.32013940811157227
Final reward: -0.32001644372940063
Final reward: -0.3200068473815918
Final reward: -0.3201282024383545
Final reward: -0.32004114985466003
Final reward: -0.32010963559150696
Final reward: -0.32006728649139404
Final reward: -0.3202109634876251
Final reward: -0.3202909827232361
Final reward: -0.32027098536491394
Final reward: -0.3201736509799957
Final reward: -0.320311039686203
Final reward: -0.3203519582748413
Final reward: -0.3204234540462494
Final reward: -0.3203256130218506
Final reward: -0.32038387656211853
Final reward: -0.32052499055862427
Final reward: -0.3205290734767914
Final reward: -0.3205333948135376
Final reward: -0.3204318881034851
Final reward: -0.32032421231269836
Final reward: -0.320229172706604
Final reward: -0.32029590010643005
Final reward: -0.32032057642936707
Final reward: -0.3204081654548645
Final reward: -0.32039982080459595
Final reward: -0.32038381695747375
Final reward: -0.3204251229763031
Final reward: -0.3203766644001007
Final reward: -0.3201739192008972
Final reward: -0.3200177550315857
Final reward: -0.31999045610427856
Final reward: -0.3199726939201355
Final reward: -0.31994521617889404
Final reward: -0.31996896862983704
Final reward: -0.3200606107711792
Final reward: -0.3203318119049072
Final reward: -0.3203718960285187
Final reward: -0.3202022910118103
Final reward: -0.3202011287212372
Final reward: -0.3203502595424652
Final reward: -0.32034218311309814
Final reward: -0.32027992606163025
Final reward: -0.32023707032203674
Final reward: -0.32038044929504395
Final reward: -0.3202767074108124
Final reward: -0.32019177079200745
Final reward: -0.3202793598175049
Final reward: -0.32050415873527527
Final reward: -0.3204735815525055
Final reward: -0.3205113112926483
Final reward: -0.3205123245716095
Final reward: -0.32055243849754333
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3206031620502472
Final reward: -0.32054978609085083
Final reward: -0.32055869698524475
Final reward: -0.32060161232948303
Final reward: -0.3205178380012512
Final reward: -0.320516973733902
Final reward: -0.3203348219394684
Final reward: -0.32033106684684753
Final reward: -0.3203403353691101
Final reward: -0.32034891843795776
Final reward: -0.3203549385070801
Final reward: -0.3204363286495209
Final reward: -0.32035529613494873
Final reward: -0.3203449547290802
Final reward: -0.32038721442222595
Final reward: -0.3202822208404541
Final reward: -0.32026800513267517
Final reward: -0.3201477527618408
Final reward: -0.32019752264022827
Final reward: -0.32020118832588196
Final reward: -0.32032784819602966
Final reward: -0.32039061188697815
Final reward: -0.3204014003276825
Final reward: -0.32037869095802307
Final reward: -0.32049039006233215
Final reward: -0.32054248452186584
Final reward: -0.3206002414226532
Final reward: -0.320478618144989
Final reward: -0.3204888105392456
Final reward: -0.32049208879470825
Final reward: -0.3205591142177582
Final reward: -0.3205879032611847
Final reward: -0.32050374150276184
Final reward: -0.32043758034706116
Final reward: -0.32047122716903687
Final reward: -0.3204926550388336
Final reward: -0.32044723629951477
Final reward: -0.32033678889274597
Final reward: -0.3203597366809845
Final reward: -0.3203252851963043
Final reward: -0.3202650547027588
Final reward: -0.3202812075614929
Final reward: -0.32019922137260437
Final reward: -0.3203096091747284
Final reward: -0.3203265368938446
Final reward: -0.3203093111515045
Final reward: -0.3204689621925354
Final reward: -0.3204617202281952
Final reward: -0.3203769624233246
Final reward: -0.3202308714389801
Final reward: -0.3202902376651764
Final reward: -0.3203144967556
Final reward: -0.32039377093315125
Final reward: -0.32035332918167114
Final reward: -0.32030174136161804
Final reward: -0.3203605115413666
Final reward: -0.32039904594421387
Final reward: -0.32042378187179565
Final reward: -0.320420503616333
Final reward: -0.3202613890171051
Final reward: -0.3203761875629425
Final reward: -0.32033708691596985
Final reward: -0.32029780745506287
Final reward: -0.3204475939273834
Final reward: -0.32045766711235046
Final reward: -0.3205568492412567
Final reward: -0.32052934169769287
Final reward: -0.3203565180301666
Final reward: -0.3204154670238495
Final reward: -0.3204070031642914
Final reward: -0.3204915225505829
Final reward: -0.3204415738582611
Final reward: -0.3203947842121124
Final reward: -0.3204750716686249
Final reward: -0.32049041986465454
Final reward: -0.32054588198661804
Final reward: -0.3204718232154846
Final reward: -0.32044705748558044
Final reward: -0.32055655121803284
Final reward: -0.32057544589042664
Final reward: -0.3204399347305298
Final reward: -0.3204880654811859
Final reward: -0.32060572504997253
Final reward: -0.3204689621925354
Final reward: -0.3204213082790375
Final reward: -0.32044994831085205
Final reward: -0.3204606771469116
Final reward: -0.3204239010810852
Final reward: -0.32050102949142456
Final reward: -0.3205223083496094
Final reward: -0.32042983174324036
Final reward: -0.3204772472381592
Final reward: -0.3204997181892395
Final reward: -0.32047387957572937
Final reward: -0.3204997777938843
Final reward: -0.32037025690078735
Final reward: -0.3205001652240753
Final reward: -0.3206019997596741
Final reward: -0.3205416202545166
Final reward: -0.32054707407951355
Final reward: -0.3204902112483978
Final reward: -0.32054832577705383
Final reward: -0.320689857006073
Final reward: -0.3207356333732605
Final reward: -0.3207490146160126
Final reward: -0.32062825560569763
Final reward: -0.32059526443481445
Final reward: -0.32064080238342285
Final reward: -0.3205910623073578
Final reward: -0.320461630821228
Final reward: -0.32041895389556885
Final reward: -0.3204665184020996
Final reward: -0.32034948468208313
Final reward: -0.3204393982887268
Final reward: -0.32039380073547363
Final reward: -0.3203507363796234
Final reward: -0.3203156590461731
Final reward: -0.3204493522644043
Final reward: -0.3202686607837677
Final reward: -0.3202193081378937
Final reward: -0.3203527629375458
Final reward: -0.32027244567871094
Final reward: -0.3203761577606201
Final reward: -0.32060372829437256
Final reward: -0.3206927478313446
Final reward: -0.32062360644340515
Final reward: -0.3205970823764801
Final reward: -0.3205258250236511
Final reward: -0.3204928934574127
Final reward: -0.3203946650028229
Final reward: -0.3205256164073944
Final reward: -0.3205263614654541
Final reward: -0.32045114040374756
Final reward: -0.32022222876548767
Final reward: -0.32024791836738586
Final reward: -0.32026809453964233
Final reward: -0.32039809226989746
Final reward: -0.320516437292099
Final reward: -0.320501446723938
Final reward: -0.3204174041748047
Final reward: -0.3205350637435913
Final reward: -0.32049262523651123
Final reward: -0.3205021619796753
Final reward: -0.32041943073272705
Final reward: -0.3204019069671631
Final reward: -0.32034215331077576
Final reward: -0.32027384638786316
Final reward: -0.3203808069229126
Final reward: -0.3204468786716461
Final reward: -0.32057100534439087
Final reward: -0.32050299644470215
Final reward: -0.32056400179862976
Final reward: -0.32052117586135864
Final reward: -0.3206648826599121
Final reward: -0.3207438290119171
Final reward: -0.32070058584213257
Final reward: -0.32068932056427
Final reward: -0.3205327093601227
Final reward: -0.3204943835735321
Final reward: -0.320579469203949
Final reward: -0.3206465542316437
Final reward: -0.32056888937950134
Final reward: -0.3206365406513214
Final reward: -0.32055819034576416
Final reward: -0.3206264078617096
Final reward: -0.3204910457134247
Final reward: -0.3205457329750061
Final reward: -0.3205091953277588
Final reward: -0.32042446732521057
Final reward: -0.32049760222435
Final reward: -0.32037296891212463
Final reward: -0.32040268182754517
Final reward: -0.32038789987564087
Final reward: -0.3203229308128357
Final reward: -0.3203750550746918
Final reward: -0.3203411400318146
Final reward: -0.32036614418029785
Final reward: -0.3204704523086548
Final reward: -0.32048219442367554
Final reward: -0.3204859793186188
Final reward: -0.3206425905227661
Final reward: -0.32057860493659973
Final reward: -0.32056188583374023
Final reward: -0.3204529583454132
Final reward: -0.3205190598964691
Final reward: -0.32041671872138977
Final reward: -0.32036638259887695
Final reward: -0.32030072808265686
Final reward: -0.32048580050468445
Final reward: -0.32061967253685
Final reward: -0.320686012506485
Final reward: -0.32059818506240845
Final reward: -0.32069483399391174
Final reward: -0.32071149349212646
Final reward: -0.3207719027996063
Final reward: -0.3205921947956085
Final reward: -0.32052406668663025
Final reward: -0.32054802775382996
Final reward: -0.3205440640449524
Final reward: -0.3205161988735199
Final reward: -0.320556640625
Final reward: -0.3205745220184326
Final reward: -0.32065996527671814
Final reward: -0.32058149576187134
Final reward: -0.3207024931907654
Final reward: -0.32074034214019775
Final reward: -0.32080399990081787
Final reward: -0.3207830786705017
Final reward: -0.3208255469799042
Final reward: -0.3208233416080475
Final reward: -0.3208197355270386
Final reward: -0.32071223855018616
Final reward: -0.3206899166107178
Final reward: -0.32067203521728516
Final reward: -0.32061299681663513
Final reward: -0.3205670118331909
Final reward: -0.3203597366809845
Final reward: -0.3204590380191803
Final reward: -0.3205364942550659
Final reward: -0.3204745948314667
Final reward: -0.32056257128715515
Final reward: -0.32066628336906433
Final reward: -0.3206179141998291
Final reward: -0.32053253054618835
Final reward: -0.32049039006233215
Final reward: -0.32046744227409363
Final reward: -0.32055357098579407
Final reward: -0.32047995924949646
Final reward: -0.3204711675643921
Final reward: -0.3206842243671417
Final reward: -0.3208030164241791
Final reward: -0.320725679397583
Final reward: -0.3207441568374634
Final reward: -0.320731520652771
Final reward: -0.3205791413784027
Final reward: -0.3205009996891022
Final reward: -0.32048603892326355
Final reward: -0.32042625546455383
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.32048070430755615
Final reward: -0.3204263150691986
Final reward: -0.3205125033855438
Final reward: -0.3205867111682892
Final reward: -0.320550799369812
Final reward: -0.3207738995552063
Final reward: -0.32089486718177795
Final reward: -0.3208467662334442
Final reward: -0.32068881392478943
Final reward: -0.3207415044307709
Final reward: -0.32091331481933594
Final reward: -0.32084956765174866
Final reward: -0.32076844573020935
Final reward: -0.3206116259098053
Final reward: -0.32070618867874146
Final reward: -0.3207419812679291
Final reward: -0.3206202983856201
Final reward: -0.32059091329574585
Final reward: -0.3206336498260498
Final reward: -0.3208218216896057
Final reward: -0.32079702615737915
Final reward: -0.32084921002388
Final reward: -0.3208250403404236
Final reward: -0.3208887279033661
Final reward: -0.3208255171775818
Final reward: -0.3207235634326935
Final reward: -0.3206748962402344
Final reward: -0.32067635655403137
Final reward: -0.32058924436569214
Final reward: -0.32051199674606323
Final reward: -0.3206203281879425
Final reward: -0.3205544650554657
Final reward: -0.32060638070106506
Final reward: -0.32061639428138733
Final reward: -0.32050207257270813
Final reward: -0.3206014037132263
Final reward: -0.32061633467674255
Final reward: -0.320706844329834
Final reward: -0.3207629919052124
Final reward: -0.3207276165485382
Final reward: -0.32088330388069153
Final reward: -0.3208695948123932
Final reward: -0.32086294889450073
Final reward: -0.3208368122577667
Final reward: -0.3207355737686157
Final reward: -0.3206353485584259
Final reward: -0.3206825852394104
Final reward: -0.32076573371887207
Final reward: -0.3207540810108185
Final reward: -0.32057636976242065
Final reward: -0.32062575221061707
Final reward: -0.32071346044540405
Final reward: -0.3207085132598877
Final reward: -0.3207189440727234
Final reward: -0.3205767869949341
Final reward: -0.3206688463687897
Final reward: -0.320573627948761
Final reward: -0.3204590976238251
Final reward: -0.3205052316188812
Final reward: -0.3205251693725586
Final reward: -0.32047316431999207
Final reward: -0.3206861913204193
Final reward: -0.3207302391529083
Final reward: -0.3205866813659668
Final reward: -0.3206028640270233
Final reward: -0.3205966353416443
Final reward: -0.3207489848136902
Final reward: -0.32069459557533264
Final reward: -0.32075580954551697
Final reward: -0.32087603211402893
Final reward: -0.32081225514411926
Final reward: -0.3208328187465668
Final reward: -0.32093697786331177
Final reward: -0.3209657669067383
Final reward: -0.3209633231163025
Final reward: -0.32088762521743774
Final reward: -0.3208763599395752
Final reward: -0.32089629769325256
Final reward: -0.32076290249824524
Final reward: -0.3207520842552185
Final reward: -0.3208860158920288
Final reward: -0.3207685351371765
Final reward: -0.32076314091682434
Final reward: -0.3207571804523468
Final reward: -0.32061097025871277
Final reward: -0.3206278383731842
Final reward: -0.3206446170806885
Final reward: -0.3205132484436035
Final reward: -0.3206161856651306
Final reward: -0.3206976354122162
Final reward: -0.3207046687602997
Final reward: -0.3207458257675171
Final reward: -0.32061660289764404
Final reward: -0.32064288854599
Final reward: -0.32068154215812683
Final reward: -0.32076317071914673
Final reward: -0.32067349553108215
Final reward: -0.3206109404563904
Final reward: -0.3206074833869934
Final reward: -0.32062605023384094
Final reward: -0.32061970233917236
Final reward: -0.32054027915000916
Final reward: -0.3206053078174591
Final reward: -0.3207125961780548
Final reward: -0.320767879486084
Final reward: -0.3207639753818512
Final reward: -0.32081836462020874
Final reward: -0.3207390606403351
Final reward: -0.32084813714027405
Final reward: -0.3207857012748718
Final reward: -0.320803701877594
Final reward: -0.32078221440315247
Final reward: -0.32080137729644775
Final reward: -0.3208973705768585
Final reward: -0.3208509087562561
Final reward: -0.32096394896507263
Final reward: -0.32093530893325806
Final reward: -0.3210008144378662
Final reward: -0.3209537863731384
Final reward: -0.32103362679481506
Final reward: -0.32106107473373413
Final reward: -0.32097622752189636
Final reward: -0.3209717571735382
Final reward: -0.32100826501846313
Final reward: -0.32090261578559875
Final reward: -0.32082435488700867
Final reward: -0.3209163546562195
Final reward: -0.32088524103164673
Final reward: -0.3208068013191223
Final reward: -0.3207400143146515
Final reward: -0.3207719326019287
Final reward: -0.32086724042892456
Final reward: -0.3208329379558563
Final reward: -0.320814847946167
Final reward: -0.3207031190395355
Final reward: -0.320789635181427
Final reward: -0.3208666145801544
Final reward: -0.32078075408935547
Final reward: -0.32076576352119446
Final reward: -0.3207072615623474
Final reward: -0.32068198919296265
Final reward: -0.3205742835998535
Final reward: -0.32062095403671265
Final reward: -0.3207111060619354
Final reward: -0.32068830728530884
Final reward: -0.32070547342300415
Final reward: -0.3207147717475891
Final reward: -0.32076162099838257
Final reward: -0.32088425755500793
Final reward: -0.3208775818347931
Final reward: -0.32087814807891846
Final reward: -0.3207242488861084
Final reward: -0.32077234983444214
Final reward: -0.32071810960769653
Final reward: -0.320600688457489
Final reward: -0.32060229778289795
Final reward: -0.32071948051452637
Final reward: -0.3207203447818756
Final reward: -0.32070377469062805
Final reward: -0.3208242952823639
Final reward: -0.32085999846458435
Final reward: -0.3209283947944641
Final reward: -0.3209435045719147
Final reward: -0.32092055678367615
Final reward: -0.32090917229652405
Final reward: -0.32087400555610657
Final reward: -0.3207602798938751
Final reward: -0.3206530511379242
Final reward: -0.32081347703933716
Final reward: -0.3208175003528595
Final reward: -0.3207284212112427
Final reward: -0.32078999280929565
Final reward: -0.32090699672698975
Final reward: -0.32089000940322876
Final reward: -0.32094869017601013
Final reward: -0.3209209144115448
Final reward: -0.32084956765174866
Final reward: -0.32084211707115173
Final reward: -0.3207627236843109
Final reward: -0.32071253657341003
Final reward: -0.32062748074531555
Final reward: -0.32071876525878906
Final reward: -0.3206728398799896
Final reward: -0.3208097815513611
Final reward: -0.3208288550376892
Final reward: -0.32077738642692566
Final reward: -0.3207041621208191
Final reward: -0.3207988440990448
Final reward: -0.3208859860897064
Final reward: -0.32083338499069214
Final reward: -0.32095810770988464
Final reward: -0.320911169052124
Final reward: -0.32092660665512085
Final reward: -0.320983350276947
Final reward: -0.3210098147392273
Final reward: -0.320869117975235
Final reward: -0.32082995772361755
Final reward: -0.32091379165649414
Final reward: -0.32087552547454834
Final reward: -0.3209249973297119
Final reward: -0.3210303485393524
Final reward: -0.32090139389038086
Final reward: -0.3209107518196106
Final reward: -0.3209400177001953
Final reward: -0.3208159804344177
Final reward: -0.3208130896091461
Final reward: -0.3208670914173126
Final reward: -0.3208449184894562
Final reward: -0.32086849212646484
Final reward: -0.3207806646823883
Final reward: -0.32069557905197144
Final reward: -0.32075682282447815
Final reward: -0.3207387626171112
Final reward: -0.32090136408805847
Final reward: -0.32086309790611267
Final reward: -0.3209347128868103
Final reward: -0.3210066556930542
Final reward: -0.3210460841655731
Final reward: -0.3210335075855255
Final reward: -0.321020245552063
Final reward: -0.32098716497421265
Final reward: -0.3209657371044159
Final reward: -0.32109272480010986
Final reward: -0.32101723551750183
Final reward: -0.32096701860427856
Final reward: -0.3209545314311981
Final reward: -0.32094573974609375
Final reward: -0.32079407572746277
Final reward: -0.32084980607032776
Final reward: -0.3208100497722626
Final reward: -0.32085806131362915
Final reward: -0.32070839405059814
Final reward: -0.32068926095962524
Final reward: -0.32087159156799316
Final reward: -0.32080352306365967
Final reward: -0.32071423530578613
Final reward: -0.32070592045783997
Final reward: -0.3207798898220062
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3207723796367645
Final reward: -0.32085177302360535
Final reward: -0.32103630900382996
Final reward: -0.3210710287094116
Final reward: -0.32123157382011414
Final reward: -0.32111701369285583
Final reward: -0.32103535532951355
Final reward: -0.3210986852645874
Final reward: -0.32113632559776306
Final reward: -0.3212101459503174
Final reward: -0.3211818337440491
Final reward: -0.3211412727832794
Final reward: -0.32096460461616516
Final reward: -0.32093220949172974
Final reward: -0.32077914476394653
Final reward: -0.3208450675010681
Final reward: -0.32081475853919983
Final reward: -0.3209262490272522
Final reward: -0.3209771513938904
Final reward: -0.32097890973091125
Final reward: -0.3209264576435089
Final reward: -0.32091930508613586
Final reward: -0.32098180055618286
Final reward: -0.32104331254959106
Final reward: -0.3212168514728546
Final reward: -0.32133543491363525
Final reward: -0.3212514817714691
Final reward: -0.3211972117424011
Final reward: -0.3211766183376312
Final reward: -0.3210851848125458
Final reward: -0.32105863094329834
Final reward: -0.32108524441719055
Final reward: -0.3210415244102478
Final reward: -0.3209956884384155
Final reward: -0.320962518453598
Final reward: -0.32108327746391296
Final reward: -0.3211584687232971
Final reward: -0.32113033533096313
Final reward: -0.32102903723716736
Final reward: -0.3211190700531006
Final reward: -0.32100650668144226
Final reward: -0.3209473490715027
Final reward: -0.3210645914077759
Final reward: -0.32101747393608093
Final reward: -0.32106250524520874
Final reward: -0.3211137056350708
Final reward: -0.32117512822151184
Final reward: -0.3210853040218353
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                   avg_speed ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÇ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                        cost ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  is_success ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   max_speed ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÇ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                      reward ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:             train/approx_kl ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ
wandb:         train/clip_fraction ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ
wandb:            train/clip_range ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/cost_returns ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:       train/cost_value_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           train/cost_values ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:               train/entropy ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:          train/entropy_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:    train/explained_variance ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñá‚ñÇ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÜ‚ñà‚ñà‚ñÖ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/lagrangian_multiplier ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train/loss ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             train/n_updates ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  train/policy_gradient_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ
wandb:                   train/std ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            train/value_loss ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                   avg_speed 0.0674
wandb:                        cost 0
wandb:                  is_success 0
wandb:                   max_speed 0.0674
wandb:                      reward -0.55056
wandb:             train/approx_kl 0.0045
wandb:         train/clip_fraction 0.03301
wandb:            train/clip_range 0.2
wandb:          train/cost_returns 0.0028
wandb:       train/cost_value_loss 0.0
wandb:           train/cost_values 0.00278
wandb:               train/entropy -1.22393
wandb:          train/entropy_loss -1.21588
wandb:    train/explained_variance 0.99992
wandb: train/lagrangian_multiplier 0.0
wandb:         train/learning_rate 0.0003
wandb:                  train/loss -0.00683
wandb:             train/n_updates 14690
wandb:  train/policy_gradient_loss -0.00141
wandb:                   train/std 0.50102
wandb:            train/value_loss 0.00303
wandb: 
wandb: üöÄ View run still-violet-49 at: https://wandb.ai/ecrl/seed-testing/runs/3rk8b0u2
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240123_021837-3rk8b0u2/logs
