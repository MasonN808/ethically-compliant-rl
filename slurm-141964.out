wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240222_193128-ld0gv8xm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-orchid-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/ld0gv8xm
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
Using cpu device
-----------------------------------
| avg_speed          | 0.995      |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.995      |
| reward             | -0.5213231 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.18e+03  |
| time/              |            |
|    fps             | 86         |
|    iterations      | 1          |
|    time_elapsed    | 23         |
|    total_timesteps | 2048       |
-----------------------------------
------------------------------------------
| avg_speed                | 0.518       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.518       |
| reward                   | -0.31974357 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 81          |
|    iterations            | 2           |
|    time_elapsed          | 50          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.002687201 |
|    clip_fraction         | 0.0191      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.543       |
|    cost_value_loss       | 2.49        |
|    cost_values           | 0.116       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0181      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 166         |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00241    |
|    std                   | 1           |
|    value_loss            | 387         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.633        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.633        |
| reward                   | -0.49348783  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 80           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0052072033 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.632        |
|    cost_value_loss       | 4.32         |
|    cost_values           | 0.339        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0685       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 259          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 1.01         |
|    value_loss            | 528          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0921      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0921      |
| reward                   | -0.44225904 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 112         |
|    total_timesteps       | 8192        |
| train/                   |             |
|    approx_kl             | 0.005090203 |
|    clip_fraction         | 0.0319      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 7.79        |
|    cost_values           | 0.739       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0896      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 178         |
|    n_updates             | 30          |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 1.01        |
|    value_loss            | 350         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.9806529   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 142          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0046462505 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 0.918        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0996       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 273          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 1.01         |
|    value_loss            | 549          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.8306762   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 6            |
|    time_elapsed          | 175          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0031457827 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 2.22         |
|    cost_values           | 0.951        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.075        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 128          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 1.01         |
|    value_loss            | 259          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -1.6798544  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 7           |
|    time_elapsed          | 213         |
|    total_timesteps       | 14336       |
| train/                   |             |
|    approx_kl             | 0.004024473 |
|    clip_fraction         | 0.0179      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 4.3         |
|    cost_values           | 0.963       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0895      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 191         |
|    n_updates             | 60          |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 1.01        |
|    value_loss            | 391         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.03         |
| reward                   | -0.5337548   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 8            |
|    time_elapsed          | 247          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0029520611 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 7.26         |
|    cost_values           | 0.985        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0606       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 426          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 1.01         |
|    value_loss            | 844          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.3175455   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 9            |
|    time_elapsed          | 285          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0042767283 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.944        |
|    cost_values           | 0.975        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.033        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 194          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 1.01         |
|    value_loss            | 411          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.5071274  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 10          |
|    time_elapsed          | 329         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.003773455 |
|    clip_fraction         | 0.0247      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 2.94        |
|    cost_values           | 0.992       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0473      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 192         |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 1.01        |
|    value_loss            | 386         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.0493152   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0026494756 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 4.14         |
|    cost_values           | 0.977        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0566       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 238          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 1.01         |
|    value_loss            | 481          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.823677    |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 12           |
|    time_elapsed          | 417          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0034935563 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.04         |
|    cost_values           | 0.973        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0553       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 255          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 1.01         |
|    value_loss            | 508          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -2.0428412   |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 57           |
|    iterations            | 13           |
|    time_elapsed          | 464          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0042569772 |
|    clip_fraction         | 0.0412       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.36         |
|    cost_values           | 0.982        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0287       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 218          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 1.01         |
|    value_loss            | 437          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -1.5131842  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 14          |
|    time_elapsed          | 516         |
|    total_timesteps       | 28672       |
| train/                   |             |
|    approx_kl             | 0.006390806 |
|    clip_fraction         | 0.0444      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.995       |
|    cost_value_loss       | 1.31        |
|    cost_values           | 0.988       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0343      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 283         |
|    n_updates             | 130         |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 1.01        |
|    value_loss            | 572         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.7475448   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 53           |
|    iterations            | 15           |
|    time_elapsed          | 569          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0031041356 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.41         |
|    cost_values           | 0.986        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0223       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 422          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 1.01         |
|    value_loss            | 846          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.2946769  |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 52          |
|    iterations            | 16          |
|    time_elapsed          | 625         |
|    total_timesteps       | 32768       |
| train/                   |             |
|    approx_kl             | 0.003051464 |
|    clip_fraction         | 0.00781     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 6.52        |
|    cost_values           | 0.967       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0491      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 292         |
|    n_updates             | 150         |
|    policy_gradient_loss  | -0.00196    |
|    std                   | 1.01        |
|    value_loss            | 610         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.155184    |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 17           |
|    time_elapsed          | 684          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0038818885 |
|    clip_fraction         | 0.037        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 2.07         |
|    cost_values           | 0.937        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0265       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 196          |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 1.02         |
|    value_loss            | 428          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.53         |
| reward                   | -0.5380005   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 49           |
|    iterations            | 18           |
|    time_elapsed          | 748          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0017899593 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 4.72         |
|    cost_values           | 0.964        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0501       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 162          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 1.02         |
|    value_loss            | 344          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4810059   |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 19           |
|    time_elapsed          | 808          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0050126472 |
|    clip_fraction         | 0.056        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 9.86         |
|    cost_values           | 0.984        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0537       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.6         |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 1.01         |
|    value_loss            | 172          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -2.0162942   |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 20           |
|    time_elapsed          | 885          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0036784392 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 7.12         |
|    cost_values           | 0.988        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0331       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 156          |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 1.01         |
|    value_loss            | 311          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.9170686  |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 45          |
|    iterations            | 21          |
|    time_elapsed          | 954         |
|    total_timesteps       | 43008       |
| train/                   |             |
|    approx_kl             | 0.002923334 |
|    clip_fraction         | 0.0177      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 0.991       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0228      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 189         |
|    n_updates             | 200         |
|    policy_gradient_loss  | -0.00245    |
|    std                   | 1.02        |
|    value_loss            | 397         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.54         |
| reward                   | -2.5965285   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 43           |
|    iterations            | 22           |
|    time_elapsed          | 1026         |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0011972897 |
|    clip_fraction         | 0.0062       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 6.89         |
|    cost_values           | 0.99         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0222       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 224          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 1.01         |
|    value_loss            | 457          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -1.639356   |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 42          |
|    iterations            | 23          |
|    time_elapsed          | 1110        |
|    total_timesteps       | 47104       |
| train/                   |             |
|    approx_kl             | 0.002018623 |
|    clip_fraction         | 0.0418      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 6.59        |
|    cost_values           | 0.99        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0203      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 150         |
|    n_updates             | 220         |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 1.01        |
|    value_loss            | 292         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.66808     |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 41           |
|    iterations            | 24           |
|    time_elapsed          | 1189         |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0030988355 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.83         |
|    cost_values           | 0.992        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00554      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 249          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 1            |
|    value_loss            | 484          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3098762   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 40           |
|    iterations            | 25           |
|    time_elapsed          | 1266         |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0050918995 |
|    clip_fraction         | 0.0501       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.956        |
|    cost_values           | 0.994        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0105       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 173          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00543     |
|    std                   | 1            |
|    value_loss            | 353          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5435606   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 39           |
|    iterations            | 26           |
|    time_elapsed          | 1351         |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0035904953 |
|    clip_fraction         | 0.0322       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 1.22         |
|    cost_values           | 0.999        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00224      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 388          |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 1            |
|    value_loss            | 761          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.5851657   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 38           |
|    iterations            | 27           |
|    time_elapsed          | 1440         |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0042808233 |
|    clip_fraction         | 0.042        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 1.52         |
|    cost_values           | 0.998        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00761      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 189          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 1            |
|    value_loss            | 390          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -2.1205556   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 37           |
|    iterations            | 28           |
|    time_elapsed          | 1530         |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0044581005 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 6.96         |
|    cost_values           | 0.993        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0148       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 80.1         |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 1.01         |
|    value_loss            | 167          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.43         |
| reward                   | -0.6024062   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 36           |
|    iterations            | 29           |
|    time_elapsed          | 1618         |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0028355445 |
|    clip_fraction         | 0.00796      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 3.83         |
|    cost_values           | 0.991        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0219       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 241          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 1.02         |
|    value_loss            | 475          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.000794     |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.000794     |
| reward                   | -0.37733757  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 35           |
|    iterations            | 30           |
|    time_elapsed          | 1708         |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0054787705 |
|    clip_fraction         | 0.042        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 4.04         |
|    cost_values           | 0.989        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0127       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 108          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 1.02         |
|    value_loss            | 240          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.18        |
| reward                   | -0.4309134  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 35          |
|    iterations            | 31          |
|    time_elapsed          | 1805        |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.003568198 |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.13        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 0.997       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0355      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 209         |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 1.02        |
|    value_loss            | 395         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.86        |
| reward                   | -0.84279543 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 34          |
|    iterations            | 32          |
|    time_elapsed          | 1906        |
|    total_timesteps       | 65536       |
| train/                   |             |
|    approx_kl             | 0.003030717 |
|    clip_fraction         | 0.0467      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 4.41        |
|    cost_values           | 0.991       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0106      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 169         |
|    n_updates             | 310         |
|    policy_gradient_loss  | -0.00575    |
|    std                   | 1.02        |
|    value_loss            | 371         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.86         |
| reward                   | -0.74870473  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 33           |
|    iterations            | 33           |
|    time_elapsed          | 2004         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0023466956 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 0.991        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0107       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 170          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 1.02         |
|    value_loss            | 345          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.20175853 |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 33          |
|    iterations            | 34          |
|    time_elapsed          | 2107        |
|    total_timesteps       | 69632       |
| train/                   |             |
|    approx_kl             | 0.004910933 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.89        |
|    cost_values           | 0.98        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.00391     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 99.8        |
|    n_updates             | 330         |
|    policy_gradient_loss  | -0.00571    |
|    std                   | 1.03        |
|    value_loss            | 218         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.85         |
| reward                   | -0.4703249   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 32           |
|    iterations            | 35           |
|    time_elapsed          | 2211         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0039995317 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 1.04         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.109       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.3         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 1.03         |
|    value_loss            | 64.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.12         |
| reward                   | -0.8473995   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 31           |
|    iterations            | 36           |
|    time_elapsed          | 2320         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0036412347 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 5.51         |
|    cost_values           | 1            |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0147       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 135          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00494     |
|    std                   | 1.03         |
|    value_loss            | 286          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.15        |
| reward                   | -0.75365275 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 31          |
|    iterations            | 37          |
|    time_elapsed          | 2425        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.006683281 |
|    clip_fraction         | 0.0725      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 2.57        |
|    cost_values           | 0.993       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.0115      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 66.4        |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00794    |
|    std                   | 1.04        |
|    value_loss            | 133         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.929        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.929        |
| reward                   | -0.5720931   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 30           |
|    iterations            | 38           |
|    time_elapsed          | 2536         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0059318542 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 4.1          |
|    cost_values           | 0.994        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0237       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 89.4         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 1.04         |
|    value_loss            | 193          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -1.2728776  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 30          |
|    iterations            | 39          |
|    time_elapsed          | 2647        |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.003970912 |
|    clip_fraction         | 0.0266      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.2         |
|    cost_value_loss       | 11          |
|    cost_values           | 1           |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.0258      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 63.2        |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 1.04        |
|    value_loss            | 123         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.74         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.74         |
| reward                   | -0.34562287  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 40           |
|    time_elapsed          | 2762         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0038291032 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 5.8          |
|    cost_values           | 1            |
|    entropy               | -2.93        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0242       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.3         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00383     |
|    std                   | 1.05         |
|    value_loss            | 134          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 5.91       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.91       |
| reward                   | -0.5873222 |
| rollout/                 |            |
|    ep_len_mean           | 952        |
|    ep_rew_mean           | -1.17e+03  |
| time/                    |            |
|    fps                   | 29         |
|    iterations            | 41         |
|    time_elapsed          | 2879       |
|    total_timesteps       | 83968      |
| train/                   |            |
|    approx_kl             | 0.00603894 |
|    clip_fraction         | 0.0442     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.2        |
|    cost_value_loss       | 8.44       |
|    cost_values           | 1          |
|    entropy               | -2.93      |
|    entropy_loss          | -2.93      |
|    explained_variance    | 0.0173     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 48.4       |
|    n_updates             | 400        |
|    policy_gradient_loss  | -0.00528   |
|    std                   | 1.05       |
|    value_loss            | 97.2       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 1.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.19         |
| reward                   | -0.38580307  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 42           |
|    time_elapsed          | 2996         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0048145126 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 3.02         |
|    cost_values           | 0.989        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00357      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 154          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 1.05         |
|    value_loss            | 298          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.4          |
| reward                   | -0.3885726   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 43           |
|    time_elapsed          | 3115         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0032215025 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 2.24         |
|    cost_values           | 0.998        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00463      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 147          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 1.05         |
|    value_loss            | 311          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.57         |
| reward                   | -1.2676083   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 44           |
|    time_elapsed          | 3231         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0033021257 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 5.4          |
|    cost_values           | 1            |
|    entropy               | -2.93        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.016        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 59.3         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 1.05         |
|    value_loss            | 106          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.65         |
| reward                   | -1.6376115   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 45           |
|    time_elapsed          | 3352         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0046834075 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 1            |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.0147       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.9         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00565     |
|    std                   | 1.05         |
|    value_loss            | 130          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.32242364  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 46           |
|    time_elapsed          | 3482         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0028357324 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 8.18         |
|    cost_values           | 1            |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0146       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 91.8         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 1.05         |
|    value_loss            | 190          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.81         |
| reward                   | -0.5010996   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 47           |
|    time_elapsed          | 3615         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0051164804 |
|    clip_fraction         | 0.0432       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 6.19         |
|    cost_values           | 1            |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.00981      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 135          |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 1.06         |
|    value_loss            | 281          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.04        |
| reward                   | -0.5960093  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 48          |
|    time_elapsed          | 3751        |
|    total_timesteps       | 98304       |
| train/                   |             |
|    approx_kl             | 0.004543394 |
|    clip_fraction         | 0.0325      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 6.67        |
|    cost_values           | 1           |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.0117      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 77.3        |
|    n_updates             | 470         |
|    policy_gradient_loss  | -0.0059     |
|    std                   | 1.06        |
|    value_loss            | 163         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.114        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.114        |
| reward                   | -0.6355647   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 49           |
|    time_elapsed          | 3884         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0052510872 |
|    clip_fraction         | 0.071        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 3.85         |
|    cost_values           | 1            |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0106       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.8         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00823     |
|    std                   | 1.07         |
|    value_loss            | 106          |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/ld0gv8xm
------------------------------------
| avg_speed          | 6.34        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 6.34        |
| reward             | -0.98590523 |
| rollout/           |             |
|    ep_len_mean     | 938         |
|    ep_rew_mean     | -1.11e+03   |
| time/              |             |
|    fps             | 14          |
|    iterations      | 1           |
|    time_elapsed    | 138         |
|    total_timesteps | 102400      |
------------------------------------
-------------------------------------------
| avg_speed                | 6.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.5          |
| reward                   | -0.90674967  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 2            |
|    time_elapsed          | 288          |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0047841016 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 8.62         |
|    cost_values           | 1            |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00565      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.1         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 1.06         |
|    value_loss            | 108          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.44         |
| reward                   | -0.64732575  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 3            |
|    time_elapsed          | 434          |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0024582148 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 1            |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0236       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.4         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 1.06         |
|    value_loss            | 50.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.7886356   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 4            |
|    time_elapsed          | 575          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0035798703 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.02         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 1.08         |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0109       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.7         |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 1.06         |
|    value_loss            | 56           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -1.370578    |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 5            |
|    time_elapsed          | 734          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0044746245 |
|    clip_fraction         | 0.0422       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 2.74         |
|    cost_values           | 1.06         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.00881      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.7         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 1.07         |
|    value_loss            | 72.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -1.1260467  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 6           |
|    time_elapsed          | 889         |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.006249406 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.04        |
|    cost_value_loss       | 7.88        |
|    cost_values           | 1.07        |
|    entropy               | -3          |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.00217     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.2        |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 1.09        |
|    value_loss            | 28.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.19         |
| reward                   | -0.45092675  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 7            |
|    time_elapsed          | 1052         |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0030763098 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 1.58         |
|    cost_values           | 1.01         |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.0053       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.9         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1.09         |
|    value_loss            | 106          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.04         |
| reward                   | -0.41016027  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 8            |
|    time_elapsed          | 1217         |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0029142085 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 1            |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00851      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65.4         |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00432     |
|    std                   | 1.1          |
|    value_loss            | 129          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.05        |
| reward                   | -1.46237    |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 9           |
|    time_elapsed          | 1384        |
|    total_timesteps       | 118784      |
| train/                   |             |
|    approx_kl             | 0.004824834 |
|    clip_fraction         | 0.0364      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 2.16        |
|    cost_values           | 1           |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00317     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 93.7        |
|    n_updates             | 570         |
|    policy_gradient_loss  | -0.00475    |
|    std                   | 1.1         |
|    value_loss            | 189         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.92        |
| reward                   | -0.83551747 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 10          |
|    time_elapsed          | 1552        |
|    total_timesteps       | 120832      |
| train/                   |             |
|    approx_kl             | 0.004575957 |
|    clip_fraction         | 0.0594      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 5.53        |
|    cost_values           | 1           |
|    entropy               | -3.03       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00783     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.9        |
|    n_updates             | 580         |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 1.1         |
|    value_loss            | 44.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0179      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0179      |
| reward                   | -0.4745622  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 11          |
|    time_elapsed          | 1725        |
|    total_timesteps       | 122880      |
| train/                   |             |
|    approx_kl             | 0.005157572 |
|    clip_fraction         | 0.0442      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 2.29        |
|    cost_values           | 0.999       |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.00179     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 141         |
|    n_updates             | 590         |
|    policy_gradient_loss  | -0.00608    |
|    std                   | 1.1         |
|    value_loss            | 306         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.7174832  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -996        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 12          |
|    time_elapsed          | 1896        |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.004997244 |
|    clip_fraction         | 0.0297      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 1.01        |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00845     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.6        |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 1.09        |
|    value_loss            | 58          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.3453258  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -986        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 13          |
|    time_elapsed          | 2078        |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.006175603 |
|    clip_fraction         | 0.0379      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.74        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 1.16        |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.0113      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 1.09        |
|    value_loss            | 17.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.375        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.375        |
| reward                   | -0.94380623  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -988         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 14           |
|    time_elapsed          | 2248         |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0021245456 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 2.59         |
|    cost_values           | 1.29         |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.00608      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 76.6         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 1.09         |
|    value_loss            | 165          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.6455149   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -995         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 15           |
|    time_elapsed          | 2436         |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0025692643 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 8.84         |
|    cost_values           | 0.992        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.00605      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 99.3         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 1.09         |
|    value_loss            | 205          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.42         |
| reward                   | -0.83564395  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -992         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 16           |
|    time_elapsed          | 2617         |
|    total_timesteps       | 133120       |
| train/                   |              |
|    approx_kl             | 0.0042360527 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 6.1          |
|    cost_values           | 1.01         |
|    entropy               | -3           |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.00605      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.5         |
|    n_updates             | 640          |
|    policy_gradient_loss  | -0.00436     |
|    std                   | 1.09         |
|    value_loss            | 54.5         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.825679  |
| rollout/                 |            |
|    ep_len_mean           | 943        |
|    ep_rew_mean           | -964       |
| time/                    |            |
|    fps                   | 12         |
|    iterations            | 17         |
|    time_elapsed          | 2794       |
|    total_timesteps       | 135168     |
| train/                   |            |
|    approx_kl             | 0.00489229 |
|    clip_fraction         | 0.0467     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.94       |
|    cost_value_loss       | 24.6       |
|    cost_values           | 1.17       |
|    entropy               | -3         |
|    entropy_loss          | -3         |
|    explained_variance    | 0.0127     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 22.2       |
|    n_updates             | 650        |
|    policy_gradient_loss  | -0.0071    |
|    std                   | 1.09       |
|    value_loss            | 23.4       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.2622569   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -962         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 18           |
|    time_elapsed          | 2990         |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0062817577 |
|    clip_fraction         | 0.0644       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 26.2         |
|    cost_values           | 1.82         |
|    entropy               | -2.99        |
|    entropy_loss          | -3           |
|    explained_variance    | 0.0169       |
|    lagrangian_multiplier | 6.78e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 23           |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00685     |
|    std                   | 1.08         |
|    value_loss            | 25.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.99         |
| reward                   | -0.95207626  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -956         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 19           |
|    time_elapsed          | 3178         |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0056511723 |
|    clip_fraction         | 0.0581       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.64         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 2.38         |
|    entropy               | -2.98        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.0154       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.7         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.00498     |
|    std                   | 1.08         |
|    value_loss            | 66.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.32         |
| reward                   | -0.3951209   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -935         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 20           |
|    time_elapsed          | 3366         |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0034013048 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.1          |
|    cost_value_loss       | 8.79         |
|    cost_values           | 2.1          |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | -0.251       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 1.08         |
|    value_loss            | 33.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.36         |
| reward                   | -0.36045557  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -935         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 21           |
|    time_elapsed          | 3569         |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0070337583 |
|    clip_fraction         | 0.0527       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.75         |
|    cost_value_loss       | 15.5         |
|    cost_values           | 2.08         |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.0273       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 1.08         |
|    value_loss            | 44.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.96692467  |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -913         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 22           |
|    time_elapsed          | 3770         |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0029380582 |
|    clip_fraction         | 0.045        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 4.74         |
|    cost_values           | 2.38         |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.0134       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.1         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 1.08         |
|    value_loss            | 202          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.4758971  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -905        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 23          |
|    time_elapsed          | 3971        |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.005931892 |
|    clip_fraction         | 0.0423      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 9.53        |
|    cost_values           | 2.12        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.0284      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34          |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00598    |
|    std                   | 1.07        |
|    value_loss            | 54.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.907        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.907        |
| reward                   | -0.560644    |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 24           |
|    time_elapsed          | 4179         |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0066700317 |
|    clip_fraction         | 0.0674       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 1.92         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.0264       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.1         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00542     |
|    std                   | 1.07         |
|    value_loss            | 72.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.835       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.835       |
| reward                   | -0.6381013  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -891        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 25          |
|    time_elapsed          | 4397        |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.005881753 |
|    clip_fraction         | 0.0515      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.28        |
|    cost_value_loss       | 18.6        |
|    cost_values           | 1.64        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.0407      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 58.8        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00526    |
|    std                   | 1.07        |
|    value_loss            | 99.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.39        |
| reward                   | -0.55746    |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -890        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 26          |
|    time_elapsed          | 4607        |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.004823199 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 1.55        |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.0877      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 45.3        |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00429    |
|    std                   | 1.07        |
|    value_loss            | 71.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.667       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.667       |
| reward                   | -0.3413655  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -882        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 27          |
|    time_elapsed          | 4816        |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.005455833 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 1.44        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.0487      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 37.2        |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 1.07        |
|    value_loss            | 63.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.334        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.334        |
| reward                   | -0.34714863  |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -875         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 28           |
|    time_elapsed          | 5026         |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0028071837 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.51         |
|    cost_values           | 1.25         |
|    entropy               | -2.95        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0216       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.4         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 1.06         |
|    value_loss            | 57.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.5          |
| reward                   | -0.56061196  |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -869         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 29           |
|    time_elapsed          | 5236         |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0036960668 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 8.37         |
|    cost_values           | 1.01         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0325       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41           |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00382     |
|    std                   | 1.05         |
|    value_loss            | 76.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.27        |
| reward                   | -1.0252159  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -873        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 30          |
|    time_elapsed          | 5458        |
|    total_timesteps       | 161792      |
| train/                   |             |
|    approx_kl             | 0.004776356 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 5.36        |
|    cost_values           | 0.992       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.0244      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 46.2        |
|    n_updates             | 780         |
|    policy_gradient_loss  | -0.00459    |
|    std                   | 1.05        |
|    value_loss            | 94.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.87         |
| reward                   | -0.64952093  |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -877         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 31           |
|    time_elapsed          | 5675         |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0037028054 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 5.29         |
|    cost_values           | 1            |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.027        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 1.04         |
|    value_loss            | 201          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.988       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.988       |
| reward                   | -0.49562642 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -859        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 32          |
|    time_elapsed          | 5896        |
|    total_timesteps       | 165888      |
| train/                   |             |
|    approx_kl             | 0.005589695 |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 3.09        |
|    cost_values           | 0.998       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.0235      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.3        |
|    n_updates             | 800         |
|    policy_gradient_loss  | -0.00365    |
|    std                   | 1.04        |
|    value_loss            | 51.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.267        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.267        |
| reward                   | -0.407012    |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -854         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 33           |
|    time_elapsed          | 6120         |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0082133915 |
|    clip_fraction         | 0.0648       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.64         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 1.2          |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0377       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00609     |
|    std                   | 1.04         |
|    value_loss            | 34.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.69        |
| reward                   | -0.5534358  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -856        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 34          |
|    time_elapsed          | 6348        |
|    total_timesteps       | 169984      |
| train/                   |             |
|    approx_kl             | 0.007926063 |
|    clip_fraction         | 0.0888      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 1.38        |
|    cost_values           | 1.48        |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.0387      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.9        |
|    n_updates             | 820         |
|    policy_gradient_loss  | -0.00564    |
|    std                   | 1.05        |
|    value_loss            | 39.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.188        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.188        |
| reward                   | -0.5947606   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -854         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 35           |
|    time_elapsed          | 6578         |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0038390604 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 12.4         |
|    cost_values           | 1.21         |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.127        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.8         |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 1.05         |
|    value_loss            | 59.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2            |
| reward                   | -0.6774657   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 36           |
|    time_elapsed          | 6807         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0039698756 |
|    clip_fraction         | 0.0455       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 9.9          |
|    cost_values           | 1.04         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.149        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.3         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.00533     |
|    std                   | 1.04         |
|    value_loss            | 36           |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.57        |
| reward                   | -0.5863621  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -848        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 37          |
|    time_elapsed          | 7043        |
|    total_timesteps       | 176128      |
| train/                   |             |
|    approx_kl             | 0.005691674 |
|    clip_fraction         | 0.0493      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 25.7        |
|    cost_values           | 1.19        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.199       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23          |
|    n_updates             | 850         |
|    policy_gradient_loss  | -0.00616    |
|    std                   | 1.03        |
|    value_loss            | 19.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.64        |
| reward                   | -0.48260587 |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -851        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 38          |
|    time_elapsed          | 7279        |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.004397975 |
|    clip_fraction         | 0.0419      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 1.96        |
|    cost_values           | 1.44        |
|    entropy               | -2.89       |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.107       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.3        |
|    n_updates             | 860         |
|    policy_gradient_loss  | -0.00429    |
|    std                   | 1.03        |
|    value_loss            | 45.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1148055   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -848         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 39           |
|    time_elapsed          | 7508         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0056468784 |
|    clip_fraction         | 0.0503       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 6.19         |
|    cost_values           | 1.21         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.25         |
|    lagrangian_multiplier | 0.000841     |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00565     |
|    std                   | 1.03         |
|    value_loss            | 36.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.29        |
| reward                   | -0.877705   |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -848        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 40          |
|    time_elapsed          | 7734        |
|    total_timesteps       | 182272      |
| train/                   |             |
|    approx_kl             | 0.002531664 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 3.11        |
|    cost_values           | 0.95        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.123       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 73.1        |
|    n_updates             | 880         |
|    policy_gradient_loss  | -0.00456    |
|    std                   | 1.03        |
|    value_loss            | 150         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.748        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.748        |
| reward                   | -0.4949624   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -850         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 41           |
|    time_elapsed          | 7952         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0053637973 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.918        |
|    cost_value_loss       | 0.856        |
|    cost_values           | 0.684        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.208        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 1.03         |
|    value_loss            | 38.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1019722   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -840         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 42           |
|    time_elapsed          | 8173         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0054437355 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 0.617        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.493        |
|    lagrangian_multiplier | 0.000436     |
|    learning_rate         | 0.0003       |
|    loss                  | 29           |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00421     |
|    std                   | 1.03         |
|    value_loss            | 58           |
-------------------------------------------
wandb: Network error (ReadTimeout), entering retry loop.
------------------------------------------
| avg_speed                | 7.44        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.44        |
| reward                   | -1.6261901  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -828        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 43          |
|    time_elapsed          | 8424        |
|    total_timesteps       | 188416      |
| train/                   |             |
|    approx_kl             | 0.007964335 |
|    clip_fraction         | 0.0753      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.83        |
|    cost_value_loss       | 17.4        |
|    cost_values           | 0.844       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.566       |
|    lagrangian_multiplier | 0.00096     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.46        |
|    n_updates             | 910         |
|    policy_gradient_loss  | -0.00969    |
|    std                   | 1.02        |
|    value_loss            | 10.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.58         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.58         |
| reward                   | -0.555034    |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -828         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 44           |
|    time_elapsed          | 8684         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0053087696 |
|    clip_fraction         | 0.057        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 4.95         |
|    cost_values           | 0.881        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.37         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 1.01         |
|    value_loss            | 19.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -1.1402955  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -824        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 45          |
|    time_elapsed          | 8941        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.005479606 |
|    clip_fraction         | 0.0563      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.13        |
|    cost_value_loss       | 8.34        |
|    cost_values           | 0.919       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.408       |
|    lagrangian_multiplier | 7.77e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 28.7        |
|    n_updates             | 930         |
|    policy_gradient_loss  | -0.00598    |
|    std                   | 1.01        |
|    value_loss            | 55.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.59        |
| reward                   | -0.71762013 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -835        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 46          |
|    time_elapsed          | 9193        |
|    total_timesteps       | 194560      |
| train/                   |             |
|    approx_kl             | 0.005583113 |
|    clip_fraction         | 0.035       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.78        |
|    cost_value_loss       | 4.96        |
|    cost_values           | 0.939       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.61        |
|    lagrangian_multiplier | 0.00052     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.6         |
|    n_updates             | 940         |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 1.01        |
|    value_loss            | 17.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.96        |
| reward                   | -0.5022818  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -828        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 47          |
|    time_elapsed          | 9459        |
|    total_timesteps       | 196608      |
| train/                   |             |
|    approx_kl             | 0.004939935 |
|    clip_fraction         | 0.0365      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 0.959       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.449       |
|    lagrangian_multiplier | 0.000984    |
|    learning_rate         | 0.0003      |
|    loss                  | 47.1        |
|    n_updates             | 950         |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 1.01        |
|    value_loss            | 135         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.46         |
| reward                   | -0.8566104   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 48           |
|    time_elapsed          | 9720         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0031813667 |
|    clip_fraction         | 0.0445       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.1          |
|    cost_value_loss       | 23.2         |
|    cost_values           | 0.853        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.538        |
|    lagrangian_multiplier | 0.00103      |
|    learning_rate         | 0.0003       |
|    loss                  | 51           |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 1.02         |
|    value_loss            | 120          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.31         |
| reward                   | -0.4507239   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 49           |
|    time_elapsed          | 9982         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0041165156 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 3.6          |
|    cost_values           | 0.537        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.544        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65           |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 1.01         |
|    value_loss            | 114          |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.16       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.16       |
| reward             | -0.6090202 |
| rollout/           |            |
|    ep_len_mean     | 926        |
|    ep_rew_mean     | -843       |
| time/              |            |
|    fps             | 7          |
|    iterations      | 1          |
|    time_elapsed    | 263        |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.52445024  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 2            |
|    time_elapsed          | 528          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0055586635 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 5.32         |
|    cost_values           | 0.475        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.795        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 1.01         |
|    value_loss            | 33.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4726948   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -837         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 3            |
|    time_elapsed          | 797          |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0067563783 |
|    clip_fraction         | 0.0523       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 0.612        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.669        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.5         |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.00625     |
|    std                   | 1.01         |
|    value_loss            | 35           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.32         |
| reward                   | -0.56992865  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -840         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 4            |
|    time_elapsed          | 1071         |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0038881782 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.859        |
|    cost_value_loss       | 1.68         |
|    cost_values           | 0.497        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.705        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.7         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 1.01         |
|    value_loss            | 70.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.65        |
| reward                   | -0.62031627 |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -839        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 5           |
|    time_elapsed          | 1348        |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.004014676 |
|    clip_fraction         | 0.0526      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 6.29        |
|    cost_values           | 0.576       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.595       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 96.8        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00519    |
|    std                   | 1.01        |
|    value_loss            | 198         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.6798792   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -826         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 6            |
|    time_elapsed          | 1628         |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0058398815 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.37         |
|    cost_value_loss       | 27.4         |
|    cost_values           | 0.879        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.736        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.8         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00525     |
|    std                   | 1.01         |
|    value_loss            | 20.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1309215   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -830         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 7            |
|    time_elapsed          | 1909         |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0054203095 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 6.73         |
|    cost_values           | 0.918        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.625        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.1         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00629     |
|    std                   | 1.01         |
|    value_loss            | 61.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.755        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.755        |
| reward                   | -0.65879714  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 8            |
|    time_elapsed          | 2198         |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0041290605 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.952        |
|    cost_value_loss       | 2.59         |
|    cost_values           | 0.545        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.749        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.00443     |
|    std                   | 1.01         |
|    value_loss            | 35.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1522387   |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -808         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 9            |
|    time_elapsed          | 2475         |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0021096463 |
|    clip_fraction         | 0.00337      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.56         |
|    cost_value_loss       | 22.1         |
|    cost_values           | 0.758        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.577        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 76.7         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 1            |
|    value_loss            | 141          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2399215   |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 10           |
|    time_elapsed          | 2776         |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0061395457 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 8.12         |
|    cost_values           | 0.524        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.8         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00594     |
|    std                   | 1            |
|    value_loss            | 31.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.66         |
| reward                   | -0.85230243  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 11           |
|    time_elapsed          | 3066         |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0076420587 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 0.558        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.6          |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.0104      |
|    std                   | 1.01         |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.965       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.965       |
| reward                   | -0.34968048 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -815        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 12          |
|    time_elapsed          | 3354        |
|    total_timesteps       | 225280      |
| train/                   |             |
|    approx_kl             | 0.007916452 |
|    clip_fraction         | 0.0662      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 5.74        |
|    cost_values           | 0.717       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.799       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.8        |
|    n_updates             | 1090        |
|    policy_gradient_loss  | -0.00769    |
|    std                   | 1.01        |
|    value_loss            | 41.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.94808984 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -816        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 13          |
|    time_elapsed          | 3645        |
|    total_timesteps       | 227328      |
| train/                   |             |
|    approx_kl             | 0.004386324 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 16.5        |
|    cost_values           | 0.926       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0.000781    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.41        |
|    n_updates             | 1100        |
|    policy_gradient_loss  | -0.00502    |
|    std                   | 1.01        |
|    value_loss            | 10          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0484       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0484       |
| reward                   | -0.64159733  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 14           |
|    time_elapsed          | 3945         |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0032210448 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 14           |
|    cost_values           | 0.861        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.843        |
|    lagrangian_multiplier | 0.000233     |
|    learning_rate         | 0.0003       |
|    loss                  | 26.6         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.00547     |
|    std                   | 1.01         |
|    value_loss            | 49.5         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.6        |
| reward                   | -0.512252  |
| rollout/                 |            |
|    ep_len_mean           | 904        |
|    ep_rew_mean           | -812       |
| time/                    |            |
|    fps                   | 7          |
|    iterations            | 15         |
|    time_elapsed          | 4253       |
|    total_timesteps       | 231424     |
| train/                   |            |
|    approx_kl             | 0.00519281 |
|    clip_fraction         | 0.0363     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.9        |
|    cost_value_loss       | 20         |
|    cost_values           | 0.947      |
|    entropy               | -2.85      |
|    entropy_loss          | -2.85      |
|    explained_variance    | 0.85       |
|    lagrangian_multiplier | 0.000128   |
|    learning_rate         | 0.0003     |
|    loss                  | 15.2       |
|    n_updates             | 1120       |
|    policy_gradient_loss  | -0.00601   |
|    std                   | 1.01       |
|    value_loss            | 10.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.93660086 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -798        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 16          |
|    time_elapsed          | 4555        |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.005751305 |
|    clip_fraction         | 0.0497      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.54        |
|    cost_value_loss       | 16          |
|    cost_values           | 1.27        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.712       |
|    lagrangian_multiplier | 0.00169     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.24        |
|    n_updates             | 1130        |
|    policy_gradient_loss  | -0.00616    |
|    std                   | 1.01        |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.6147592   |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 17           |
|    time_elapsed          | 4867         |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0048585655 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 5.55         |
|    cost_values           | 1.22         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.682        |
|    lagrangian_multiplier | 0.000225     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00493     |
|    std                   | 1.01         |
|    value_loss            | 26.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.8493777   |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 18           |
|    time_elapsed          | 5180         |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0046071354 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 0.769        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 3.05e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 1.01         |
|    value_loss            | 23.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.56200546 |
| rollout/                 |             |
|    ep_len_mean           | 905         |
|    ep_rew_mean           | -800        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 19          |
|    time_elapsed          | 5481        |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.004692002 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 0.866       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.8         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 1           |
|    value_loss            | 19.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3774425  |
| rollout/                 |             |
|    ep_len_mean           | 905         |
|    ep_rew_mean           | -791        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 20          |
|    time_elapsed          | 5796        |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.003683762 |
|    clip_fraction         | 0.0453      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.78        |
|    cost_value_loss       | 7.79        |
|    cost_values           | 0.641       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.861       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 1170        |
|    policy_gradient_loss  | -0.00635    |
|    std                   | 1.01        |
|    value_loss            | 16.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.98        |
| reward                   | -0.45230287 |
| rollout/                 |             |
|    ep_len_mean           | 905         |
|    ep_rew_mean           | -789        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 21          |
|    time_elapsed          | 6118        |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.008209818 |
|    clip_fraction         | 0.0549      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 0.795       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.000676    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.00736    |
|    std                   | 1.01        |
|    value_loss            | 14.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.57         |
| reward                   | -0.4687203   |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 22           |
|    time_elapsed          | 6435         |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0053431727 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 14.2         |
|    cost_values           | 0.907        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0.000826     |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.0045      |
|    std                   | 1.01         |
|    value_loss            | 19.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.8494615   |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -780         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 23           |
|    time_elapsed          | 6753         |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0055533955 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 9.17         |
|    cost_values           | 0.98         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.839        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.53         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 1.01         |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.6          |
| reward                   | -0.42548743  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 24           |
|    time_elapsed          | 7081         |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0069187977 |
|    clip_fraction         | 0.0444       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 5.94         |
|    cost_values           | 0.638        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.99         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00673     |
|    std                   | 1.01         |
|    value_loss            | 9.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.94516516 |
| rollout/                 |             |
|    ep_len_mean           | 905         |
|    ep_rew_mean           | -761        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 25          |
|    time_elapsed          | 7425        |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.004099534 |
|    clip_fraction         | 0.0186      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 32.9        |
|    cost_values           | 1.07        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0.00665     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.24        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00451    |
|    std                   | 1.01        |
|    value_loss            | 4.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3418022  |
| rollout/                 |             |
|    ep_len_mean           | 905         |
|    ep_rew_mean           | -757        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 26          |
|    time_elapsed          | 7762        |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.009002322 |
|    clip_fraction         | 0.0663      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 0.851       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 4.22e-06    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 1230        |
|    policy_gradient_loss  | -0.00777    |
|    std                   | 1.01        |
|    value_loss            | 14.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.35245442 |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -764        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 27          |
|    time_elapsed          | 8091        |
|    total_timesteps       | 256000      |
| train/                   |             |
|    approx_kl             | 0.008799597 |
|    clip_fraction         | 0.0778      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 4.49        |
|    cost_values           | 0.66        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 1240        |
|    policy_gradient_loss  | -0.00637    |
|    std                   | 1.01        |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.242        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.242        |
| reward                   | -0.5607058   |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 28           |
|    time_elapsed          | 8423         |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0066902903 |
|    clip_fraction         | 0.0585       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 3.78         |
|    cost_values           | 0.534        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.6         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.00655     |
|    std                   | 1.01         |
|    value_loss            | 35.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.319       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.319       |
| reward                   | -0.28822082 |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -760        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 29          |
|    time_elapsed          | 8752        |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.009207644 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.57        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 0.941       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0.00171     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.3         |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.0061     |
|    std                   | 1.01        |
|    value_loss            | 8.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.702        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.702        |
| reward                   | -0.40322077  |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 30           |
|    time_elapsed          | 9089         |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0031705871 |
|    clip_fraction         | 0.0433       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 21.3         |
|    cost_values           | 0.95         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 1.01         |
|    value_loss            | 11.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.258        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.258        |
| reward                   | -0.44618288  |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 31           |
|    time_elapsed          | 9429         |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0059267785 |
|    clip_fraction         | 0.0399       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 18.9         |
|    cost_values           | 0.956        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.914        |
|    lagrangian_multiplier | 0.00117      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.59         |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.0077      |
|    std                   | 1.01         |
|    value_loss            | 12.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.21         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.21         |
| reward                   | -0.4261813   |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 32           |
|    time_elapsed          | 9771         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0038365521 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 19.4         |
|    cost_values           | 0.828        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0.000117     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 1            |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.24        |
| reward                   | -0.4399495  |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 33          |
|    time_elapsed          | 10109       |
|    total_timesteps       | 268288      |
| train/                   |             |
|    approx_kl             | 0.006017039 |
|    clip_fraction         | 0.0403      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.5         |
|    cost_value_loss       | 22.3        |
|    cost_values           | 1.12        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.861       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.7        |
|    n_updates             | 1300        |
|    policy_gradient_loss  | -0.00624    |
|    std                   | 1           |
|    value_loss            | 6.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.345       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.345       |
| reward                   | -0.4803699  |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -733        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 34          |
|    time_elapsed          | 10453       |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.013404266 |
|    clip_fraction         | 0.0772      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 16.9        |
|    cost_values           | 1.07        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.83        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.00849    |
|    std                   | 1           |
|    value_loss            | 9.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.607       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.607       |
| reward                   | -0.51584417 |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 35          |
|    time_elapsed          | 10805       |
|    total_timesteps       | 272384      |
| train/                   |             |
|    approx_kl             | 0.005674953 |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 42.3        |
|    cost_values           | 1.31        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.731       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.7        |
|    n_updates             | 1320        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 1           |
|    value_loss            | 9.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.29        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.29        |
| reward                   | -0.76820564 |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -710        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 36          |
|    time_elapsed          | 11152       |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.00801964  |
|    clip_fraction         | 0.0471      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.71        |
|    cost_value_loss       | 35.3        |
|    cost_values           | 1.58        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0.00493     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.61        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00689    |
|    std                   | 0.997       |
|    value_loss            | 4.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.496       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.496       |
| reward                   | -0.44222084 |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 37          |
|    time_elapsed          | 11496       |
|    total_timesteps       | 276480      |
| train/                   |             |
|    approx_kl             | 0.00550045  |
|    clip_fraction         | 0.0557      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.15        |
|    cost_value_loss       | 36.9        |
|    cost_values           | 1.72        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.555       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 1340        |
|    policy_gradient_loss  | -0.00612    |
|    std                   | 0.992       |
|    value_loss            | 2.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.1         |
| reward                   | -0.37893286 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -702        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 38          |
|    time_elapsed          | 11855       |
|    total_timesteps       | 278528      |
| train/                   |             |
|    approx_kl             | 0.003998071 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.62        |
|    cost_value_loss       | 55          |
|    cost_values           | 1.97        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.689       |
|    lagrangian_multiplier | 0.00586     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.57        |
|    n_updates             | 1350        |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.99        |
|    value_loss            | 6.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.7133151   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 39           |
|    time_elapsed          | 12217        |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0035432898 |
|    clip_fraction         | 0.00928      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.52         |
|    cost_value_loss       | 36.8         |
|    cost_values           | 2.42         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.251        |
|    lagrangian_multiplier | 0.00217      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.988        |
|    value_loss            | 18.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.96184623  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 40           |
|    time_elapsed          | 12589        |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0023202442 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 19.7         |
|    cost_values           | 1.86         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0.00178      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.49         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | 4.64e-05     |
|    std                   | 0.986        |
|    value_loss            | 10.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.118       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.118       |
| reward                   | -0.53180057 |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -674        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 41          |
|    time_elapsed          | 12950       |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.008079559 |
|    clip_fraction         | 0.0498      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 24.7        |
|    cost_values           | 1.34        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0.000937    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.92        |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.00688    |
|    std                   | 0.987       |
|    value_loss            | 4.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.28        |
| reward                   | -0.47902015 |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 42          |
|    time_elapsed          | 13315       |
|    total_timesteps       | 286720      |
| train/                   |             |
|    approx_kl             | 0.006919373 |
|    clip_fraction         | 0.0556      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.3         |
|    cost_value_loss       | 46.1        |
|    cost_values           | 1.31        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.74        |
|    lagrangian_multiplier | 0.017       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.26        |
|    n_updates             | 1390        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.986       |
|    value_loss            | 16.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.623        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.623        |
| reward                   | -0.26759607  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 43           |
|    time_elapsed          | 13686        |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0023197937 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.2          |
|    cost_value_loss       | 58.6         |
|    cost_values           | 1.5          |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.417        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.5         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 0.986        |
|    value_loss            | 4.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0292      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0292      |
| reward                   | -0.73376477 |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -663        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 44          |
|    time_elapsed          | 14067       |
|    total_timesteps       | 290816      |
| train/                   |             |
|    approx_kl             | 0.00474581  |
|    clip_fraction         | 0.0338      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.97        |
|    cost_value_loss       | 56.6        |
|    cost_values           | 2.04        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.135       |
|    lagrangian_multiplier | 0.000609    |
|    learning_rate         | 0.0003      |
|    loss                  | 24.8        |
|    n_updates             | 1410        |
|    policy_gradient_loss  | -0.0037     |
|    std                   | 0.98        |
|    value_loss            | 15.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.11         |
| reward                   | -0.5386264   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 45           |
|    time_elapsed          | 14445        |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0014886557 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.75         |
|    cost_value_loss       | 50.2         |
|    cost_values           | 1.7          |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0.0622       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.66         |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.979        |
|    value_loss            | 17           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.4800502   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -659         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 46           |
|    time_elapsed          | 14838        |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0041827583 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.87         |
|    cost_value_loss       | 49.5         |
|    cost_values           | 1.45         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -0.17        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.5         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.983        |
|    value_loss            | 4.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.833        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.833        |
| reward                   | -0.5046362   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -655         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 47           |
|    time_elapsed          | 15227        |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0016006073 |
|    clip_fraction         | 0.00884      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.78         |
|    cost_value_loss       | 37.5         |
|    cost_values           | 1.13         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.905        |
|    lagrangian_multiplier | 0.0027       |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.000546    |
|    std                   | 0.985        |
|    value_loss            | 37.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.343        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.343        |
| reward                   | -0.35613403  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -647         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 48           |
|    time_elapsed          | 15622        |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0072731585 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.27         |
|    cost_value_loss       | 26.8         |
|    cost_values           | 0.832        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.00719     |
|    std                   | 0.985        |
|    value_loss            | 8.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.48952353 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -645        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 49          |
|    time_elapsed          | 16006       |
|    total_timesteps       | 301056      |
| train/                   |             |
|    approx_kl             | 0.004600728 |
|    clip_fraction         | 0.0688      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 42          |
|    cost_values           | 1.01        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22          |
|    n_updates             | 1460        |
|    policy_gradient_loss  | -0.00612    |
|    std                   | 0.984       |
|    value_loss            | 4.98        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/ld0gv8xm
------------------------------------
| avg_speed          | 0.2         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.2         |
| reward             | -0.42746052 |
| rollout/           |             |
|    ep_len_mean     | 946         |
|    ep_rew_mean     | -623        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 392         |
|    total_timesteps | 303104      |
------------------------------------
------------------------------------------
| avg_speed                | 0.000654    |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.000654    |
| reward                   | -0.46979788 |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -618        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 780         |
|    total_timesteps       | 305152      |
| train/                   |             |
|    approx_kl             | 0.003069491 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 32.5        |
|    cost_values           | 1.07        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0.00405     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.26        |
|    n_updates             | 1480        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.979       |
|    value_loss            | 21.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.435        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.435        |
| reward                   | -0.37087575  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -611         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 3            |
|    time_elapsed          | 1171         |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0055474485 |
|    clip_fraction         | 0.0327       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.61         |
|    cost_value_loss       | 54.3         |
|    cost_values           | 1.08         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.786        |
|    lagrangian_multiplier | 0.00211      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 0.974        |
|    value_loss            | 7.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.256        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.256        |
| reward                   | -0.54473764  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -610         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 4            |
|    time_elapsed          | 1583         |
|    total_timesteps       | 309248       |
| train/                   |              |
|    approx_kl             | 0.0053171357 |
|    clip_fraction         | 0.0609       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.58         |
|    cost_value_loss       | 54.7         |
|    cost_values           | 1.25         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0.00552      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.98         |
|    n_updates             | 1500         |
|    policy_gradient_loss  | -0.00889     |
|    std                   | 0.973        |
|    value_loss            | 5.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.319       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.319       |
| reward                   | -0.19343735 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -596        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 5           |
|    time_elapsed          | 1989        |
|    total_timesteps       | 311296      |
| train/                   |             |
|    approx_kl             | 0.006735773 |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.21        |
|    cost_value_loss       | 73.2        |
|    cost_values           | 0.921       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00271     |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 1510        |
|    policy_gradient_loss  | -0.00394    |
|    std                   | 0.975       |
|    value_loss            | 8.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.94        |
| reward                   | -0.7310609  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -602        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 6           |
|    time_elapsed          | 2373        |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.004423434 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 40.1        |
|    cost_values           | 0.857       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19          |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.0061     |
|    std                   | 0.976       |
|    value_loss            | 5.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.3         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.3         |
| reward                   | -0.5125094  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -599        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 7           |
|    time_elapsed          | 2733        |
|    total_timesteps       | 315392      |
| train/                   |             |
|    approx_kl             | 0.007136183 |
|    clip_fraction         | 0.045       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.33        |
|    cost_value_loss       | 49          |
|    cost_values           | 1.19        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0.00842     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.56        |
|    n_updates             | 1530        |
|    policy_gradient_loss  | -0.00707    |
|    std                   | 0.971       |
|    value_loss            | 6.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.839        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.839        |
| reward                   | -0.25612867  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -586         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 8            |
|    time_elapsed          | 3095         |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0050381883 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.41         |
|    cost_value_loss       | 44.4         |
|    cost_values           | 1.4          |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.75         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.4         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00563     |
|    std                   | 0.971        |
|    value_loss            | 5.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.54        |
| reward                   | -0.54247075 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -581        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3460        |
|    total_timesteps       | 319488      |
| train/                   |             |
|    approx_kl             | 0.005040081 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.28        |
|    cost_value_loss       | 76.6        |
|    cost_values           | 1.84        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.559       |
|    lagrangian_multiplier | 0.0062      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 1550        |
|    policy_gradient_loss  | -0.00369    |
|    std                   | 0.971       |
|    value_loss            | 15.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.899        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.899        |
| reward                   | -0.5194056   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -578         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 10           |
|    time_elapsed          | 3829         |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0055233752 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.19         |
|    cost_value_loss       | 73.1         |
|    cost_values           | 2.26         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.75         |
|    lagrangian_multiplier | 0.0087       |
|    learning_rate         | 0.0003       |
|    loss                  | 9            |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 0.975        |
|    value_loss            | 3.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.27         |
| reward                   | -0.31223536  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -570         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 11           |
|    time_elapsed          | 4199         |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0060358336 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 102          |
|    cost_values           | 2.65         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -2.27        |
|    lagrangian_multiplier | 0.00758      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.976        |
|    value_loss            | 2.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0392      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0392      |
| reward                   | -0.4323706  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -563        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 12          |
|    time_elapsed          | 4583        |
|    total_timesteps       | 325632      |
| train/                   |             |
|    approx_kl             | 0.004317886 |
|    clip_fraction         | 0.0503      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.08        |
|    cost_value_loss       | 60.9        |
|    cost_values           | 2.94        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.267       |
|    lagrangian_multiplier | 0.00952     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.91        |
|    n_updates             | 1580        |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 0.972       |
|    value_loss            | 2.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.294       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.294       |
| reward                   | -0.3805339  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -560        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 13          |
|    time_elapsed          | 4957        |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.005376692 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.5         |
|    cost_value_loss       | 50.4        |
|    cost_values           | 2.94        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.78       |
|    explained_variance    | -0.493      |
|    lagrangian_multiplier | 0.00765     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.02        |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.00159    |
|    std                   | 0.976       |
|    value_loss            | 1.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0148958  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -557        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 5325        |
|    total_timesteps       | 329728      |
| train/                   |             |
|    approx_kl             | 0.009870241 |
|    clip_fraction         | 0.0781      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.46        |
|    cost_value_loss       | 50.6        |
|    cost_values           | 2.95        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.79       |
|    explained_variance    | -0.161      |
|    lagrangian_multiplier | 0.00768     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.92        |
|    n_updates             | 1600        |
|    policy_gradient_loss  | -0.0051     |
|    std                   | 0.969       |
|    value_loss            | 0.405       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.021       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.021       |
| reward                   | -0.5129461  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -562        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 15          |
|    time_elapsed          | 5691        |
|    total_timesteps       | 331776      |
| train/                   |             |
|    approx_kl             | 0.004446123 |
|    clip_fraction         | 0.0253      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 17.3        |
|    cost_values           | 2.53        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.11        |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 1610        |
|    policy_gradient_loss  | 0.00177     |
|    std                   | 0.967       |
|    value_loss            | 8.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.202        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.202        |
| reward                   | -0.35560367  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -556         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6047         |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0054717865 |
|    clip_fraction         | 0.00894      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 6.94         |
|    cost_values           | 1.47         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0.00089      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.61         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.967        |
|    value_loss            | 3.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0939      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0939      |
| reward                   | -0.564646   |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -549        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 17          |
|    time_elapsed          | 6409        |
|    total_timesteps       | 335872      |
| train/                   |             |
|    approx_kl             | 0.005318874 |
|    clip_fraction         | 0.0207      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.34        |
|    cost_value_loss       | 97.7        |
|    cost_values           | 1.48        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.435       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 47.9        |
|    n_updates             | 1630        |
|    policy_gradient_loss  | -0.00311    |
|    std                   | 0.966       |
|    value_loss            | 1.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.44500858  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 6789         |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0031765574 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.57         |
|    cost_value_loss       | 33           |
|    cost_values           | 1.76         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.752        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.5         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.963        |
|    value_loss            | 0.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.33967265  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 19           |
|    time_elapsed          | 7143         |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0018698396 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.18         |
|    cost_value_loss       | 99.5         |
|    cost_values           | 1.71         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0.0186       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.89         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.000994    |
|    std                   | 0.962        |
|    value_loss            | 5.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0175       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0175       |
| reward                   | -0.28888673  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -533         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7476         |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0070182416 |
|    clip_fraction         | 0.0524       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.35         |
|    cost_value_loss       | 88.2         |
|    cost_values           | 1.41         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.422        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.8         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00534     |
|    std                   | 0.962        |
|    value_loss            | 1.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.114       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.114       |
| reward                   | -0.536835   |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -532        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 7812        |
|    total_timesteps       | 344064      |
| train/                   |             |
|    approx_kl             | 0.002534007 |
|    clip_fraction         | 0.00513     |
|    clip_range            | 0.2         |
|    cost_returns          | 8.1         |
|    cost_value_loss       | 75          |
|    cost_values           | 1.84        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.774       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.3        |
|    n_updates             | 1670        |
|    policy_gradient_loss  | -0.000933   |
|    std                   | 0.963       |
|    value_loss            | 0.948       |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.0402        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0402        |
| reward                   | -0.32093957   |
| rollout/                 |               |
|    ep_len_mean           | 972           |
|    ep_rew_mean           | -525          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 22            |
|    time_elapsed          | 8151          |
|    total_timesteps       | 346112        |
| train/                   |               |
|    approx_kl             | 0.00079343386 |
|    clip_fraction         | 0.000439      |
|    clip_range            | 0.2           |
|    cost_returns          | 4.29          |
|    cost_value_loss       | 29.4          |
|    cost_values           | 1.54          |
|    entropy               | -2.76         |
|    entropy_loss          | -2.76         |
|    explained_variance    | 0.963         |
|    lagrangian_multiplier | 0.047         |
|    learning_rate         | 0.0003        |
|    loss                  | 2.43          |
|    n_updates             | 1680          |
|    policy_gradient_loss  | -0.00049      |
|    std                   | 0.964         |
|    value_loss            | 17.8          |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.418       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.418       |
| reward                   | -0.56173795 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 23          |
|    time_elapsed          | 8491        |
|    total_timesteps       | 348160      |
| train/                   |             |
|    approx_kl             | 0.003997742 |
|    clip_fraction         | 0.0135      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.04        |
|    cost_value_loss       | 32.1        |
|    cost_values           | 1.25        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.76       |
|    explained_variance    | -0.659      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.8        |
|    n_updates             | 1690        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.965       |
|    value_loss            | 2.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.167       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.167       |
| reward                   | -0.48077714 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -516        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 8834        |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.00305396  |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.91        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 1.55        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -0.152      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.92        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00267    |
|    std                   | 0.964       |
|    value_loss            | 1.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.25003302  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 25           |
|    time_elapsed          | 9175         |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0017269809 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.2          |
|    cost_value_loss       | 98.1         |
|    cost_values           | 1.32         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0.0162       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.000433    |
|    std                   | 0.965        |
|    value_loss            | 6.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.189        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.189        |
| reward                   | -0.28529668  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 9513         |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0016691802 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.93         |
|    cost_value_loss       | 124          |
|    cost_values           | 1.23         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.76         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 59.2         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.965        |
|    value_loss            | 1.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.027        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.027        |
| reward                   | -0.3117344   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 27           |
|    time_elapsed          | 9866         |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0047467016 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.85         |
|    cost_value_loss       | 51.3         |
|    cost_values           | 1.62         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.412        |
|    lagrangian_multiplier | 0.000459     |
|    learning_rate         | 0.0003       |
|    loss                  | 24.5         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.965        |
|    value_loss            | 11.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.602         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.602         |
| reward                   | -0.55988836   |
| rollout/                 |               |
|    ep_len_mean           | 969           |
|    ep_rew_mean           | -494          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 28            |
|    time_elapsed          | 10222         |
|    total_timesteps       | 358400        |
| train/                   |               |
|    approx_kl             | 0.00038455988 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 13.3          |
|    cost_value_loss       | 185           |
|    cost_values           | 1.6           |
|    entropy               | -2.77         |
|    entropy_loss          | -2.77         |
|    explained_variance    | 0.983         |
|    lagrangian_multiplier | 0.0325        |
|    learning_rate         | 0.0003        |
|    loss                  | 7.18          |
|    n_updates             | 1740          |
|    policy_gradient_loss  | -0.000138     |
|    std                   | 0.965         |
|    value_loss            | 7.07          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0839       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0839       |
| reward                   | -0.4945639   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 10574        |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0058795605 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.04         |
|    cost_value_loss       | 107          |
|    cost_values           | 0.939        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.015        |
|    learning_rate         | 0.0003       |
|    loss                  | 7.37         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 0.964        |
|    value_loss            | 7.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0489       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0489       |
| reward                   | -0.44764632  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 30           |
|    time_elapsed          | 10932        |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0059198616 |
|    clip_fraction         | 0.0491       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.66         |
|    cost_value_loss       | 73.9         |
|    cost_values           | 0.769        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0.0076       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.83         |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 0.962        |
|    value_loss            | 7.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.26         |
| reward                   | -0.27084306  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 31           |
|    time_elapsed          | 11281        |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0045666434 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 0.943        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.96         |
|    value_loss            | 7.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.46        |
| reward                   | -0.78738844 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 32          |
|    time_elapsed          | 11636       |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.004759974 |
|    clip_fraction         | 0.02        |
|    clip_range            | 0.2         |
|    cost_returns          | 7.66        |
|    cost_value_loss       | 86.6        |
|    cost_values           | 1.23        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 40          |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 0.959       |
|    value_loss            | 1.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.306        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.306        |
| reward                   | -0.44515496  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 33           |
|    time_elapsed          | 11989        |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0034253434 |
|    clip_fraction         | 0.00479      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.93         |
|    cost_value_loss       | 74.4         |
|    cost_values           | 1.6          |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.662        |
|    lagrangian_multiplier | 0.000749     |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.959        |
|    value_loss            | 3.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0204       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0204       |
| reward                   | -0.5632082   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 12336        |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0047537275 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.57         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 1.53         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0.00292      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.956        |
|    value_loss            | 1.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.346       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.346       |
| reward                   | -0.5589209  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 35          |
|    time_elapsed          | 12688       |
|    total_timesteps       | 372736      |
| train/                   |             |
|    approx_kl             | 0.010501493 |
|    clip_fraction         | 0.0735      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 18.1        |
|    cost_values           | 1.2         |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0.00339     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.42        |
|    n_updates             | 1810        |
|    policy_gradient_loss  | -0.00423    |
|    std                   | 0.954       |
|    value_loss            | 12.8        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.116         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.116         |
| reward                   | -0.27238393   |
| rollout/                 |               |
|    ep_len_mean           | 964           |
|    ep_rew_mean           | -480          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 36            |
|    time_elapsed          | 13045         |
|    total_timesteps       | 374784        |
| train/                   |               |
|    approx_kl             | 0.00066977023 |
|    clip_fraction         | 0.000391      |
|    clip_range            | 0.2           |
|    cost_returns          | 11.3          |
|    cost_value_loss       | 131           |
|    cost_values           | 1.57          |
|    entropy               | -2.74         |
|    entropy_loss          | -2.74         |
|    explained_variance    | 0.787         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 61.9          |
|    n_updates             | 1820          |
|    policy_gradient_loss  | -0.000845     |
|    std                   | 0.953         |
|    value_loss            | 1.78          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0549       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0549       |
| reward                   | -0.54745394  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 37           |
|    time_elapsed          | 13403        |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0024230606 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.1         |
|    cost_value_loss       | 117          |
|    cost_values           | 1.95         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -12.3        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 59.9         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.000878    |
|    std                   | 0.954        |
|    value_loss            | 3.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0655       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0655       |
| reward                   | -0.3927645   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 38           |
|    time_elapsed          | 13762        |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0060121045 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.51         |
|    cost_value_loss       | 32.4         |
|    cost_values           | 2.29         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.0464       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.956        |
|    value_loss            | 2.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00665     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00665     |
| reward                   | -0.3178323  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 39          |
|    time_elapsed          | 14122       |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.007839329 |
|    clip_fraction         | 0.0698      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.82        |
|    cost_value_loss       | 83          |
|    cost_values           | 2.6         |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.798       |
|    lagrangian_multiplier | 0.0141      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.63        |
|    n_updates             | 1850        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.952       |
|    value_loss            | 0.495       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0747       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0747       |
| reward                   | -0.50462854  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 40           |
|    time_elapsed          | 14483        |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0044904253 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 119          |
|    cost_values           | 2.75         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.824        |
|    lagrangian_multiplier | 0.0195       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.09         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.948        |
|    value_loss            | 0.472        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0221       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0221       |
| reward                   | -0.38689357  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 41           |
|    time_elapsed          | 14848        |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0046841274 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.18         |
|    cost_value_loss       | 86.6         |
|    cost_values           | 2.77         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.564        |
|    lagrangian_multiplier | 0.0149       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.946        |
|    value_loss            | 0.917        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.144       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.144       |
| reward                   | -0.37909538 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 42          |
|    time_elapsed          | 15213       |
|    total_timesteps       | 387072      |
| train/                   |             |
|    approx_kl             | 0.005125176 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 2.95        |
|    cost_values           | 2.7         |
|    entropy               | -2.72       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -0.00236    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 1880        |
|    policy_gradient_loss  | 0.000889    |
|    std                   | 0.941       |
|    value_loss            | 2.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.48726898  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 43           |
|    time_elapsed          | 15575        |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0076010707 |
|    clip_fraction         | 0.0759       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.65         |
|    cost_value_loss       | 104          |
|    cost_values           | 2.82         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.671        |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.93         |
|    value_loss            | 0.157        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0188      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0188      |
| reward                   | -0.4391063  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 44          |
|    time_elapsed          | 15942       |
|    total_timesteps       | 391168      |
| train/                   |             |
|    approx_kl             | 0.012486054 |
|    clip_fraction         | 0.0441      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 0.676       |
|    cost_values           | 2.66        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.403       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.06        |
|    n_updates             | 1900        |
|    policy_gradient_loss  | -0.000584   |
|    std                   | 0.924       |
|    value_loss            | 2.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.21        |
| reward                   | -0.46894145 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 45          |
|    time_elapsed          | 16313       |
|    total_timesteps       | 393216      |
| train/                   |             |
|    approx_kl             | 0.008736927 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.31        |
|    cost_value_loss       | 1.83        |
|    cost_values           | 2.33        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.705       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.677       |
|    n_updates             | 1910        |
|    policy_gradient_loss  | 0.0056      |
|    std                   | 0.92        |
|    value_loss            | 0.365       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.192        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.192        |
| reward                   | -0.39760306  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 46           |
|    time_elapsed          | 16687        |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0048022475 |
|    clip_fraction         | 0.175        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 107          |
|    cost_values           | 2.46         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.402        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.6         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | 0.00967      |
|    std                   | 0.919        |
|    value_loss            | 3.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.14        |
| reward                   | -0.34526068 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 47          |
|    time_elapsed          | 17059       |
|    total_timesteps       | 397312      |
| train/                   |             |
|    approx_kl             | 0.00475159  |
|    clip_fraction         | 0.00962     |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 175         |
|    cost_values           | 2.89        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | -4.6        |
|    lagrangian_multiplier | 0.0027      |
|    learning_rate         | 0.0003      |
|    loss                  | 37.8        |
|    n_updates             | 1930        |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.919       |
|    value_loss            | 0.794       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.23         |
| reward                   | -0.6320268   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 48           |
|    time_elapsed          | 17433        |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0072901733 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.42         |
|    cost_value_loss       | 101          |
|    cost_values           | 2.85         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -2.71        |
|    lagrangian_multiplier | 0.0105       |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 1940         |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.919        |
|    value_loss            | 1.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.251        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.251        |
| reward                   | -0.54944545  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 49           |
|    time_elapsed          | 17809        |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0039027827 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.68         |
|    cost_value_loss       | 62.9         |
|    cost_values           | 2.88         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.402        |
|    lagrangian_multiplier | 0.0084       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.47         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.922        |
|    value_loss            | 1.92         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.0046     |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.0046     |
| reward             | -0.4200041 |
| rollout/           |            |
|    ep_len_mean     | 980        |
|    ep_rew_mean     | -456       |
| time/              |            |
|    fps             | 5          |
|    iterations      | 1          |
|    time_elapsed    | 376        |
|    total_timesteps | 403456     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.0279      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0279      |
| reward                   | -0.30288237 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 760         |
|    total_timesteps       | 405504      |
| train/                   |             |
|    approx_kl             | 0.004842859 |
|    clip_fraction         | 0.0101      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.76        |
|    cost_value_loss       | 100         |
|    cost_values           | 2.69        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | -1.27       |
|    lagrangian_multiplier | 0.0139      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.3         |
|    n_updates             | 1970        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.926       |
|    value_loss            | 1.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.185        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.185        |
| reward                   | -0.5157168   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 3            |
|    time_elapsed          | 1135         |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0058856877 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.1         |
|    cost_value_loss       | 149          |
|    cost_values           | 2.78         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.0306       |
|    lagrangian_multiplier | 0.0179       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.85         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.928        |
|    value_loss            | 1.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0893       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0893       |
| reward                   | -0.58748525  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 4            |
|    time_elapsed          | 1503         |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0046327263 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.09         |
|    cost_value_loss       | 65.3         |
|    cost_values           | 2.62         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.591        |
|    lagrangian_multiplier | 0.00314      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.7         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.000924    |
|    std                   | 0.928        |
|    value_loss            | 3.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.02         |
| reward                   | -0.33186156  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 5            |
|    time_elapsed          | 1875         |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0056788907 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.9          |
|    cost_value_loss       | 5.57         |
|    cost_values           | 2.23         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.0957       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.92         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.93         |
|    value_loss            | 2.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.134        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.134        |
| reward                   | -0.46964285  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2250         |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0026365044 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.42         |
|    cost_value_loss       | 18.8         |
|    cost_values           | 1.69         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0.0553       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.21         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | 0.00186      |
|    std                   | 0.931        |
|    value_loss            | 6.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.177       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.177       |
| reward                   | -0.26100108 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 7           |
|    time_elapsed          | 2624        |
|    total_timesteps       | 415744      |
| train/                   |             |
|    approx_kl             | 0.005562164 |
|    clip_fraction         | 0.0303      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.62        |
|    cost_value_loss       | 50.9        |
|    cost_values           | 1.6         |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.51        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.5        |
|    n_updates             | 2020        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.931       |
|    value_loss            | 1.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0587       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0587       |
| reward                   | -0.5246618   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 8            |
|    time_elapsed          | 3001         |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0037676857 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.33         |
|    cost_value_loss       | 19.4         |
|    cost_values           | 1.84         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -0.169       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.931        |
|    value_loss            | 2.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0967       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0967       |
| reward                   | -0.27912158  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 9            |
|    time_elapsed          | 3381         |
|    total_timesteps       | 419840       |
| train/                   |              |
|    approx_kl             | 0.0057997457 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.81         |
|    cost_value_loss       | 101          |
|    cost_values           | 2.36         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -2.85        |
|    lagrangian_multiplier | 0.0128       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.22         |
|    n_updates             | 2040         |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 0.931        |
|    value_loss            | 1.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.189262   |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 10          |
|    time_elapsed          | 3764        |
|    total_timesteps       | 421888      |
| train/                   |             |
|    approx_kl             | 0.004514767 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.47        |
|    cost_value_loss       | 68.8        |
|    cost_values           | 2.72        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | -0.0947     |
|    lagrangian_multiplier | 0.0101      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.58        |
|    n_updates             | 2050        |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.933       |
|    value_loss            | 2.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.543        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.543        |
| reward                   | -0.4038917   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 11           |
|    time_elapsed          | 4153         |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0018781498 |
|    clip_fraction         | 0.00396      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.82         |
|    cost_value_loss       | 54.8         |
|    cost_values           | 1.95         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0.456        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.47         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.000983    |
|    std                   | 0.933        |
|    value_loss            | 25.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.31441292  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 12           |
|    time_elapsed          | 4543         |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0016358141 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.4         |
|    cost_value_loss       | 226          |
|    cost_values           | 1.64         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0.0222       |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 0.933        |
|    value_loss            | 7.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0538       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0538       |
| reward                   | -0.35140032  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 13           |
|    time_elapsed          | 4930         |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0045726905 |
|    clip_fraction         | 0.0386       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 167          |
|    cost_values           | 1.2          |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0.0152       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.934        |
|    value_loss            | 4.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.728       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.728       |
| reward                   | -0.3372931  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 5318        |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.002321387 |
|    clip_fraction         | 0.000684    |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 153         |
|    cost_values           | 1.65        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.635       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 76          |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.934       |
|    value_loss            | 1.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.159        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.159        |
| reward                   | -0.49516356  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 15           |
|    time_elapsed          | 5711         |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0062609334 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.69         |
|    cost_value_loss       | 67.8         |
|    cost_values           | 2.12         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.564        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.5         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.00499     |
|    std                   | 0.933        |
|    value_loss            | 1.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.221        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.221        |
| reward                   | -0.34080753  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6099         |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0063701803 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.9         |
|    cost_value_loss       | 251          |
|    cost_values           | 2.39         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0.0336       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.22         |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 0.934        |
|    value_loss            | 0.784        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.248        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.248        |
| reward                   | -0.56254023  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 17           |
|    time_elapsed          | 6493         |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0061432095 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.76         |
|    cost_value_loss       | 19.9         |
|    cost_values           | 2.48         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | -0.888       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.62         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.933        |
|    value_loss            | 0.239        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0436        |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.0436        |
| reward                   | -0.44565833   |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -451          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 18            |
|    time_elapsed          | 6889          |
|    total_timesteps       | 438272        |
| train/                   |               |
|    approx_kl             | 0.00059554534 |
|    clip_fraction         | 0.00776       |
|    clip_range            | 0.2           |
|    cost_returns          | 5.55          |
|    cost_value_loss       | 25.7          |
|    cost_values           | 2.87          |
|    entropy               | -2.69         |
|    entropy_loss          | -2.7          |
|    explained_variance    | -0.0222       |
|    lagrangian_multiplier | 0.00363       |
|    learning_rate         | 0.0003        |
|    loss                  | 6.41          |
|    n_updates             | 2130          |
|    policy_gradient_loss  | -0.000876     |
|    std                   | 0.93          |
|    value_loss            | 2.04          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0112       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0112       |
| reward                   | -0.3520626   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 19           |
|    time_elapsed          | 7289         |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0015781868 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.91         |
|    cost_value_loss       | 38.8         |
|    cost_values           | 2.96         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -0.351       |
|    lagrangian_multiplier | 0.008        |
|    learning_rate         | 0.0003       |
|    loss                  | 6.13         |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.93         |
|    value_loss            | 1.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0329      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0329      |
| reward                   | -0.5388858  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 20          |
|    time_elapsed          | 7690        |
|    total_timesteps       | 442368      |
| train/                   |             |
|    approx_kl             | 0.005501097 |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.79        |
|    cost_value_loss       | 28.2        |
|    cost_values           | 2.95        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.0242      |
|    lagrangian_multiplier | 0.00577     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.92        |
|    n_updates             | 2150        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.924       |
|    value_loss            | 0.764       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.399       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.399       |
| reward                   | -0.46325907 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 8091        |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.002468157 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 118         |
|    cost_values           | 2.96        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | -0.732      |
|    lagrangian_multiplier | 0.015       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.62        |
|    n_updates             | 2160        |
|    policy_gradient_loss  | 0.00312     |
|    std                   | 0.926       |
|    value_loss            | 1.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.5690486   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 22           |
|    time_elapsed          | 8492         |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0019951584 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 82.5         |
|    cost_values           | 2.99         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.00527     |
|    lagrangian_multiplier | 0.0144       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.41         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.923        |
|    value_loss            | 0.789        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0146      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0146      |
| reward                   | -0.49113753 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 23          |
|    time_elapsed          | 8893        |
|    total_timesteps       | 448512      |
| train/                   |             |
|    approx_kl             | 0.004544661 |
|    clip_fraction         | 0.0138      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 159         |
|    cost_values           | 2.98        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.106       |
|    lagrangian_multiplier | 0.023       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.03        |
|    n_updates             | 2180        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.923       |
|    value_loss            | 1.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0872       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0872       |
| reward                   | -0.53670627  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 24           |
|    time_elapsed          | 9299         |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0043213135 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 165          |
|    cost_values           | 2.98         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -7.1         |
|    lagrangian_multiplier | 0.0204       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.75         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.925        |
|    value_loss            | 0.763        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.322        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.322        |
| reward                   | -0.34873053  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 25           |
|    time_elapsed          | 9705         |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0036895843 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 90.1         |
|    cost_values           | 2.98         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.237       |
|    lagrangian_multiplier | 0.0106       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.26         |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.925        |
|    value_loss            | 0.816        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0172       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0172       |
| reward                   | -0.5728887   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 10117        |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0034908578 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.01         |
|    cost_value_loss       | 48.1         |
|    cost_values           | 2.99         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.12         |
|    lagrangian_multiplier | 0.00613      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.25         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.92         |
|    value_loss            | 1.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.46693096  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 27           |
|    time_elapsed          | 10522        |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0021633566 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.9         |
|    cost_value_loss       | 121          |
|    cost_values           | 2.98         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.392        |
|    lagrangian_multiplier | 0.0178       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.49         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.000742    |
|    std                   | 0.918        |
|    value_loss            | 1.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0828       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0828       |
| reward                   | -0.4501815   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 28           |
|    time_elapsed          | 10935        |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0036031352 |
|    clip_fraction         | 0.0449       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.2          |
|    cost_value_loss       | 57.6         |
|    cost_values           | 2.99         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.519        |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.913        |
|    value_loss            | 0.868        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.114        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.114        |
| reward                   | -0.4472905   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 11352        |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0024326858 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 182          |
|    cost_values           | 2.99         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.297        |
|    lagrangian_multiplier | 0.0246       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.52         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.912        |
|    value_loss            | 1.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0306      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0306      |
| reward                   | -0.36738077 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 30          |
|    time_elapsed          | 11771       |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.003692873 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.5        |
|    cost_value_loss       | 220         |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.234       |
|    lagrangian_multiplier | 0.0254      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.00238    |
|    std                   | 0.911       |
|    value_loss            | 1.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00887      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00887      |
| reward                   | -0.44643286  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 31           |
|    time_elapsed          | 12189        |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0010748229 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 124          |
|    cost_values           | 2.99         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.575        |
|    lagrangian_multiplier | 0.031        |
|    learning_rate         | 0.0003       |
|    loss                  | 6.38         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.91         |
|    value_loss            | 0.523        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.157        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.157        |
| reward                   | -0.39354277  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 32           |
|    time_elapsed          | 12610        |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0020526792 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.24         |
|    cost_value_loss       | 95.2         |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.00977      |
|    lagrangian_multiplier | 0.017        |
|    learning_rate         | 0.0003       |
|    loss                  | 7.41         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.909        |
|    value_loss            | 4.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.46169752  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 33           |
|    time_elapsed          | 13054        |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0005291167 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 98.4         |
|    cost_values           | 3            |
|    entropy               | -2.64        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.645        |
|    lagrangian_multiplier | 0.00441      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.7         |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.908        |
|    value_loss            | 0.183        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0533       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0533       |
| reward                   | -0.46889707  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 13502        |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0007740023 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 116          |
|    cost_values           | 3            |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.466        |
|    lagrangian_multiplier | 0.0121       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.00015     |
|    std                   | 0.908        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0906       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0906       |
| reward                   | -0.4427912   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 35           |
|    time_elapsed          | 13953        |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0026038052 |
|    clip_fraction         | 0.00977      |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 123          |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.112        |
|    lagrangian_multiplier | 0.0223       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.75         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.91         |
|    value_loss            | 0.211        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0382       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0382       |
| reward                   | -0.3593902   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 14413        |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0068686204 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 14           |
|    cost_value_loss       | 152          |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -3.14        |
|    lagrangian_multiplier | 0.00555      |
|    learning_rate         | 0.0003       |
|    loss                  | 22.6         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.000428    |
|    std                   | 0.91         |
|    value_loss            | 1.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.245       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.245       |
| reward                   | -0.42715856 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 37          |
|    time_elapsed          | 14869       |
|    total_timesteps       | 477184      |
| train/                   |             |
|    approx_kl             | 0.00587309  |
|    clip_fraction         | 0.0353      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 118         |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.389       |
|    lagrangian_multiplier | 0.00335     |
|    learning_rate         | 0.0003      |
|    loss                  | 25.2        |
|    n_updates             | 2320        |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 0.911       |
|    value_loss            | 0.717       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0411      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0411      |
| reward                   | -0.2771225  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 38          |
|    time_elapsed          | 15326       |
|    total_timesteps       | 479232      |
| train/                   |             |
|    approx_kl             | 0.004616877 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 184         |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0.0139      |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 2330        |
|    policy_gradient_loss  | -0.00561    |
|    std                   | 0.91        |
|    value_loss            | 0.349       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.171       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.171       |
| reward                   | -0.3843374  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 39          |
|    time_elapsed          | 15781       |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.004324543 |
|    clip_fraction         | 0.0215      |
|    clip_range            | 0.2         |
|    cost_returns          | 16.2        |
|    cost_value_loss       | 193         |
|    cost_values           | 3           |
|    entropy               | -2.64       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0.0277      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.21        |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.908       |
|    value_loss            | 0.179       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0317      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0317      |
| reward                   | -0.36789548 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 40          |
|    time_elapsed          | 16241       |
|    total_timesteps       | 483328      |
| train/                   |             |
|    approx_kl             | 0.005568319 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 146         |
|    cost_values           | 3           |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.629       |
|    lagrangian_multiplier | 0.00906     |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 2350        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.905       |
|    value_loss            | 1.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.213        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.213        |
| reward                   | -0.3905122   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 41           |
|    time_elapsed          | 16702        |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0044141426 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 130          |
|    cost_values           | 3            |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.217        |
|    lagrangian_multiplier | 0.00182      |
|    learning_rate         | 0.0003       |
|    loss                  | 34.8         |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.000967    |
|    std                   | 0.905        |
|    value_loss            | 0.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0569       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0569       |
| reward                   | -0.5605803   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 42           |
|    time_elapsed          | 17160        |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0025474685 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.29         |
|    cost_value_loss       | 65.8         |
|    cost_values           | 2.99         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | -0.0719      |
|    lagrangian_multiplier | 0.00484      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.906        |
|    value_loss            | 1.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.198        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.198        |
| reward                   | -0.26075473  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 17628        |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0050704796 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.7         |
|    cost_value_loss       | 127          |
|    cost_values           | 3            |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.271        |
|    lagrangian_multiplier | 0.00171      |
|    learning_rate         | 0.0003       |
|    loss                  | 34.2         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.905        |
|    value_loss            | 1.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0222       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0222       |
| reward                   | -0.49786583  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 44           |
|    time_elapsed          | 18097        |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0031925733 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 136          |
|    cost_values           | 3            |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.562        |
|    lagrangian_multiplier | 0.0318       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.98         |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.905        |
|    value_loss            | 1.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.54152334  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 45           |
|    time_elapsed          | 18567        |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0042045494 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.01         |
|    cost_value_loss       | 32           |
|    cost_values           | 2.99         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.0683       |
|    lagrangian_multiplier | 0.0065       |
|    learning_rate         | 0.0003       |
|    loss                  | 6            |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.000815    |
|    std                   | 0.903        |
|    value_loss            | 2.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.188       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.188       |
| reward                   | -0.41557455 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 46          |
|    time_elapsed          | 19040       |
|    total_timesteps       | 495616      |
| train/                   |             |
|    approx_kl             | 0.003074378 |
|    clip_fraction         | 0.0122      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 155         |
|    cost_values           | 3           |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | -0.436      |
|    lagrangian_multiplier | 0.00917     |
|    learning_rate         | 0.0003      |
|    loss                  | 16.2        |
|    n_updates             | 2410        |
|    policy_gradient_loss  | -0.000704   |
|    std                   | 0.903       |
|    value_loss            | 3.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.226        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.226        |
| reward                   | -0.34504175  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 47           |
|    time_elapsed          | 19512        |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0044876086 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 123          |
|    cost_values           | 2.99         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.63        |
|    explained_variance    | -0.101       |
|    lagrangian_multiplier | 0.0158       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.42         |
|    n_updates             | 2420         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.904        |
|    value_loss            | 2.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.384        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.384        |
| reward                   | -0.3013666   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 48           |
|    time_elapsed          | 19989        |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0040828562 |
|    clip_fraction         | 0.0445       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.96         |
|    cost_value_loss       | 50.2         |
|    cost_values           | 2.99         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.61         |
|    lagrangian_multiplier | 0.000208     |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.911        |
|    value_loss            | 0.621        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.124        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.124        |
| reward                   | -0.5102953   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 49           |
|    time_elapsed          | 20463        |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0076191504 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.05         |
|    cost_value_loss       | 5.28         |
|    cost_values           | 3            |
|    entropy               | -2.66        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -0.0292      |
|    lagrangian_multiplier | 0.000183     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.43         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.000849    |
|    std                   | 0.913        |
|    value_loss            | 0.419        |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/ld0gv8xm
----------------------------------
| avg_speed          | 0.209     |
| cost               | 1         |
| is_success         | 0         |
| max_speed          | 0.209     |
| reward             | -0.460149 |
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | -432      |
| time/              |           |
|    fps             | 4         |
|    iterations      | 1         |
|    time_elapsed    | 480       |
|    total_timesteps | 503808    |
----------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -0.4149218   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 2            |
|    time_elapsed          | 962          |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0031712686 |
|    clip_fraction         | 0.0444       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 150          |
|    cost_values           | 3            |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.262       |
|    lagrangian_multiplier | 0.000765     |
|    learning_rate         | 0.0003       |
|    loss                  | 57.1         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.918        |
|    value_loss            | 1.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0877       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0877       |
| reward                   | -0.31106225  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 3            |
|    time_elapsed          | 1447         |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0022045253 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.23         |
|    cost_value_loss       | 54.5         |
|    cost_values           | 3            |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0.00665      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.41         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.92         |
|    value_loss            | 0.223        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.5201978   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 4            |
|    time_elapsed          | 1929         |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0036352198 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.35         |
|    cost_value_loss       | 40.4         |
|    cost_values           | 3            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0.0064       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.95         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00447     |
|    std                   | 0.924        |
|    value_loss            | 0.662        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0367      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0367      |
| reward                   | -0.45569825 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 5           |
|    time_elapsed          | 2413        |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.00412698  |
|    clip_fraction         | 0.0211      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.04        |
|    cost_value_loss       | 32.6        |
|    cost_values           | 2.99        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.469       |
|    lagrangian_multiplier | 0.00544     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.87        |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.925       |
|    value_loss            | 2.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0275       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0275       |
| reward                   | -0.47790146  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 6            |
|    time_elapsed          | 2902         |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0017101469 |
|    clip_fraction         | 0.0707       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.31         |
|    cost_value_loss       | 92           |
|    cost_values           | 3            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.0352       |
|    lagrangian_multiplier | 0.0126       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.54         |
|    n_updates             | 2500         |
|    policy_gradient_loss  | 0.00117      |
|    std                   | 0.923        |
|    value_loss            | 7.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.202       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.202       |
| reward                   | -0.5112089  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 7           |
|    time_elapsed          | 3399        |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.004567241 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.68        |
|    cost_value_loss       | 74.5        |
|    cost_values           | 3           |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.415       |
|    lagrangian_multiplier | 0.0022      |
|    learning_rate         | 0.0003      |
|    loss                  | 19.3        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.000566   |
|    std                   | 0.923       |
|    value_loss            | 0.784       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0868       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0868       |
| reward                   | -0.36568472  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 8            |
|    time_elapsed          | 3881         |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0024457655 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.52         |
|    cost_value_loss       | 46.2         |
|    cost_values           | 3            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -2.34        |
|    lagrangian_multiplier | 0.00747      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.924        |
|    value_loss            | 0.828        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.219        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.219        |
| reward                   | -0.48289576  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 4372         |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0035993443 |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 102          |
|    cost_values           | 3            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.00878     |
|    lagrangian_multiplier | 0.00801      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00075     |
|    std                   | 0.925        |
|    value_loss            | 0.374        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.295        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.295        |
| reward                   | -0.26860076  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 10           |
|    time_elapsed          | 4875         |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0041016643 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.94         |
|    cost_value_loss       | 65.3         |
|    cost_values           | 3            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.281        |
|    lagrangian_multiplier | 0.00327      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -0.000803    |
|    std                   | 0.923        |
|    value_loss            | 2.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.3211694   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 11           |
|    time_elapsed          | 5368         |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0068758046 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.56         |
|    cost_value_loss       | 55.1         |
|    cost_values           | 3            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.134        |
|    lagrangian_multiplier | 0.00899      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.5          |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.923        |
|    value_loss            | 0.681        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0188        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0188        |
| reward                   | -0.37010625   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -414          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 12            |
|    time_elapsed          | 5863          |
|    total_timesteps       | 526336        |
| train/                   |               |
|    approx_kl             | 0.00028218728 |
|    clip_fraction         | 0.00405       |
|    clip_range            | 0.2           |
|    cost_returns          | 12.9          |
|    cost_value_loss       | 131           |
|    cost_values           | 3             |
|    entropy               | -2.67         |
|    entropy_loss          | -2.67         |
|    explained_variance    | 0.351         |
|    lagrangian_multiplier | 0.0119        |
|    learning_rate         | 0.0003        |
|    loss                  | 12.1          |
|    n_updates             | 2560          |
|    policy_gradient_loss  | 0.000239      |
|    std                   | 0.92          |
|    value_loss            | 2.18          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0391       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0391       |
| reward                   | -0.32076645  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 13           |
|    time_elapsed          | 6365         |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0028648137 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.64         |
|    cost_value_loss       | 71.2         |
|    cost_values           | 2.99         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.223        |
|    lagrangian_multiplier | 5.96e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 36.3         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.919        |
|    value_loss            | 2.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.179        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.179        |
| reward                   | -0.561183    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 6863         |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0033190607 |
|    clip_fraction         | 0.00708      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.69         |
|    cost_value_loss       | 43.9         |
|    cost_values           | 3            |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.308       |
|    lagrangian_multiplier | 0.00324      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.919        |
|    value_loss            | 2.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.267        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.267        |
| reward                   | -0.53762984  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 15           |
|    time_elapsed          | 7363         |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0058650104 |
|    clip_fraction         | 0.0379       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 124          |
|    cost_values           | 3            |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.0429      |
|    lagrangian_multiplier | 0.0199       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.66         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.00468     |
|    std                   | 0.916        |
|    value_loss            | 3.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.31426287  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 16           |
|    time_elapsed          | 7867         |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0041274973 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 86           |
|    cost_values           | 2.99         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.0612       |
|    lagrangian_multiplier | 0.00445      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.915        |
|    value_loss            | 2.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.47600722  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 17           |
|    time_elapsed          | 8372         |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0027158486 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.1         |
|    cost_value_loss       | 102          |
|    cost_values           | 3            |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -1.23        |
|    lagrangian_multiplier | 0.00497      |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.915        |
|    value_loss            | 1.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0425       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0425       |
| reward                   | -0.35907444  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 18           |
|    time_elapsed          | 8879         |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0022645132 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 103          |
|    cost_values           | 3            |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.219       |
|    lagrangian_multiplier | 0.00558      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.000897    |
|    std                   | 0.915        |
|    value_loss            | 1.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.4598374   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 19           |
|    time_elapsed          | 9389         |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0043430524 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 93.9         |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.15        |
|    lagrangian_multiplier | 0.0226       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.56         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.000867    |
|    std                   | 0.913        |
|    value_loss            | 1.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.209        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.209        |
| reward                   | -0.3194488   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 9898         |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0018928491 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 121          |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -0.394       |
|    lagrangian_multiplier | 0.00148      |
|    learning_rate         | 0.0003       |
|    loss                  | 38.1         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.000162    |
|    std                   | 0.912        |
|    value_loss            | 0.735        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.11        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.11        |
| reward                   | -0.48405412 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 10409       |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.004704971 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 144         |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.263       |
|    lagrangian_multiplier | 0.00524     |
|    learning_rate         | 0.0003      |
|    loss                  | 21.8        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.91        |
|    value_loss            | 3.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.121        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.121        |
| reward                   | -0.5213231   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 22           |
|    time_elapsed          | 10925        |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0022595278 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 184          |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -0.0873      |
|    lagrangian_multiplier | 0.0336       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.99         |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.000927    |
|    std                   | 0.91         |
|    value_loss            | 2.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.403       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.403       |
| reward                   | -0.48014334 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 23          |
|    time_elapsed          | 11446       |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.004644845 |
|    clip_fraction         | 0.0085      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.44        |
|    cost_value_loss       | 75.1        |
|    cost_values           | 2.99        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.238       |
|    lagrangian_multiplier | 0.0153      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.22        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | -0.000164   |
|    std                   | 0.909       |
|    value_loss            | 4.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.149       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.149       |
| reward                   | -0.48084667 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 24          |
|    time_elapsed          | 11962       |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.002855219 |
|    clip_fraction         | 0.0635      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 103         |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.486       |
|    lagrangian_multiplier | 0.031       |
|    learning_rate         | 0.0003      |
|    loss                  | 5.73        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.91        |
|    value_loss            | 0.313       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0466       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0466       |
| reward                   | -0.31394118  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 25           |
|    time_elapsed          | 12487        |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0007226612 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.06         |
|    cost_value_loss       | 55.2         |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.536        |
|    lagrangian_multiplier | 0.012        |
|    learning_rate         | 0.0003       |
|    loss                  | 6.26         |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.000129    |
|    std                   | 0.911        |
|    value_loss            | 1.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.284       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.284       |
| reward                   | -0.37962788 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 26          |
|    time_elapsed          | 13016       |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.005205225 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.21        |
|    cost_value_loss       | 79.9        |
|    cost_values           | 2.99        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0.0187      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.58        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00106    |
|    std                   | 0.915       |
|    value_loss            | 0.867       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.222        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.222        |
| reward                   | -0.5544363   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 13547        |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0050155995 |
|    clip_fraction         | 0.0451       |
|    clip_range            | 0.2          |
|    cost_returns          | 12           |
|    cost_value_loss       | 115          |
|    cost_values           | 3            |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0.0242       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.21         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.915        |
|    value_loss            | 0.623        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0514       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0514       |
| reward                   | -0.5485994   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 28           |
|    time_elapsed          | 14082        |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0033732734 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 116          |
|    cost_values           | 3            |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.314       |
|    lagrangian_multiplier | 0.00853      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.914        |
|    value_loss            | 1.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.257        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.257        |
| reward                   | -0.31699786  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 29           |
|    time_elapsed          | 14611        |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0074156984 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.65         |
|    cost_value_loss       | 60.4         |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.802        |
|    lagrangian_multiplier | 0.000703     |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.0095      |
|    std                   | 0.912        |
|    value_loss            | 0.708        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0543      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0543      |
| reward                   | -0.32121226 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 30          |
|    time_elapsed          | 15127       |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.003332374 |
|    clip_fraction         | 0.00474     |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 118         |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | -1.33       |
|    lagrangian_multiplier | 0.00953     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.000728   |
|    std                   | 0.911       |
|    value_loss            | 3.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0704      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0704      |
| reward                   | -0.53259337 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 31          |
|    time_elapsed          | 15658       |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.005652984 |
|    clip_fraction         | 0.0287      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.64        |
|    cost_value_loss       | 74.8        |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.016       |
|    learning_rate         | 0.0003      |
|    loss                  | 6.83        |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.911       |
|    value_loss            | 0.837       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00511      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00511      |
| reward                   | -0.5016352   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 32           |
|    time_elapsed          | 16192        |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0034604305 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.94         |
|    cost_value_loss       | 86.5         |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.783        |
|    lagrangian_multiplier | 0.0112       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.22         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.000348    |
|    std                   | 0.91         |
|    value_loss            | 1.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.239        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.239        |
| reward                   | -0.5191787   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 33           |
|    time_elapsed          | 16723        |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0030899476 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 104          |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.316        |
|    lagrangian_multiplier | 1.28e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 50.7         |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.911        |
|    value_loss            | 0.534        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.114       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.114       |
| reward                   | -0.46908692 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 34          |
|    time_elapsed          | 17257       |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.004436625 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 148         |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | -2.88       |
|    lagrangian_multiplier | 0.0106      |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.91        |
|    value_loss            | 1.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.153        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.153        |
| reward                   | -0.4776494   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 35           |
|    time_elapsed          | 17799        |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0048094164 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.77         |
|    cost_value_loss       | 47.6         |
|    cost_values           | 3            |
|    entropy               | -2.64        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.154        |
|    lagrangian_multiplier | 0.0224       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.76         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.907        |
|    value_loss            | 0.465        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0243      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0243      |
| reward                   | -0.552661   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 36          |
|    time_elapsed          | 18343       |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.002451694 |
|    clip_fraction         | 0.0808      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.56        |
|    cost_value_loss       | 66.5        |
|    cost_values           | 3           |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.224       |
|    lagrangian_multiplier | 0.00108     |
|    learning_rate         | 0.0003      |
|    loss                  | 23.8        |
|    n_updates             | 2800        |
|    policy_gradient_loss  | 0.00221     |
|    std                   | 0.905       |
|    value_loss            | 0.0858      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.161        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.161        |
| reward                   | -0.5876849   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 37           |
|    time_elapsed          | 18883        |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0032554213 |
|    clip_fraction         | 0.00542      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 114          |
|    cost_values           | 3            |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.596        |
|    lagrangian_multiplier | 0.00466      |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.905        |
|    value_loss            | 2.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0239      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0239      |
| reward                   | -0.38483623 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 38          |
|    time_elapsed          | 19424       |
|    total_timesteps       | 579584      |
| train/                   |             |
|    approx_kl             | 0.004039297 |
|    clip_fraction         | 0.0367      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.85        |
|    cost_value_loss       | 42.7        |
|    cost_values           | 2.99        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0.00558     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.84        |
|    n_updates             | 2820        |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 0.902       |
|    value_loss            | 0.721       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.253       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.253       |
| reward                   | -0.3220103  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 39          |
|    time_elapsed          | 19968       |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.003760527 |
|    clip_fraction         | 0.029       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 95.2        |
|    cost_values           | 3           |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.381       |
|    lagrangian_multiplier | 0.00866     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.000515   |
|    std                   | 0.9         |
|    value_loss            | 1.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0435      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0435      |
| reward                   | -0.3218642  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 40          |
|    time_elapsed          | 20519       |
|    total_timesteps       | 583680      |
| train/                   |             |
|    approx_kl             | 0.004748504 |
|    clip_fraction         | 0.0458      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 75.4        |
|    cost_values           | 3           |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 6e-07       |
|    learning_rate         | 0.0003      |
|    loss                  | 37.2        |
|    n_updates             | 2840        |
|    policy_gradient_loss  | -0.00341    |
|    std                   | 0.901       |
|    value_loss            | 0.472       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0289      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0289      |
| reward                   | -0.46586132 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 41          |
|    time_elapsed          | 21068       |
|    total_timesteps       | 585728      |
| train/                   |             |
|    approx_kl             | 0.014136548 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.55        |
|    cost_value_loss       | 71.4        |
|    cost_values           | 3           |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.0374      |
|    lagrangian_multiplier | 0.015       |
|    learning_rate         | 0.0003      |
|    loss                  | 6.91        |
|    n_updates             | 2850        |
|    policy_gradient_loss  | -0.00876    |
|    std                   | 0.9         |
|    value_loss            | 0.497       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.211        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.211        |
| reward                   | -0.38990298  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 21625        |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0062078442 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.5          |
|    cost_value_loss       | 48.2         |
|    cost_values           | 2.99         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.47         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.000685    |
|    std                   | 0.899        |
|    value_loss            | 1.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.113        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.113        |
| reward                   | -0.49835533  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 43           |
|    time_elapsed          | 22180        |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0006285389 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 147          |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.816        |
|    lagrangian_multiplier | 0.0322       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.9          |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.896        |
|    value_loss            | 0.309        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.102       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.102       |
| reward                   | -0.30779085 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 44          |
|    time_elapsed          | 22735       |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.005844515 |
|    clip_fraction         | 0.0444      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 173         |
|    cost_values           | 3           |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.77        |
|    lagrangian_multiplier | 0.00298     |
|    learning_rate         | 0.0003      |
|    loss                  | 34.9        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.00302    |
|    std                   | 0.895       |
|    value_loss            | 0.343       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.245        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.245        |
| reward                   | -0.5448693   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 45           |
|    time_elapsed          | 23293        |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0009573952 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 162          |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.325        |
|    lagrangian_multiplier | 0.0166       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00062     |
|    std                   | 0.894        |
|    value_loss            | 2.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0755       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0755       |
| reward                   | -0.6081529   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 46           |
|    time_elapsed          | 23848        |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0040840646 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 89.1         |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -0.589       |
|    lagrangian_multiplier | 0.0282       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.66         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.000532    |
|    std                   | 0.895        |
|    value_loss            | 1.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.50598484  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 47           |
|    time_elapsed          | 24413        |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0049390886 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 156          |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0.00065      |
|    learning_rate         | 0.0003       |
|    loss                  | 60.3         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.895        |
|    value_loss            | 1.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.283        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.283        |
| reward                   | -0.501207    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 48           |
|    time_elapsed          | 24976        |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0025158925 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 123          |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.0862       |
|    lagrangian_multiplier | 0.00912      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.896        |
|    value_loss            | 4.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0311       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0311       |
| reward                   | -0.29900637  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 49           |
|    time_elapsed          | 25536        |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0104209045 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.59         |
|    cost_value_loss       | 65.7         |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0.0232       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.895        |
|    value_loss            | 0.203        |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.27       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.27       |
| reward             | -0.4190454 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -435       |
| time/              |            |
|    fps             | 3          |
|    iterations      | 1          |
|    time_elapsed    | 562        |
|    total_timesteps | 604160     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.38019684  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 2            |
|    time_elapsed          | 1131         |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0037987921 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.9         |
|    cost_value_loss       | 193          |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.364        |
|    lagrangian_multiplier | 0.0198       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.894        |
|    value_loss            | 1.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0484      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0484      |
| reward                   | -0.29799885 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 3           |
|    time_elapsed          | 1699        |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.004102906 |
|    clip_fraction         | 0.00942     |
|    clip_range            | 0.2         |
|    cost_returns          | 16.1        |
|    cost_value_loss       | 197         |
|    cost_values           | 3.01        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.227       |
|    lagrangian_multiplier | 0.018       |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.894       |
|    value_loss            | 0.348       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.20980962  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 4            |
|    time_elapsed          | 2272         |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0024447078 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.1         |
|    cost_value_loss       | 76.2         |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -0.293       |
|    lagrangian_multiplier | 0.00232      |
|    learning_rate         | 0.0003       |
|    loss                  | 19.9         |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.894        |
|    value_loss            | 3.74         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0665      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0665      |
| reward                   | -0.47960567 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 2850        |
|    total_timesteps       | 612352      |
| train/                   |             |
|    approx_kl             | 0.002814292 |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.64        |
|    cost_value_loss       | 88.5        |
|    cost_values           | 2.99        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -0.239      |
|    lagrangian_multiplier | 0.000205    |
|    learning_rate         | 0.0003      |
|    loss                  | 43.6        |
|    n_updates             | 2980        |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 0.893       |
|    value_loss            | 4.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0519      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0519      |
| reward                   | -0.25163633 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 6           |
|    time_elapsed          | 3423        |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.005914704 |
|    clip_fraction         | 0.0375      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.36        |
|    cost_value_loss       | 65.9        |
|    cost_values           | 3           |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.263       |
|    lagrangian_multiplier | 0.0127      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.23        |
|    n_updates             | 2990        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.894       |
|    value_loss            | 5.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00325      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00325      |
| reward                   | -0.4163255   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 7            |
|    time_elapsed          | 4002         |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0028405203 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.68         |
|    cost_value_loss       | 50           |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.834        |
|    lagrangian_multiplier | 0.00107      |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 0.891        |
|    value_loss            | 0.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0805      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0805      |
| reward                   | -0.30235356 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 4584        |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.006866634 |
|    clip_fraction         | 0.082       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.36        |
|    cost_value_loss       | 4.58        |
|    cost_values           | 2.97        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0.000745    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 0.893       |
|    value_loss            | 0.995       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.034        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.034        |
| reward                   | -0.37339857  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 9            |
|    time_elapsed          | 5162         |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0061490275 |
|    clip_fraction         | 0.176        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 165          |
|    cost_values           | 2.93         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -0.993       |
|    lagrangian_multiplier | 0.000368     |
|    learning_rate         | 0.0003       |
|    loss                  | 70.6         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | 0.0056       |
|    std                   | 0.892        |
|    value_loss            | 0.845        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.281        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.281        |
| reward                   | -0.3625373   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 10           |
|    time_elapsed          | 5742         |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0047053993 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 90.2         |
|    cost_values           | 2.98         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0.0125       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.892        |
|    value_loss            | 0.276        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0088      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0088      |
| reward                   | -0.35951743 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 11          |
|    time_elapsed          | 6336        |
|    total_timesteps       | 624640      |
| train/                   |             |
|    approx_kl             | 0.012837923 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.43        |
|    cost_value_loss       | 49.2        |
|    cost_values           | 3           |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.439       |
|    lagrangian_multiplier | 0.0171      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 3040        |
|    policy_gradient_loss  | 0.000208    |
|    std                   | 0.891       |
|    value_loss            | 1.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00106      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00106      |
| reward                   | -0.57387596  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 12           |
|    time_elapsed          | 6915         |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0036797666 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 90.2         |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -0.578       |
|    lagrangian_multiplier | 0.0157       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.98         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.000517    |
|    std                   | 0.89         |
|    value_loss            | 0.818        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.208       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.208       |
| reward                   | -0.505307   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 7492        |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.008109234 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.14        |
|    cost_value_loss       | 49.4        |
|    cost_values           | 2.95        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0.00814     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.41        |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.00095    |
|    std                   | 0.894       |
|    value_loss            | 1.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0606       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0606       |
| reward                   | -0.20563528  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 14           |
|    time_elapsed          | 8084         |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0065328386 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 82.1         |
|    cost_values           | 2.96         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.809        |
|    lagrangian_multiplier | 0.0173       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.87         |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.895        |
|    value_loss            | 0.935        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.267        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.267        |
| reward                   | -0.2284469   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 15           |
|    time_elapsed          | 8673         |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0040754573 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 166          |
|    cost_values           | 2.96         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.833        |
|    lagrangian_multiplier | 0.00526      |
|    learning_rate         | 0.0003       |
|    loss                  | 24.7         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.895        |
|    value_loss            | 3.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.157        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.157        |
| reward                   | -0.45816758  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 16           |
|    time_elapsed          | 9269         |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0028543414 |
|    clip_fraction         | 0.0511       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.95         |
|    cost_value_loss       | 57.4         |
|    cost_values           | 2.99         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0.00828      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.49         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 0.895        |
|    value_loss            | 0.748        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0288       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0288       |
| reward                   | -0.21399187  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 17           |
|    time_elapsed          | 9859         |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0039408132 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.2         |
|    cost_value_loss       | 136          |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0.0054       |
|    learning_rate         | 0.0003       |
|    loss                  | 20           |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.000676    |
|    std                   | 0.894        |
|    value_loss            | 1.57         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.228       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.228       |
| reward                   | -0.5291466  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 18          |
|    time_elapsed          | 10450       |
|    total_timesteps       | 638976      |
| train/                   |             |
|    approx_kl             | 0.006675002 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 195         |
|    cost_values           | 3           |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0.0384      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.49        |
|    n_updates             | 3110        |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 0.893       |
|    value_loss            | 2.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0477      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0477      |
| reward                   | -0.4263492  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 19          |
|    time_elapsed          | 11048       |
|    total_timesteps       | 641024      |
| train/                   |             |
|    approx_kl             | 0.005149706 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.8        |
|    cost_value_loss       | 139         |
|    cost_values           | 2.99        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.025       |
|    learning_rate         | 0.0003      |
|    loss                  | 8.06        |
|    n_updates             | 3120        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.893       |
|    value_loss            | 2.07        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.274         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.274         |
| reward                   | -0.33643192   |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -429          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 20            |
|    time_elapsed          | 11657         |
|    total_timesteps       | 643072        |
| train/                   |               |
|    approx_kl             | 0.00086820853 |
|    clip_fraction         | 0.00171       |
|    clip_range            | 0.2           |
|    cost_returns          | 9.9           |
|    cost_value_loss       | 83.5          |
|    cost_values           | 2.55          |
|    entropy               | -2.61         |
|    entropy_loss          | -2.61         |
|    explained_variance    | 0.851         |
|    lagrangian_multiplier | 0.211         |
|    learning_rate         | 0.0003        |
|    loss                  | 2.9           |
|    n_updates             | 3130          |
|    policy_gradient_loss  | -0.0011       |
|    std                   | 0.893         |
|    value_loss            | 28.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.39501783  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 21           |
|    time_elapsed          | 12262        |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0007136157 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 10           |
|    cost_value_loss       | 124          |
|    cost_values           | 1.95         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0.017        |
|    learning_rate         | 0.0003       |
|    loss                  | 9.44         |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.000863    |
|    std                   | 0.893        |
|    value_loss            | 26.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.08         |
| reward                   | -0.46386063  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 22           |
|    time_elapsed          | 12866        |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0051709665 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 194          |
|    cost_values           | 1.58         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.836        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 102          |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.892        |
|    value_loss            | 7.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0622      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0622      |
| reward                   | -0.5221444  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 23          |
|    time_elapsed          | 13477       |
|    total_timesteps       | 649216      |
| train/                   |             |
|    approx_kl             | 0.001964854 |
|    clip_fraction         | 0.00591     |
|    clip_range            | 0.2         |
|    cost_returns          | 9.88        |
|    cost_value_loss       | 113         |
|    cost_values           | 1.45        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.00479     |
|    learning_rate         | 0.0003      |
|    loss                  | 19.8        |
|    n_updates             | 3160        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.892       |
|    value_loss            | 21.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0702       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0702       |
| reward                   | -0.34955588  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 24           |
|    time_elapsed          | 14092        |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0043793046 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.72         |
|    cost_value_loss       | 66.4         |
|    cost_values           | 1.33         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.631        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.4         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.892        |
|    value_loss            | 0.869        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.269        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.269        |
| reward                   | -0.4132786   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 25           |
|    time_elapsed          | 14709        |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0024622795 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 10           |
|    cost_value_loss       | 133          |
|    cost_values           | 1.24         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0.017        |
|    learning_rate         | 0.0003       |
|    loss                  | 9.87         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.892        |
|    value_loss            | 44.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0672       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0672       |
| reward                   | -0.42127204  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 26           |
|    time_elapsed          | 15325        |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0031010532 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.94         |
|    cost_value_loss       | 104          |
|    cost_values           | 1.48         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.5         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.892        |
|    value_loss            | 0.678        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0522      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0522      |
| reward                   | -0.17726645 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 27          |
|    time_elapsed          | 15930       |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.002326017 |
|    clip_fraction         | 0.00371     |
|    clip_range            | 0.2         |
|    cost_returns          | 9.82        |
|    cost_value_loss       | 125         |
|    cost_values           | 1.6         |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.0121      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.000159   |
|    std                   | 0.892       |
|    value_loss            | 4.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0208      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0208      |
| reward                   | -0.4816212  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 28          |
|    time_elapsed          | 16547       |
|    total_timesteps       | 659456      |
| train/                   |             |
|    approx_kl             | 0.010276266 |
|    clip_fraction         | 0.0677      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.42        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 1.51        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.52        |
|    n_updates             | 3210        |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 0.894       |
|    value_loss            | 0.787       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.4732038  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 29          |
|    time_elapsed          | 17169       |
|    total_timesteps       | 661504      |
| train/                   |             |
|    approx_kl             | 0.005098902 |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.56        |
|    cost_value_loss       | 25.2        |
|    cost_values           | 1.76        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.5        |
|    n_updates             | 3220        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.894       |
|    value_loss            | 1.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0564       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0564       |
| reward                   | -0.6216704   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 17784        |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0026640126 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.14         |
|    cost_value_loss       | 57.9         |
|    cost_values           | 1.5          |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0.0029       |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 0.893        |
|    value_loss            | 5.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0421       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0421       |
| reward                   | -0.3751618   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 31           |
|    time_elapsed          | 18414        |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0039411644 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.57         |
|    cost_value_loss       | 117          |
|    cost_values           | 1.16         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00046     |
|    std                   | 0.893        |
|    value_loss            | 60           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0172       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0172       |
| reward                   | -0.26270944  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 32           |
|    time_elapsed          | 19034        |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0034111603 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 213          |
|    cost_values           | 1.5          |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 104          |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 0.892        |
|    value_loss            | 0.817        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0535        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0535        |
| reward                   | -0.48906296   |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -430          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 33            |
|    time_elapsed          | 19661         |
|    total_timesteps       | 669696        |
| train/                   |               |
|    approx_kl             | 0.00079285237 |
|    clip_fraction         | 0.000146      |
|    clip_range            | 0.2           |
|    cost_returns          | 10.2          |
|    cost_value_loss       | 130           |
|    cost_values           | 1.88          |
|    entropy               | -2.61         |
|    entropy_loss          | -2.61         |
|    explained_variance    | 0.994         |
|    lagrangian_multiplier | 0.0115        |
|    learning_rate         | 0.0003        |
|    loss                  | 11.5          |
|    n_updates             | 3260          |
|    policy_gradient_loss  | -0.000961     |
|    std                   | 0.893         |
|    value_loss            | 0.424         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0373       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0373       |
| reward                   | -0.48156127  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 34           |
|    time_elapsed          | 20292        |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0008044133 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 10.4         |
|    cost_value_loss       | 138          |
|    cost_values           | 1.85         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0.0427       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.71         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -2.92e-05    |
|    std                   | 0.892        |
|    value_loss            | 5.46         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.507929   |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 35          |
|    time_elapsed          | 20926       |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.010870229 |
|    clip_fraction         | 0.0993      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 2.5         |
|    cost_values           | 1.31        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.24        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.894       |
|    value_loss            | 0.216       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0785      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0785      |
| reward                   | -0.35905224 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 36          |
|    time_elapsed          | 21561       |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.005158638 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 0.145       |
|    cost_values           | 1.35        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -0.791      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.992       |
|    n_updates             | 3290        |
|    policy_gradient_loss  | 0.00493     |
|    std                   | 0.891       |
|    value_loss            | 3.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.19         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.19         |
| reward                   | -0.5166027   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 22197        |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0012027002 |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.02         |
|    cost_value_loss       | 106          |
|    cost_values           | 1.43         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.7         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | 0.00776      |
|    std                   | 0.887        |
|    value_loss            | 0.984        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0887       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0887       |
| reward                   | -0.48679814  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 38           |
|    time_elapsed          | 22837        |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0028962535 |
|    clip_fraction         | 0.00449      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.8         |
|    cost_value_loss       | 216          |
|    cost_values           | 1.81         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 0.886        |
|    value_loss            | 0.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0432       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0432       |
| reward                   | -0.20454454  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 39           |
|    time_elapsed          | 23474        |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0029225764 |
|    clip_fraction         | 0.00923      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 0.16         |
|    cost_values           | 1.79         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.441        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.768        |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.885        |
|    value_loss            | 2.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.3398208   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 40           |
|    time_elapsed          | 24113        |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0017968351 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.63         |
|    cost_value_loss       | 130          |
|    cost_values           | 1.79         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0.015        |
|    learning_rate         | 0.0003       |
|    loss                  | 9.43         |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.000113    |
|    std                   | 0.885        |
|    value_loss            | 2.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.101        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.101        |
| reward                   | -0.4916695   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 24756        |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0046992274 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 1.81         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.921        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.94         |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.884        |
|    value_loss            | 0.7          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0362        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0362        |
| reward                   | -0.28252462   |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -430          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 42            |
|    time_elapsed          | 25392         |
|    total_timesteps       | 688128        |
| train/                   |               |
|    approx_kl             | 0.00057931774 |
|    clip_fraction         | 0.000391      |
|    clip_range            | 0.2           |
|    cost_returns          | 16.6          |
|    cost_value_loss       | 235           |
|    cost_values           | 2.01          |
|    entropy               | -2.59         |
|    entropy_loss          | -2.59         |
|    explained_variance    | 0.887         |
|    lagrangian_multiplier | 0.000182      |
|    learning_rate         | 0.0003        |
|    loss                  | 105           |
|    n_updates             | 3350          |
|    policy_gradient_loss  | 0.000916      |
|    std                   | 0.884         |
|    value_loss            | 0.668         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0749       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0749       |
| reward                   | -0.4004674   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 43           |
|    time_elapsed          | 26033        |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0073332544 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.75         |
|    cost_value_loss       | 126          |
|    cost_values           | 2.15         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.863        |
|    lagrangian_multiplier | 0.0135       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.42         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.885        |
|    value_loss            | 1.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.022       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.022       |
| reward                   | -0.4909913  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 44          |
|    time_elapsed          | 26678       |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.002791164 |
|    clip_fraction         | 0.0432      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 149         |
|    cost_values           | 2.21        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | -0.332      |
|    lagrangian_multiplier | 0.012       |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 3370        |
|    policy_gradient_loss  | 3.58e-05    |
|    std                   | 0.884       |
|    value_loss            | 1.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.064        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.064        |
| reward                   | -0.30652326  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 45           |
|    time_elapsed          | 27328        |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0055034896 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 16           |
|    cost_value_loss       | 218          |
|    cost_values           | 2.52         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0.0234       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.00476     |
|    std                   | 0.882        |
|    value_loss            | 0.384        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0933       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0933       |
| reward                   | -0.3591454   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 46           |
|    time_elapsed          | 27980        |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0008739367 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 130          |
|    cost_values           | 2.24         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0.0105       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | 0.000889     |
|    std                   | 0.882        |
|    value_loss            | 2.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.236       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.236       |
| reward                   | -0.4395283  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 47          |
|    time_elapsed          | 28636       |
|    total_timesteps       | 698368      |
| train/                   |             |
|    approx_kl             | 0.006470015 |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.19        |
|    cost_value_loss       | 82.5        |
|    cost_values           | 2.29        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0.00955     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.87        |
|    n_updates             | 3400        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.885       |
|    value_loss            | 1.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.136       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.136       |
| reward                   | -0.19810365 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 48          |
|    time_elapsed          | 29286       |
|    total_timesteps       | 700416      |
| train/                   |             |
|    approx_kl             | 0.004985733 |
|    clip_fraction         | 0.0408      |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 140         |
|    cost_values           | 2.36        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.017       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.29        |
|    n_updates             | 3410        |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 0.885       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0169      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0169      |
| reward                   | -0.47488683 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 49          |
|    time_elapsed          | 29942       |
|    total_timesteps       | 702464      |
| train/                   |             |
|    approx_kl             | 0.005938441 |
|    clip_fraction         | 0.0343      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.83        |
|    cost_value_loss       | 0.0911      |
|    cost_values           | 1.99        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.188       |
|    n_updates             | 3420        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.883       |
|    value_loss            | 1.25        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/ld0gv8xm
------------------------------------
| avg_speed          | 0.0596      |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.0596      |
| reward             | -0.46688107 |
| rollout/           |             |
|    ep_len_mean     | 976         |
|    ep_rew_mean     | -419        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 650         |
|    total_timesteps | 704512      |
------------------------------------
------------------------------------------
| avg_speed                | 0.0555      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0555      |
| reward                   | -0.42487845 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 2           |
|    time_elapsed          | 1310        |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.007884884 |
|    clip_fraction         | 0.067       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 130         |
|    cost_values           | 2.08        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.0141      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 0.882       |
|    value_loss            | 1           |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0451       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0451       |
| reward                   | -0.24338199  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 3            |
|    time_elapsed          | 1954         |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0043022563 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.93         |
|    cost_value_loss       | 130          |
|    cost_values           | 1.99         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.0154       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.84         |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.882        |
|    value_loss            | 0.787        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0295      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0295      |
| reward                   | -0.36122316 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 4           |
|    time_elapsed          | 2611        |
|    total_timesteps       | 710656      |
| train/                   |             |
|    approx_kl             | 0.002574656 |
|    clip_fraction         | 0.00293     |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 176         |
|    cost_values           | 2.37        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.593       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 87.2        |
|    n_updates             | 3460        |
|    policy_gradient_loss  | -0.000975   |
|    std                   | 0.882       |
|    value_loss            | 1.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0175      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0175      |
| reward                   | -0.3980605  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 3260        |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.000477284 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 17.4        |
|    cost_value_loss       | 231         |
|    cost_values           | 2.83        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | -0.386      |
|    lagrangian_multiplier | 0.0457      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.56        |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.000547   |
|    std                   | 0.882       |
|    value_loss            | 0.916       |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.041         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.041         |
| reward                   | -0.34156865   |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -422          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 6             |
|    time_elapsed          | 3923          |
|    total_timesteps       | 714752        |
| train/                   |               |
|    approx_kl             | 0.00058799546 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 10.5          |
|    cost_value_loss       | 132           |
|    cost_values           | 2.45          |
|    entropy               | -2.59         |
|    entropy_loss          | -2.59         |
|    explained_variance    | 0.991         |
|    lagrangian_multiplier | 0.0324        |
|    learning_rate         | 0.0003        |
|    loss                  | 6.08          |
|    n_updates             | 3480          |
|    policy_gradient_loss  | -0.00113      |
|    std                   | 0.882         |
|    value_loss            | 1.37          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.404        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.404        |
| reward                   | -0.43960634  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 7            |
|    time_elapsed          | 4587         |
|    total_timesteps       | 716800       |
| train/                   |              |
|    approx_kl             | 0.0033169263 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 144          |
|    cost_values           | 1.93         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.832        |
|    lagrangian_multiplier | 0.0172       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.15         |
|    n_updates             | 3490         |
|    policy_gradient_loss  | -0.000221    |
|    std                   | 0.881        |
|    value_loss            | 1.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0198      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0198      |
| reward                   | -0.16939558 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 5250        |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.00784841  |
|    clip_fraction         | 0.064       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.18        |
|    cost_value_loss       | 117         |
|    cost_values           | 1.97        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.013       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.72        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00548    |
|    std                   | 0.88        |
|    value_loss            | 0.227       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.17       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.17       |
| reward                   | -0.38024   |
| rollout/                 |            |
|    ep_len_mean           | 968        |
|    ep_rew_mean           | -428       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 9          |
|    time_elapsed          | 5910       |
|    total_timesteps       | 720896     |
| train/                   |            |
|    approx_kl             | 0.01085269 |
|    clip_fraction         | 0.096      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.14       |
|    cost_value_loss       | 8.65       |
|    cost_values           | 1.55       |
|    entropy               | -2.58      |
|    entropy_loss          | -2.58      |
|    explained_variance    | 0.683      |
|    lagrangian_multiplier | 0.153      |
|    learning_rate         | 0.0003     |
|    loss                  | 2.23       |
|    n_updates             | 3510       |
|    policy_gradient_loss  | 0.00429    |
|    std                   | 0.88       |
|    value_loss            | 103        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0446       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0446       |
| reward                   | -0.333813    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 10           |
|    time_elapsed          | 6573         |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0055322624 |
|    clip_fraction         | 0.0747       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.023        |
|    cost_values           | 1.04         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0524       |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.879        |
|    value_loss            | 0.492        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0861      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0861      |
| reward                   | -0.30605268 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 11          |
|    time_elapsed          | 7245        |
|    total_timesteps       | 724992      |
| train/                   |             |
|    approx_kl             | 0.00963707  |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.727       |
|    cost_value_loss       | 0.0299      |
|    cost_values           | 0.882       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.345       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.122       |
|    n_updates             | 3530        |
|    policy_gradient_loss  | 0.00123     |
|    std                   | 0.871       |
|    value_loss            | 0.484       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.235        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.235        |
| reward                   | -0.5071931   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 12           |
|    time_elapsed          | 7897         |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0024645284 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.8          |
|    cost_value_loss       | 84.5         |
|    cost_values           | 0.99         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0.00958      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | 0.000441     |
|    std                   | 0.868        |
|    value_loss            | 33.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0905       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0905       |
| reward                   | -0.48383886  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 13           |
|    time_elapsed          | 8569         |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0013912944 |
|    clip_fraction         | 0.00542      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.21         |
|    cost_value_loss       | 118          |
|    cost_values           | 1.04         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -8.95e-05    |
|    std                   | 0.868        |
|    value_loss            | 6.45         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0709        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0709        |
| reward                   | -0.4201187    |
| rollout/                 |               |
|    ep_len_mean           | 968           |
|    ep_rew_mean           | -431          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 14            |
|    time_elapsed          | 9242          |
|    total_timesteps       | 731136        |
| train/                   |               |
|    approx_kl             | 0.00076375634 |
|    clip_fraction         | 0.000244      |
|    clip_range            | 0.2           |
|    cost_returns          | 14.8          |
|    cost_value_loss       | 205           |
|    cost_values           | 1.52          |
|    entropy               | -2.55         |
|    entropy_loss          | -2.56         |
|    explained_variance    | 0.702         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 99.8          |
|    n_updates             | 3560          |
|    policy_gradient_loss  | 0.000326      |
|    std                   | 0.868         |
|    value_loss            | 2.49          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.1          |
| reward                   | -0.49524066  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 15           |
|    time_elapsed          | 9920         |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0036176422 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.81         |
|    cost_value_loss       | 92.6         |
|    cost_values           | 1.73         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.815        |
|    lagrangian_multiplier | 0.00847      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.67         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.868        |
|    value_loss            | 1.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0796      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0796      |
| reward                   | -0.3333427  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 16          |
|    time_elapsed          | 10600       |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.004943035 |
|    clip_fraction         | 0.019       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 0.063       |
|    cost_values           | 1.55        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.781       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0368      |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00202    |
|    std                   | 0.869       |
|    value_loss            | 0.551       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0735       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0735       |
| reward                   | -0.4551879   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 17           |
|    time_elapsed          | 11278        |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0029379777 |
|    clip_fraction         | 0.142        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.97         |
|    cost_value_loss       | 47.2         |
|    cost_values           | 0.914        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 4.76e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 52.2         |
|    n_updates             | 3590         |
|    policy_gradient_loss  | 0.00692      |
|    std                   | 0.871        |
|    value_loss            | 62           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.21         |
| reward                   | -0.5862693   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 18           |
|    time_elapsed          | 11942        |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0039804345 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.83         |
|    cost_value_loss       | 112          |
|    cost_values           | 1.01         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.2         |
|    n_updates             | 3600         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.872        |
|    value_loss            | 0.719        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0998       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0998       |
| reward                   | -0.3889481   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 12617        |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0024452475 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.3          |
|    cost_value_loss       | 79.6         |
|    cost_values           | 1.38         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.8         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.871        |
|    value_loss            | 0.764        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0144       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0144       |
| reward                   | -0.58336204  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 20           |
|    time_elapsed          | 13291        |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0040009217 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.28         |
|    cost_value_loss       | 65.8         |
|    cost_values           | 1.74         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0.00825      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.51         |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.872        |
|    value_loss            | 1.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.131       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.131       |
| reward                   | -0.41015095 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 21          |
|    time_elapsed          | 13981       |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.006090297 |
|    clip_fraction         | 0.0378      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 0.0603      |
|    cost_values           | 1.42        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.561       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.271       |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00229    |
|    std                   | 0.867       |
|    value_loss            | 0.997       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0895       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0895       |
| reward                   | -0.30956858  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 22           |
|    time_elapsed          | 14667        |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0020591894 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.96         |
|    cost_value_loss       | 43.4         |
|    cost_values           | 1.51         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.000398     |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.00023     |
|    std                   | 0.864        |
|    value_loss            | 2.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0231      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0231      |
| reward                   | -0.42516118 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 23          |
|    time_elapsed          | 15353       |
|    total_timesteps       | 749568      |
| train/                   |             |
|    approx_kl             | 0.004841264 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.5         |
|    cost_value_loss       | 79.6        |
|    cost_values           | 1.83        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0.00769     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.31        |
|    n_updates             | 3650        |
|    policy_gradient_loss  | -0.0022     |
|    std                   | 0.866       |
|    value_loss            | 0.67        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.256        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.256        |
| reward                   | -0.5037261   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 24           |
|    time_elapsed          | 16038        |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0029622614 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 0.0473       |
|    cost_values           | 1.44         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -1.31        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.605        |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.868        |
|    value_loss            | 2.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0505       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0505       |
| reward                   | -0.3739547   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 25           |
|    time_elapsed          | 16728        |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0045133117 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.02         |
|    cost_value_loss       | 114          |
|    cost_values           | 1.68         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0.0137       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.56         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | 0.00352      |
|    std                   | 0.868        |
|    value_loss            | 0.551        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.185        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.185        |
| reward                   | -0.5627966   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 26           |
|    time_elapsed          | 17420        |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0031627405 |
|    clip_fraction         | 0.0379       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 4.91         |
|    cost_values           | 1.39         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -0.797       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.78         |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.867        |
|    value_loss            | 1.74         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.122       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.122       |
| reward                   | -0.4611512  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 27          |
|    time_elapsed          | 18104       |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.003480711 |
|    clip_fraction         | 0.0536      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 73.2        |
|    cost_values           | 1.41        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.596       |
|    lagrangian_multiplier | 0.00831     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.2         |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.866       |
|    value_loss            | 0.497       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0696       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0696       |
| reward                   | -0.36490253  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 28           |
|    time_elapsed          | 18787        |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0032042242 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 188          |
|    cost_values           | 1.97         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 90.2         |
|    n_updates             | 3700         |
|    policy_gradient_loss  | 0.00141      |
|    std                   | 0.867        |
|    value_loss            | 1.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0543      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0543      |
| reward                   | -0.30429476 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 29          |
|    time_elapsed          | 19477       |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.002233805 |
|    clip_fraction         | 0.000586    |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 130         |
|    cost_values           | 2.43        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 63.9        |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.867       |
|    value_loss            | 0.332       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0348       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0348       |
| reward                   | -0.41774338  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 20177        |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0004608047 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 120          |
|    cost_values           | 2.23         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -5.87        |
|    lagrangian_multiplier | 0.0661       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.81         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.867        |
|    value_loss            | 1.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0773      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0773      |
| reward                   | -0.4365545  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 31          |
|    time_elapsed          | 20875       |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.008966998 |
|    clip_fraction         | 0.0469      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 146         |
|    cost_values           | 1.85        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0.0171      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.47        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.867       |
|    value_loss            | 0.524       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.54368216  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 32           |
|    time_elapsed          | 21585        |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0021543028 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.4          |
|    cost_value_loss       | 99.9         |
|    cost_values           | 1.72         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -2.45        |
|    lagrangian_multiplier | 0.0118       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.61         |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.869        |
|    value_loss            | 0.219        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0273       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0273       |
| reward                   | -0.32115653  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 33           |
|    time_elapsed          | 22283        |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0045901127 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.58         |
|    cost_value_loss       | 90.2         |
|    cost_values           | 1.93         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0.012        |
|    learning_rate         | 0.0003       |
|    loss                  | 7.68         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.000699    |
|    std                   | 0.872        |
|    value_loss            | 0.976        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0873      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0873      |
| reward                   | -0.52046514 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 34          |
|    time_elapsed          | 22990       |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.005055859 |
|    clip_fraction         | 0.0271      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 4.62        |
|    cost_values           | 1.22        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.805       |
|    lagrangian_multiplier | 0.000861    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 3760        |
|    policy_gradient_loss  | -0.000544   |
|    std                   | 0.873       |
|    value_loss            | 1.04        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.35          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.35          |
| reward                   | -0.4308631    |
| rollout/                 |               |
|    ep_len_mean           | 992           |
|    ep_rew_mean           | -430          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 35            |
|    time_elapsed          | 23695         |
|    total_timesteps       | 774144        |
| train/                   |               |
|    approx_kl             | 0.00096974365 |
|    clip_fraction         | 0.0875        |
|    clip_range            | 0.2           |
|    cost_returns          | 8.77          |
|    cost_value_loss       | 100           |
|    cost_values           | 1.73          |
|    entropy               | -2.56         |
|    entropy_loss          | -2.56         |
|    explained_variance    | -14.8         |
|    lagrangian_multiplier | 0.00149       |
|    learning_rate         | 0.0003        |
|    loss                  | 30.3          |
|    n_updates             | 3770          |
|    policy_gradient_loss  | 0.00382       |
|    std                   | 0.872         |
|    value_loss            | 5.36          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.102        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.102        |
| reward                   | -0.2543263   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 36           |
|    time_elapsed          | 24408        |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0072902627 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 42           |
|    cost_values           | 1.72         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0.0079       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.6          |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.871        |
|    value_loss            | 0.571        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0184       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0184       |
| reward                   | -0.42236373  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 25113        |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0019541215 |
|    clip_fraction         | 0.00493      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.57         |
|    cost_value_loss       | 34           |
|    cost_values           | 1.75         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -12.4        |
|    lagrangian_multiplier | 0.00629      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.56         |
|    n_updates             | 3790         |
|    policy_gradient_loss  | -0.000629    |
|    std                   | 0.87         |
|    value_loss            | 0.381        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0269      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0269      |
| reward                   | -0.5137438  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 38          |
|    time_elapsed          | 25824       |
|    total_timesteps       | 780288      |
| train/                   |             |
|    approx_kl             | 0.004564675 |
|    clip_fraction         | 0.00557     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.38        |
|    cost_value_loss       | 36.7        |
|    cost_values           | 2.13        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.79        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.2        |
|    n_updates             | 3800        |
|    policy_gradient_loss  | -0.000107   |
|    std                   | 0.869       |
|    value_loss            | 1.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0754       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0754       |
| reward                   | -0.4297432   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 39           |
|    time_elapsed          | 26536        |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0050836764 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.96         |
|    cost_value_loss       | 63           |
|    cost_values           | 2.13         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.542        |
|    lagrangian_multiplier | 0.00627      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.99         |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.87         |
|    value_loss            | 0.717        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00296     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00296     |
| reward                   | -0.3571575  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 40          |
|    time_elapsed          | 27252       |
|    total_timesteps       | 784384      |
| train/                   |             |
|    approx_kl             | 0.009148681 |
|    clip_fraction         | 0.0697      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 0.657       |
|    cost_values           | 1.31        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | -0.0169     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.373       |
|    n_updates             | 3820        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.87        |
|    value_loss            | 0.662       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.029        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.029        |
| reward                   | -0.2515317   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 27972        |
|    total_timesteps       | 786432       |
| train/                   |              |
|    approx_kl             | 0.0049340352 |
|    clip_fraction         | 0.0777       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 7.14         |
|    cost_values           | 1.66         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.605        |
|    lagrangian_multiplier | 0.00375      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.63         |
|    n_updates             | 3830         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.868        |
|    value_loss            | 0.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00472     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00472     |
| reward                   | -0.4137152  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 42          |
|    time_elapsed          | 28699       |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.002607158 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 20.7        |
|    cost_values           | 1.56        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | -4.9        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.866       |
|    value_loss            | 1.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0955      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0955      |
| reward                   | -0.5592887  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 43          |
|    time_elapsed          | 29415       |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.003360012 |
|    clip_fraction         | 0.0121      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 2.53        |
|    cost_values           | 1.72        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.64        |
|    n_updates             | 3850        |
|    policy_gradient_loss  | 6.89e-06    |
|    std                   | 0.871       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.178       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.178       |
| reward                   | -0.51308674 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 44          |
|    time_elapsed          | 30138       |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.006889482 |
|    clip_fraction         | 0.0614      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 1.34        |
|    cost_values           | 1.47        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000137    |
|    learning_rate         | 0.0003      |
|    loss                  | 0.507       |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 0.873       |
|    value_loss            | 0.265       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.106        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.106        |
| reward                   | -0.5361248   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 45           |
|    time_elapsed          | 30864        |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0024139576 |
|    clip_fraction         | 0.0427       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 6.63         |
|    cost_values           | 1.45         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0.00151      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.79         |
|    n_updates             | 3870         |
|    policy_gradient_loss  | 0.000716     |
|    std                   | 0.872        |
|    value_loss            | 1.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0115       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0115       |
| reward                   | -0.50909036  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 46           |
|    time_elapsed          | 31596        |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0042622983 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 1.56         |
|    cost_values           | 1.21         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 6.56e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.846        |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.869        |
|    value_loss            | 0.897        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0301       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0301       |
| reward                   | -0.4686962   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 47           |
|    time_elapsed          | 32328        |
|    total_timesteps       | 798720       |
| train/                   |              |
|    approx_kl             | 0.0067408755 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 5.83         |
|    cost_values           | 1.42         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -1.44        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.94         |
|    n_updates             | 3890         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.869        |
|    value_loss            | 8.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00703     |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.00703     |
| reward                   | -0.47599822 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 48          |
|    time_elapsed          | 33073       |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.017496523 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.524       |
|    cost_values           | 1.01        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.306       |
|    n_updates             | 3900        |
|    policy_gradient_loss  | 0.000403    |
|    std                   | 0.87        |
|    value_loss            | 0.857       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.122       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.122       |
| reward                   | -0.43504715 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 49          |
|    time_elapsed          | 33808       |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.006502269 |
|    clip_fraction         | 0.0676      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 74          |
|    cost_values           | 0.991       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.7        |
|    n_updates             | 3910        |
|    policy_gradient_loss  | -0.00616    |
|    std                   | 0.87        |
|    value_loss            | 0.565       |
------------------------------------------
------------------------------------
| avg_speed          | 0.0285      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0285      |
| reward             | -0.55429167 |
| rollout/           |             |
|    ep_len_mean     | 992         |
|    ep_rew_mean     | -440        |
| time/              |             |
|    fps             | 2           |
|    iterations      | 1           |
|    time_elapsed    | 742         |
|    total_timesteps | 804864      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.113        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.113        |
| reward                   | -0.53035754  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 2            |
|    time_elapsed          | 1479         |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0021026863 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.17         |
|    cost_value_loss       | 53.2         |
|    cost_values           | 1.65         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -3.19        |
|    lagrangian_multiplier | 0.00815      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.34         |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.861        |
|    value_loss            | 1.1          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.167       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.167       |
| reward                   | -0.54884815 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 3           |
|    time_elapsed          | 2219        |
|    total_timesteps       | 808960      |
| train/                   |             |
|    approx_kl             | 0.009153916 |
|    clip_fraction         | 0.0444      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 0.0312      |
|    cost_values           | 1.24        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.13        |
|    n_updates             | 3940        |
|    policy_gradient_loss  | -0.000927   |
|    std                   | 0.862       |
|    value_loss            | 0.523       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0852      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0852      |
| reward                   | -0.55292594 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 4           |
|    time_elapsed          | 2964        |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.003264957 |
|    clip_fraction         | 0.0976      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.84        |
|    cost_value_loss       | 77.8        |
|    cost_values           | 1.41        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.421       |
|    lagrangian_multiplier | 0.0114      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.9         |
|    n_updates             | 3950        |
|    policy_gradient_loss  | 0.00341     |
|    std                   | 0.865       |
|    value_loss            | 0.643       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0238       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0238       |
| reward                   | -0.2519238   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 5            |
|    time_elapsed          | 3719         |
|    total_timesteps       | 813056       |
| train/                   |              |
|    approx_kl             | 0.0046334406 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.966        |
|    cost_value_loss       | 0.0295       |
|    cost_values           | 1.1          |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -3.12        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.932        |
|    n_updates             | 3960         |
|    policy_gradient_loss  | 0.000394     |
|    std                   | 0.863        |
|    value_loss            | 3.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0124       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0124       |
| reward                   | -0.46987224  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 6            |
|    time_elapsed          | 4461         |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0055392454 |
|    clip_fraction         | 0.0772       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.806        |
|    cost_value_loss       | 0.0576       |
|    cost_values           | 1.03         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | -0.228       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.803        |
|    n_updates             | 3970         |
|    policy_gradient_loss  | -0.000933    |
|    std                   | 0.861        |
|    value_loss            | 4.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0618       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0618       |
| reward                   | -0.44962895  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 7            |
|    time_elapsed          | 5223         |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0053188363 |
|    clip_fraction         | 0.0724       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.733        |
|    cost_value_loss       | 0.00813      |
|    cost_values           | 0.749        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.54        |
|    explained_variance    | -0.115       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.428        |
|    n_updates             | 3980         |
|    policy_gradient_loss  | 0.000846     |
|    std                   | 0.858        |
|    value_loss            | 0.977        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.15         |
| reward                   | -0.4188985   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 8            |
|    time_elapsed          | 5986         |
|    total_timesteps       | 819200       |
| train/                   |              |
|    approx_kl             | 0.0019307267 |
|    clip_fraction         | 0.0833       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.76         |
|    cost_value_loss       | 90.3         |
|    cost_values           | 1.15         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | -0.278       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.5         |
|    n_updates             | 3990         |
|    policy_gradient_loss  | -3.54e-05    |
|    std                   | 0.856        |
|    value_loss            | 0.995        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0202      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0202      |
| reward                   | -0.4170343  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 9           |
|    time_elapsed          | 6740        |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.004360333 |
|    clip_fraction         | 0.0409      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.975       |
|    cost_value_loss       | 0.0388      |
|    cost_values           | 1.08        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.0827      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.296       |
|    n_updates             | 4000        |
|    policy_gradient_loss  | -0.000934   |
|    std                   | 0.849       |
|    value_loss            | 0.697       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0254       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0254       |
| reward                   | -0.4186104   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 10           |
|    time_elapsed          | 7513         |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0021974728 |
|    clip_fraction         | 0.19         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.35         |
|    cost_value_loss       | 56.1         |
|    cost_values           | 1.28         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29           |
|    n_updates             | 4010         |
|    policy_gradient_loss  | 0.00789      |
|    std                   | 0.846        |
|    value_loss            | 0.073        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.268        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.268        |
| reward                   | -0.5008413   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 11           |
|    time_elapsed          | 8278         |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0045129433 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.6          |
|    cost_value_loss       | 57.7         |
|    cost_values           | 1.63         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0.00874      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.846        |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0381      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0381      |
| reward                   | -0.37476003 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 12          |
|    time_elapsed          | 9035        |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.008278368 |
|    clip_fraction         | 0.0723      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.65        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 1.47        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.00238     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 0.845       |
|    value_loss            | 0.112       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0478       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0478       |
| reward                   | -0.28868216  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 13           |
|    time_elapsed          | 9797         |
|    total_timesteps       | 829440       |
| train/                   |              |
|    approx_kl             | 0.0053810533 |
|    clip_fraction         | 0.0689       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.989        |
|    cost_value_loss       | 0.0326       |
|    cost_values           | 1.11         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.0632       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.14         |
|    n_updates             | 4040         |
|    policy_gradient_loss  | -2.28e-05    |
|    std                   | 0.84         |
|    value_loss            | 2.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.281       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.281       |
| reward                   | -0.4364686  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 14          |
|    time_elapsed          | 10555       |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.002606105 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 146         |
|    cost_values           | 1.48        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.0261      |
|    lagrangian_multiplier | 0.0123      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | 0.00611     |
|    std                   | 0.838       |
|    value_loss            | 1.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.132       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.132       |
| reward                   | -0.26064828 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 15          |
|    time_elapsed          | 11331       |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.004392832 |
|    clip_fraction         | 0.0202      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 201         |
|    cost_values           | 1.97        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.753       |
|    lagrangian_multiplier | 0.0257      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.08        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.835       |
|    value_loss            | 0.495       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.57866883  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 16           |
|    time_elapsed          | 12091        |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0025553883 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.35         |
|    cost_value_loss       | 66.5         |
|    cost_values           | 1.54         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -1.56        |
|    lagrangian_multiplier | 0.00339      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.834        |
|    value_loss            | 2.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.223        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.223        |
| reward                   | -0.38575846  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 17           |
|    time_elapsed          | 12864        |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0026617893 |
|    clip_fraction         | 0.00381      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.14         |
|    cost_value_loss       | 120          |
|    cost_values           | 1.82         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.0315       |
|    lagrangian_multiplier | 0.0123       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.000619    |
|    std                   | 0.834        |
|    value_loss            | 3.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0368      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0368      |
| reward                   | -0.5062928  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 18          |
|    time_elapsed          | 13637       |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.004010913 |
|    clip_fraction         | 0.00493     |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 173         |
|    cost_values           | 2.09        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.382       |
|    lagrangian_multiplier | 0.0203      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.64        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.000491   |
|    std                   | 0.834       |
|    value_loss            | 1.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.32262155  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 19           |
|    time_elapsed          | 14410        |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0052986667 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.1          |
|    cost_value_loss       | 95           |
|    cost_values           | 1.74         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.0747       |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.2          |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.835        |
|    value_loss            | 0.776        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0849      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0849      |
| reward                   | -0.4024859  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 20          |
|    time_elapsed          | 15186       |
|    total_timesteps       | 843776      |
| train/                   |             |
|    approx_kl             | 0.001558464 |
|    clip_fraction         | 0.000439    |
|    clip_range            | 0.2         |
|    cost_returns          | 16.3        |
|    cost_value_loss       | 220         |
|    cost_values           | 2.04        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 110         |
|    n_updates             | 4110        |
|    policy_gradient_loss  | -0.000507   |
|    std                   | 0.836       |
|    value_loss            | 1.23        |
------------------------------------------
slurmstepd: error: *** STEP 141964.0 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-02-24T19:31:50 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 141964 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-02-24T19:31:50 DUE TO TIME LIMIT ***
