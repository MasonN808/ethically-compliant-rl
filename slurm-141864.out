wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240222_152550-x99x1ok7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vermilion-dragon-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/x99x1ok7
Using cpu device
-----------------------------------
| avg_speed          | 2.05       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.05       |
| reward             | -0.5392303 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.49e+03  |
| time/              |            |
|    fps             | 84         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2048       |
-----------------------------------
------------------------------------------
| avg_speed                | 4.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.38        |
| reward                   | -0.5373402  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.005195329 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.524       |
|    cost_value_loss       | 3.25        |
|    cost_values           | -0.259      |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -5.29e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 292         |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00219    |
|    std                   | 0.999       |
|    value_loss            | 614         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.39         |
| reward                   | -0.58613294  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0039938013 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.563        |
|    cost_value_loss       | 2.32         |
|    cost_values           | 0.178        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 231          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.997        |
|    value_loss            | 497          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.1713011  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 126         |
|    total_timesteps       | 8192        |
| train/                   |             |
|    approx_kl             | 0.004785725 |
|    clip_fraction         | 0.0338      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 2.93        |
|    cost_values           | 0.758       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 155         |
|    n_updates             | 30          |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.996       |
|    value_loss            | 335         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.52943754  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 160          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0025361734 |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.95         |
|    cost_values           | 0.956        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 122          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.000493    |
|    std                   | 0.997        |
|    value_loss            | 254          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.45        |
| reward                   | -0.37557924 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 6           |
|    time_elapsed          | 194         |
|    total_timesteps       | 12288       |
| train/                   |             |
|    approx_kl             | 0.004107836 |
|    clip_fraction         | 0.0148      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.7         |
|    cost_value_loss       | 5.41        |
|    cost_values           | 0.991       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 130         |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.999       |
|    value_loss            | 263         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.57         |
| reward                   | -0.87585056  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 228          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0014900917 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 6.55         |
|    cost_values           | 0.999        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 118          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00038     |
|    std                   | 1            |
|    value_loss            | 231          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.48         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.48         |
| reward                   | -0.50627553  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 262          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0033665989 |
|    clip_fraction         | 0.035        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 6.07         |
|    cost_values           | 1            |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.7         |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.997        |
|    value_loss            | 144          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.85         |
| reward                   | -0.68768096  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 9            |
|    time_elapsed          | 296          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0049040793 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 1            |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 130          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00383     |
|    std                   | 0.997        |
|    value_loss            | 251          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 6.65       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.65       |
| reward                   | -1.4567941 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -1.02e+03  |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 10         |
|    time_elapsed          | 331        |
|    total_timesteps       | 20480      |
| train/                   |            |
|    approx_kl             | 0.00401155 |
|    clip_fraction         | 0.0269     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.79       |
|    cost_value_loss       | 26.9       |
|    cost_values           | 1.01       |
|    entropy               | -2.83      |
|    entropy_loss          | -2.83      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 53         |
|    n_updates             | 90         |
|    policy_gradient_loss  | -0.00121   |
|    std                   | 0.997      |
|    value_loss            | 84.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 3.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.51         |
| reward                   | -0.5924093   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 365          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0029337197 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.56         |
|    cost_value_loss       | 18           |
|    cost_values           | 1            |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 136          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.997        |
|    value_loss            | 266          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.32         |
| reward                   | -0.4284192   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -956         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 399          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0058829933 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.19         |
|    cost_value_loss       | 20.3         |
|    cost_values           | 1.01         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 150          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.994        |
|    value_loss            | 297          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.54        |
| reward                   | -0.97028506 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -932        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 434         |
|    total_timesteps       | 26624       |
| train/                   |             |
|    approx_kl             | 0.004951889 |
|    clip_fraction         | 0.0219      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 23.1        |
|    cost_values           | 1.07        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.9        |
|    n_updates             | 120         |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.986       |
|    value_loss            | 44.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.8619109  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -933        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 14          |
|    time_elapsed          | 467         |
|    total_timesteps       | 28672       |
| train/                   |             |
|    approx_kl             | 0.003922279 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.45        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 1.14        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 46.1        |
|    n_updates             | 130         |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.987       |
|    value_loss            | 80.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4797533   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 502          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0029495284 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 3.46         |
|    cost_values           | 0.987        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 102          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.000598    |
|    std                   | 0.987        |
|    value_loss            | 202          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.95         |
| reward                   | -0.8690684   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -913         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 537          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0025284202 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 1.01         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.6         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.000891    |
|    std                   | 0.986        |
|    value_loss            | 98.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.767       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.767       |
| reward                   | -0.5105897  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -896        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 571         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.003070634 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 1.01        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59.5        |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.989       |
|    value_loss            | 111         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.5          |
| reward                   | -0.41169545  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -855         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 606          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0034376858 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.62         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 1.02         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.4         |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.983        |
|    value_loss            | 64           |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.54        |
| reward                   | -0.5109446  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -827        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 641         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.007816001 |
|    clip_fraction         | 0.0555      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.92        |
|    cost_value_loss       | 43          |
|    cost_values           | 1.2         |
|    entropy               | -2.79       |
|    entropy_loss          | -2.8        |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.2        |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 0.978       |
|    value_loss            | 27.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.09         |
| reward                   | -0.61577845  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -822         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 676          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0021927077 |
|    clip_fraction         | 0.00864      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.57         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 1.5          |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.2         |
|    n_updates             | 190          |
|    policy_gradient_loss  | 4.11e-05     |
|    std                   | 0.975        |
|    value_loss            | 83.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.29         |
| reward                   | -0.74735355  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 710          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0027126728 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 1.4          |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53           |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.973        |
|    value_loss            | 94.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.86        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.86        |
| reward                   | -0.7591437  |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -814        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 744         |
|    total_timesteps       | 45056       |
| train/                   |             |
|    approx_kl             | 0.004219958 |
|    clip_fraction         | 0.0151      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 8.4         |
|    cost_values           | 1.22        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.78       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 44.6        |
|    n_updates             | 210         |
|    policy_gradient_loss  | -0.00069    |
|    std                   | 0.976       |
|    value_loss            | 88.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.29         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.29         |
| reward                   | -0.4480576   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 779          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0043145064 |
|    clip_fraction         | 0.0356       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.09         |
|    cost_value_loss       | 26.6         |
|    cost_values           | 1.07         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 57.4         |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.976        |
|    value_loss            | 91.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.49         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.49         |
| reward                   | -0.7032637   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 814          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0010212578 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 33.9         |
|    cost_values           | 1.13         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.9         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.97         |
|    value_loss            | 47.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.878        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.878        |
| reward                   | -0.40438592  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 848          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0026615886 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.77         |
|    cost_value_loss       | 42.1         |
|    cost_values           | 1.41         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.5         |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.000566    |
|    std                   | 0.966        |
|    value_loss            | 42.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 2.06          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.06          |
| reward                   | -0.48904976   |
| rollout/                 |               |
|    ep_len_mean           | 930           |
|    ep_rew_mean           | -754          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 26            |
|    time_elapsed          | 883           |
|    total_timesteps       | 53248         |
| train/                   |               |
|    approx_kl             | 0.00026519503 |
|    clip_fraction         | 0.0138        |
|    clip_range            | 0.2           |
|    cost_returns          | 4.46          |
|    cost_value_loss       | 24.8          |
|    cost_values           | 1.66          |
|    entropy               | -2.76         |
|    entropy_loss          | -2.76         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 45.9          |
|    n_updates             | 250           |
|    policy_gradient_loss  | -0.000188     |
|    std                   | 0.963         |
|    value_loss            | 70            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 3.08         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.08         |
| reward                   | -0.3702789   |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 917          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0020089638 |
|    clip_fraction         | 0.041        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.48         |
|    cost_value_loss       | 16.3         |
|    cost_values           | 1.83         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.962        |
|    value_loss            | 7.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.822        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.822        |
| reward                   | -0.37007898  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 952          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0018508931 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.15         |
|    cost_value_loss       | 40.6         |
|    cost_values           | 2.27         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30           |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.000234    |
|    std                   | 0.962        |
|    value_loss            | 22.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.488        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.488        |
| reward                   | -0.87349504  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 986          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0021033343 |
|    clip_fraction         | 0.00674      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.16         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 2.54         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.8         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.000497    |
|    std                   | 0.957        |
|    value_loss            | 67.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.29         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.29         |
| reward                   | -0.3468593   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0032009555 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.7          |
|    cost_value_loss       | 19.7         |
|    cost_values           | 2.49         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.9         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.955        |
|    value_loss            | 52.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.82         |
| reward                   | -0.40574235  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1054         |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0014400193 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.32         |
|    cost_value_loss       | 33.8         |
|    cost_values           | 2.59         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30           |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.000174    |
|    std                   | 0.953        |
|    value_loss            | 27.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.2          |
| reward                   | -0.6010636   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0022731107 |
|    clip_fraction         | 0.0381       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.9          |
|    cost_value_loss       | 20.9         |
|    cost_values           | 2.83         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.95         |
|    value_loss            | 24.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.779        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.779        |
| reward                   | -0.3219929   |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1123         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0032121828 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.47         |
|    cost_value_loss       | 26.8         |
|    cost_values           | 2.99         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00436      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.19         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.000604    |
|    std                   | 0.946        |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.72         |
| reward                   | -0.7472004   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1157         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0028681336 |
|    clip_fraction         | 0.0596       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.86         |
|    cost_value_loss       | 6.72         |
|    cost_values           | 2.93         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.2         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00383     |
|    std                   | 0.947        |
|    value_loss            | 61           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.73         |
| reward                   | -0.5547663   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1191         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0021343827 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 11           |
|    cost_values           | 2.76         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.3         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.000653    |
|    std                   | 0.944        |
|    value_loss            | 61.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.04         |
| reward                   | -0.5123628   |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1225         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0042602606 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.78         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 2.66         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.5         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.943        |
|    value_loss            | 70.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.45        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.45        |
| reward                   | -0.68015766 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -680        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1259        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.004348032 |
|    clip_fraction         | 0.0266      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.84        |
|    cost_value_loss       | 18.2        |
|    cost_values           | 2.63        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.2        |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.941       |
|    value_loss            | 58.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.42         |
| reward                   | -0.4724      |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1293         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0081720175 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.61         |
|    cost_value_loss       | 36.6         |
|    cost_values           | 2.74         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.2         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.941        |
|    value_loss            | 27.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.112        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.112        |
| reward                   | -0.55613685  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1327         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0012404458 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.67         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 2.98         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.000583    |
|    std                   | 0.942        |
|    value_loss            | 38.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.22         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.22         |
| reward                   | -0.48213458  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1362         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0069642365 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.36         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 3            |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00283      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.941        |
|    value_loss            | 35.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.58         |
| reward                   | -0.35292566  |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1396         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0022644824 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.61         |
|    cost_value_loss       | 20           |
|    cost_values           | 3            |
|    entropy               | -2.73        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00106      |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00019     |
|    std                   | 0.946        |
|    value_loss            | 36.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.62         |
| reward                   | -0.74297506  |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1431         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0021877512 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.57         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 3            |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00134      |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00039     |
|    std                   | 0.945        |
|    value_loss            | 29.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.97         |
| reward                   | -0.31491882  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -658         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1465         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0045535676 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.94         |
|    cost_value_loss       | 33.1         |
|    cost_values           | 3            |
|    entropy               | -2.71        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.4         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.938        |
|    value_loss            | 20.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.268        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.268        |
| reward                   | -0.5135842   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -648         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1500         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0041206097 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.69         |
|    cost_value_loss       | 28           |
|    cost_values           | 3            |
|    entropy               | -2.7         |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.5         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.936        |
|    value_loss            | 20.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.95        |
| reward                   | -0.47429186 |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -635        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 45          |
|    time_elapsed          | 1534        |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.005119285 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.37        |
|    cost_value_loss       | 37.7        |
|    cost_values           | 3           |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00271     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.000267   |
|    std                   | 0.934       |
|    value_loss            | 10          |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.62         |
| reward                   | -0.5350187   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -625         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1568         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0030278324 |
|    clip_fraction         | 0.00811      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 7.59         |
|    cost_values           | 2.92         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.8         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00049     |
|    std                   | 0.935        |
|    value_loss            | 106          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.6          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.6          |
| reward                   | -0.3742404   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -617         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1603         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0029039464 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.01         |
|    cost_value_loss       | 9.91         |
|    cost_values           | 2.74         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.7         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.3         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.000827    |
|    std                   | 0.936        |
|    value_loss            | 79.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -1.1824425   |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -604         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1637         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0032778329 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.39         |
|    cost_value_loss       | 5.95         |
|    cost_values           | 2.58         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.000772    |
|    std                   | 0.932        |
|    value_loss            | 38.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.91        |
| reward                   | -0.42967904 |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -598        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 49          |
|    time_elapsed          | 1671        |
|    total_timesteps       | 100352      |
| train/                   |             |
|    approx_kl             | 0.004629895 |
|    clip_fraction         | 0.0153      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 2.53        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22          |
|    n_updates             | 480         |
|    policy_gradient_loss  | -0.000229   |
|    std                   | 0.927       |
|    value_loss            | 31.7        |
------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
-----------------------------------
| avg_speed          | 7.93       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.93       |
| reward             | -0.7190264 |
| rollout/           |            |
|    ep_len_mean     | 887        |
|    ep_rew_mean     | -583       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 102400     |
-----------------------------------
-------------------------------------------
| avg_speed                | 5.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.64         |
| reward                   | -1.0338439   |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -576         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0041488097 |
|    clip_fraction         | 0.033        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.48         |
|    cost_value_loss       | 15.8         |
|    cost_values           | 2.94         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.8         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.000759    |
|    std                   | 0.924        |
|    value_loss            | 16.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.71291083 |
| rollout/                 |             |
|    ep_len_mean           | 887         |
|    ep_rew_mean           | -576        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 106496      |
| train/                   |             |
|    approx_kl             | 0.004806947 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.96        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.1        |
|    n_updates             | 510         |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 0.927       |
|    value_loss            | 47.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.51102394  |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -578         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 126          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0038376055 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.6          |
|    cost_value_loss       | 7.43         |
|    cost_values           | 2.84         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.9         |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.000902    |
|    std                   | 0.925        |
|    value_loss            | 51.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.36261356  |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -573         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0035085974 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.32         |
|    cost_value_loss       | 5.5          |
|    cost_values           | 2.64         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.926        |
|    value_loss            | 50.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.62        |
| reward                   | -0.562641   |
| rollout/                 |             |
|    ep_len_mean           | 887         |
|    ep_rew_mean           | -570        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 195         |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.006478328 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 5.23        |
|    cost_values           | 2.42        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59.4        |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.926       |
|    value_loss            | 113         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.933        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.933        |
| reward                   | -0.23853089  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -576         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0038856855 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.01         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 2.27         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.6         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.000985    |
|    std                   | 0.923        |
|    value_loss            | 29.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -1.0997857   |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -558         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 264          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0015474235 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.53         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 2.34         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.000588    |
|    std                   | 0.926        |
|    value_loss            | 19           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.69         |
| reward                   | -0.6366344   |
| rollout/                 |              |
|    ep_len_mean           | 873          |
|    ep_rew_mean           | -552         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 298          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0020152351 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 14.5         |
|    cost_values           | 2.63         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.69        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.6         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.000896    |
|    std                   | 0.933        |
|    value_loss            | 29.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.39        |
| reward                   | -0.34764153 |
| rollout/                 |             |
|    ep_len_mean           | 873         |
|    ep_rew_mean           | -551        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 333         |
|    total_timesteps       | 120832      |
| train/                   |             |
|    approx_kl             | 0.004519183 |
|    clip_fraction         | 0.0567      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 2.97        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.0052      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.41        |
|    n_updates             | 580         |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.93        |
|    value_loss            | 33.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -0.7460441   |
| rollout/                 |              |
|    ep_len_mean           | 873          |
|    ep_rew_mean           | -550         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0023604296 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.96         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 3            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00589      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.48         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.000161    |
|    std                   | 0.924        |
|    value_loss            | 29.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.48         |
| reward                   | -0.62258595  |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -560         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 402          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0025835177 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.28         |
|    cost_value_loss       | 7.48         |
|    cost_values           | 3            |
|    entropy               | -2.69        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.000672    |
|    std                   | 0.927        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.13         |
| reward                   | -0.7552047   |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -566         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 436          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0042192033 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.29         |
|    cost_value_loss       | 4.2          |
|    cost_values           | 2.92         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.4         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.929        |
|    value_loss            | 54.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -0.426754    |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -562         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 471          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0065376447 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.27         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 2.85         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.928        |
|    value_loss            | 15.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.82865554  |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -561         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 505          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0034428793 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.41         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 3            |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.43         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.921        |
|    value_loss            | 6.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.88         |
| reward                   | -0.5095531   |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -560         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 539          |
|    total_timesteps       | 133120       |
| train/                   |              |
|    approx_kl             | 0.0011656235 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.36         |
|    cost_value_loss       | 14.3         |
|    cost_values           | 3            |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00912      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.76         |
|    n_updates             | 640          |
|    policy_gradient_loss  | -0.000232    |
|    std                   | 0.92         |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.66615057  |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -561         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 573          |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0030651428 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.35         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 2.98         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 650          |
|    policy_gradient_loss  | -0.000314    |
|    std                   | 0.922        |
|    value_loss            | 30.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.735        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.735        |
| reward                   | -0.42873985  |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -563         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 608          |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0029548123 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 9.43         |
|    cost_values           | 2.97         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 0.921        |
|    value_loss            | 24.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.81        |
| reward                   | -0.3444514  |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -569        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 642         |
|    total_timesteps       | 139264      |
| train/                   |             |
|    approx_kl             | 0.013486675 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.9         |
|    cost_value_loss       | 22.8        |
|    cost_values           | 3           |
|    entropy               | -2.66       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00659     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.75        |
|    n_updates             | 670         |
|    policy_gradient_loss  | -0.00309    |
|    std                   | 0.915       |
|    value_loss            | 13.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.41        |
| reward                   | -0.49080592 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -566        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 677         |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.004963102 |
|    clip_fraction         | 0.0523      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.55        |
|    cost_value_loss       | 25.4        |
|    cost_values           | 3           |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.2        |
|    n_updates             | 680         |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.914       |
|    value_loss            | 9.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.53         |
| reward                   | -0.39116102  |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -571         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 712          |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0028408985 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.62         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 3            |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00994      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.74         |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.000332    |
|    std                   | 0.914        |
|    value_loss            | 4.61         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.27        |
| reward                   | -0.5567552  |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -572        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 747         |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.006398459 |
|    clip_fraction         | 0.0209      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.48        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.000895   |
|    std                   | 0.91        |
|    value_loss            | 7.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.67        |
| reward                   | -0.48390326 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -573        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 781         |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.002489311 |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.95        |
|    cost_value_loss       | 39.4        |
|    cost_values           | 3           |
|    entropy               | -2.64       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.3        |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.907       |
|    value_loss            | 2.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5276377   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -574         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 816          |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0034505858 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.49         |
|    cost_value_loss       | 22           |
|    cost_values           | 3            |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00306      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.906        |
|    value_loss            | 22.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.14        |
| reward                   | -0.5563046  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -577        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 25          |
|    time_elapsed          | 850         |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.005801264 |
|    clip_fraction         | 0.0951      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.27        |
|    cost_value_loss       | 24.9        |
|    cost_values           | 3           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00591     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.87        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.909       |
|    value_loss            | 22          |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.77         |
| reward                   | -0.6526462   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -574         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 885          |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0012426716 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.2          |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00628      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 740          |
|    policy_gradient_loss  | 6.52e-05     |
|    std                   | 0.909        |
|    value_loss            | 3.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -0.85784644  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -573         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 920          |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0023672748 |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.82         |
|    cost_value_loss       | 23.3         |
|    cost_values           | 2.99         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00492      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.49         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.903        |
|    value_loss            | 16.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.7012198  |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -575        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 954         |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.005258155 |
|    clip_fraction         | 0.0314      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 3           |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.2        |
|    n_updates             | 760         |
|    policy_gradient_loss  | -0.000816   |
|    std                   | 0.897       |
|    value_loss            | 9.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.68032575  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -571         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 989          |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0026801508 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.44         |
|    cost_value_loss       | 18.2         |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00886      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 770          |
|    policy_gradient_loss  | 0.000299     |
|    std                   | 0.898        |
|    value_loss            | 5.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.955        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.955        |
| reward                   | -0.27941656  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -562         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1024         |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0034778481 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.56         |
|    cost_value_loss       | 25.2         |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0121       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.57         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.897        |
|    value_loss            | 3.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.62         |
| reward                   | -0.36396262  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -568         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1059         |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0048886184 |
|    clip_fraction         | 0.0616       |
|    clip_range            | 0.2          |
|    cost_returns          | 6            |
|    cost_value_loss       | 19.5         |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0108       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.97         |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 0.896        |
|    value_loss            | 19           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.472       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.472       |
| reward                   | -0.40013763 |
| rollout/                 |             |
|    ep_len_mean           | 920         |
|    ep_rew_mean           | -559        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1094        |
|    total_timesteps       | 165888      |
| train/                   |             |
|    approx_kl             | 0.00707324  |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.08        |
|    cost_value_loss       | 39.3        |
|    cost_values           | 3           |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0168      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 800         |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.894       |
|    value_loss            | 2.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.767        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.767        |
| reward                   | -0.37352678  |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -560         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1129         |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0059917727 |
|    clip_fraction         | 0.0708       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.62         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.04         |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.895        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.21         |
| reward                   | -0.45218664  |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -556         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0037422683 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.68         |
|    cost_value_loss       | 22.5         |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00998      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.76         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.000689    |
|    std                   | 0.891        |
|    value_loss            | 4.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.31        |
| reward                   | -0.5318773  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -555        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1198        |
|    total_timesteps       | 172032      |
| train/                   |             |
|    approx_kl             | 0.007519947 |
|    clip_fraction         | 0.0445      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.11        |
|    cost_value_loss       | 19.7        |
|    cost_values           | 3           |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00768     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 830         |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.892       |
|    value_loss            | 4.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.48        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.48        |
| reward                   | -0.43875438 |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -554        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1233        |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.005303182 |
|    clip_fraction         | 0.06        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.14        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 3           |
|    entropy               | -2.62       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.13        |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.895       |
|    value_loss            | 2.58        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.88         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.88         |
| reward                   | -0.6523462   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -552         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1269         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0023530296 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.24         |
|    cost_value_loss       | 26.5         |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00583      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.58         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.895        |
|    value_loss            | 14.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.46188694  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -550         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1304         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0005470293 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 6.43         |
|    cost_value_loss       | 28.1         |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0138       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 860          |
|    policy_gradient_loss  | 7.12e-05     |
|    std                   | 0.897        |
|    value_loss            | 2.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.571112    |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1338         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0049989116 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 8.14         |
|    cost_values           | 2.99         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.43         |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.903        |
|    value_loss            | 3            |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.64        |
| reward                   | -0.6817164  |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -551        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1373        |
|    total_timesteps       | 182272      |
| train/                   |             |
|    approx_kl             | 0.005942569 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.59        |
|    cost_value_loss       | 9.64        |
|    cost_values           | 3           |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00964     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 880         |
|    policy_gradient_loss  | -0.001      |
|    std                   | 0.895       |
|    value_loss            | 14.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 3.86          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 3.86          |
| reward                   | -0.2707537    |
| rollout/                 |               |
|    ep_len_mean           | 943           |
|    ep_rew_mean           | -557          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1409          |
|    total_timesteps       | 184320        |
| train/                   |               |
|    approx_kl             | 0.00010816063 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 6.01          |
|    cost_value_loss       | 22.2          |
|    cost_values           | 3             |
|    entropy               | -2.6          |
|    entropy_loss          | -2.61         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0.0142        |
|    learning_rate         | 0.0003        |
|    loss                  | 4.14          |
|    n_updates             | 890           |
|    policy_gradient_loss  | -4.39e-06     |
|    std                   | 0.89          |
|    value_loss            | 4.49          |
--------------------------------------------
------------------------------------------
| avg_speed                | 1.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.98        |
| reward                   | -0.33035806 |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -552        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1444        |
|    total_timesteps       | 186368      |
| train/                   |             |
|    approx_kl             | 0.001991387 |
|    clip_fraction         | 0.0215      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.19        |
|    cost_value_loss       | 24.8        |
|    cost_values           | 3           |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0109      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 900         |
|    policy_gradient_loss  | -0.000188   |
|    std                   | 0.887       |
|    value_loss            | 9.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.06        |
| reward                   | -0.50192434 |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -547        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1479        |
|    total_timesteps       | 188416      |
| train/                   |             |
|    approx_kl             | 0.008219732 |
|    clip_fraction         | 0.0394      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.04        |
|    cost_value_loss       | 27.1        |
|    cost_values           | 3           |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0119      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.45        |
|    n_updates             | 910         |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.888       |
|    value_loss            | 32.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.51        |
| reward                   | -0.5277492  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -547        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1514        |
|    total_timesteps       | 190464      |
| train/                   |             |
|    approx_kl             | 0.005083245 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.15        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 3           |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00616     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 920         |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.89        |
|    value_loss            | 3.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5014889   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1548         |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0038497783 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.45         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 3            |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00442      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.96         |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.889        |
|    value_loss            | 15.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.272        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.272        |
| reward                   | -0.38551387  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1583         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0028501516 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 16           |
|    cost_values           | 3            |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00502      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.93         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.889        |
|    value_loss            | 27.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.441908   |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -557        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1618        |
|    total_timesteps       | 196608      |
| train/                   |             |
|    approx_kl             | 0.004541072 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.98        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 3           |
|    entropy               | -2.61       |
|    entropy_loss          | -2.6        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00582     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 950         |
|    policy_gradient_loss  | -0.000537   |
|    std                   | 0.891       |
|    value_loss            | 19          |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.86         |
| reward                   | -0.33828512  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -559         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1653         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0038463278 |
|    clip_fraction         | 0.0336       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.58         |
|    cost_value_loss       | 5.85         |
|    cost_values           | 2.94         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.8         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.893        |
|    value_loss            | 42.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.04         |
| reward                   | -0.7352984   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -556         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1688         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0022614636 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.5          |
|    cost_value_loss       | 18.7         |
|    cost_values           | 2.92         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00976      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.893        |
|    value_loss            | 26.1         |
-------------------------------------------
-----------------------------------
| avg_speed          | 3.05       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 3.05       |
| reward             | -0.2234039 |
| rollout/           |            |
|    ep_len_mean     | 949        |
|    ep_rew_mean     | -556       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.0215       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0215       |
| reward                   | -0.5262265   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -542         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0035045731 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.11         |
|    cost_value_loss       | 8.47         |
|    cost_values           | 2.98         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.5         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.895        |
|    value_loss            | 41.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.64        |
| reward                   | -0.6613761  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -541        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 3           |
|    time_elapsed          | 94          |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.043802604 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.99        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.99        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0114      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | 0.00705     |
|    std                   | 0.899       |
|    value_loss            | 22.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.34         |
| reward                   | -0.67439103  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -536         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0046587596 |
|    clip_fraction         | 0.0494       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 3            |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000962     |
|    learning_rate         | 0.0003       |
|    loss                  | 9.72         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.000513    |
|    std                   | 0.899        |
|    value_loss            | 11.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -1.2629803  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -541        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 164         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.006310449 |
|    clip_fraction         | 0.0353      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 14.3        |
|    cost_values           | 3           |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0086      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.895       |
|    value_loss            | 19.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.65         |
| reward                   | -0.8354807   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 199          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0030723026 |
|    clip_fraction         | 0.041        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.69         |
|    cost_value_loss       | 11           |
|    cost_values           | 3            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0049       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.76         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.891        |
|    value_loss            | 30.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.82          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.82          |
| reward                   | -0.4501219    |
| rollout/                 |               |
|    ep_len_mean           | 938           |
|    ep_rew_mean           | -535          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 7             |
|    time_elapsed          | 234           |
|    total_timesteps       | 215040        |
| train/                   |               |
|    approx_kl             | 0.00084052375 |
|    clip_fraction         | 0.00137       |
|    clip_range            | 0.2           |
|    cost_returns          | 5             |
|    cost_value_loss       | 13.6          |
|    cost_values           | 3             |
|    entropy               | -2.61         |
|    entropy_loss          | -2.6          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00662       |
|    learning_rate         | 0.0003        |
|    loss                  | 7.5           |
|    n_updates             | 1040          |
|    policy_gradient_loss  | 2.51e-05      |
|    std                   | 0.891         |
|    value_loss            | 31.8          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.32          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 7.32          |
| reward                   | -0.72915643   |
| rollout/                 |               |
|    ep_len_mean           | 938           |
|    ep_rew_mean           | -537          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 8             |
|    time_elapsed          | 270           |
|    total_timesteps       | 217088        |
| train/                   |               |
|    approx_kl             | 0.00014553985 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 5.87          |
|    cost_value_loss       | 18.8          |
|    cost_values           | 3             |
|    entropy               | -2.6          |
|    entropy_loss          | -2.61         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.0104        |
|    learning_rate         | 0.0003        |
|    loss                  | 7.35          |
|    n_updates             | 1050          |
|    policy_gradient_loss  | -1.25e-05     |
|    std                   | 0.89          |
|    value_loss            | 44.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.8716989   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 305          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0028847135 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.69         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 2.99         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00413      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.52         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.89         |
|    value_loss            | 25.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0346701   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 339          |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0046332963 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.19         |
|    cost_value_loss       | 9.66         |
|    cost_values           | 3            |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00511      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.72         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.000708    |
|    std                   | 0.887        |
|    value_loss            | 8.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2099818  |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -544        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 374         |
|    total_timesteps       | 223232      |
| train/                   |             |
|    approx_kl             | 0.005087959 |
|    clip_fraction         | 0.0345      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 2.86        |
|    cost_values           | 2.92        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.7        |
|    n_updates             | 1080        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.886       |
|    value_loss            | 48.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1226133   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 408          |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0022290433 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.19         |
|    cost_value_loss       | 4.52         |
|    cost_values           | 2.74         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.887        |
|    value_loss            | 24.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.5          |
| reward                   | -0.7268006   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 442          |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0024938094 |
|    clip_fraction         | 0.00654      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.65         |
|    cost_value_loss       | 8.46         |
|    cost_values           | 2.63         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.2         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.000706    |
|    std                   | 0.888        |
|    value_loss            | 28.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.65          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.65          |
| reward                   | -0.7679843    |
| rollout/                 |               |
|    ep_len_mean           | 929           |
|    ep_rew_mean           | -546          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 14            |
|    time_elapsed          | 476           |
|    total_timesteps       | 229376        |
| train/                   |               |
|    approx_kl             | 0.00057135685 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.99          |
|    cost_value_loss       | 3.35          |
|    cost_values           | 2.58          |
|    entropy               | -2.6          |
|    entropy_loss          | -2.6          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 25            |
|    n_updates             | 1110          |
|    policy_gradient_loss  | 2.44e-05      |
|    std                   | 0.888         |
|    value_loss            | 41            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.54         |
| reward                   | -0.966252    |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -549         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0064411582 |
|    clip_fraction         | 0.0523       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 4.44         |
|    cost_values           | 2.47         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.41         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 0.884        |
|    value_loss            | 13.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.62          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.62          |
| reward                   | -0.7626657    |
| rollout/                 |               |
|    ep_len_mean           | 933           |
|    ep_rew_mean           | -550          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 16            |
|    time_elapsed          | 546           |
|    total_timesteps       | 233472        |
| train/                   |               |
|    approx_kl             | 2.4957873e-05 |
|    clip_fraction         | 0.00532       |
|    clip_range            | 0.2           |
|    cost_returns          | 5.09          |
|    cost_value_loss       | 19.2          |
|    cost_values           | 2.56          |
|    entropy               | -2.59         |
|    entropy_loss          | -2.59         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.6          |
|    n_updates             | 1130          |
|    policy_gradient_loss  | -6.63e-05     |
|    std                   | 0.883         |
|    value_loss            | 8.06          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.776        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.776        |
| reward                   | -0.59480006  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -550         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 581          |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0029645623 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.23         |
|    cost_value_loss       | 11           |
|    cost_values           | 2.93         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00153      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.01         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.000273    |
|    std                   | 0.88         |
|    value_loss            | 18           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.72         |
| reward                   | -0.29963568  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -550         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 616          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0072740666 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.13         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00679      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.875        |
|    value_loss            | 5.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.14        |
| reward                   | -0.30106935 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -553        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 650         |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.00465448  |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.06        |
|    cost_value_loss       | 8.98        |
|    cost_values           | 3           |
|    entropy               | -2.56       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00427     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | -0.000588   |
|    std                   | 0.873       |
|    value_loss            | 9.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.70840305  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 685          |
|    total_timesteps       | 241664       |
| train/                   |              |
|    approx_kl             | 0.0015257163 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.22         |
|    cost_value_loss       | 3.38         |
|    cost_values           | 2.94         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 1170         |
|    policy_gradient_loss  | 0.000149     |
|    std                   | 0.874        |
|    value_loss            | 23.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.43715358 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -562        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 721         |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.004415665 |
|    clip_fraction         | 0.0189      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.92        |
|    cost_value_loss       | 9.76        |
|    cost_values           | 2.88        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.872       |
|    value_loss            | 22          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.6473312  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -563        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 756         |
|    total_timesteps       | 245760      |
| train/                   |             |
|    approx_kl             | 0.003728325 |
|    clip_fraction         | 0.0185      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 23          |
|    cost_values           | 2.99        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0.00514     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.27        |
|    n_updates             | 1190        |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.872       |
|    value_loss            | 14.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.91         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.91         |
| reward                   | -0.45863244  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -562         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 790          |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0026195562 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.51         |
|    cost_value_loss       | 18.8         |
|    cost_values           | 3            |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00203      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.91         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.869        |
|    value_loss            | 9.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.56        |
| reward                   | -0.28912094 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -556        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 825         |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.007515357 |
|    clip_fraction         | 0.042       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.93        |
|    cost_value_loss       | 7.92        |
|    cost_values           | 3           |
|    entropy               | -2.54       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 5.67e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 19.7        |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 0.863       |
|    value_loss            | 32.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.26        |
| reward                   | -0.38690117 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -555        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 860         |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.003604514 |
|    clip_fraction         | 0.0725      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.05        |
|    cost_value_loss       | 20.4        |
|    cost_values           | 3           |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00809     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.49        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00245    |
|    std                   | 0.861       |
|    value_loss            | 46.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.97         |
| reward                   | -0.7485601   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -559         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 895          |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0014487049 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.95         |
|    cost_value_loss       | 19.1         |
|    cost_values           | 3            |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00336      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.09         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | 4.51e-05     |
|    std                   | 0.861        |
|    value_loss            | 11.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.54         |
| reward                   | -0.59772146  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -560         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 930          |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0017911632 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.66         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 3            |
|    entropy               | -2.52        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00457      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.000506    |
|    std                   | 0.854        |
|    value_loss            | 7.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.99         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.99         |
| reward                   | -0.43469858  |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -562         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 966          |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0064515984 |
|    clip_fraction         | 0.0753       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 11.2         |
|    cost_values           | 3            |
|    entropy               | -2.51        |
|    entropy_loss          | -2.52        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00838      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 0.852        |
|    value_loss            | 24.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0543       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0543       |
| reward                   | -0.5374282   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -564         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 1001         |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0051661166 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.84         |
|    cost_value_loss       | 18.8         |
|    cost_values           | 3            |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0024       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.83         |
|    n_updates             | 1260         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.853        |
|    value_loss            | 9.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.36404264  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -564         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1037         |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0029371073 |
|    clip_fraction         | 0.00767      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.89         |
|    cost_value_loss       | 30.2         |
|    cost_values           | 3            |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16           |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00063     |
|    std                   | 0.854        |
|    value_loss            | 5.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.8924831   |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -555         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1073         |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0017013338 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.75         |
|    cost_value_loss       | 43.6         |
|    cost_values           | 3            |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.5         |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.000489    |
|    std                   | 0.854        |
|    value_loss            | 22.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8378581   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1109         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0061762943 |
|    clip_fraction         | 0.063        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.49         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 3            |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00421      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.855        |
|    value_loss            | 43.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.9832273   |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -552         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1144         |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0040115593 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.72         |
|    cost_value_loss       | 18.2         |
|    cost_values           | 3            |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00948      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.854        |
|    value_loss            | 59.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.7203421  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -552        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1180        |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.004627047 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.81        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 3           |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00895     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.23        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.000653   |
|    std                   | 0.849       |
|    value_loss            | 13.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5665985  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -552        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 35          |
|    time_elapsed          | 1215        |
|    total_timesteps       | 272384      |
| train/                   |             |
|    approx_kl             | 0.002944207 |
|    clip_fraction         | 0.00322     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.48        |
|    cost_value_loss       | 18.1        |
|    cost_values           | 3           |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0108      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 1320        |
|    policy_gradient_loss  | -3.84e-05   |
|    std                   | 0.846       |
|    value_loss            | 25.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.7345614   |
| rollout/                 |              |
|    ep_len_mean           | 886          |
|    ep_rew_mean           | -551         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 36           |
|    time_elapsed          | 1250         |
|    total_timesteps       | 274432       |
| train/                   |              |
|    approx_kl             | 0.0051109158 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.27         |
|    cost_value_loss       | 26.7         |
|    cost_values           | 3            |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00967      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.13         |
|    n_updates             | 1330         |
|    policy_gradient_loss  | -0.000725    |
|    std                   | 0.845        |
|    value_loss            | 3.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -0.616097    |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -558         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 37           |
|    time_elapsed          | 1284         |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0046653436 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.33         |
|    cost_value_loss       | 3.47         |
|    cost_values           | 2.99         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.5         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00805      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.46         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.000752    |
|    std                   | 0.852        |
|    value_loss            | 7.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.89         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.89         |
| reward                   | -0.3822407   |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -553         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 38           |
|    time_elapsed          | 1320         |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0061241644 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 11.5         |
|    cost_values           | 3            |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00576      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.43         |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.000575    |
|    std                   | 0.853        |
|    value_loss            | 16.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.43        |
| reward                   | -0.29995605 |
| rollout/                 |             |
|    ep_len_mean           | 881         |
|    ep_rew_mean           | -549        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 39          |
|    time_elapsed          | 1355        |
|    total_timesteps       | 280576      |
| train/                   |             |
|    approx_kl             | 0.003459015 |
|    clip_fraction         | 0.0116      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.07        |
|    cost_value_loss       | 16          |
|    cost_values           | 3           |
|    entropy               | -2.51       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000609    |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 1360        |
|    policy_gradient_loss  | -0.00085    |
|    std                   | 0.851       |
|    value_loss            | 25.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.58         |
| reward                   | -0.7354167   |
| rollout/                 |              |
|    ep_len_mean           | 874          |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 40           |
|    time_elapsed          | 1390         |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0034757596 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 7            |
|    cost_value_loss       | 35.8         |
|    cost_values           | 3            |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0122       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.43         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.849        |
|    value_loss            | 5.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.688        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.688        |
| reward                   | -0.30550787  |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 41           |
|    time_elapsed          | 1425         |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0022788264 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.65         |
|    cost_value_loss       | 31.9         |
|    cost_values           | 3            |
|    entropy               | -2.5         |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00578      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.52         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.847        |
|    value_loss            | 24.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.353        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.353        |
| reward                   | -0.5460403   |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 42           |
|    time_elapsed          | 1459         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0026150092 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.49         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 3            |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00417      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.845        |
|    value_loss            | 15.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.72         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.72         |
| reward                   | -0.42603168  |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -541         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 43           |
|    time_elapsed          | 1494         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0029362342 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.25         |
|    cost_value_loss       | 9.21         |
|    cost_values           | 3            |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00213      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.19         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.000886    |
|    std                   | 0.845        |
|    value_loss            | 22.9         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 3.11       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.11       |
| reward                   | -0.5881929 |
| rollout/                 |            |
|    ep_len_mean           | 876        |
|    ep_rew_mean           | -535       |
| time/                    |            |
|    fps                   | 58         |
|    iterations            | 44         |
|    time_elapsed          | 1529       |
|    total_timesteps       | 290816     |
| train/                   |            |
|    approx_kl             | 0.00409809 |
|    clip_fraction         | 0.0317     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.98       |
|    cost_value_loss       | 29.8       |
|    cost_values           | 3          |
|    entropy               | -2.5       |
|    entropy_loss          | -2.5       |
|    explained_variance    | 1.19e-07   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 25.5       |
|    n_updates             | 1410       |
|    policy_gradient_loss  | -0.00182   |
|    std                   | 0.844      |
|    value_loss            | 24.8       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 2.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.8          |
| reward                   | -0.57411397  |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 45           |
|    time_elapsed          | 1563         |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0066643716 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 18           |
|    cost_values           | 3            |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00221      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.57         |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 0.841        |
|    value_loss            | 4.46         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.93        |
| reward                   | -0.57764965 |
| rollout/                 |             |
|    ep_len_mean           | 885         |
|    ep_rew_mean           | -540        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 46          |
|    time_elapsed          | 1598        |
|    total_timesteps       | 294912      |
| train/                   |             |
|    approx_kl             | 0.004058472 |
|    clip_fraction         | 0.00557     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.75        |
|    cost_value_loss       | 34.4        |
|    cost_values           | 3           |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0145      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.63        |
|    n_updates             | 1430        |
|    policy_gradient_loss  | -0.000457   |
|    std                   | 0.84        |
|    value_loss            | 1.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.22         |
| reward                   | -0.3055259   |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 47           |
|    time_elapsed          | 1632         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0028437183 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 7            |
|    cost_value_loss       | 35.4         |
|    cost_values           | 2.99         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.7         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.000705    |
|    std                   | 0.84         |
|    value_loss            | 1.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.34         |
| reward                   | -0.745091    |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -539         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 48           |
|    time_elapsed          | 1667         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0023218486 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.01         |
|    cost_value_loss       | 8.6          |
|    cost_values           | 3            |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00254      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.75         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.000739    |
|    std                   | 0.841        |
|    value_loss            | 6.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.20169903  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -542         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 49           |
|    time_elapsed          | 1702         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0029430892 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 17.1         |
|    cost_values           | 3            |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00409      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.76         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.842        |
|    value_loss            | 7.58         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 5.87        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 5.87        |
| reward             | -0.77206075 |
| rollout/           |             |
|    ep_len_mean     | 899         |
|    ep_rew_mean     | -538        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 303104      |
------------------------------------
-------------------------------------------
| avg_speed                | 5.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.91         |
| reward                   | -0.43390244  |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -540         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0037493124 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.17         |
|    cost_value_loss       | 6.79         |
|    cost_values           | 2.99         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00384      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.61         |
|    n_updates             | 1480         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.84         |
|    value_loss            | 3.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.14        |
| reward                   | -0.6136874  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -538        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 307200      |
| train/                   |             |
|    approx_kl             | 0.003501182 |
|    clip_fraction         | 0.0216      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.08        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 3           |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000163    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.02        |
|    n_updates             | 1490        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.839       |
|    value_loss            | 3.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.25         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.25         |
| reward                   | -0.5605385   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -533         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 309248       |
| train/                   |              |
|    approx_kl             | 0.0034067966 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 3            |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00665      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.46         |
|    n_updates             | 1500         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.837        |
|    value_loss            | 5.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.85        |
| reward                   | -0.39178365 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -529        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 311296      |
| train/                   |             |
|    approx_kl             | 0.004351101 |
|    clip_fraction         | 0.00962     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 8.96        |
|    cost_values           | 3           |
|    entropy               | -2.47       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00772     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 1510        |
|    policy_gradient_loss  | -9.81e-05   |
|    std                   | 0.834       |
|    value_loss            | 19.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.1          |
| reward                   | -0.5923931   |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0048840092 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.11         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 3            |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000773     |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.83         |
|    value_loss            | 12           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.17          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.17          |
| reward                   | -0.7832728    |
| rollout/                 |               |
|    ep_len_mean           | 895           |
|    ep_rew_mean           | -509          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 7             |
|    time_elapsed          | 233           |
|    total_timesteps       | 315392        |
| train/                   |               |
|    approx_kl             | 0.00096409896 |
|    clip_fraction         | 0.000293      |
|    clip_range            | 0.2           |
|    cost_returns          | 6.31          |
|    cost_value_loss       | 26.6          |
|    cost_values           | 3             |
|    entropy               | -2.46         |
|    entropy_loss          | -2.46         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00716       |
|    learning_rate         | 0.0003        |
|    loss                  | 9.4           |
|    n_updates             | 1530          |
|    policy_gradient_loss  | -0.000229     |
|    std                   | 0.827         |
|    value_loss            | 30.5          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.552995   |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -511        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 268         |
|    total_timesteps       | 317440      |
| train/                   |             |
|    approx_kl             | 0.005313564 |
|    clip_fraction         | 0.0326      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 14          |
|    cost_values           | 3           |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00774     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.23        |
|    n_updates             | 1540        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.824       |
|    value_loss            | 5.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.4020104   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0010987539 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.52         |
|    cost_value_loss       | 4.97         |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00309      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.000837    |
|    std                   | 0.823        |
|    value_loss            | 9.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -0.41348958  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0011685014 |
|    clip_fraction         | 0.0339       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.04         |
|    cost_value_loss       | 25.2         |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0115       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.79         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | 0.000357     |
|    std                   | 0.825        |
|    value_loss            | 4.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.62         |
| reward                   | -0.6267578   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 374          |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0047067343 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.54         |
|    cost_value_loss       | 12           |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.000598    |
|    std                   | 0.824        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.95252997  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 409          |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0032946358 |
|    clip_fraction         | 0.00928      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.5          |
|    cost_value_loss       | 34.8         |
|    cost_values           | 2.99         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0232       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.000467    |
|    std                   | 0.823        |
|    value_loss            | 3.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -0.35108295  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 13           |
|    time_elapsed          | 444          |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 6.786734e-05 |
|    clip_fraction         | 0.00605      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.29         |
|    cost_value_loss       | 35.5         |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.8         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00029     |
|    std                   | 0.822        |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.04         |
| reward                   | -0.67949545  |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 14           |
|    time_elapsed          | 480          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0050581093 |
|    clip_fraction         | 0.0381       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.6          |
|    cost_value_loss       | 47.5         |
|    cost_values           | 2.99         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0166       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.62         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.822        |
|    value_loss            | 7.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.54046106 |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 15          |
|    time_elapsed          | 516         |
|    total_timesteps       | 331776      |
| train/                   |             |
|    approx_kl             | 0.004624606 |
|    clip_fraction         | 0.0043      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.29        |
|    cost_value_loss       | 25.6        |
|    cost_values           | 2.99        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23          |
|    n_updates             | 1610        |
|    policy_gradient_loss  | -0.000572   |
|    std                   | 0.82        |
|    value_loss            | 19.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.46         |
| reward                   | -0.3201361   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 552          |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0055268416 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.04         |
|    cost_value_loss       | 48           |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00312      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.000577    |
|    std                   | 0.819        |
|    value_loss            | 7            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.18         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.18         |
| reward                   | -0.6426405   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 588          |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0035383329 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.29         |
|    cost_value_loss       | 45.4         |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0244       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.62         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00045     |
|    std                   | 0.818        |
|    value_loss            | 5.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.08        |
| reward                   | -0.3794132  |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 624         |
|    total_timesteps       | 337920      |
| train/                   |             |
|    approx_kl             | 0.002381125 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.33        |
|    cost_value_loss       | 26.8        |
|    cost_values           | 3           |
|    entropy               | -2.43       |
|    entropy_loss          | -2.44       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 1640        |
|    policy_gradient_loss  | -0.000605   |
|    std                   | 0.818       |
|    value_loss            | 6.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0729       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0729       |
| reward                   | -0.3192385   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 659          |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0039256415 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.68         |
|    cost_value_loss       | 28.7         |
|    cost_values           | 2.99         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.000292    |
|    std                   | 0.818        |
|    value_loss            | 6.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.76         |
| reward                   | -0.60151243  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 694          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0031138859 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.12         |
|    cost_value_loss       | 26.3         |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.822        |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.949        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.949        |
| reward                   | -0.32929513  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 21           |
|    time_elapsed          | 729          |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0018848822 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.8          |
|    cost_value_loss       | 35.3         |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.8         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.823        |
|    value_loss            | 2.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.27         |
| reward                   | -0.51199055  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 22           |
|    time_elapsed          | 763          |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0029741914 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.51         |
|    cost_value_loss       | 42.7         |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0284       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 1680         |
|    policy_gradient_loss  | 0.000339     |
|    std                   | 0.823        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.7          |
| reward                   | -0.31634334  |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 23           |
|    time_elapsed          | 798          |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0033463805 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00757      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.95         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.824        |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.24         |
| reward                   | -0.4101769   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 832          |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0033376203 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 5.88         |
|    cost_values           | 2.97         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.825        |
|    value_loss            | 17.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.439        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.439        |
| reward                   | -0.38164926  |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 867          |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0036735977 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.67         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 2.94         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00503      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.826        |
|    value_loss            | 3.26         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0859        |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.0859        |
| reward                   | -0.43392092   |
| rollout/                 |               |
|    ep_len_mean           | 922           |
|    ep_rew_mean           | -475          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 26            |
|    time_elapsed          | 902           |
|    total_timesteps       | 354304        |
| train/                   |               |
|    approx_kl             | 0.00067502516 |
|    clip_fraction         | 0.0232        |
|    clip_range            | 0.2           |
|    cost_returns          | 4.22          |
|    cost_value_loss       | 7.22          |
|    cost_values           | 2.98          |
|    entropy               | -2.45         |
|    entropy_loss          | -2.45         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.21          |
|    n_updates             | 1720          |
|    policy_gradient_loss  | -0.00173      |
|    std                   | 0.826         |
|    value_loss            | 1.37          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.8          |
| reward                   | -0.4367236   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 27           |
|    time_elapsed          | 937          |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0010828874 |
|    clip_fraction         | 0.00845      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 7.32         |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.000269    |
|    std                   | 0.82         |
|    value_loss            | 1.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.91         |
| reward                   | -0.5367631   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 28           |
|    time_elapsed          | 972          |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0036339227 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.56         |
|    cost_value_loss       | 28           |
|    cost_values           | 3            |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.816        |
|    value_loss            | 2.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.663        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.663        |
| reward                   | -0.5825831   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 1006         |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0017291149 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.82         |
|    cost_value_loss       | 36.3         |
|    cost_values           | 3            |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0132       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.88         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.000439    |
|    std                   | 0.817        |
|    value_loss            | 0.549        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.518       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.518       |
| reward                   | -0.4541241  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1040        |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.005560509 |
|    clip_fraction         | 0.0284      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.81        |
|    cost_value_loss       | 4.72        |
|    cost_values           | 2.99        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00698     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 1760        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.819       |
|    value_loss            | 2.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.65         |
| reward                   | -0.58723515  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 31           |
|    time_elapsed          | 1076         |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0038621617 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.25         |
|    cost_value_loss       | 6.65         |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00767      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.39         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.824        |
|    value_loss            | 2.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.44808504 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -493        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 32          |
|    time_elapsed          | 1111        |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.004469114 |
|    clip_fraction         | 0.012       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.25        |
|    cost_value_loss       | 55.2        |
|    cost_values           | 3           |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00875     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.13        |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.823       |
|    value_loss            | 2.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -0.30830267 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 33          |
|    time_elapsed          | 1146        |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.004477764 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.48        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 3           |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.21        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.823       |
|    value_loss            | 2.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4791554   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 34           |
|    time_elapsed          | 1181         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0015488582 |
|    clip_fraction         | 0.0754       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.11         |
|    cost_value_loss       | 38           |
|    cost_values           | 2.99         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0297       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | 0.00162      |
|    std                   | 0.823        |
|    value_loss            | 4.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57385087  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 35           |
|    time_elapsed          | 1217         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0034374124 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.44         |
|    cost_value_loss       | 35.4         |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00682      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 1810         |
|    policy_gradient_loss  | 0.00257      |
|    std                   | 0.821        |
|    value_loss            | 3.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.43138734  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 36           |
|    time_elapsed          | 1253         |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0028980018 |
|    clip_fraction         | 0.127        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.32         |
|    cost_value_loss       | 27.6         |
|    cost_values           | 2.99         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | 0.00153      |
|    std                   | 0.82         |
|    value_loss            | 2.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.46200445  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 37           |
|    time_elapsed          | 1288         |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0038644224 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.29         |
|    cost_value_loss       | 33.5         |
|    cost_values           | 2.99         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0149       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.76         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.819        |
|    value_loss            | 3.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.03        |
| reward                   | -0.31693587 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -482        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 38          |
|    time_elapsed          | 1323        |
|    total_timesteps       | 378880      |
| train/                   |             |
|    approx_kl             | 0.005611814 |
|    clip_fraction         | 0.0202      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.29        |
|    cost_value_loss       | 19.6        |
|    cost_values           | 2.99        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00402     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 1840        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.821       |
|    value_loss            | 1.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.53         |
| reward                   | -0.34151247  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 39           |
|    time_elapsed          | 1359         |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0011812219 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.52         |
|    cost_value_loss       | 49.2         |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.2         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.000492    |
|    std                   | 0.82         |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5            |
| reward                   | -0.24502821  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 40           |
|    time_elapsed          | 1394         |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0009314743 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.78         |
|    cost_value_loss       | 42.1         |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | 0.000459     |
|    std                   | 0.82         |
|    value_loss            | 1.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.31         |
| reward                   | -0.38435197  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 41           |
|    time_elapsed          | 1429         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0069954493 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.42         |
|    cost_value_loss       | 36.2         |
|    cost_values           | 2.99         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.9         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -3.39e-05    |
|    std                   | 0.819        |
|    value_loss            | 1.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.05         |
| reward                   | -0.32252264  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 42           |
|    time_elapsed          | 1464         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0041774767 |
|    clip_fraction         | 0.00396      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.86         |
|    cost_value_loss       | 35.1         |
|    cost_values           | 3            |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.9         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.000844    |
|    std                   | 0.816        |
|    value_loss            | 1.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.32         |
| reward                   | -0.50741744  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 43           |
|    time_elapsed          | 1499         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0017323956 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.02         |
|    cost_value_loss       | 19.3         |
|    cost_values           | 3            |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00995      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.000273    |
|    std                   | 0.815        |
|    value_loss            | 0.717        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.8          |
| reward                   | -0.5714376   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 44           |
|    time_elapsed          | 1533         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0004485219 |
|    clip_fraction         | 0.0435       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.77         |
|    cost_value_loss       | 38           |
|    cost_values           | 2.99         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0138       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | 0.00076      |
|    std                   | 0.814        |
|    value_loss            | 2.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.83         |
| reward                   | -0.3995215   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 45           |
|    time_elapsed          | 1568         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0024023072 |
|    clip_fraction         | 0.00542      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.89         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 3            |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0277       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.18         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.000538    |
|    std                   | 0.814        |
|    value_loss            | 1.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.61         |
| reward                   | -0.46989283  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 46           |
|    time_elapsed          | 1602         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0024995361 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.74         |
|    cost_value_loss       | 17.5         |
|    cost_values           | 2.99         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00406      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.32         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -1.25e-05    |
|    std                   | 0.811        |
|    value_loss            | 2.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -0.41838005  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 47           |
|    time_elapsed          | 1637         |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0032135323 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 9.52         |
|    cost_values           | 2.99         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00381      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 1930         |
|    policy_gradient_loss  | 0.000216     |
|    std                   | 0.809        |
|    value_loss            | 2.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.41         |
| reward                   | -0.4418206   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 48           |
|    time_elapsed          | 1671         |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0062675225 |
|    clip_fraction         | 0.052        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.03         |
|    cost_value_loss       | 20.5         |
|    cost_values           | 3            |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0206       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.62         |
|    n_updates             | 1940         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.809        |
|    value_loss            | 1            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.51626384  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 49           |
|    time_elapsed          | 1706         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0015947048 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.59         |
|    cost_value_loss       | 25           |
|    cost_values           | 3            |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.806        |
|    value_loss            | 2.59         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.01       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.01       |
| reward             | -0.3524203 |
| rollout/           |            |
|    ep_len_mean     | 976        |
|    ep_rew_mean     | -461       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 403456     |
-----------------------------------
-------------------------------------------
| avg_speed                | 4.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.84         |
| reward                   | -0.21802776  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0042864205 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 14.1         |
|    cost_values           | 2.99         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.05         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.000927    |
|    std                   | 0.809        |
|    value_loss            | 3.21         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 4.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.01       |
| reward                   | -0.4702988 |
| rollout/                 |            |
|    ep_len_mean           | 976        |
|    ep_rew_mean           | -459       |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 3          |
|    time_elapsed          | 95         |
|    total_timesteps       | 407552     |
| train/                   |            |
|    approx_kl             | 0.0048608  |
|    clip_fraction         | 0.016      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.24       |
|    cost_value_loss       | 7.63       |
|    cost_values           | 2.99       |
|    entropy               | -2.41      |
|    entropy_loss          | -2.41      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0.00741    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.62       |
|    n_updates             | 1980       |
|    policy_gradient_loss  | -0.000778  |
|    std                   | 0.81       |
|    value_loss            | 11         |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.31        |
| reward                   | -0.41269207 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 4           |
|    time_elapsed          | 130         |
|    total_timesteps       | 409600      |
| train/                   |             |
|    approx_kl             | 0.015783183 |
|    clip_fraction         | 0.0617      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.99        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.52        |
|    n_updates             | 1990        |
|    policy_gradient_loss  | -1.25e-05   |
|    std                   | 0.811       |
|    value_loss            | 3.77        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.82       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.82       |
| reward                   | -0.57443   |
| rollout/                 |            |
|    ep_len_mean           | 985        |
|    ep_rew_mean           | -464       |
| time/                    |            |
|    fps                   | 62         |
|    iterations            | 5          |
|    time_elapsed          | 164        |
|    total_timesteps       | 411648     |
| train/                   |            |
|    approx_kl             | 0.00346881 |
|    clip_fraction         | 0.0152     |
|    clip_range            | 0.2        |
|    cost_returns          | 7.58       |
|    cost_value_loss       | 29.5       |
|    cost_values           | 3          |
|    entropy               | -2.42      |
|    entropy_loss          | -2.42      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.0261     |
|    learning_rate         | 0.0003     |
|    loss                  | 3.99       |
|    n_updates             | 2000       |
|    policy_gradient_loss  | -0.000221  |
|    std                   | 0.81       |
|    value_loss            | 7.07       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -0.2760211   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 199          |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0017175943 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.75         |
|    cost_value_loss       | 9.91         |
|    cost_values           | 2.99         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.85         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.81         |
|    value_loss            | 2.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50230014  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 233          |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0035406505 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.9          |
|    cost_value_loss       | 11.1         |
|    cost_values           | 3            |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00296      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.02         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.807        |
|    value_loss            | 5.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5236106   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0067416113 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.65         |
|    cost_value_loss       | 3.04         |
|    cost_values           | 3            |
|    entropy               | -2.39        |
|    entropy_loss          | -2.4         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00459      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.05         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.801        |
|    value_loss            | 3.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.740347    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 419840       |
| train/                   |              |
|    approx_kl             | 0.0032508685 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.49         |
|    cost_value_loss       | 14.3         |
|    cost_values           | 3            |
|    entropy               | -2.38        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00767      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.36         |
|    n_updates             | 2040         |
|    policy_gradient_loss  | -0.000243    |
|    std                   | 0.798        |
|    value_loss            | 5.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.4          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.4          |
| reward                   | -0.47648865  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0020075347 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.28         |
|    cost_value_loss       | 19.1         |
|    cost_values           | 2.99         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.00018     |
|    std                   | 0.797        |
|    value_loss            | 15           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.7336771  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 371         |
|    total_timesteps       | 423936      |
| train/                   |             |
|    approx_kl             | 0.004121329 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 17.3        |
|    cost_values           | 3           |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.5        |
|    n_updates             | 2060        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.794       |
|    value_loss            | 20.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -0.63581395  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0023607553 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.62         |
|    cost_value_loss       | 28.5         |
|    cost_values           | 3            |
|    entropy               | -2.38        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0183       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.794        |
|    value_loss            | 3.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.45724398  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0031466144 |
|    clip_fraction         | 0.00581      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.34         |
|    cost_value_loss       | 6.86         |
|    cost_values           | 2.99         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00022      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.6          |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -1.65e-05    |
|    std                   | 0.791        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.4760751   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 475          |
|    total_timesteps       | 430080       |
| train/                   |              |
|    approx_kl             | 0.0042357435 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.78         |
|    cost_value_loss       | 11.1         |
|    cost_values           | 3            |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 2090         |
|    policy_gradient_loss  | -0.000739    |
|    std                   | 0.789        |
|    value_loss            | 16.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.55        |
| reward                   | -0.55616385 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 511         |
|    total_timesteps       | 432128      |
| train/                   |             |
|    approx_kl             | 0.001026408 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.99        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.21        |
|    n_updates             | 2100        |
|    policy_gradient_loss  | 0.00018     |
|    std                   | 0.79        |
|    value_loss            | 2.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.98        |
| reward                   | -0.422347   |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 16          |
|    time_elapsed          | 546         |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.004312667 |
|    clip_fraction         | 0.00708     |
|    clip_range            | 0.2         |
|    cost_returns          | 7.03        |
|    cost_value_loss       | 30.6        |
|    cost_values           | 3           |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.000984   |
|    std                   | 0.79        |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.5662114   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 580          |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0028463746 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.04         |
|    cost_value_loss       | 21.9         |
|    cost_values           | 3            |
|    entropy               | -2.37        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0149       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.49         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.000346    |
|    std                   | 0.79         |
|    value_loss            | 12.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.48210302 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 615         |
|    total_timesteps       | 438272      |
| train/                   |             |
|    approx_kl             | 0.00221813  |
|    clip_fraction         | 0.00107     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.44        |
|    cost_value_loss       | 21.9        |
|    cost_values           | 3           |
|    entropy               | -2.36       |
|    entropy_loss          | -2.37       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00699     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 2130        |
|    policy_gradient_loss  | -8.21e-06   |
|    std                   | 0.79        |
|    value_loss            | 15.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.55028945 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 649         |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.000669652 |
|    clip_fraction         | 0.0288      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.98        |
|    cost_values           | 3           |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0121      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.5         |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -2.3e-06    |
|    std                   | 0.786       |
|    value_loss            | 2.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.62994856 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 684         |
|    total_timesteps       | 442368      |
| train/                   |             |
|    approx_kl             | 0.005497768 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 3           |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.000621    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 2150        |
|    policy_gradient_loss  | -0.00196    |
|    std                   | 0.785       |
|    value_loss            | 1.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8366195   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 718          |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0047220546 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.73         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 3            |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.21         |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.000141    |
|    std                   | 0.784        |
|    value_loss            | 1.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6902433   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 753          |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0052830004 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.98         |
|    cost_value_loss       | 19.5         |
|    cost_values           | 3            |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.006        |
|    learning_rate         | 0.0003       |
|    loss                  | 5.82         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.784        |
|    value_loss            | 16.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.5710111  |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 788         |
|    total_timesteps       | 448512      |
| train/                   |             |
|    approx_kl             | 0.002098797 |
|    clip_fraction         | 0.00747     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 12          |
|    cost_values           | 3           |
|    entropy               | -2.36       |
|    entropy_loss          | -2.35       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00388     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 2180        |
|    policy_gradient_loss  | -0.000866   |
|    std                   | 0.786       |
|    value_loss            | 8.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57037383  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 823          |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0042177932 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.43         |
|    cost_value_loss       | 7.37         |
|    cost_values           | 3            |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00933      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.000789    |
|    std                   | 0.785        |
|    value_loss            | 18.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.3371468   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 858          |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0037528747 |
|    clip_fraction         | 0.0482       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.63         |
|    cost_value_loss       | 26.1         |
|    cost_values           | 3            |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.9         |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 0.784        |
|    value_loss            | 16.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.64234734 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 892         |
|    total_timesteps       | 454656      |
| train/                   |             |
|    approx_kl             | 0.005169974 |
|    clip_fraction         | 0.0507      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.23        |
|    cost_value_loss       | 36.8        |
|    cost_values           | 3           |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.6        |
|    n_updates             | 2210        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.782       |
|    value_loss            | 3.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3190017   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 927          |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0032688926 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.66         |
|    cost_value_loss       | 24.2         |
|    cost_values           | 3            |
|    entropy               | -2.34        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.7         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.000467    |
|    std                   | 0.782        |
|    value_loss            | 13.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.26124445 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 962         |
|    total_timesteps       | 458752      |
| train/                   |             |
|    approx_kl             | 0.003945874 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 14.7        |
|    cost_values           | 3           |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00349     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 2230        |
|    policy_gradient_loss  | -0.0022     |
|    std                   | 0.78        |
|    value_loss            | 4.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.29700172 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 997         |
|    total_timesteps       | 460800      |
| train/                   |             |
|    approx_kl             | 0.004812275 |
|    clip_fraction         | 0.0182      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 5.08        |
|    cost_values           | 2.99        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.25        |
|    n_updates             | 2240        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.779       |
|    value_loss            | 2.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.65        |
| reward                   | -0.5122932  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1031        |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.002358737 |
|    clip_fraction         | 0.00186     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 3           |
|    entropy               | -2.33       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00406     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.000546   |
|    std                   | 0.778       |
|    value_loss            | 4.57        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.99         |
| reward                   | -0.6118963   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1066         |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0047790734 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.88         |
|    cost_value_loss       | 3.94         |
|    cost_values           | 3            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00646      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.92         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.778        |
|    value_loss            | 2.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.47         |
| reward                   | -0.44398937  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1100         |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0040554386 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.77         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 3            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.43         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.775        |
|    value_loss            | 1.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.51         |
| reward                   | -0.36001274  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1135         |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0035829358 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.03         |
|    cost_value_loss       | 6.18         |
|    cost_values           | 3            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.31         |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -0.000384    |
|    std                   | 0.776        |
|    value_loss            | 0.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.53         |
| reward                   | -0.16611269  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1169         |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0057377056 |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.79         |
|    cost_value_loss       | 6.55         |
|    cost_values           | 3            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.777        |
|    value_loss            | 2.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.44844043  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1204         |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0009644368 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.15         |
|    cost_value_loss       | 1.83         |
|    cost_values           | 2.91         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.13         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00063     |
|    std                   | 0.774        |
|    value_loss            | 2.83         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.758       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.758       |
| reward                   | -0.4133837  |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1238        |
|    total_timesteps       | 475136      |
| train/                   |             |
|    approx_kl             | 0.005457212 |
|    clip_fraction         | 0.0232      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 0.657       |
|    cost_values           | 2.57        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 2310        |
|    policy_gradient_loss  | -0.000925   |
|    std                   | 0.776       |
|    value_loss            | 18.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.03        |
| reward                   | -0.27810723 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1272        |
|    total_timesteps       | 477184      |
| train/                   |             |
|    approx_kl             | 0.008558217 |
|    clip_fraction         | 0.0512      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 2.33        |
|    cost_values           | 2.68        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.18        |
|    n_updates             | 2320        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.779       |
|    value_loss            | 10.1        |
------------------------------------------
--------------------------------------------
| avg_speed                | 4.62          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.62          |
| reward                   | -0.54631263   |
| rollout/                 |               |
|    ep_len_mean           | 923           |
|    ep_rew_mean           | -435          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1306          |
|    total_timesteps       | 479232        |
| train/                   |               |
|    approx_kl             | 0.00011479063 |
|    clip_fraction         | 0.00474       |
|    clip_range            | 0.2           |
|    cost_returns          | 6.67          |
|    cost_value_loss       | 24.1          |
|    cost_values           | 2.97          |
|    entropy               | -2.34         |
|    entropy_loss          | -2.34         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00126       |
|    learning_rate         | 0.0003        |
|    loss                  | 9.03          |
|    n_updates             | 2330          |
|    policy_gradient_loss  | 0.0011        |
|    std                   | 0.78          |
|    value_loss            | 0.943         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.43         |
| reward                   | -0.40378028  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1340         |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0022606452 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.3          |
|    cost_value_loss       | 2.99         |
|    cost_values           | 2.87         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.91         |
|    n_updates             | 2340         |
|    policy_gradient_loss  | 3.77e-05     |
|    std                   | 0.778        |
|    value_loss            | 1.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.74         |
| reward                   | -0.48233202  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1375         |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0036958114 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.17         |
|    cost_value_loss       | 9.77         |
|    cost_values           | 2.99         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00259      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.81         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.000123    |
|    std                   | 0.776        |
|    value_loss            | 0.623        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.29          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.29          |
| reward                   | -0.33498105   |
| rollout/                 |               |
|    ep_len_mean           | 923           |
|    ep_rew_mean           | -438          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1410          |
|    total_timesteps       | 485376        |
| train/                   |               |
|    approx_kl             | 0.00020134886 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 5.36          |
|    cost_value_loss       | 12.8          |
|    cost_values           | 3             |
|    entropy               | -2.34         |
|    entropy_loss          | -2.33         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.0092        |
|    learning_rate         | 0.0003        |
|    loss                  | 3.59          |
|    n_updates             | 2360          |
|    policy_gradient_loss  | 0.000109      |
|    std                   | 0.778         |
|    value_loss            | 1.68          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.46         |
| reward                   | -0.41604507  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1444         |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0025681234 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.69         |
|    cost_value_loss       | 4.08         |
|    cost_values           | 3            |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00731      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.86         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.78         |
|    value_loss            | 0.836        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.45         |
| reward                   | -0.39269543  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1479         |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0048847827 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 0.995        |
|    cost_values           | 2.88         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.815        |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.784        |
|    value_loss            | 0.542        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 1.79          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.79          |
| reward                   | -0.45415246   |
| rollout/                 |               |
|    ep_len_mean           | 923           |
|    ep_rew_mean           | -436          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 44            |
|    time_elapsed          | 1514          |
|    total_timesteps       | 491520        |
| train/                   |               |
|    approx_kl             | 0.00045793047 |
|    clip_fraction         | 0.0285        |
|    clip_range            | 0.2           |
|    cost_returns          | 3.05          |
|    cost_value_loss       | 2.03          |
|    cost_values           | 2.92          |
|    entropy               | -2.34         |
|    entropy_loss          | -2.35         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.54          |
|    n_updates             | 2390          |
|    policy_gradient_loss  | -0.00159      |
|    std                   | 0.78          |
|    value_loss            | 1.06          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.02         |
| reward                   | -0.26774928  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1549         |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0076079275 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 0.893        |
|    cost_values           | 2.82         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.683        |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.776        |
|    value_loss            | 0.333        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.56         |
| reward                   | -0.5868967   |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1584         |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0015094246 |
|    clip_fraction         | 0.00869      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.72         |
|    cost_value_loss       | 6.08         |
|    cost_values           | 2.81         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00493      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.2          |
|    n_updates             | 2410         |
|    policy_gradient_loss  | 0.000933     |
|    std                   | 0.776        |
|    value_loss            | 1.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.34015232 |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1618        |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.007354377 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 4.23        |
|    cost_values           | 3           |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0125      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.14        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | 0.000178    |
|    std                   | 0.777       |
|    value_loss            | 3.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.12         |
| reward                   | -0.38729796  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1653         |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0064892285 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.01         |
|    cost_value_loss       | 1.29         |
|    cost_values           | 2.98         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.52         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.000551    |
|    std                   | 0.777        |
|    value_loss            | 5.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.6370923   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1687         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0005975636 |
|    clip_fraction         | 0.0041       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 2.98         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.53         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | 0.00131      |
|    std                   | 0.778        |
|    value_loss            | 1.68         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 6.71        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 6.71        |
| reward             | -0.36275187 |
| rollout/           |             |
|    ep_len_mean     | 927         |
|    ep_rew_mean     | -434        |
| time/              |             |
|    fps             | 82          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 6.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.66         |
| reward                   | -0.54973656  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0068705594 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.06         |
|    cost_value_loss       | 16.2         |
|    cost_values           | 3            |
|    entropy               | -2.34        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 6.1e-05      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.778        |
|    value_loss            | 4.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5364524   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0035257884 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.35         |
|    cost_value_loss       | 1.62         |
|    cost_values           | 2.99         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00274      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.3          |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 0.777        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.78         |
| reward                   | -0.5267524   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0034748488 |
|    clip_fraction         | 0.00259      |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 14.6         |
|    cost_values           | 3            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0129       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.78         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.000466    |
|    std                   | 0.777        |
|    value_loss            | 3.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.3         |
| reward                   | -0.50003415 |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.005863504 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 6.82        |
|    cost_values           | 3           |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00513     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.03        |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.777       |
|    value_loss            | 0.776       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0137       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0137       |
| reward                   | -0.5684045   |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0011950268 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.55         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 3            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00601      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.69         |
|    n_updates             | 2500         |
|    policy_gradient_loss  | -0.000167    |
|    std                   | 0.776        |
|    value_loss            | 0.878        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.01         |
| reward                   | -0.5476295   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 233          |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0054316306 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.49         |
|    cost_value_loss       | 9.27         |
|    cost_values           | 3            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00553      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.4          |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.777        |
|    value_loss            | 0.827        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.799        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.799        |
| reward                   | -0.356117    |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0061710766 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.26         |
|    cost_value_loss       | 15           |
|    cost_values           | 3            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.776        |
|    value_loss            | 0.485        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.23         |
| reward                   | -0.2631362   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0041898317 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 9.73         |
|    cost_values           | 3            |
|    entropy               | -2.32        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0104       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.773        |
|    value_loss            | 2.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.986       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.986       |
| reward                   | -0.61394376 |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 336         |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.00459343  |
|    clip_fraction         | 0.00659     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.29        |
|    cost_value_loss       | 2.54        |
|    cost_values           | 2.94        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.0013     |
|    std                   | 0.773       |
|    value_loss            | 4.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.47         |
| reward                   | -0.3645695   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0018885698 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.1          |
|    cost_value_loss       | 1.86         |
|    cost_values           | 2.95         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.94         |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.768        |
|    value_loss            | 2.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.57         |
| reward                   | -0.4122895   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0011395365 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.14         |
|    cost_value_loss       | 8.12         |
|    cost_values           | 3            |
|    entropy               | -2.3         |
|    entropy_loss          | -2.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00122      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.000242    |
|    std                   | 0.766        |
|    value_loss            | 1.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.37504515  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0057484508 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.03         |
|    cost_value_loss       | 14           |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00327      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.78         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.766        |
|    value_loss            | 1.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.6          |
| reward                   | -0.5482381   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0036084363 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.12         |
|    cost_value_loss       | 8.86         |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.84         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.768        |
|    value_loss            | 2.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.3          |
| reward                   | -0.42411304  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0031514396 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 6.03         |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00887      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.15         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.768        |
|    value_loss            | 2.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.41         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.41         |
| reward                   | -0.45191976  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0043778946 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.13         |
|    cost_value_loss       | 7.8          |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00477      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.35         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.768        |
|    value_loss            | 0.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.76        |
| reward                   | -0.54826146 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 578         |
|    total_timesteps       | 536576      |
| train/                   |             |
|    approx_kl             | 0.002890464 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.75        |
|    cost_value_loss       | 0.673       |
|    cost_values           | 2.8         |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.12        |
|    n_updates             | 2610        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.769       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.32699275 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 612         |
|    total_timesteps       | 538624      |
| train/                   |             |
|    approx_kl             | 0.002973029 |
|    clip_fraction         | 0.0346      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 16.3        |
|    cost_values           | 2.81        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0146      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.48        |
|    n_updates             | 2620        |
|    policy_gradient_loss  | 0.00192     |
|    std                   | 0.769       |
|    value_loss            | 0.794       |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.21         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.21         |
| reward                   | -0.31370202  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 647          |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0036281606 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.96         |
|    cost_value_loss       | 4.7          |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00126      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.14         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.000575    |
|    std                   | 0.769        |
|    value_loss            | 2.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.19        |
| reward                   | -0.29961896 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 682         |
|    total_timesteps       | 542720      |
| train/                   |             |
|    approx_kl             | 0.006030003 |
|    clip_fraction         | 0.0158      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.36        |
|    cost_value_loss       | 19.2        |
|    cost_values           | 3           |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 2640        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.768       |
|    value_loss            | 2.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42815033  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 716          |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0024552518 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.91         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0089       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.67         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.000662    |
|    std                   | 0.767        |
|    value_loss            | 2.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.9          |
| reward                   | -0.47314754  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 751          |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0031408765 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.1          |
|    cost_value_loss       | 2.71         |
|    cost_values           | 2.98         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.2          |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.000223    |
|    std                   | 0.76         |
|    value_loss            | 1.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.56        |
| reward                   | -0.6084799  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 785         |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.005403228 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 5.33        |
|    cost_values           | 3           |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00229     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.98        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | -0.00176    |
|    std                   | 0.759       |
|    value_loss            | 0.671       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.828        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.828        |
| reward                   | -0.27970758  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 820          |
|    total_timesteps       | 550912       |
| train/                   |              |
|    approx_kl             | 0.0042394954 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 9.1          |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00321      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.53         |
|    n_updates             | 2680         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.76         |
|    value_loss            | 5.65         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6733142  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 854         |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.004649884 |
|    clip_fraction         | 0.0262      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.71        |
|    cost_value_loss       | 0.688       |
|    cost_values           | 2.78        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.22        |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.759       |
|    value_loss            | 1.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.53        |
| reward                   | -0.5227117  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 889         |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.001079432 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 19.2        |
|    cost_values           | 2.76        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.000614   |
|    std                   | 0.759       |
|    value_loss            | 4.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.43969324 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 924         |
|    total_timesteps       | 557056      |
| train/                   |             |
|    approx_kl             | 0.003985816 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.55        |
|    cost_value_loss       | 5.22        |
|    cost_values           | 2.99        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00153     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.17        |
|    n_updates             | 2710        |
|    policy_gradient_loss  | -0.000472   |
|    std                   | 0.759       |
|    value_loss            | 1.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.36282986  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0013399527 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00437      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.21         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.000158    |
|    std                   | 0.76         |
|    value_loss            | 4.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.294        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.294        |
| reward                   | -0.47217283  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 992          |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0027762738 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.18         |
|    cost_value_loss       | 6.48         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00188      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.77         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.000893    |
|    std                   | 0.76         |
|    value_loss            | 3.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.6014792   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0038114411 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.8          |
|    cost_value_loss       | 4.46         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.7          |
|    n_updates             | 2740         |
|    policy_gradient_loss  | -0.00076     |
|    std                   | 0.76         |
|    value_loss            | 1.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.86         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.86         |
| reward                   | -0.591168    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1061         |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0043033026 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.92         |
|    cost_value_loss       | 21.7         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00909      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.76         |
|    value_loss            | 16.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.37639964  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1095         |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0036746257 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 7.74         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.76         |
|    value_loss            | 2.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.53         |
| reward                   | -0.50737774  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1130         |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0040912535 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.13         |
|    cost_value_loss       | 29.5         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.87         |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.000644    |
|    std                   | 0.76         |
|    value_loss            | 3.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.17         |
| reward                   | -0.33846936  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0053252126 |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.18         |
|    cost_value_loss       | 21           |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0164       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.91         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.761        |
|    value_loss            | 1.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.29         |
| reward                   | -0.5876591   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1198         |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0031062916 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 2.42         |
|    cost_values           | 2.99         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.9          |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.000399    |
|    std                   | 0.759        |
|    value_loss            | 1.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.24023835  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1233         |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0047798823 |
|    clip_fraction         | 0.0614       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 0.953        |
|    cost_values           | 2.86         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.951        |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.758        |
|    value_loss            | 1.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.69498944  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1268         |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0030476954 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.7          |
|    cost_value_loss       | 20.4         |
|    cost_values           | 2.93         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.757        |
|    value_loss            | 4.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.27         |
| reward                   | -0.5164298   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1303         |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0028610225 |
|    clip_fraction         | 0.00337      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 3            |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000885     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.000752    |
|    std                   | 0.757        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.83         |
| reward                   | -0.51571715  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0017699233 |
|    clip_fraction         | 0.00527      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 0.322        |
|    cost_values           | 2.81         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.282        |
|    n_updates             | 2830         |
|    policy_gradient_loss  | -0.000635    |
|    std                   | 0.758        |
|    value_loss            | 0.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.07         |
| reward                   | -0.41749313  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1371         |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0016433357 |
|    clip_fraction         | 0.0022       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.39         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 2.59         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 2840         |
|    policy_gradient_loss  | 0.000364     |
|    std                   | 0.76         |
|    value_loss            | 0.611        |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.59        |
| reward                   | -0.42224193 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1405        |
|    total_timesteps       | 585728      |
| train/                   |             |
|    approx_kl             | 0.002399874 |
|    clip_fraction         | 0.000635    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 0.358       |
|    cost_values           | 2.71        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.868       |
|    n_updates             | 2850        |
|    policy_gradient_loss  | -0.000689   |
|    std                   | 0.76        |
|    value_loss            | 2.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.11         |
| reward                   | -0.2361154   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1440         |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0025184862 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.91         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 2.6          |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.72         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.000635    |
|    std                   | 0.759        |
|    value_loss            | 0.667        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.5316388  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1474        |
|    total_timesteps       | 589824      |
| train/                   |             |
|    approx_kl             | 0.003947192 |
|    clip_fraction         | 0.0176      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.34        |
|    cost_value_loss       | 0.225       |
|    cost_values           | 2.65        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.882       |
|    n_updates             | 2870        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.761       |
|    value_loss            | 2.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.3         |
| reward                   | -0.603683   |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1509        |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.005861319 |
|    clip_fraction         | 0.0868      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.94        |
|    cost_value_loss       | 30          |
|    cost_values           | 2.41        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.5        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | 0.0027      |
|    std                   | 0.762       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.28520113  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1543         |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0012182081 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.5          |
|    cost_value_loss       | 19.4         |
|    cost_values           | 2.79         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00434      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.8          |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.000579    |
|    std                   | 0.762        |
|    value_loss            | 0.909        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31255585  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1578         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0032987203 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.3          |
|    cost_value_loss       | 2.19         |
|    cost_values           | 2.98         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.81         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.761        |
|    value_loss            | 1.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.5836701   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1613         |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0004250253 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.77         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00305      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | 9.31e-05     |
|    std                   | 0.76         |
|    value_loss            | 5.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -0.5013267   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1647         |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0066329166 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.19         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 2.99         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00862      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.74         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 0.76         |
|    value_loss            | 1.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.75         |
| reward                   | -0.47541985  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1682         |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0004061833 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.22         |
|    cost_value_loss       | 18.3         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00646      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.79         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -1.82e-05    |
|    std                   | 0.76         |
|    value_loss            | 3.81         |
-------------------------------------------
-----------------------------------
| avg_speed          | 2.69       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.69       |
| reward             | -0.2847008 |
| rollout/           |            |
|    ep_len_mean     | 989        |
|    ep_rew_mean     | -465       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 604160     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.314       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.314       |
| reward                   | -0.47352356 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.004822719 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 1.35        |
|    cost_values           | 2.98        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.89        |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.000941   |
|    std                   | 0.758       |
|    value_loss            | 2.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.15         |
| reward                   | -0.28471196  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 608256       |
| train/                   |              |
|    approx_kl             | 0.0010933136 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.64         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 3            |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00693      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 2960         |
|    policy_gradient_loss  | 0.000813     |
|    std                   | 0.757        |
|    value_loss            | 5.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.07         |
| reward                   | -0.6592669   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0028317817 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.54         |
|    cost_value_loss       | 2.84         |
|    cost_values           | 3            |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000983     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.56         |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.000932    |
|    std                   | 0.757        |
|    value_loss            | 1.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.514        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.514        |
| reward                   | -0.45209265  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0019312726 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.81         |
|    cost_value_loss       | 8.89         |
|    cost_values           | 3            |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.93         |
|    n_updates             | 2980         |
|    policy_gradient_loss  | 0.00113      |
|    std                   | 0.756        |
|    value_loss            | 1.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.54         |
| reward                   | -0.4082674   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0038693303 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.59         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 3            |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00738      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.76         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.756        |
|    value_loss            | 2.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -0.46923286  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0018394632 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.12         |
|    cost_value_loss       | 1.39         |
|    cost_values           | 2.97         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.15         |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.000764    |
|    std                   | 0.758        |
|    value_loss            | 1.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.88         |
| reward                   | -0.3928529   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0019565898 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.55         |
|    cost_value_loss       | 2.91         |
|    cost_values           | 3            |
|    entropy               | -2.28        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00948      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.82         |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.000471    |
|    std                   | 0.759        |
|    value_loss            | 1.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.15        |
| reward                   | -0.5839807  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 301         |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.002610013 |
|    clip_fraction         | 0.00688     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 0.179       |
|    cost_values           | 2.73        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.29       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.45        |
|    n_updates             | 3020        |
|    policy_gradient_loss  | -0.000364   |
|    std                   | 0.766       |
|    value_loss            | 0.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.88        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.88        |
| reward                   | -0.4982005  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -458        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 622592      |
| train/                   |             |
|    approx_kl             | 0.002696947 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 3.67        |
|    cost_values           | 2.58        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.88        |
|    n_updates             | 3030        |
|    policy_gradient_loss  | -0.000603   |
|    std                   | 0.768       |
|    value_loss            | 2.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5            |
| reward                   | -0.348521    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0037048876 |
|    clip_fraction         | 0.00308      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 5.03         |
|    cost_values           | 2.94         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00235      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.57         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -1.81e-05    |
|    std                   | 0.767        |
|    value_loss            | 4.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.42632684  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0060957447 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.61         |
|    cost_value_loss       | 28.3         |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.3         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.7         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.000847    |
|    std                   | 0.766        |
|    value_loss            | 1.03         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.95          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.95          |
| reward                   | -0.40714577   |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -455          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 13            |
|    time_elapsed          | 438           |
|    total_timesteps       | 628736        |
| train/                   |               |
|    approx_kl             | 0.00039113534 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.49          |
|    cost_value_loss       | 11.5          |
|    cost_values           | 3             |
|    entropy               | -2.3          |
|    entropy_loss          | -2.3          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.000781      |
|    learning_rate         | 0.0003        |
|    loss                  | 4.78          |
|    n_updates             | 3060          |
|    policy_gradient_loss  | 9.82e-05      |
|    std                   | 0.766         |
|    value_loss            | 1.75          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.3866649   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 472          |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0009674557 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.55         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 2.99         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00559      |
|    learning_rate         | 0.0003       |
|    loss                  | 4            |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.000397    |
|    std                   | 0.765        |
|    value_loss            | 1.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.35         |
| reward                   | -0.4469328   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0037635425 |
|    clip_fraction         | 0.00327      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.44         |
|    cost_value_loss       | 9.8          |
|    cost_values           | 2.99         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00305      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.05         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.000972    |
|    std                   | 0.766        |
|    value_loss            | 1.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.19        |
| reward                   | -0.42702964 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 541         |
|    total_timesteps       | 634880      |
| train/                   |             |
|    approx_kl             | 0.004451149 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.57        |
|    cost_value_loss       | 5.29        |
|    cost_values           | 3           |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.41        |
|    n_updates             | 3090        |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.767       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.71        |
| reward                   | -0.43762586 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 576         |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.008264142 |
|    clip_fraction         | 0.0414      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.57        |
|    cost_value_loss       | 3.58        |
|    cost_values           | 2.97        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 2.38e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.767       |
|    value_loss            | 9.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.14        |
| reward                   | -0.4398462  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 610         |
|    total_timesteps       | 638976      |
| train/                   |             |
|    approx_kl             | 0.004445589 |
|    clip_fraction         | 0.00493     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.91        |
|    cost_values           | 2.99        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 3110        |
|    policy_gradient_loss  | -0.000238   |
|    std                   | 0.766       |
|    value_loss            | 0.639       |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.79         |
| reward                   | -0.19473347  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 644          |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0066381777 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.93         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 2.99         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00638      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.76         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.766        |
|    value_loss            | 0.613        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.52         |
| reward                   | -0.5004902   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 678          |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0058259945 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 9.37         |
|    cost_values           | 3            |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00406      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.000274    |
|    std                   | 0.765        |
|    value_loss            | 4.05         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.8           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.8           |
| reward                   | -0.1721       |
| rollout/                 |               |
|    ep_len_mean           | 987           |
|    ep_rew_mean           | -449          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 21            |
|    time_elapsed          | 713           |
|    total_timesteps       | 645120        |
| train/                   |               |
|    approx_kl             | 0.00097009935 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.45          |
|    cost_value_loss       | 11.7          |
|    cost_values           | 3             |
|    entropy               | -2.3          |
|    entropy_loss          | -2.3          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.15          |
|    n_updates             | 3140          |
|    policy_gradient_loss  | -2.88e-05     |
|    std                   | 0.765         |
|    value_loss            | 2.1           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.24851392  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 747          |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0005156291 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 6.36         |
|    cost_value_loss       | 22.1         |
|    cost_values           | 3            |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 3150         |
|    policy_gradient_loss  | 0.00054      |
|    std                   | 0.765        |
|    value_loss            | 3.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.34705585  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 781          |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0067808973 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.48         |
|    cost_value_loss       | 6.59         |
|    cost_values           | 3            |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00271      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.17         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.765        |
|    value_loss            | 22.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.84        |
| reward                   | -0.58440703 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 815         |
|    total_timesteps       | 651264      |
| train/                   |             |
|    approx_kl             | 0.002961996 |
|    clip_fraction         | 0.00244     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.62        |
|    cost_value_loss       | 18.8        |
|    cost_values           | 3           |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 3170        |
|    policy_gradient_loss  | -0.000195   |
|    std                   | 0.765       |
|    value_loss            | 6.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.85         |
| reward                   | -0.5147868   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 849          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0063166143 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.86         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 2.99         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.5         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.000573    |
|    std                   | 0.765        |
|    value_loss            | 24.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.15         |
| reward                   | -0.33529767  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 884          |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0023654988 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.51         |
|    cost_value_loss       | 8.48         |
|    cost_values           | 3            |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.83         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.000518    |
|    std                   | 0.765        |
|    value_loss            | 2.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.58         |
| reward                   | -0.27167338  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 919          |
|    total_timesteps       | 657408       |
| train/                   |              |
|    approx_kl             | 0.0072676674 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.67         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 3            |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00163      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.91         |
|    n_updates             | 3200         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.766        |
|    value_loss            | 3.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.27896273  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 953          |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0026178951 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.33         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 3            |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00427      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.26         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.000786    |
|    std                   | 0.766        |
|    value_loss            | 12.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.33          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.33          |
| reward                   | -0.25721475   |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -441          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 29            |
|    time_elapsed          | 988           |
|    total_timesteps       | 661504        |
| train/                   |               |
|    approx_kl             | 0.00074621395 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 5.26          |
|    cost_value_loss       | 11.2          |
|    cost_values           | 2.99          |
|    entropy               | -2.3          |
|    entropy_loss          | -2.3          |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0.0144        |
|    learning_rate         | 0.0003        |
|    loss                  | 3.71          |
|    n_updates             | 3220          |
|    policy_gradient_loss  | -3.26e-05     |
|    std                   | 0.766         |
|    value_loss            | 6.55          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.182        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.182        |
| reward                   | -0.25287226  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1023         |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0067681726 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.61         |
|    cost_value_loss       | 15           |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00515      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.65         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.766        |
|    value_loss            | 4.1          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.31800807 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.006079383 |
|    clip_fraction         | 0.0266      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 1.06        |
|    cost_values           | 2.9         |
|    entropy               | -2.29       |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.21        |
|    n_updates             | 3240        |
|    policy_gradient_loss  | -0.000718   |
|    std                   | 0.76        |
|    value_loss            | 5.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.13         |
| reward                   | -0.53754044  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1092         |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0019064241 |
|    clip_fraction         | 0.0651       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.79         |
|    cost_value_loss       | 4.92         |
|    cost_values           | 2.86         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.17         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.000185    |
|    std                   | 0.758        |
|    value_loss            | 3.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.38         |
| reward                   | -0.45325232  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1127         |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0010562956 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.12         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 2.98         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00367      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.71         |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.000203    |
|    std                   | 0.758        |
|    value_loss            | 13.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.21         |
| reward                   | -0.6263472   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1161         |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0047683395 |
|    clip_fraction         | 0.00874      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.32         |
|    cost_value_loss       | 20.4         |
|    cost_values           | 3            |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.758        |
|    value_loss            | 4.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.02         |
| reward                   | -0.22342613  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1196         |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0022360035 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.47         |
|    cost_value_loss       | 8.54         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00494      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.57         |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00034     |
|    std                   | 0.759        |
|    value_loss            | 1.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.23         |
| reward                   | -0.30649674  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1230         |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0038214908 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 6.89         |
|    cost_values           | 3            |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00376      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.43         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.000534    |
|    std                   | 0.759        |
|    value_loss            | 1.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.88         |
| reward                   | -0.6138867   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1265         |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0025447914 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 0.912        |
|    cost_values           | 2.82         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.18         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | 0.001        |
|    std                   | 0.757        |
|    value_loss            | 5.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5638041   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1300         |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0013576329 |
|    clip_fraction         | 0.0566       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 1.11         |
|    cost_values           | 2.66         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.6          |
|    n_updates             | 3310         |
|    policy_gradient_loss  | 0.00123      |
|    std                   | 0.757        |
|    value_loss            | 3.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.21         |
| reward                   | -0.50128967  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1335         |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0041490323 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 2.81         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0165       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.757        |
|    value_loss            | 0.673        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 6.91          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.91          |
| reward                   | -0.3758327    |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -433          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 40            |
|    time_elapsed          | 1370          |
|    total_timesteps       | 684032        |
| train/                   |               |
|    approx_kl             | 0.00041469056 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.21          |
|    cost_value_loss       | 4.64          |
|    cost_values           | 3             |
|    entropy               | -2.28         |
|    entropy_loss          | -2.28         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00629       |
|    learning_rate         | 0.0003        |
|    loss                  | 2.85          |
|    n_updates             | 3330          |
|    policy_gradient_loss  | -6.16e-05     |
|    std                   | 0.757         |
|    value_loss            | 0.365         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.342        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.342        |
| reward                   | -0.5026145   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1405         |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0023792034 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 0.277        |
|    cost_values           | 2.84         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.375        |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.000252    |
|    std                   | 0.755        |
|    value_loss            | 0.924        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.558        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.558        |
| reward                   | -0.37653765  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1440         |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0039213765 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.45         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 2.71         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.81         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.000363    |
|    std                   | 0.753        |
|    value_loss            | 1.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.35        |
| reward                   | -0.18694413 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1475        |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.005155576 |
|    clip_fraction         | 0.00718     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.98        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.43        |
|    n_updates             | 3360        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.753       |
|    value_loss            | 3.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.44         |
| reward                   | -0.4410715   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1509         |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0037316233 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.85         |
|    cost_value_loss       | 22           |
|    cost_values           | 3            |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0145       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.29         |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.000837    |
|    std                   | 0.752        |
|    value_loss            | 3.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.26        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.26        |
| reward                   | -0.48303705 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1544        |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.005840973 |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 18.7        |
|    cost_values           | 3           |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.14        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00216    |
|    std                   | 0.752       |
|    value_loss            | 1.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.46053198  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1580         |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0005891469 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 6.58         |
|    cost_value_loss       | 39.4         |
|    cost_values           | 3            |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00306      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.99         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | 4.74e-05     |
|    std                   | 0.752        |
|    value_loss            | 2.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.38         |
| reward                   | -0.45449442  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1615         |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0044496306 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.31         |
|    cost_value_loss       | 2.3          |
|    cost_values           | 2.99         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0034       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.76         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.751        |
|    value_loss            | 2.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.6          |
| reward                   | -0.24283755  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1650         |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0039956197 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.31         |
|    cost_value_loss       | 16.8         |
|    cost_values           | 3            |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00689      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.751        |
|    value_loss            | 3.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.91         |
| reward                   | -0.23810647  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1685         |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0003858067 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.44         |
|    cost_value_loss       | 8.51         |
|    cost_values           | 3            |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0052       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.7          |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -3.87e-05    |
|    std                   | 0.751        |
|    value_loss            | 2.34         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 0.679       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.679       |
| reward             | -0.43268618 |
| rollout/           |             |
|    ep_len_mean     | 970         |
|    ep_rew_mean     | -433        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 704512      |
------------------------------------
-------------------------------------------
| avg_speed                | 2.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.07         |
| reward                   | -0.50412774  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0025600311 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 4.71         |
|    cost_values           | 3            |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.29         |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.000558    |
|    std                   | 0.749        |
|    value_loss            | 2.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.835       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.835       |
| reward                   | -0.45136967 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 708608      |
| train/                   |             |
|    approx_kl             | 0.001339833 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 6.39        |
|    cost_value_loss       | 29.7        |
|    cost_values           | 3           |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0117      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 3450        |
|    policy_gradient_loss  | -0.000614   |
|    std                   | 0.749       |
|    value_loss            | 2.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.86         |
| reward                   | -0.4159793   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0032275652 |
|    clip_fraction         | 0.0422       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.5          |
|    cost_value_loss       | 3.04         |
|    cost_values           | 3            |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00194      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.3          |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 0.75         |
|    value_loss            | 0.429        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -0.5864261   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0044002105 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.94         |
|    cost_value_loss       | 3.57         |
|    cost_values           | 3            |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00293      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.1          |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.749        |
|    value_loss            | 3.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.244        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.244        |
| reward                   | -0.27713642  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 714752       |
| train/                   |              |
|    approx_kl             | 0.0022222498 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.77         |
|    cost_value_loss       | 5.09         |
|    cost_values           | 3            |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 3480         |
|    policy_gradient_loss  | -0.000392    |
|    std                   | 0.747        |
|    value_loss            | 6            |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.4859142  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 231         |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.004127344 |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.2         |
|    cost_value_loss       | 7.87        |
|    cost_values           | 3           |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00522     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.63        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.000755   |
|    std                   | 0.745       |
|    value_loss            | 2.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.15         |
| reward                   | -0.365823    |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 718848       |
| train/                   |              |
|    approx_kl             | 0.0020433678 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.57         |
|    cost_value_loss       | 3.93         |
|    cost_values           | 3            |
|    entropy               | -2.24        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00203      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.73         |
|    n_updates             | 3500         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.743        |
|    value_loss            | 1.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.54         |
| reward                   | -0.5836742   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 299          |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0039701615 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.16         |
|    cost_value_loss       | 2.95         |
|    cost_values           | 3            |
|    entropy               | -2.23        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00156      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.43         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.739        |
|    value_loss            | 0.796        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.54025406 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 333         |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.004256499 |
|    clip_fraction         | 0.0233      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 7.54        |
|    cost_values           | 3           |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00416     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 3520        |
|    policy_gradient_loss  | -0.00106    |
|    std                   | 0.738       |
|    value_loss            | 2.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4774207   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 367          |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0053393524 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 3.57         |
|    cost_values           | 3            |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.35         |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.74         |
|    value_loss            | 1.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.46853992  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 402          |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0027225981 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.32         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 2.99         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.45         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.000246    |
|    std                   | 0.74         |
|    value_loss            | 1.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0348       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0348       |
| reward                   | -0.31820083  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 435          |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0039876597 |
|    clip_fraction         | 0.00273      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.29         |
|    cost_value_loss       | 6.26         |
|    cost_values           | 3            |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00298      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.57         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.00039     |
|    std                   | 0.739        |
|    value_loss            | 3.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.724       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.724       |
| reward                   | -0.4167985  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 470         |
|    total_timesteps       | 731136      |
| train/                   |             |
|    approx_kl             | 0.005638947 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 0.263       |
|    cost_values           | 2.73        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.28        |
|    n_updates             | 3560        |
|    policy_gradient_loss  | -0.000637   |
|    std                   | 0.732       |
|    value_loss            | 2.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.82         |
| reward                   | -0.5870661   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 505          |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0038705308 |
|    clip_fraction         | 0.0482       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.58         |
|    cost_value_loss       | 19.8         |
|    cost_values           | 2.56         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.98         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | 0.000754     |
|    std                   | 0.73         |
|    value_loss            | 2.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.16        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.16        |
| reward                   | -0.41480708 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 539         |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.003775319 |
|    clip_fraction         | 0.00264     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 2.9         |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000303    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.23        |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.729       |
|    value_loss            | 1.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.88        |
| reward                   | -0.3847645  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 574         |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.004128094 |
|    clip_fraction         | 0.0372      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 0.368       |
|    cost_values           | 2.86        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.73        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.726       |
|    value_loss            | 3.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.562       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.562       |
| reward                   | -0.5184672  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 608         |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.002725083 |
|    clip_fraction         | 0.000879    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.33        |
|    cost_value_loss       | 0.209       |
|    cost_values           | 2.54        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.474       |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.000503   |
|    std                   | 0.724       |
|    value_loss            | 1.62        |
------------------------------------------
--------------------------------------------
| avg_speed                | 2.13          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.13          |
| reward                   | -0.44050014   |
| rollout/                 |               |
|    ep_len_mean           | 973           |
|    ep_rew_mean           | -443          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 19            |
|    time_elapsed          | 643           |
|    total_timesteps       | 741376        |
| train/                   |               |
|    approx_kl             | 0.00043936714 |
|    clip_fraction         | 0.019         |
|    clip_range            | 0.2           |
|    cost_returns          | 2.09          |
|    cost_value_loss       | 0.208         |
|    cost_values           | 2.13          |
|    entropy               | -2.17         |
|    entropy_loss          | -2.18         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.87          |
|    n_updates             | 3610          |
|    policy_gradient_loss  | -0.000576     |
|    std                   | 0.716         |
|    value_loss            | 3.66          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.726        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.726        |
| reward                   | -0.30682367  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 677          |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0067243115 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 0.14         |
|    cost_values           | 1.82         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.503        |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.705        |
|    value_loss            | 0.943        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.93        |
| reward                   | -0.50805783 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 712         |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.004535177 |
|    clip_fraction         | 0.0348      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 5.85        |
|    cost_values           | 1.86        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3           |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 0.702       |
|    value_loss            | 1.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.27         |
| reward                   | -0.35227343  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 746          |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0049766926 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 2.83         |
|    cost_values           | 2.18         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.25         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.702        |
|    value_loss            | 3.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.5          |
| reward                   | -0.38583264  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 780          |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0019862754 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 2.46         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.19         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.000127    |
|    std                   | 0.702        |
|    value_loss            | 0.441        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.342        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.342        |
| reward                   | -0.50226176  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 814          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0009212365 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 0.332        |
|    cost_values           | 2.6          |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.394        |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.000167    |
|    std                   | 0.701        |
|    value_loss            | 1.05         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 3.76       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.76       |
| reward                   | -0.5921908 |
| rollout/                 |            |
|    ep_len_mean           | 989        |
|    ep_rew_mean           | -449       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 25         |
|    time_elapsed          | 848        |
|    total_timesteps       | 753664     |
| train/                   |            |
|    approx_kl             | 0.0038517  |
|    clip_fraction         | 0.0144     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.84       |
|    cost_value_loss       | 1.86       |
|    cost_values           | 2.47       |
|    entropy               | -2.13      |
|    entropy_loss          | -2.13      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.894      |
|    n_updates             | 3670       |
|    policy_gradient_loss  | -0.00112   |
|    std                   | 0.702      |
|    value_loss            | 0.384      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.53         |
| reward                   | -0.33420792  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 883          |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0052379193 |
|    clip_fraction         | 0.00776      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 0.685        |
|    cost_values           | 2.65         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.602        |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.000795    |
|    std                   | 0.701        |
|    value_loss            | 1.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.45938328  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 917          |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0029500918 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.29         |
|    cost_value_loss       | 3.47         |
|    cost_values           | 2.66         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.95         |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.699        |
|    value_loss            | 2.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -0.38516983  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 952          |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0026548645 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.29         |
|    cost_value_loss       | 2.53         |
|    cost_values           | 2.94         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.76         |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.698        |
|    value_loss            | 1.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.34361598 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 986         |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.004763197 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.69        |
|    cost_value_loss       | 5.7         |
|    cost_values           | 3           |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00554     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.29        |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.698       |
|    value_loss            | 3.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52929765  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0035546625 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.68         |
|    cost_value_loss       | 7.91         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00572      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.698        |
|    value_loss            | 2.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.43056253  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1054         |
|    total_timesteps       | 765952       |
| train/                   |              |
|    approx_kl             | 0.0020165474 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 1.69         |
|    cost_values           | 2.94         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.96         |
|    n_updates             | 3730         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.702        |
|    value_loss            | 4.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4163825   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1088         |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0020610848 |
|    clip_fraction         | 0.00269      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 0.389        |
|    cost_values           | 2.81         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.07         |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.000108    |
|    std                   | 0.703        |
|    value_loss            | 2.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.87         |
| reward                   | -0.40031976  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1122         |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0052699046 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.36         |
|    cost_value_loss       | 0.408        |
|    cost_values           | 2.46         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.381        |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 0.702        |
|    value_loss            | 1.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.5709964   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1156         |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0043032137 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 0.15         |
|    cost_values           | 2.04         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.54         |
|    n_updates             | 3760         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.701        |
|    value_loss            | 4.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00273      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00273      |
| reward                   | -0.42490622  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1190         |
|    total_timesteps       | 774144       |
| train/                   |              |
|    approx_kl             | 0.0044200807 |
|    clip_fraction         | 0.00781      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 7.3          |
|    cost_values           | 1.96         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 3770         |
|    policy_gradient_loss  | -0.000835    |
|    std                   | 0.701        |
|    value_loss            | 3.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.18         |
| reward                   | -0.48662052  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1224         |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0038755774 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 0.293        |
|    cost_values           | 2.06         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.49         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.000694    |
|    std                   | 0.7          |
|    value_loss            | 3.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.882       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.882       |
| reward                   | -0.6245179  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1258        |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.002110152 |
|    clip_fraction         | 0.000391    |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 16.4        |
|    cost_values           | 1.97        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.42        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.699       |
|    value_loss            | 1.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.69         |
| reward                   | -0.3807697   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1292         |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0017486498 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.82         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 2.38         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.57         |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.000856    |
|    std                   | 0.699        |
|    value_loss            | 1.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.97         |
| reward                   | -0.44037712  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1326         |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0030855925 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 6.9          |
|    cost_values           | 2.75         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.26         |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.699        |
|    value_loss            | 5.41         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 3.96          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 3.96          |
| reward                   | -0.51524776   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -447          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 40            |
|    time_elapsed          | 1361          |
|    total_timesteps       | 784384        |
| train/                   |               |
|    approx_kl             | 0.00015474946 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.89          |
|    cost_value_loss       | 2.28          |
|    cost_values           | 2.94          |
|    entropy               | -2.12         |
|    entropy_loss          | -2.12         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.000809      |
|    learning_rate         | 0.0003        |
|    loss                  | 2.34          |
|    n_updates             | 3820          |
|    policy_gradient_loss  | -3.67e-05     |
|    std                   | 0.699         |
|    value_loss            | 3.1           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 6.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.25         |
| reward                   | -0.42546293  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1395         |
|    total_timesteps       | 786432       |
| train/                   |              |
|    approx_kl             | 0.0035548978 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.89         |
|    cost_value_loss       | 4.79         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00885      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.92         |
|    n_updates             | 3830         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.699        |
|    value_loss            | 0.443        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 6.42          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.42          |
| reward                   | -0.23386945   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -451          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 42            |
|    time_elapsed          | 1429          |
|    total_timesteps       | 788480        |
| train/                   |               |
|    approx_kl             | 7.7579316e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 6.38          |
|    cost_value_loss       | 20.3          |
|    cost_values           | 3             |
|    entropy               | -2.12         |
|    entropy_loss          | -2.12         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.0118        |
|    learning_rate         | 0.0003        |
|    loss                  | 4.01          |
|    n_updates             | 3840          |
|    policy_gradient_loss  | 1.2e-06       |
|    std                   | 0.699         |
|    value_loss            | 1.18          |
--------------------------------------------
------------------------------------------
| avg_speed                | 5.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.84        |
| reward                   | -0.6105239  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 43          |
|    time_elapsed          | 1463        |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.003351069 |
|    clip_fraction         | 0.00229     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.9         |
|    cost_value_loss       | 5.37        |
|    cost_values           | 3           |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.82        |
|    n_updates             | 3850        |
|    policy_gradient_loss  | -0.000486   |
|    std                   | 0.699       |
|    value_loss            | 2.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.29152617 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 44          |
|    time_elapsed          | 1498        |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.005168335 |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.58        |
|    cost_value_loss       | 4           |
|    cost_values           | 3           |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.44        |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.7         |
|    value_loss            | 3.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.520346   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 45          |
|    time_elapsed          | 1532        |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.005038422 |
|    clip_fraction         | 0.0118      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 3           |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.23        |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.701       |
|    value_loss            | 5.71        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.97          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.97          |
| reward                   | -0.5051001    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -454          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 46            |
|    time_elapsed          | 1566          |
|    total_timesteps       | 796672        |
| train/                   |               |
|    approx_kl             | 0.00052011147 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.9           |
|    cost_value_loss       | 17            |
|    cost_values           | 3             |
|    entropy               | -2.13         |
|    entropy_loss          | -2.13         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00348       |
|    learning_rate         | 0.0003        |
|    loss                  | 4.93          |
|    n_updates             | 3880          |
|    policy_gradient_loss  | -2.53e-05     |
|    std                   | 0.701         |
|    value_loss            | 1.74          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2729085   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1600         |
|    total_timesteps       | 798720       |
| train/                   |              |
|    approx_kl             | 0.0018956559 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.49         |
|    cost_value_loss       | 9.46         |
|    cost_values           | 3            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00742      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.44         |
|    n_updates             | 3890         |
|    policy_gradient_loss  | 1.2e-05      |
|    std                   | 0.701        |
|    value_loss            | 1.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.6          |
| reward                   | -0.55882245  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1634         |
|    total_timesteps       | 800768       |
| train/                   |              |
|    approx_kl             | 0.0018144217 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.18         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 3            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00703      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 3900         |
|    policy_gradient_loss  | -0.00036     |
|    std                   | 0.701        |
|    value_loss            | 1.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.6097703  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 49          |
|    time_elapsed          | 1668        |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.004417544 |
|    clip_fraction         | 0.0126      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.68        |
|    cost_value_loss       | 0.449       |
|    cost_values           | 2.85        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.83        |
|    n_updates             | 3910        |
|    policy_gradient_loss  | -0.000876   |
|    std                   | 0.702       |
|    value_loss            | 3.6         |
------------------------------------------
------------------------------------
| avg_speed          | 7.99        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.99        |
| reward             | -0.44869807 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -458        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 804864      |
------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.23363486  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0021425188 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.46         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 2.9          |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.41         |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.000645    |
|    std                   | 0.702        |
|    value_loss            | 2.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.63698286  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0051345974 |
|    clip_fraction         | 0.00713      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.39         |
|    cost_value_loss       | 8.24         |
|    cost_values           | 3            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00277      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.83         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.702        |
|    value_loss            | 2.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.2679631   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 811008       |
| train/                   |              |
|    approx_kl             | 0.0006342176 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.44         |
|    cost_value_loss       | 18.2         |
|    cost_values           | 3            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0081       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.56         |
|    n_updates             | 3950         |
|    policy_gradient_loss  | -0.000187    |
|    std                   | 0.702        |
|    value_loss            | 3.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49866298  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 813056       |
| train/                   |              |
|    approx_kl             | 0.0044009704 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 8.67         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.53         |
|    n_updates             | 3960         |
|    policy_gradient_loss  | -0.000955    |
|    std                   | 0.7          |
|    value_loss            | 6.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4889325   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0003583662 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 6.54         |
|    cost_value_loss       | 19.6         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 3970         |
|    policy_gradient_loss  | -5.18e-05    |
|    std                   | 0.7          |
|    value_loss            | 2.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3269123   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0029325914 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.2          |
|    cost_value_loss       | 4.18         |
|    cost_values           | 3            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.73         |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.000216    |
|    std                   | 0.703        |
|    value_loss            | 0.797        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.54         |
| reward                   | -0.55974865  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 264          |
|    total_timesteps       | 819200       |
| train/                   |              |
|    approx_kl             | 0.0005208036 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 3.43         |
|    cost_values           | 2.97         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.01         |
|    n_updates             | 3990         |
|    policy_gradient_loss  | 0.00084      |
|    std                   | 0.704        |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.6075651   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 298          |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0065028057 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 4.62         |
|    cost_values           | 2.99         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.703        |
|    value_loss            | 4.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3251519   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 332          |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0009343016 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.99         |
|    cost_value_loss       | 23.4         |
|    cost_values           | 3            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00169      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.93         |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.000147    |
|    std                   | 0.702        |
|    value_loss            | 2.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5509353  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 367         |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.005066121 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 7.03        |
|    cost_value_loss       | 29.9        |
|    cost_values           | 2.99        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00635     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.18        |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.702       |
|    value_loss            | 4.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4187172  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 12          |
|    time_elapsed          | 401         |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.003831726 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.17        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 3           |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00528     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.702       |
|    value_loss            | 0.926       |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5773895 |
| rollout/                 |            |
|    ep_len_mean           | 988        |
|    ep_rew_mean           | -445       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 13         |
|    time_elapsed          | 436        |
|    total_timesteps       | 829440     |
| train/                   |            |
|    approx_kl             | 0.00624003 |
|    clip_fraction         | 0.0177     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.18       |
|    cost_value_loss       | 1.83       |
|    cost_values           | 2.96       |
|    entropy               | -2.13      |
|    entropy_loss          | -2.13      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.15       |
|    n_updates             | 4040       |
|    policy_gradient_loss  | -0.00118   |
|    std                   | 0.703      |
|    value_loss            | 10.7       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.45866278  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 470          |
|    total_timesteps       | 831488       |
| train/                   |              |
|    approx_kl             | 0.0029402184 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 5.8          |
|    cost_values           | 2.97         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.47         |
|    n_updates             | 4050         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.702        |
|    value_loss            | 1.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.64        |
| reward                   | -0.41113555 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 504         |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.005025926 |
|    clip_fraction         | 0.0186      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.66        |
|    cost_value_loss       | 3.69        |
|    cost_values           | 3           |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00277     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.12        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.702       |
|    value_loss            | 2.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5326341  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 538         |
|    total_timesteps       | 835584      |
| train/                   |             |
|    approx_kl             | 0.005558325 |
|    clip_fraction         | 0.0151      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 0.944       |
|    cost_values           | 2.89        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.06        |
|    n_updates             | 4070        |
|    policy_gradient_loss  | -0.00163    |
|    std                   | 0.703       |
|    value_loss            | 2.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.40890133 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 572         |
|    total_timesteps       | 837632      |
| train/                   |             |
|    approx_kl             | 0.005103495 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 3.28        |
|    cost_values           | 2.84        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0126      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.89        |
|    n_updates             | 4080        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.702       |
|    value_loss            | 1.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.35427424  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 606          |
|    total_timesteps       | 839680       |
| train/                   |              |
|    approx_kl             | 0.0037649428 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.03         |
|    cost_value_loss       | 30.2         |
|    cost_values           | 3            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 4090         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.7          |
|    value_loss            | 2.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.512413   |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 641         |
|    total_timesteps       | 841728      |
| train/                   |             |
|    approx_kl             | 0.003585737 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 3           |
|    entropy               | -2.12       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 4100        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.7         |
|    value_loss            | 0.991       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.4445541   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 675          |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0015416679 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.92         |
|    cost_value_loss       | 28.7         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0112       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.63         |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -9.32e-05    |
|    std                   | 0.7          |
|    value_loss            | 0.868        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.29065898  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 710          |
|    total_timesteps       | 845824       |
| train/                   |              |
|    approx_kl             | 0.0064672967 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 7.54         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00732      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.6          |
|    n_updates             | 4120         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.699        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.37756574  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 744          |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0054381285 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 5.87         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00422      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.15         |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.000943    |
|    std                   | 0.699        |
|    value_loss            | 1.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5406211  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 779         |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.004696826 |
|    clip_fraction         | 0.00757     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.12        |
|    cost_value_loss       | 22.9        |
|    cost_values           | 3           |
|    entropy               | -2.13       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0175      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.94        |
|    n_updates             | 4140        |
|    policy_gradient_loss  | -0.00092    |
|    std                   | 0.701       |
|    value_loss            | 0.814       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.39466432  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 813          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0043555093 |
|    clip_fraction         | 0.00557      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.73         |
|    cost_value_loss       | 22.1         |
|    cost_values           | 2.99         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00893      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.69         |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.702        |
|    value_loss            | 1.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4234924   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 848          |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 0.0011498851 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 6.12         |
|    cost_value_loss       | 26.3         |
|    cost_values           | 3            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0091       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 4160         |
|    policy_gradient_loss  | -0.000368    |
|    std                   | 0.701        |
|    value_loss            | 3.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30042708 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 883         |
|    total_timesteps       | 856064      |
| train/                   |             |
|    approx_kl             | 0.003623974 |
|    clip_fraction         | 0.019       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 3           |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0081      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.45        |
|    n_updates             | 4170        |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 0.702       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.44876313 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 917         |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.001523888 |
|    clip_fraction         | 0.000244    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 1.95        |
|    cost_values           | 2.93        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.000206   |
|    std                   | 0.703       |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44766226  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 952          |
|    total_timesteps       | 860160       |
| train/                   |              |
|    approx_kl             | 0.0003386913 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.94         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 2.93         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00512      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.38         |
|    n_updates             | 4190         |
|    policy_gradient_loss  | -3.55e-05    |
|    std                   | 0.704        |
|    value_loss            | 1.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.98        |
| reward                   | -0.42857522 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 986         |
|    total_timesteps       | 862208      |
| train/                   |             |
|    approx_kl             | 0.005565658 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.21        |
|    cost_value_loss       | 38.7        |
|    cost_values           | 3           |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00796     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.33        |
|    n_updates             | 4200        |
|    policy_gradient_loss  | -0.0013     |
|    std                   | 0.704       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.3350664  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.004677198 |
|    clip_fraction         | 0.00688     |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 7.87        |
|    cost_values           | 2.99        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00247     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.37        |
|    n_updates             | 4210        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.705       |
|    value_loss            | 13.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42440277 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1054        |
|    total_timesteps       | 866304      |
| train/                   |             |
|    approx_kl             | 0.005117302 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 1.84        |
|    cost_values           | 2.96        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.3         |
|    n_updates             | 4220        |
|    policy_gradient_loss  | -0.00202    |
|    std                   | 0.702       |
|    value_loss            | 1.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.4204885   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0044617113 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.9          |
|    cost_value_loss       | 16.5         |
|    cost_values           | 2.99         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00688      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.84         |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.699        |
|    value_loss            | 6.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5185941   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1124         |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0034180218 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.16         |
|    cost_value_loss       | 2.58         |
|    cost_values           | 2.95         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.13         |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.000311    |
|    std                   | 0.698        |
|    value_loss            | 2.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.578372    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1158         |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0038410625 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.76         |
|    cost_value_loss       | 17.4         |
|    cost_values           | 2.98         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0129       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.8          |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.000876    |
|    std                   | 0.698        |
|    value_loss            | 1.65         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30901754 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1193        |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.005355031 |
|    clip_fraction         | 0.0547      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.63        |
|    cost_value_loss       | 33.6        |
|    cost_values           | 3           |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0269      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.99        |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.697       |
|    value_loss            | 2.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.25831965  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1227         |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0036278232 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.61         |
|    cost_value_loss       | 20.1         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000769     |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.697        |
|    value_loss            | 5.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3614144   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1261         |
|    total_timesteps       | 878592       |
| train/                   |              |
|    approx_kl             | 0.0041590305 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.34         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 3            |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00625      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 4280         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.696        |
|    value_loss            | 1.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5236267   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1296         |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0008554267 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.56         |
|    cost_value_loss       | 8.76         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00507      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.58         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00026     |
|    std                   | 0.697        |
|    value_loss            | 1.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6427581   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1330         |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0027195904 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.9          |
|    cost_value_loss       | 18.4         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00649      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.79         |
|    n_updates             | 4300         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.698        |
|    value_loss            | 2.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6308401   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1364         |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0008984591 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 7.29         |
|    cost_value_loss       | 25.7         |
|    cost_values           | 3            |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0165       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 4310         |
|    policy_gradient_loss  | -0.000226    |
|    std                   | 0.697        |
|    value_loss            | 2.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.24010608  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1398         |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 0.0026111847 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 5.82         |
|    cost_values           | 3            |
|    entropy               | -2.11        |
|    entropy_loss          | -2.12        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.81         |
|    n_updates             | 4320         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.696        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.30833673  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1433         |
|    total_timesteps       | 888832       |
| train/                   |              |
|    approx_kl             | 0.0015640625 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.95         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 3            |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0031       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 4330         |
|    policy_gradient_loss  | -0.000337    |
|    std                   | 0.696        |
|    value_loss            | 4.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36014932 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1468        |
|    total_timesteps       | 890880      |
| train/                   |             |
|    approx_kl             | 0.00798412  |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.96        |
|    cost_value_loss       | 8.34        |
|    cost_values           | 3           |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00436     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 4340        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.694       |
|    value_loss            | 14.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48228624 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1502        |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.00188098  |
|    clip_fraction         | 0.00728     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.59        |
|    cost_value_loss       | 26.2        |
|    cost_values           | 3           |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00591     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.89        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.000602   |
|    std                   | 0.694       |
|    value_loss            | 1.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3763063   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1536         |
|    total_timesteps       | 894976       |
| train/                   |              |
|    approx_kl             | 0.0043166373 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.71         |
|    cost_value_loss       | 6.12         |
|    cost_values           | 3            |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00204      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.54         |
|    n_updates             | 4360         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.695        |
|    value_loss            | 1.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2236555  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1571        |
|    total_timesteps       | 897024      |
| train/                   |             |
|    approx_kl             | 0.004437376 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.99        |
|    cost_value_loss       | 27.4        |
|    cost_values           | 3           |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0191      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.2         |
|    n_updates             | 4370        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.694       |
|    value_loss            | 1.53        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.8535751 |
| rollout/                 |            |
|    ep_len_mean           | 973        |
|    ep_rew_mean           | -427       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 47         |
|    time_elapsed          | 1605       |
|    total_timesteps       | 899072     |
| train/                   |            |
|    approx_kl             | 0.00466686 |
|    clip_fraction         | 0.0146     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.23       |
|    cost_value_loss       | 14.3       |
|    cost_values           | 2.99       |
|    entropy               | -2.1       |
|    entropy_loss          | -2.11      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.00765    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.19       |
|    n_updates             | 4380       |
|    policy_gradient_loss  | -0.000583  |
|    std                   | 0.693      |
|    value_loss            | 1.9        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.36412063 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1640        |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.004429128 |
|    clip_fraction         | 0.0191      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 5.56        |
|    cost_values           | 3           |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00654     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 4390        |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.692       |
|    value_loss            | 9.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4505758  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1673        |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.003838834 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 5.63        |
|    cost_values           | 3           |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.64        |
|    n_updates             | 4400        |
|    policy_gradient_loss  | -0.000801   |
|    std                   | 0.692       |
|    value_loss            | 8.11        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 8.01        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.45502153 |
| rollout/           |             |
|    ep_len_mean     | 969         |
|    ep_rew_mean     | -427        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 905216      |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.58393204 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 907264      |
| train/                   |             |
|    approx_kl             | 0.002457377 |
|    clip_fraction         | 0.0131      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.11        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 3           |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.92        |
|    n_updates             | 4420        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.692       |
|    value_loss            | 3.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44904357  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0042635575 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.08         |
|    cost_value_loss       | 22.2         |
|    cost_values           | 3            |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 4430         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.691        |
|    value_loss            | 1.51         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.45790836   |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -425          |
| time/                    |               |
|    fps                   | 64            |
|    iterations            | 4             |
|    time_elapsed          | 126           |
|    total_timesteps       | 911360        |
| train/                   |               |
|    approx_kl             | 0.00027925216 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.64          |
|    cost_value_loss       | 11.3          |
|    cost_values           | 3             |
|    entropy               | -2.1          |
|    entropy_loss          | -2.1          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00791       |
|    learning_rate         | 0.0003        |
|    loss                  | 3.75          |
|    n_updates             | 4440          |
|    policy_gradient_loss  | 7.37e-05      |
|    std                   | 0.692         |
|    value_loss            | 1.39          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.38172612   |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -424          |
| time/                    |               |
|    fps                   | 63            |
|    iterations            | 5             |
|    time_elapsed          | 160           |
|    total_timesteps       | 913408        |
| train/                   |               |
|    approx_kl             | 0.00088378746 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.14          |
|    cost_value_loss       | 5.55          |
|    cost_values           | 3             |
|    entropy               | -2.1          |
|    entropy_loss          | -2.1          |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0.00725       |
|    learning_rate         | 0.0003        |
|    loss                  | 3.72          |
|    n_updates             | 4450          |
|    policy_gradient_loss  | -1.84e-05     |
|    std                   | 0.693         |
|    value_loss            | 9.59          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.605653    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 6            |
|    time_elapsed          | 194          |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0028949769 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.31         |
|    cost_value_loss       | 26.9         |
|    cost_values           | 3            |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00418      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.71         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.692        |
|    value_loss            | 1.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6376907  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 228         |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.002796599 |
|    clip_fraction         | 0.0114      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.98        |
|    cost_value_loss       | 7.54        |
|    cost_values           | 3           |
|    entropy               | -2.09       |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.000979   |
|    std                   | 0.689       |
|    value_loss            | 2.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6945454  |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 8           |
|    time_elapsed          | 262         |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.004332952 |
|    clip_fraction         | 0.0116      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 15.1        |
|    cost_values           | 3           |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.688       |
|    value_loss            | 9.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5304083  |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 298         |
|    total_timesteps       | 921600      |
| train/                   |             |
|    approx_kl             | 0.006346086 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.99        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 3           |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.1        |
|    n_updates             | 4490        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.686       |
|    value_loss            | 36.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.393632   |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 332         |
|    total_timesteps       | 923648      |
| train/                   |             |
|    approx_kl             | 0.004907055 |
|    clip_fraction         | 0.0563      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 15.6        |
|    cost_values           | 3           |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00686     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 4500        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.686       |
|    value_loss            | 1.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.40709847  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 366          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0061516976 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.76         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 3            |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00541      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.01         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 0.685        |
|    value_loss            | 1.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5047535   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 400          |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0050484696 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.45         |
|    cost_value_loss       | 23.7         |
|    cost_values           | 3            |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 4520         |
|    policy_gradient_loss  | -0.0009      |
|    std                   | 0.685        |
|    value_loss            | 11           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.58159363   |
| rollout/                 |               |
|    ep_len_mean           | 948           |
|    ep_rew_mean           | -427          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 13            |
|    time_elapsed          | 435           |
|    total_timesteps       | 929792        |
| train/                   |               |
|    approx_kl             | 0.00075584446 |
|    clip_fraction         | 0.0042        |
|    clip_range            | 0.2           |
|    cost_returns          | 3.78          |
|    cost_value_loss       | 5.49          |
|    cost_values           | 3             |
|    entropy               | -2.09         |
|    entropy_loss          | -2.08         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0.00525       |
|    learning_rate         | 0.0003        |
|    loss                  | 3.35          |
|    n_updates             | 4530          |
|    policy_gradient_loss  | 0.000121      |
|    std                   | 0.688         |
|    value_loss            | 3.28          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.42408386 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 14          |
|    time_elapsed          | 469         |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.006726886 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.35        |
|    cost_value_loss       | 30.6        |
|    cost_values           | 3           |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.1        |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.00184    |
|    std                   | 0.689       |
|    value_loss            | 11.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.47826394  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 503          |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0024149609 |
|    clip_fraction         | 0.00322      |
|    clip_range            | 0.2          |
|    cost_returns          | 6            |
|    cost_value_loss       | 19.4         |
|    cost_values           | 3            |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0172       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.8          |
|    n_updates             | 4550         |
|    policy_gradient_loss  | 0.000299     |
|    std                   | 0.689        |
|    value_loss            | 1.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.49442178 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 538         |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.005007331 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.5         |
|    cost_value_loss       | 32.4        |
|    cost_values           | 3           |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0158      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.689       |
|    value_loss            | 3.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.36774385  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 572          |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0036643455 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.92         |
|    cost_value_loss       | 26.5         |
|    cost_values           | 3            |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0127       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.689        |
|    value_loss            | 3.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.35037512  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 606          |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0030863655 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.82         |
|    cost_value_loss       | 4.46         |
|    cost_values           | 3            |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.59         |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.688        |
|    value_loss            | 4.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5911145   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 641          |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0023386567 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.25         |
|    cost_value_loss       | 8.55         |
|    cost_values           | 3            |
|    entropy               | -2.07        |
|    entropy_loss          | -2.08        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00195      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.29         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.000626    |
|    std                   | 0.682        |
|    value_loss            | 1.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.56190944  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 675          |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0018127592 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.39         |
|    cost_value_loss       | 32           |
|    cost_values           | 2.99         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.1         |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.681        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2761872   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 710          |
|    total_timesteps       | 946176       |
| train/                   |              |
|    approx_kl             | 0.0032735884 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.91         |
|    cost_value_loss       | 14.4         |
|    cost_values           | 2.99         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00644      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 4610         |
|    policy_gradient_loss  | 0.000206     |
|    std                   | 0.683        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7852328  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 744         |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.005498464 |
|    clip_fraction         | 0.0129      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.3         |
|    cost_value_loss       | 16.3        |
|    cost_values           | 3           |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00812     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.000423   |
|    std                   | 0.683       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3161896  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 778         |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.005216495 |
|    clip_fraction         | 0.0121      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 9.04        |
|    cost_values           | 3           |
|    entropy               | -2.07       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.99        |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.000355   |
|    std                   | 0.682       |
|    value_loss            | 9.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.57185024  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 812          |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0043941922 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.06         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 3            |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00454      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.681        |
|    value_loss            | 7.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.22307639  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 846          |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0052793785 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.99         |
|    cost_value_loss       | 5.62         |
|    cost_values           | 3            |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00116      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.682        |
|    value_loss            | 5.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.62635016  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 880          |
|    total_timesteps       | 956416       |
| train/                   |              |
|    approx_kl             | 0.0028987578 |
|    clip_fraction         | 0.00557      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.17         |
|    cost_value_loss       | 21.9         |
|    cost_values           | 3            |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00887      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.59         |
|    n_updates             | 4660         |
|    policy_gradient_loss  | -0.000625    |
|    std                   | 0.681        |
|    value_loss            | 3.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.74         |
| reward                   | -0.46117333  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 915          |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0034895774 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.54         |
|    cost_value_loss       | 23.9         |
|    cost_values           | 2.99         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00456      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.681        |
|    value_loss            | 3.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.47145337  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 949          |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0044321064 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.57         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 3            |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.25         |
|    n_updates             | 4680         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.681        |
|    value_loss            | 1.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.42153382 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 983         |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.002145701 |
|    clip_fraction         | 0.0457      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.2         |
|    cost_value_loss       | 20.6        |
|    cost_values           | 3           |
|    entropy               | -2.07       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.7        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.68        |
|    value_loss            | 15.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.54975533  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1017         |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0045419503 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.44         |
|    cost_value_loss       | 15           |
|    cost_values           | 3            |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00146      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.19         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.678        |
|    value_loss            | 14.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44961786  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1051         |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0030809988 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.9          |
|    cost_value_loss       | 12.4         |
|    cost_values           | 3            |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00144      |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.00053     |
|    std                   | 0.677        |
|    value_loss            | 20.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5536083   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0037523843 |
|    clip_fraction         | 0.0623       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.4          |
|    cost_value_loss       | 22.3         |
|    cost_values           | 2.99         |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00593      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.677        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.43         |
| reward                   | -0.61528414  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1119         |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0037015222 |
|    clip_fraction         | 0.0438       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.22         |
|    cost_value_loss       | 19.9         |
|    cost_values           | 3            |
|    entropy               | -2.05        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.1         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.676        |
|    value_loss            | 20.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4780184   |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1154         |
|    total_timesteps       | 972800       |
| train/                   |              |
|    approx_kl             | 0.0019530272 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 3            |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00196      |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 4740         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.673        |
|    value_loss            | 22.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5154949  |
| rollout/                 |             |
|    ep_len_mean           | 875         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1188        |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.003543811 |
|    clip_fraction         | 0.00327     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.44        |
|    cost_value_loss       | 22.5        |
|    cost_values           | 3           |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00942     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.2         |
|    n_updates             | 4750        |
|    policy_gradient_loss  | 0.000262    |
|    std                   | 0.673       |
|    value_loss            | 14.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49341193  |
| rollout/                 |              |
|    ep_len_mean           | 877          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1222         |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0037909723 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.37         |
|    cost_value_loss       | 7.73         |
|    cost_values           | 3            |
|    entropy               | -2.06        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00768      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.52         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.000616    |
|    std                   | 0.676        |
|    value_loss            | 26.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.59501505  |
| rollout/                 |              |
|    ep_len_mean           | 877          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1257         |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0038981976 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.3          |
|    cost_value_loss       | 21.3         |
|    cost_values           | 3            |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 4770         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.676        |
|    value_loss            | 3.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36730927 |
| rollout/                 |             |
|    ep_len_mean           | 877         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 38          |
|    time_elapsed          | 1292        |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.003389541 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 8.48        |
|    cost_values           | 3           |
|    entropy               | -2.05       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00521     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.71        |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.676       |
|    value_loss            | 2.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5394316   |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1326         |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0038015507 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 6.91         |
|    cost_values           | 3            |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00453      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.81         |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.676        |
|    value_loss            | 4.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.5         |
| reward                   | -0.58604395 |
| rollout/                 |             |
|    ep_len_mean           | 876         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 40          |
|    time_elapsed          | 1361        |
|    total_timesteps       | 985088      |
| train/                   |             |
|    approx_kl             | 0.006296402 |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.9         |
|    cost_value_loss       | 13.1        |
|    cost_values           | 3           |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00635     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 4800        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.675       |
|    value_loss            | 15          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.43852714 |
| rollout/                 |             |
|    ep_len_mean           | 868         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 41          |
|    time_elapsed          | 1396        |
|    total_timesteps       | 987136      |
| train/                   |             |
|    approx_kl             | 0.003075783 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.85        |
|    cost_value_loss       | 18          |
|    cost_values           | 3           |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0124      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.24        |
|    n_updates             | 4810        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.674       |
|    value_loss            | 7.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.41808254 |
| rollout/                 |             |
|    ep_len_mean           | 868         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 42          |
|    time_elapsed          | 1431        |
|    total_timesteps       | 989184      |
| train/                   |             |
|    approx_kl             | 0.010466579 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.41        |
|    cost_value_loss       | 29.8        |
|    cost_values           | 3           |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.6        |
|    n_updates             | 4820        |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.674       |
|    value_loss            | 14.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.535521   |
| rollout/                 |             |
|    ep_len_mean           | 853         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 43          |
|    time_elapsed          | 1466        |
|    total_timesteps       | 991232      |
| train/                   |             |
|    approx_kl             | 0.003030649 |
|    clip_fraction         | 0.0135      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.99        |
|    cost_value_loss       | 29.6        |
|    cost_values           | 3           |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00342     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.53        |
|    n_updates             | 4830        |
|    policy_gradient_loss  | -0.000868   |
|    std                   | 0.673       |
|    value_loss            | 2.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3721938   |
| rollout/                 |              |
|    ep_len_mean           | 846          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1501         |
|    total_timesteps       | 993280       |
| train/                   |              |
|    approx_kl             | 0.0004696841 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 7.49         |
|    cost_value_loss       | 30.8         |
|    cost_values           | 3            |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0177       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.27         |
|    n_updates             | 4840         |
|    policy_gradient_loss  | -0.000196    |
|    std                   | 0.674        |
|    value_loss            | 23.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40182132  |
| rollout/                 |              |
|    ep_len_mean           | 846          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1535         |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0042009824 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.93         |
|    cost_value_loss       | 19.1         |
|    cost_values           | 3            |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00715      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.75         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.673        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45428154  |
| rollout/                 |              |
|    ep_len_mean           | 847          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1570         |
|    total_timesteps       | 997376       |
| train/                   |              |
|    approx_kl             | 0.0036063143 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.54         |
|    cost_value_loss       | 24.8         |
|    cost_values           | 2.99         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00807      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.31         |
|    n_updates             | 4860         |
|    policy_gradient_loss  | -0.000784    |
|    std                   | 0.672        |
|    value_loss            | 2.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39332873 |
| rollout/                 |             |
|    ep_len_mean           | 847         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1605        |
|    total_timesteps       | 999424      |
| train/                   |             |
|    approx_kl             | 0.006734847 |
|    clip_fraction         | 0.0124      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.29        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 3           |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 4870        |
|    policy_gradient_loss  | -0.000403   |
|    std                   | 0.671       |
|    value_loss            | 5.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.3964076  |
| rollout/                 |             |
|    ep_len_mean           | 847         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1639        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.003874553 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.9         |
|    cost_value_loss       | 34          |
|    cost_values           | 3           |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0161      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.67        |
|    value_loss            | 2.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.82762194  |
| rollout/                 |              |
|    ep_len_mean           | 847          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1674         |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0051550465 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.44         |
|    cost_value_loss       | 24.5         |
|    cost_values           | 3            |
|    entropy               | -2.03        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.668        |
|    value_loss            | 1.79         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.97       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.97       |
| reward             | -0.6124299 |
| rollout/           |            |
|    ep_len_mean     | 863        |
|    ep_rew_mean     | -410       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1005568    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44245285  |
| rollout/                 |              |
|    ep_len_mean           | 857          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0049338834 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.91         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 3            |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0135       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.18         |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.665        |
|    value_loss            | 4.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.3688417   |
| rollout/                 |              |
|    ep_len_mean           | 857          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1009664      |
| train/                   |              |
|    approx_kl             | 0.0039932304 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 11.7         |
|    cost_values           | 2.97         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00516      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.7          |
|    n_updates             | 4920         |
|    policy_gradient_loss  | -0.000822    |
|    std                   | 0.665        |
|    value_loss            | 25.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6889781   |
| rollout/                 |              |
|    ep_len_mean           | 861          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1011712      |
| train/                   |              |
|    approx_kl             | 0.0043211686 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.3          |
|    cost_value_loss       | 32.1         |
|    cost_values           | 2.99         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00972      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.26         |
|    n_updates             | 4930         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.665        |
|    value_loss            | 3.18         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.52400976   |
| rollout/                 |               |
|    ep_len_mean           | 861           |
|    ep_rew_mean           | -415          |
| time/                    |               |
|    fps                   | 63            |
|    iterations            | 5             |
|    time_elapsed          | 162           |
|    total_timesteps       | 1013760       |
| train/                   |               |
|    approx_kl             | 0.00072716083 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 6.35          |
|    cost_value_loss       | 20.3          |
|    cost_values           | 3             |
|    entropy               | -2.02         |
|    entropy_loss          | -2.02         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.3          |
|    n_updates             | 4940          |
|    policy_gradient_loss  | -0.000245     |
|    std                   | 0.664         |
|    value_loss            | 4.74          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.59552664  |
| rollout/                 |              |
|    ep_len_mean           | 867          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 1015808      |
| train/                   |              |
|    approx_kl             | 0.0034746984 |
|    clip_fraction         | 0.00415      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.08         |
|    cost_value_loss       | 7.6          |
|    cost_values           | 2.99         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00258      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.33         |
|    n_updates             | 4950         |
|    policy_gradient_loss  | -0.000662    |
|    std                   | 0.664        |
|    value_loss            | 12.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.6164198   |
| rollout/                 |              |
|    ep_len_mean           | 859          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0012928883 |
|    clip_fraction         | 0.0438       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.57         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 3            |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00876      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.23         |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.000796    |
|    std                   | 0.663        |
|    value_loss            | 4.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.62417406 |
| rollout/                 |             |
|    ep_len_mean           | 850         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 264         |
|    total_timesteps       | 1019904     |
| train/                   |             |
|    approx_kl             | 0.005628232 |
|    clip_fraction         | 0.0185      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.29        |
|    cost_value_loss       | 20.6        |
|    cost_values           | 3           |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00863     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.12        |
|    n_updates             | 4970        |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.662       |
|    value_loss            | 14.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.33991155  |
| rollout/                 |              |
|    ep_len_mean           | 839          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 299          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0036726187 |
|    clip_fraction         | 0.00586      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.68         |
|    cost_value_loss       | 16           |
|    cost_values           | 3            |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00451      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 4980         |
|    policy_gradient_loss  | -8.19e-05    |
|    std                   | 0.661        |
|    value_loss            | 24.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6481223   |
| rollout/                 |              |
|    ep_len_mean           | 839          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 333          |
|    total_timesteps       | 1024000      |
| train/                   |              |
|    approx_kl             | 0.0029512946 |
|    clip_fraction         | 0.00557      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.19         |
|    cost_value_loss       | 14           |
|    cost_values           | 3            |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00594      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 4990         |
|    policy_gradient_loss  | -0.000173    |
|    std                   | 0.662        |
|    value_loss            | 29.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.66        |
| reward                   | -0.5712816  |
| rollout/                 |             |
|    ep_len_mean           | 841         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 367         |
|    total_timesteps       | 1026048     |
| train/                   |             |
|    approx_kl             | 0.002997647 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.05        |
|    cost_value_loss       | 20.4        |
|    cost_values           | 3           |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00424     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.73        |
|    n_updates             | 5000        |
|    policy_gradient_loss  | -0.000171   |
|    std                   | 0.662       |
|    value_loss            | 2.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5787783   |
| rollout/                 |              |
|    ep_len_mean           | 847          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 401          |
|    total_timesteps       | 1028096      |
| train/                   |              |
|    approx_kl             | 0.0048553715 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.05         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 3            |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.81         |
|    n_updates             | 5010         |
|    policy_gradient_loss  | -0.000663    |
|    std                   | 0.662        |
|    value_loss            | 2.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.65712994 |
| rollout/                 |             |
|    ep_len_mean           | 842         |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 435         |
|    total_timesteps       | 1030144     |
| train/                   |             |
|    approx_kl             | 0.004526531 |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 18.4        |
|    cost_values           | 3           |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0103      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.82        |
|    n_updates             | 5020        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.662       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32895684 |
| rollout/                 |             |
|    ep_len_mean           | 834         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 14          |
|    time_elapsed          | 469         |
|    total_timesteps       | 1032192     |
| train/                   |             |
|    approx_kl             | 0.011099109 |
|    clip_fraction         | 0.0275      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.3         |
|    cost_value_loss       | 11.4        |
|    cost_values           | 3           |
|    entropy               | -2.02       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 5030        |
|    policy_gradient_loss  | -8.59e-05   |
|    std                   | 0.663       |
|    value_loss            | 17.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.56992143 |
| rollout/                 |             |
|    ep_len_mean           | 831         |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 504         |
|    total_timesteps       | 1034240     |
| train/                   |             |
|    approx_kl             | 0.008675994 |
|    clip_fraction         | 0.0456      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 9.23        |
|    cost_values           | 2.99        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.5        |
|    n_updates             | 5040        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.664       |
|    value_loss            | 28.1        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.4407475    |
| rollout/                 |               |
|    ep_len_mean           | 831           |
|    ep_rew_mean           | -416          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 16            |
|    time_elapsed          | 538           |
|    total_timesteps       | 1036288       |
| train/                   |               |
|    approx_kl             | 4.4395274e-05 |
|    clip_fraction         | 0.0523        |
|    clip_range            | 0.2           |
|    cost_returns          | 6.85          |
|    cost_value_loss       | 21.8          |
|    cost_values           | 3             |
|    entropy               | -2.02         |
|    entropy_loss          | -2.02         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0.0133        |
|    learning_rate         | 0.0003        |
|    loss                  | 4.99          |
|    n_updates             | 5050          |
|    policy_gradient_loss  | 1.8e-05       |
|    std                   | 0.664         |
|    value_loss            | 18.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5911279   |
| rollout/                 |              |
|    ep_len_mean           | 827          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 572          |
|    total_timesteps       | 1038336      |
| train/                   |              |
|    approx_kl             | 0.0015216261 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.51         |
|    cost_value_loss       | 26.8         |
|    cost_values           | 3            |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.96         |
|    n_updates             | 5060         |
|    policy_gradient_loss  | -0.000336    |
|    std                   | 0.664        |
|    value_loss            | 3.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48581508  |
| rollout/                 |              |
|    ep_len_mean           | 827          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 607          |
|    total_timesteps       | 1040384      |
| train/                   |              |
|    approx_kl             | 0.0058741244 |
|    clip_fraction         | 0.0446       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.9          |
|    cost_value_loss       | 6.97         |
|    cost_values           | 3            |
|    entropy               | -2.01        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.49         |
|    n_updates             | 5070         |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.662        |
|    value_loss            | 18.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41843244  |
| rollout/                 |              |
|    ep_len_mean           | 832          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 642          |
|    total_timesteps       | 1042432      |
| train/                   |              |
|    approx_kl             | 0.0036829668 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.28         |
|    cost_value_loss       | 9.28         |
|    cost_values           | 3            |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000368     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.04         |
|    n_updates             | 5080         |
|    policy_gradient_loss  | -0.000998    |
|    std                   | 0.661        |
|    value_loss            | 9.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54227084  |
| rollout/                 |              |
|    ep_len_mean           | 832          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 677          |
|    total_timesteps       | 1044480      |
| train/                   |              |
|    approx_kl             | 0.0018218129 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.95         |
|    cost_value_loss       | 33.2         |
|    cost_values           | 3            |
|    entropy               | -2           |
|    entropy_loss          | -2.01        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 5090         |
|    policy_gradient_loss  | -0.00054     |
|    std                   | 0.659        |
|    value_loss            | 3.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5186219   |
| rollout/                 |              |
|    ep_len_mean           | 836          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 711          |
|    total_timesteps       | 1046528      |
| train/                   |              |
|    approx_kl             | 0.0035845044 |
|    clip_fraction         | 0.0449       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 18.6         |
|    cost_values           | 3            |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 5100         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.656        |
|    value_loss            | 3.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.48551607 |
| rollout/                 |             |
|    ep_len_mean           | 836         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 746         |
|    total_timesteps       | 1048576     |
| train/                   |             |
|    approx_kl             | 0.000787511 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 5.32        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 3           |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00732     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.87        |
|    n_updates             | 5110        |
|    policy_gradient_loss  | 1.42e-05    |
|    std                   | 0.655       |
|    value_loss            | 1.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.32288596  |
| rollout/                 |              |
|    ep_len_mean           | 838          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 780          |
|    total_timesteps       | 1050624      |
| train/                   |              |
|    approx_kl             | 0.0044418415 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.27         |
|    cost_value_loss       | 27.9         |
|    cost_values           | 3            |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0238       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.31         |
|    n_updates             | 5120         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.655        |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5019257  |
| rollout/                 |             |
|    ep_len_mean           | 840         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 814         |
|    total_timesteps       | 1052672     |
| train/                   |             |
|    approx_kl             | 0.009634761 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.81        |
|    cost_value_loss       | 16.7        |
|    cost_values           | 3           |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00593     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 5130        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.654       |
|    value_loss            | 28.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33665457 |
| rollout/                 |             |
|    ep_len_mean           | 849         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 25          |
|    time_elapsed          | 848         |
|    total_timesteps       | 1054720     |
| train/                   |             |
|    approx_kl             | 0.000541262 |
|    clip_fraction         | 0.00737     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.67        |
|    cost_value_loss       | 27.4        |
|    cost_values           | 3           |
|    entropy               | -1.98       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0172      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 5140        |
|    policy_gradient_loss  | 0.00032     |
|    std                   | 0.652       |
|    value_loss            | 1.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.29783913  |
| rollout/                 |              |
|    ep_len_mean           | 851          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 883          |
|    total_timesteps       | 1056768      |
| train/                   |              |
|    approx_kl             | 0.0028062793 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.9          |
|    cost_value_loss       | 11.6         |
|    cost_values           | 3            |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 5150         |
|    policy_gradient_loss  | -8.91e-05    |
|    std                   | 0.651        |
|    value_loss            | 2.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.29         |
| reward                   | -0.54865533  |
| rollout/                 |              |
|    ep_len_mean           | 859          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 916          |
|    total_timesteps       | 1058816      |
| train/                   |              |
|    approx_kl             | 0.0041071414 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.96         |
|    cost_value_loss       | 18           |
|    cost_values           | 3            |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0161       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.9          |
|    n_updates             | 5160         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.648        |
|    value_loss            | 16.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.23466337  |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 950          |
|    total_timesteps       | 1060864      |
| train/                   |              |
|    approx_kl             | 0.0034661002 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.32         |
|    cost_value_loss       | 3.08         |
|    cost_values           | 2.97         |
|    entropy               | -1.96        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00789      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 5170         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 0.645        |
|    value_loss            | 8.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.51724297  |
| rollout/                 |              |
|    ep_len_mean           | 877          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 985          |
|    total_timesteps       | 1062912      |
| train/                   |              |
|    approx_kl             | 0.0042919386 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.46         |
|    cost_value_loss       | 19.3         |
|    cost_values           | 3            |
|    entropy               | -1.96        |
|    entropy_loss          | -1.96        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00778      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.53         |
|    n_updates             | 5180         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.643        |
|    value_loss            | 4.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3797248   |
| rollout/                 |              |
|    ep_len_mean           | 877          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 1064960      |
| train/                   |              |
|    approx_kl             | 0.0033640682 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.76         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 3            |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00472      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.82         |
|    n_updates             | 5190         |
|    policy_gradient_loss  | -0.000811    |
|    std                   | 0.642        |
|    value_loss            | 6.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.61168873 |
| rollout/                 |             |
|    ep_len_mean           | 877         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1054        |
|    total_timesteps       | 1067008     |
| train/                   |             |
|    approx_kl             | 0.002167419 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 3           |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00101     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.73        |
|    n_updates             | 5200        |
|    policy_gradient_loss  | 0.000372    |
|    std                   | 0.641       |
|    value_loss            | 5.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4068583   |
| rollout/                 |              |
|    ep_len_mean           | 869          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1088         |
|    total_timesteps       | 1069056      |
| train/                   |              |
|    approx_kl             | 0.0029320372 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.38         |
|    cost_value_loss       | 14.2         |
|    cost_values           | 3            |
|    entropy               | -1.94        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00236      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.57         |
|    n_updates             | 5210         |
|    policy_gradient_loss  | -0.000242    |
|    std                   | 0.64         |
|    value_loss            | 2.78         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6011949  |
| rollout/                 |             |
|    ep_len_mean           | 864         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1123        |
|    total_timesteps       | 1071104     |
| train/                   |             |
|    approx_kl             | 0.003110841 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.78        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 2.99        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.94       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00446     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.12        |
|    n_updates             | 5220        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.64        |
|    value_loss            | 16.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5429026  |
| rollout/                 |             |
|    ep_len_mean           | 864         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 34          |
|    time_elapsed          | 1157        |
|    total_timesteps       | 1073152     |
| train/                   |             |
|    approx_kl             | 0.003482205 |
|    clip_fraction         | 0.0116      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.62        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 2.99        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18          |
|    n_updates             | 5230        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.641       |
|    value_loss            | 14.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.70540124 |
| rollout/                 |             |
|    ep_len_mean           | 872         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1190        |
|    total_timesteps       | 1075200     |
| train/                   |             |
|    approx_kl             | 0.004982688 |
|    clip_fraction         | 0.0128      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.94        |
|    cost_value_loss       | 26.5        |
|    cost_values           | 3           |
|    entropy               | -1.94       |
|    entropy_loss          | -1.95       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0105      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 5240        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.64        |
|    value_loss            | 4.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5087562   |
| rollout/                 |              |
|    ep_len_mean           | 872          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1225         |
|    total_timesteps       | 1077248      |
| train/                   |              |
|    approx_kl             | 0.0070081763 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.19         |
|    cost_value_loss       | 5.96         |
|    cost_values           | 3            |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00403      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.06         |
|    n_updates             | 5250         |
|    policy_gradient_loss  | 0.00181      |
|    std                   | 0.639        |
|    value_loss            | 15.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.30864474  |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1259         |
|    total_timesteps       | 1079296      |
| train/                   |              |
|    approx_kl             | 0.0067964788 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.79         |
|    cost_value_loss       | 26.3         |
|    cost_values           | 3            |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0224       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.95         |
|    n_updates             | 5260         |
|    policy_gradient_loss  | -0.000356    |
|    std                   | 0.638        |
|    value_loss            | 4.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7453112   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1294         |
|    total_timesteps       | 1081344      |
| train/                   |              |
|    approx_kl             | 9.055837e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.72         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 3            |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00688      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.65         |
|    n_updates             | 5270         |
|    policy_gradient_loss  | -6.57e-05    |
|    std                   | 0.637        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2666601   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1328         |
|    total_timesteps       | 1083392      |
| train/                   |              |
|    approx_kl             | 0.0025499808 |
|    clip_fraction         | 0.01         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.87         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 3            |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00629      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 5280         |
|    policy_gradient_loss  | -0.000831    |
|    std                   | 0.637        |
|    value_loss            | 3.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4692023   |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1363         |
|    total_timesteps       | 1085440      |
| train/                   |              |
|    approx_kl             | 0.0030080236 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.05         |
|    cost_value_loss       | 11.1         |
|    cost_values           | 3            |
|    entropy               | -1.93        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00787      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 5290         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.637        |
|    value_loss            | 4.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.32727054  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1398         |
|    total_timesteps       | 1087488      |
| train/                   |              |
|    approx_kl             | 0.0072014425 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 6.28         |
|    cost_values           | 3            |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00314      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.28         |
|    n_updates             | 5300         |
|    policy_gradient_loss  | -0.000819    |
|    std                   | 0.635        |
|    value_loss            | 17.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7115119  |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -466        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 42          |
|    time_elapsed          | 1432        |
|    total_timesteps       | 1089536     |
| train/                   |             |
|    approx_kl             | 0.006008456 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 3           |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00643     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 5310        |
|    policy_gradient_loss  | -0.000213   |
|    std                   | 0.635       |
|    value_loss            | 2.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49476033  |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1466         |
|    total_timesteps       | 1091584      |
| train/                   |              |
|    approx_kl             | 0.0038942415 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.67         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00037      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.4          |
|    n_updates             | 5320         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.636        |
|    value_loss            | 3.78         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.64493    |
| rollout/                 |             |
|    ep_len_mean           | 887         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 44          |
|    time_elapsed          | 1501        |
|    total_timesteps       | 1093632     |
| train/                   |             |
|    approx_kl             | 0.004131552 |
|    clip_fraction         | 0.0153      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.17        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 3           |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00581     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.11        |
|    n_updates             | 5330        |
|    policy_gradient_loss  | -0.000343   |
|    std                   | 0.634       |
|    value_loss            | 22.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7061221  |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 45          |
|    time_elapsed          | 1535        |
|    total_timesteps       | 1095680     |
| train/                   |             |
|    approx_kl             | 0.003951266 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.71        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 3           |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00527     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 5340        |
|    policy_gradient_loss  | -0.000422   |
|    std                   | 0.631       |
|    value_loss            | 3.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7861505  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 46          |
|    time_elapsed          | 1569        |
|    total_timesteps       | 1097728     |
| train/                   |             |
|    approx_kl             | 0.004558596 |
|    clip_fraction         | 0.0257      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 9.99        |
|    cost_values           | 3           |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00813     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.77        |
|    n_updates             | 5350        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.631       |
|    value_loss            | 3.7         |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.52595454   |
| rollout/                 |               |
|    ep_len_mean           | 899           |
|    ep_rew_mean           | -476          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 47            |
|    time_elapsed          | 1603          |
|    total_timesteps       | 1099776       |
| train/                   |               |
|    approx_kl             | 0.00049891754 |
|    clip_fraction         | 0.00361       |
|    clip_range            | 0.2           |
|    cost_returns          | 4.32          |
|    cost_value_loss       | 6.74          |
|    cost_values           | 3             |
|    entropy               | -1.92         |
|    entropy_loss          | -1.92         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00624       |
|    learning_rate         | 0.0003        |
|    loss                  | 4.21          |
|    n_updates             | 5360          |
|    policy_gradient_loss  | -0.000421     |
|    std                   | 0.631         |
|    value_loss            | 11            |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5393907  |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 48          |
|    time_elapsed          | 1637        |
|    total_timesteps       | 1101824     |
| train/                   |             |
|    approx_kl             | 0.003021936 |
|    clip_fraction         | 0.0266      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.05        |
|    cost_value_loss       | 19          |
|    cost_values           | 3           |
|    entropy               | -1.91       |
|    entropy_loss          | -1.91       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.0167      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.88        |
|    n_updates             | 5370        |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.629       |
|    value_loss            | 4.02        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.35354283   |
| rollout/                 |               |
|    ep_len_mean           | 891           |
|    ep_rew_mean           | -469          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 49            |
|    time_elapsed          | 1671          |
|    total_timesteps       | 1103872       |
| train/                   |               |
|    approx_kl             | 0.00074100436 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.76          |
|    cost_value_loss       | 10.7          |
|    cost_values           | 2.99          |
|    entropy               | -1.91         |
|    entropy_loss          | -1.91         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0.00471       |
|    learning_rate         | 0.0003        |
|    loss                  | 6.69          |
|    n_updates             | 5380          |
|    policy_gradient_loss  | 0.000168      |
|    std                   | 0.629         |
|    value_loss            | 20            |
--------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.4310262 |
| rollout/           |            |
|    ep_len_mean     | 884        |
|    ep_rew_mean     | -465       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1105920    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.46863028  |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1107968      |
| train/                   |              |
|    approx_kl             | 0.0050728503 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.48         |
|    cost_value_loss       | 19.8         |
|    cost_values           | 3            |
|    entropy               | -1.89        |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00612      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.91         |
|    n_updates             | 5400         |
|    policy_gradient_loss  | -0.000559    |
|    std                   | 0.624        |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7160025   |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1110016      |
| train/                   |              |
|    approx_kl             | 0.0054547386 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.54         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 3            |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00722      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 5410         |
|    policy_gradient_loss  | -0.00067     |
|    std                   | 0.624        |
|    value_loss            | 6.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.41634914 |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 127         |
|    total_timesteps       | 1112064     |
| train/                   |             |
|    approx_kl             | 0.003990061 |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.57        |
|    cost_value_loss       | 4.89        |
|    cost_values           | 3           |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00421     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.71        |
|    n_updates             | 5420        |
|    policy_gradient_loss  | -0.000803   |
|    std                   | 0.622       |
|    value_loss            | 22.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46410772  |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 1114112      |
| train/                   |              |
|    approx_kl             | 0.0048181927 |
|    clip_fraction         | 0.0569       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.23         |
|    cost_value_loss       | 5.9          |
|    cost_values           | 3            |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00333      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.09         |
|    n_updates             | 5430         |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 0.619        |
|    value_loss            | 36.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4516169  |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 195         |
|    total_timesteps       | 1116160     |
| train/                   |             |
|    approx_kl             | 0.003983542 |
|    clip_fraction         | 0.0189      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.64        |
|    cost_value_loss       | 4.8         |
|    cost_values           | 3           |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00153     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.4         |
|    n_updates             | 5440        |
|    policy_gradient_loss  | -0.000791   |
|    std                   | 0.615       |
|    value_loss            | 2.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.78532195 |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 229         |
|    total_timesteps       | 1118208     |
| train/                   |             |
|    approx_kl             | 0.003381184 |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 3.97        |
|    cost_values           | 3           |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00294     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.71        |
|    n_updates             | 5450        |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 0.615       |
|    value_loss            | 5.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9188801   |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 263          |
|    total_timesteps       | 1120256      |
| train/                   |              |
|    approx_kl             | 0.0025019965 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 5.77         |
|    cost_values           | 3            |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.19         |
|    n_updates             | 5460         |
|    policy_gradient_loss  | -0.000305    |
|    std                   | 0.614        |
|    value_loss            | 17.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6899224   |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 297          |
|    total_timesteps       | 1122304      |
| train/                   |              |
|    approx_kl             | 0.0023573334 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.59         |
|    cost_value_loss       | 8.19         |
|    cost_values           | 3            |
|    entropy               | -1.85        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 5470         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.612        |
|    value_loss            | 22.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7818887   |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 331          |
|    total_timesteps       | 1124352      |
| train/                   |              |
|    approx_kl             | 0.0015826386 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.27         |
|    cost_value_loss       | 3.33         |
|    cost_values           | 2.96         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.23         |
|    n_updates             | 5480         |
|    policy_gradient_loss  | -0.000754    |
|    std                   | 0.61         |
|    value_loss            | 17.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5521022   |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 366          |
|    total_timesteps       | 1126400      |
| train/                   |              |
|    approx_kl             | 0.0041125054 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.16         |
|    cost_value_loss       | 8.21         |
|    cost_values           | 2.95         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00583      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.11         |
|    n_updates             | 5490         |
|    policy_gradient_loss  | -0.000445    |
|    std                   | 0.61         |
|    value_loss            | 24.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7151926   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 400          |
|    total_timesteps       | 1128448      |
| train/                   |              |
|    approx_kl             | 0.0049168053 |
|    clip_fraction         | 0.00566      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.89         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 3            |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00507      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.23         |
|    n_updates             | 5500         |
|    policy_gradient_loss  | -0.000176    |
|    std                   | 0.609        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7719719   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 434          |
|    total_timesteps       | 1130496      |
| train/                   |              |
|    approx_kl             | 0.0050095753 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.14         |
|    cost_value_loss       | 12           |
|    cost_values           | 3            |
|    entropy               | -1.84        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00786      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 5510         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.608        |
|    value_loss            | 5.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4136498   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 14           |
|    time_elapsed          | 468          |
|    total_timesteps       | 1132544      |
| train/                   |              |
|    approx_kl             | 0.0029773917 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.56         |
|    cost_value_loss       | 4.34         |
|    cost_values           | 2.98         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.27         |
|    n_updates             | 5520         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.607        |
|    value_loss            | 8.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.51359165  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 503          |
|    total_timesteps       | 1134592      |
| train/                   |              |
|    approx_kl             | 0.0041002566 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 3.61         |
|    cost_values           | 2.99         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.64         |
|    n_updates             | 5530         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.602        |
|    value_loss            | 9.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.72657996 |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -493        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 16          |
|    time_elapsed          | 536         |
|    total_timesteps       | 1136640     |
| train/                   |             |
|    approx_kl             | 0.004230351 |
|    clip_fraction         | 0.0509      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.31        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 3           |
|    entropy               | -1.81       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00378     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.4         |
|    n_updates             | 5540        |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 0.599       |
|    value_loss            | 23.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.26         |
| reward                   | -0.44857183  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 17           |
|    time_elapsed          | 570          |
|    total_timesteps       | 1138688      |
| train/                   |              |
|    approx_kl             | 0.0043745963 |
|    clip_fraction         | 0.0523       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.45         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 3            |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 5550         |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.597        |
|    value_loss            | 9.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.34278548 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -504        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 604         |
|    total_timesteps       | 1140736     |
| train/                   |             |
|    approx_kl             | 0.004243886 |
|    clip_fraction         | 0.0576      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 4.11        |
|    cost_values           | 3           |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00817     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.63        |
|    n_updates             | 5560        |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.595       |
|    value_loss            | 8.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.524671    |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 639          |
|    total_timesteps       | 1142784      |
| train/                   |              |
|    approx_kl             | 0.0036874262 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.95         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 3            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00626      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.1          |
|    n_updates             | 5570         |
|    policy_gradient_loss  | -0.000793    |
|    std                   | 0.594        |
|    value_loss            | 2.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66423684  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 674          |
|    total_timesteps       | 1144832      |
| train/                   |              |
|    approx_kl             | 0.0022024112 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.81         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 3            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00698      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.26         |
|    n_updates             | 5580         |
|    policy_gradient_loss  | -0.000261    |
|    std                   | 0.593        |
|    value_loss            | 8.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5171208   |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 708          |
|    total_timesteps       | 1146880      |
| train/                   |              |
|    approx_kl             | 0.0029822951 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.22         |
|    cost_value_loss       | 15.5         |
|    cost_values           | 3            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00695      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.67         |
|    n_updates             | 5590         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.593        |
|    value_loss            | 5.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78837156  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 742          |
|    total_timesteps       | 1148928      |
| train/                   |              |
|    approx_kl             | 0.0036034696 |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.84         |
|    cost_value_loss       | 5.93         |
|    cost_values           | 3            |
|    entropy               | -1.78        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00765      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.71         |
|    n_updates             | 5600         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.59         |
|    value_loss            | 7.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7950994   |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 776          |
|    total_timesteps       | 1150976      |
| train/                   |              |
|    approx_kl             | 0.0017933289 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.74         |
|    cost_value_loss       | 5.49         |
|    cost_values           | 3            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.78        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00492      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.44         |
|    n_updates             | 5610         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.591        |
|    value_loss            | 18.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.76226085 |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 810         |
|    total_timesteps       | 1153024     |
| train/                   |             |
|    approx_kl             | 0.005778371 |
|    clip_fraction         | 0.0217      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.69        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 3           |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00405     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 5620        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.591       |
|    value_loss            | 4.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.11         |
| reward                   | -0.33652383  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 845          |
|    total_timesteps       | 1155072      |
| train/                   |              |
|    approx_kl             | 0.0032149185 |
|    clip_fraction         | 0.00415      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.1          |
|    cost_value_loss       | 18.6         |
|    cost_values           | 3            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 5630         |
|    policy_gradient_loss  | -0.000556    |
|    std                   | 0.592        |
|    value_loss            | 4.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6003632  |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -507        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 879         |
|    total_timesteps       | 1157120     |
| train/                   |             |
|    approx_kl             | 0.002597421 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 3           |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.007       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.24        |
|    n_updates             | 5640        |
|    policy_gradient_loss  | -0.000839   |
|    std                   | 0.591       |
|    value_loss            | 4.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4122372   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 913          |
|    total_timesteps       | 1159168      |
| train/                   |              |
|    approx_kl             | 0.0056909774 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.33         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 3            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00109      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 5650         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.591        |
|    value_loss            | 17.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31232935 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -515        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 946         |
|    total_timesteps       | 1161216     |
| train/                   |             |
|    approx_kl             | 0.004422229 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.31        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 3           |
|    entropy               | -1.78       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0103      |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 5660        |
|    policy_gradient_loss  | -0.000749   |
|    std                   | 0.59        |
|    value_loss            | 2.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5385472   |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 981          |
|    total_timesteps       | 1163264      |
| train/                   |              |
|    approx_kl             | 0.0031892504 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.21         |
|    cost_value_loss       | 15.5         |
|    cost_values           | 3            |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00796      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.25         |
|    n_updates             | 5670         |
|    policy_gradient_loss  | -0.000167    |
|    std                   | 0.59         |
|    value_loss            | 22.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4495724   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -518         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1015         |
|    total_timesteps       | 1165312      |
| train/                   |              |
|    approx_kl             | 0.0032590716 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.13         |
|    cost_value_loss       | 9.24         |
|    cost_values           | 3            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00178      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.46         |
|    n_updates             | 5680         |
|    policy_gradient_loss  | -0.000421    |
|    std                   | 0.591        |
|    value_loss            | 17.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5392649   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -513         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1050         |
|    total_timesteps       | 1167360      |
| train/                   |              |
|    approx_kl             | 6.789889e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.93         |
|    cost_value_loss       | 12           |
|    cost_values           | 3            |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000873     |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 5690         |
|    policy_gradient_loss  | 0.000115     |
|    std                   | 0.589        |
|    value_loss            | 19.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67988217  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -508         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1084         |
|    total_timesteps       | 1169408      |
| train/                   |              |
|    approx_kl             | 0.0029749726 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 13.2         |
|    cost_values           | 3            |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00813      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.82         |
|    n_updates             | 5700         |
|    policy_gradient_loss  | -0.000926    |
|    std                   | 0.588        |
|    value_loss            | 19.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5478874  |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -507        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1118        |
|    total_timesteps       | 1171456     |
| train/                   |             |
|    approx_kl             | 0.005333639 |
|    clip_fraction         | 0.0403      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.05        |
|    cost_value_loss       | 27.8        |
|    cost_values           | 3           |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0111      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.44        |
|    n_updates             | 5710        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.588       |
|    value_loss            | 16.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.3773525   |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1153         |
|    total_timesteps       | 1173504      |
| train/                   |              |
|    approx_kl             | 0.0040454655 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.23         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 3            |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.9          |
|    n_updates             | 5720         |
|    policy_gradient_loss  | 0.000258     |
|    std                   | 0.587        |
|    value_loss            | 1.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6879186   |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1187         |
|    total_timesteps       | 1175552      |
| train/                   |              |
|    approx_kl             | 0.0020249567 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 4.45         |
|    cost_values           | 2.98         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.000759     |
|    learning_rate         | 0.0003       |
|    loss                  | 9.98         |
|    n_updates             | 5730         |
|    policy_gradient_loss  | -0.00052     |
|    std                   | 0.588        |
|    value_loss            | 28.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6433298   |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -492         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1221         |
|    total_timesteps       | 1177600      |
| train/                   |              |
|    approx_kl             | 0.0031445294 |
|    clip_fraction         | 0.053        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.21         |
|    cost_value_loss       | 20.5         |
|    cost_values           | 3            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0179       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.53         |
|    n_updates             | 5740         |
|    policy_gradient_loss  | 0.000315     |
|    std                   | 0.591        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40853363  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1255         |
|    total_timesteps       | 1179648      |
| train/                   |              |
|    approx_kl             | 0.0045211413 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.04         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 3            |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00016      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.63         |
|    n_updates             | 5750         |
|    policy_gradient_loss  | -0.000124    |
|    std                   | 0.589        |
|    value_loss            | 4.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.55         |
| reward                   | -0.57058513  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1289         |
|    total_timesteps       | 1181696      |
| train/                   |              |
|    approx_kl             | 0.0007472161 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.91         |
|    cost_value_loss       | 7.76         |
|    cost_values           | 3            |
|    entropy               | -1.77        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00635      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.55         |
|    n_updates             | 5760         |
|    policy_gradient_loss  | -6.81e-05    |
|    std                   | 0.587        |
|    value_loss            | 4.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50878656  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1324         |
|    total_timesteps       | 1183744      |
| train/                   |              |
|    approx_kl             | 0.0038101515 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.44         |
|    cost_value_loss       | 7.36         |
|    cost_values           | 3            |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00469      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.49         |
|    n_updates             | 5770         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.587        |
|    value_loss            | 9.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.38428995  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1359         |
|    total_timesteps       | 1185792      |
| train/                   |              |
|    approx_kl             | 0.0026344545 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.01         |
|    cost_value_loss       | 7.92         |
|    cost_values           | 3            |
|    entropy               | -1.76        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.13         |
|    n_updates             | 5780         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.584        |
|    value_loss            | 1.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45010248  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1393         |
|    total_timesteps       | 1187840      |
| train/                   |              |
|    approx_kl             | 0.0037463848 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.08         |
|    cost_value_loss       | 20.4         |
|    cost_values           | 3            |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 5790         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.584        |
|    value_loss            | 2.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3454125   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1427         |
|    total_timesteps       | 1189888      |
| train/                   |              |
|    approx_kl             | 0.0039667003 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 12.1         |
|    cost_values           | 3            |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00757      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 5800         |
|    policy_gradient_loss  | -0.000311    |
|    std                   | 0.583        |
|    value_loss            | 3.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6627294   |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1462         |
|    total_timesteps       | 1191936      |
| train/                   |              |
|    approx_kl             | 0.0021851375 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.1          |
|    cost_value_loss       | 29.2         |
|    cost_values           | 2.99         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0106       |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 5810         |
|    policy_gradient_loss  | -0.000314    |
|    std                   | 0.582        |
|    value_loss            | 1.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34137323 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -489        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 44          |
|    time_elapsed          | 1496        |
|    total_timesteps       | 1193984     |
| train/                   |             |
|    approx_kl             | 0.004586675 |
|    clip_fraction         | 0.00459     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 17          |
|    cost_values           | 3           |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 5820        |
|    policy_gradient_loss  | -0.000586   |
|    std                   | 0.58        |
|    value_loss            | 8.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6306441   |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1530         |
|    total_timesteps       | 1196032      |
| train/                   |              |
|    approx_kl             | 0.0020625433 |
|    clip_fraction         | 0.00937      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.61         |
|    cost_value_loss       | 9.76         |
|    cost_values           | 3            |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00143      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.31         |
|    n_updates             | 5830         |
|    policy_gradient_loss  | -0.000447    |
|    std                   | 0.581        |
|    value_loss            | 4.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.68073183  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1565         |
|    total_timesteps       | 1198080      |
| train/                   |              |
|    approx_kl             | 0.0067938752 |
|    clip_fraction         | 0.0594       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.98         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00886      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 5840         |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.578        |
|    value_loss            | 33.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.23581807  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1599         |
|    total_timesteps       | 1200128      |
| train/                   |              |
|    approx_kl             | 0.0018562613 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.61         |
|    cost_value_loss       | 23.9         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 5850         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.578        |
|    value_loss            | 2.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27237898 |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 48          |
|    time_elapsed          | 1633        |
|    total_timesteps       | 1202176     |
| train/                   |             |
|    approx_kl             | 0.007595592 |
|    clip_fraction         | 0.0585      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.3         |
|    cost_value_loss       | 30.5        |
|    cost_values           | 3           |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00556     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 5860        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.578       |
|    value_loss            | 20.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48004535  |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 49           |
|    time_elapsed          | 1668         |
|    total_timesteps       | 1204224      |
| train/                   |              |
|    approx_kl             | 0.0019465616 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.29         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 5870         |
|    policy_gradient_loss  | -0.000381    |
|    std                   | 0.577        |
|    value_loss            | 15.2         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.4250903 |
| rollout/           |            |
|    ep_len_mean     | 902        |
|    ep_rew_mean     | -484       |
| time/              |            |
|    fps             | 81         |
|    iterations      | 1          |
|    time_elapsed    | 25         |
|    total_timesteps | 1206272    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.49974865  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1208320      |
| train/                   |              |
|    approx_kl             | 0.0008755667 |
|    clip_fraction         | 0.0717       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.98         |
|    cost_value_loss       | 30.1         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00813      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.39         |
|    n_updates             | 5890         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.577        |
|    value_loss            | 1.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.580865    |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1210368      |
| train/                   |              |
|    approx_kl             | 0.0035347464 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 9.02         |
|    cost_values           | 3            |
|    entropy               | -1.75        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.86         |
|    n_updates             | 5900         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.58         |
|    value_loss            | 3.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5774214  |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 1212416     |
| train/                   |             |
|    approx_kl             | 0.003856131 |
|    clip_fraction         | 0.0131      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 3           |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00884     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 5910        |
|    policy_gradient_loss  | -0.000925   |
|    std                   | 0.58        |
|    value_loss            | 2.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4887733  |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 161         |
|    total_timesteps       | 1214464     |
| train/                   |             |
|    approx_kl             | 0.005757655 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 8.05        |
|    cost_values           | 3           |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00473     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.46        |
|    n_updates             | 5920        |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.577       |
|    value_loss            | 2.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30944842 |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 195         |
|    total_timesteps       | 1216512     |
| train/                   |             |
|    approx_kl             | 0.002943764 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.25        |
|    cost_value_loss       | 6.48        |
|    cost_values           | 3           |
|    entropy               | -1.73       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00539     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.16        |
|    n_updates             | 5930        |
|    policy_gradient_loss  | -0.00052    |
|    std                   | 0.576       |
|    value_loss            | 1.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34678653 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 229         |
|    total_timesteps       | 1218560     |
| train/                   |             |
|    approx_kl             | 0.023691833 |
|    clip_fraction         | 0.0576      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.64        |
|    cost_value_loss       | 23.6        |
|    cost_values           | 3           |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0123      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.5         |
|    n_updates             | 5940        |
|    policy_gradient_loss  | 0.00127     |
|    std                   | 0.577       |
|    value_loss            | 3.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4468252  |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 264         |
|    total_timesteps       | 1220608     |
| train/                   |             |
|    approx_kl             | 0.008425441 |
|    clip_fraction         | 0.069       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 21.8        |
|    cost_values           | 2.99        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 5950        |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.577       |
|    value_loss            | 18.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4534123   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 298          |
|    total_timesteps       | 1222656      |
| train/                   |              |
|    approx_kl             | 0.0043100864 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.68         |
|    cost_value_loss       | 33.8         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 5960         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.577        |
|    value_loss            | 4.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5280889  |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 333         |
|    total_timesteps       | 1224704     |
| train/                   |             |
|    approx_kl             | 0.008059915 |
|    clip_fraction         | 0.0439      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.2         |
|    cost_value_loss       | 20.5        |
|    cost_values           | 3           |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0118      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.02        |
|    n_updates             | 5970        |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.576       |
|    value_loss            | 15.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6366378   |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 1226752      |
| train/                   |              |
|    approx_kl             | 0.0047266446 |
|    clip_fraction         | 0.00879      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.92         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0.000343     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 5980         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.576        |
|    value_loss            | 16.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44244996  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 1228800      |
| train/                   |              |
|    approx_kl             | 0.0032835412 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.12         |
|    cost_value_loss       | 16.3         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00804      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.22         |
|    n_updates             | 5990         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.576        |
|    value_loss            | 1.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4793221  |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 437         |
|    total_timesteps       | 1230848     |
| train/                   |             |
|    approx_kl             | 0.002098472 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.04        |
|    cost_value_loss       | 19.6        |
|    cost_values           | 3           |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00648     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 6000        |
|    policy_gradient_loss  | -0.000917   |
|    std                   | 0.578       |
|    value_loss            | 2.22        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.33276427   |
| rollout/                 |               |
|    ep_len_mean           | 894           |
|    ep_rew_mean           | -447          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 14            |
|    time_elapsed          | 472           |
|    total_timesteps       | 1232896       |
| train/                   |               |
|    approx_kl             | 0.00057443895 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 5.91          |
|    cost_value_loss       | 22.4          |
|    cost_values           | 3             |
|    entropy               | -1.74         |
|    entropy_loss          | -1.74         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00672       |
|    learning_rate         | 0.0003        |
|    loss                  | 6.21          |
|    n_updates             | 6010          |
|    policy_gradient_loss  | 0.000182      |
|    std                   | 0.579         |
|    value_loss            | 14            |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4663355  |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 506         |
|    total_timesteps       | 1234944     |
| train/                   |             |
|    approx_kl             | 0.001398086 |
|    clip_fraction         | 0.000195    |
|    clip_range            | 0.2         |
|    cost_returns          | 5.52        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.99        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.3        |
|    n_updates             | 6020        |
|    policy_gradient_loss  | -0.000168   |
|    std                   | 0.58        |
|    value_loss            | 25.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.77184266 |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 540         |
|    total_timesteps       | 1236992     |
| train/                   |             |
|    approx_kl             | 0.002805847 |
|    clip_fraction         | 0.00923     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.52        |
|    cost_value_loss       | 23.7        |
|    cost_values           | 2.95        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0197      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 6030        |
|    policy_gradient_loss  | -0.000387   |
|    std                   | 0.58        |
|    value_loss            | 2.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5627509   |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 574          |
|    total_timesteps       | 1239040      |
| train/                   |              |
|    approx_kl             | 0.0036301834 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.72         |
|    cost_value_loss       | 24.8         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00426      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.67         |
|    n_updates             | 6040         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.579        |
|    value_loss            | 4.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5439201   |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 609          |
|    total_timesteps       | 1241088      |
| train/                   |              |
|    approx_kl             | 0.0028823374 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.18         |
|    cost_value_loss       | 21.1         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 6050         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.578        |
|    value_loss            | 14           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.758       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.758       |
| reward                   | -0.25838727 |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 644         |
|    total_timesteps       | 1243136     |
| train/                   |             |
|    approx_kl             | 0.005670435 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.84        |
|    cost_value_loss       | 12.1        |
|    cost_values           | 3           |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00849     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.65        |
|    n_updates             | 6060        |
|    policy_gradient_loss  | -0.000514   |
|    std                   | 0.578       |
|    value_loss            | 0.843       |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.92         |
| reward                   | -0.2696594   |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 678          |
|    total_timesteps       | 1245184      |
| train/                   |              |
|    approx_kl             | 0.0035798666 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.37         |
|    cost_value_loss       | 8.78         |
|    cost_values           | 3            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 6070         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.577        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5523755   |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 713          |
|    total_timesteps       | 1247232      |
| train/                   |              |
|    approx_kl             | 0.0024901174 |
|    clip_fraction         | 0.117        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.55         |
|    cost_value_loss       | 16           |
|    cost_values           | 3            |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00215      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.18         |
|    n_updates             | 6080         |
|    policy_gradient_loss  | 0.00282      |
|    std                   | 0.576        |
|    value_loss            | 2.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5786013  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 747         |
|    total_timesteps       | 1249280     |
| train/                   |             |
|    approx_kl             | 0.004048831 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 9.36        |
|    cost_values           | 3           |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.74        |
|    n_updates             | 6090        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.577       |
|    value_loss            | 6.65        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.33022422   |
| rollout/                 |               |
|    ep_len_mean           | 900           |
|    ep_rew_mean           | -442          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 23            |
|    time_elapsed          | 782           |
|    total_timesteps       | 1251328       |
| train/                   |               |
|    approx_kl             | 0.00017940471 |
|    clip_fraction         | 0.0334        |
|    clip_range            | 0.2           |
|    cost_returns          | 7.02          |
|    cost_value_loss       | 24.2          |
|    cost_values           | 3             |
|    entropy               | -1.73         |
|    entropy_loss          | -1.73         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0.00846       |
|    learning_rate         | 0.0003        |
|    loss                  | 5.12          |
|    n_updates             | 6100          |
|    policy_gradient_loss  | -0.00228      |
|    std                   | 0.574         |
|    value_loss            | 5             |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27656034 |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 816         |
|    total_timesteps       | 1253376     |
| train/                   |             |
|    approx_kl             | 0.003964922 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.97        |
|    cost_value_loss       | 32.6        |
|    cost_values           | 3           |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0315      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 6110        |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 0.571       |
|    value_loss            | 4.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5109644   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 851          |
|    total_timesteps       | 1255424      |
| train/                   |              |
|    approx_kl             | 0.0023848782 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.16         |
|    cost_value_loss       | 6.45         |
|    cost_values           | 2.99         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00174      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.9          |
|    n_updates             | 6120         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.569        |
|    value_loss            | 4.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6470042  |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 885         |
|    total_timesteps       | 1257472     |
| train/                   |             |
|    approx_kl             | 0.005567605 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 3           |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00242     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 6130        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.567       |
|    value_loss            | 2.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.30723113  |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 919          |
|    total_timesteps       | 1259520      |
| train/                   |              |
|    approx_kl             | 0.0013558245 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.81         |
|    cost_value_loss       | 18.2         |
|    cost_values           | 2.99         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0111       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 6140         |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.565        |
|    value_loss            | 3.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.643802    |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 954          |
|    total_timesteps       | 1261568      |
| train/                   |              |
|    approx_kl             | 0.0056815157 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.09         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 2.99         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00631      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.95         |
|    n_updates             | 6150         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.563        |
|    value_loss            | 1.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5309422  |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 988         |
|    total_timesteps       | 1263616     |
| train/                   |             |
|    approx_kl             | 0.004438304 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 8.44        |
|    cost_values           | 3           |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.0017      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.3         |
|    n_updates             | 6160        |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 0.563       |
|    value_loss            | 4.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.52398354 |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1023        |
|    total_timesteps       | 1265664     |
| train/                   |             |
|    approx_kl             | 0.00496667  |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.87        |
|    cost_value_loss       | 5.95        |
|    cost_values           | 3           |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.55        |
|    n_updates             | 6170        |
|    policy_gradient_loss  | -0.000981   |
|    std                   | 0.562       |
|    value_loss            | 4.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5384964  |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 1267712     |
| train/                   |             |
|    approx_kl             | 0.005058607 |
|    clip_fraction         | 0.0143      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.78        |
|    cost_value_loss       | 19.8        |
|    cost_values           | 3           |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 6.41e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.82        |
|    n_updates             | 6180        |
|    policy_gradient_loss  | -0.00109    |
|    std                   | 0.562       |
|    value_loss            | 1.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40285966  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1091         |
|    total_timesteps       | 1269760      |
| train/                   |              |
|    approx_kl             | 0.0049775727 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.34         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 3            |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00021      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.82         |
|    n_updates             | 6190         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.561        |
|    value_loss            | 1.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5791149   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1125         |
|    total_timesteps       | 1271808      |
| train/                   |              |
|    approx_kl             | 0.0032286877 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.62         |
|    cost_value_loss       | 4.83         |
|    cost_values           | 3            |
|    entropy               | -1.67        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.7          |
|    n_updates             | 6200         |
|    policy_gradient_loss  | -0.000321    |
|    std                   | 0.559        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.39998773  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1160         |
|    total_timesteps       | 1273856      |
| train/                   |              |
|    approx_kl             | 0.0019014005 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.22         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 2.97         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.9          |
|    n_updates             | 6210         |
|    policy_gradient_loss  | 8.15e-05     |
|    std                   | 0.561        |
|    value_loss            | 2.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.57080203 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1194        |
|    total_timesteps       | 1275904     |
| train/                   |             |
|    approx_kl             | 0.004603192 |
|    clip_fraction         | 0.0401      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 3.77        |
|    cost_values           | 2.98        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.68       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 6220        |
|    policy_gradient_loss  | -0.00239    |
|    std                   | 0.558       |
|    value_loss            | 3.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4783542   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1228         |
|    total_timesteps       | 1277952      |
| train/                   |              |
|    approx_kl             | 0.0033000018 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.71         |
|    cost_value_loss       | 19.9         |
|    cost_values           | 3            |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00937      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 6230         |
|    policy_gradient_loss  | -0.00025     |
|    std                   | 0.558        |
|    value_loss            | 3.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.67667776 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1262        |
|    total_timesteps       | 1280000     |
| train/                   |             |
|    approx_kl             | 0.007878656 |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 1.08        |
|    cost_values           | 2.91        |
|    entropy               | -1.66       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 6240        |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.556       |
|    value_loss            | 3.43        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.3275661    |
| rollout/                 |               |
|    ep_len_mean           | 935           |
|    ep_rew_mean           | -450          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 38            |
|    time_elapsed          | 1296          |
|    total_timesteps       | 1282048       |
| train/                   |               |
|    approx_kl             | 0.00055926025 |
|    clip_fraction         | 0.109         |
|    clip_range            | 0.2           |
|    cost_returns          | 7.3           |
|    cost_value_loss       | 33.5          |
|    cost_values           | 2.92          |
|    entropy               | -1.66         |
|    entropy_loss          | -1.66         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 18.6          |
|    n_updates             | 6250          |
|    policy_gradient_loss  | 0.00419       |
|    std                   | 0.554         |
|    value_loss            | 3.03          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.40595898  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1331         |
|    total_timesteps       | 1284096      |
| train/                   |              |
|    approx_kl             | 0.0030076902 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.98         |
|    cost_value_loss       | 24.4         |
|    cost_values           | 2.99         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0184       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.09         |
|    n_updates             | 6260         |
|    policy_gradient_loss  | -0.000827    |
|    std                   | 0.554        |
|    value_loss            | 4.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6957659  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1365        |
|    total_timesteps       | 1286144     |
| train/                   |             |
|    approx_kl             | 0.007287963 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.79        |
|    cost_value_loss       | 24.7        |
|    cost_values           | 3           |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.7        |
|    n_updates             | 6270        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.553       |
|    value_loss            | 2.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.36        |
| reward                   | -0.24747267 |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1399        |
|    total_timesteps       | 1288192     |
| train/                   |             |
|    approx_kl             | 0.004557361 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.38        |
|    cost_values           | 3           |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00873     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.64        |
|    n_updates             | 6280        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.553       |
|    value_loss            | 3.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.427573    |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1433         |
|    total_timesteps       | 1290240      |
| train/                   |              |
|    approx_kl             | 0.0046632034 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.23         |
|    cost_value_loss       | 20.3         |
|    cost_values           | 3            |
|    entropy               | -1.64        |
|    entropy_loss          | -1.65        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00213      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.82         |
|    n_updates             | 6290         |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 0.551        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.60469264  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1467         |
|    total_timesteps       | 1292288      |
| train/                   |              |
|    approx_kl             | 0.0068909107 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.96         |
|    cost_value_loss       | 22.3         |
|    cost_values           | 3            |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 6300         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.55         |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.58495414  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1501         |
|    total_timesteps       | 1294336      |
| train/                   |              |
|    approx_kl             | 0.0042590713 |
|    clip_fraction         | 0.00894      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 8.88         |
|    cost_values           | 3            |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00351      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.06         |
|    n_updates             | 6310         |
|    policy_gradient_loss  | -0.000359    |
|    std                   | 0.549        |
|    value_loss            | 3.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6107618   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1536         |
|    total_timesteps       | 1296384      |
| train/                   |              |
|    approx_kl             | 0.0016205999 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.19         |
|    cost_value_loss       | 21.3         |
|    cost_values           | 3            |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00018      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.5         |
|    n_updates             | 6320         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.549        |
|    value_loss            | 16.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5643904   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1570         |
|    total_timesteps       | 1298432      |
| train/                   |              |
|    approx_kl             | 0.0042890417 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.61         |
|    cost_value_loss       | 9.88         |
|    cost_values           | 3            |
|    entropy               | -1.63        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000378     |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 6330         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.548        |
|    value_loss            | 15.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.59926695  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1605         |
|    total_timesteps       | 1300480      |
| train/                   |              |
|    approx_kl             | 0.0044657234 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.27         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 3            |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0041       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.58         |
|    n_updates             | 6340         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.547        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54642195  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1639         |
|    total_timesteps       | 1302528      |
| train/                   |              |
|    approx_kl             | 0.0049235676 |
|    clip_fraction         | 0.112        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.94         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 3            |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00674      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 6350         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.546        |
|    value_loss            | 33.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47961134  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1674         |
|    total_timesteps       | 1304576      |
| train/                   |              |
|    approx_kl             | 0.0060146046 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.08         |
|    cost_value_loss       | 26.9         |
|    cost_values           | 2.99         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.63        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00698      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.34         |
|    n_updates             | 6360         |
|    policy_gradient_loss  | -0.000667    |
|    std                   | 0.545        |
|    value_loss            | 2.07         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 8.01        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.30501202 |
| rollout/           |             |
|    ep_len_mean     | 950         |
|    ep_rew_mean     | -456        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1306624     |
------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.71965414 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 1308672     |
| train/                   |             |
|    approx_kl             | 0.005729113 |
|    clip_fraction         | 0.0411      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 8.91        |
|    cost_values           | 3           |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 6380        |
|    policy_gradient_loss  | -0.0033     |
|    std                   | 0.543       |
|    value_loss            | 2.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44871068  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 1310720      |
| train/                   |              |
|    approx_kl             | 0.0038824119 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.49         |
|    cost_value_loss       | 14           |
|    cost_values           | 2.99         |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00369      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.68         |
|    n_updates             | 6390         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.542        |
|    value_loss            | 31.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.76999635  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 126          |
|    total_timesteps       | 1312768      |
| train/                   |              |
|    approx_kl             | 0.0057300404 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.39         |
|    cost_value_loss       | 23.8         |
|    cost_values           | 3            |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0123       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.03         |
|    n_updates             | 6400         |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.542        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.37413463  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 160          |
|    total_timesteps       | 1314816      |
| train/                   |              |
|    approx_kl             | 0.0004408651 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.54         |
|    cost_value_loss       | 16.9         |
|    cost_values           | 3            |
|    entropy               | -1.6         |
|    entropy_loss          | -1.61        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.01         |
|    learning_rate         | 0.0003       |
|    loss                  | 4.34         |
|    n_updates             | 6410         |
|    policy_gradient_loss  | -0.000315    |
|    std                   | 0.538        |
|    value_loss            | 4            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2117259   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 6            |
|    time_elapsed          | 194          |
|    total_timesteps       | 1316864      |
| train/                   |              |
|    approx_kl             | 0.0048454073 |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.33         |
|    cost_value_loss       | 9.96         |
|    cost_values           | 3            |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.03         |
|    n_updates             | 6420         |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 0.535        |
|    value_loss            | 5.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.46784568  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 229          |
|    total_timesteps       | 1318912      |
| train/                   |              |
|    approx_kl             | 0.0029514146 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 10.3         |
|    cost_values           | 3            |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00452      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 6430         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.533        |
|    value_loss            | 3.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.52011645  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 263          |
|    total_timesteps       | 1320960      |
| train/                   |              |
|    approx_kl             | 0.0033903164 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.81         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 3            |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0114       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.1          |
|    n_updates             | 6440         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.532        |
|    value_loss            | 6.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.27         |
| reward                   | -0.52459323  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 297          |
|    total_timesteps       | 1323008      |
| train/                   |              |
|    approx_kl             | 0.0029171568 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.46         |
|    cost_value_loss       | 16           |
|    cost_values           | 2.99         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00479      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 6450         |
|    policy_gradient_loss  | -0.000176    |
|    std                   | 0.532        |
|    value_loss            | 3.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.19844358  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 332          |
|    total_timesteps       | 1325056      |
| train/                   |              |
|    approx_kl             | 0.0045299227 |
|    clip_fraction         | 0.059        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 7.51         |
|    cost_values           | 2.99         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.58        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.14         |
|    n_updates             | 6460         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.532        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6176538   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 366          |
|    total_timesteps       | 1327104      |
| train/                   |              |
|    approx_kl             | 0.0020107536 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.76         |
|    cost_value_loss       | 23.3         |
|    cost_values           | 3            |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00679      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.04         |
|    n_updates             | 6470         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.532        |
|    value_loss            | 9.43         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.64952266   |
| rollout/                 |               |
|    ep_len_mean           | 956           |
|    ep_rew_mean           | -474          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 12            |
|    time_elapsed          | 400           |
|    total_timesteps       | 1329152       |
| train/                   |               |
|    approx_kl             | 0.00073284365 |
|    clip_fraction         | 0.0362        |
|    clip_range            | 0.2           |
|    cost_returns          | 5.96          |
|    cost_value_loss       | 19            |
|    cost_values           | 3             |
|    entropy               | -1.57         |
|    entropy_loss          | -1.57         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00888       |
|    learning_rate         | 0.0003        |
|    loss                  | 5.09          |
|    n_updates             | 6480          |
|    policy_gradient_loss  | 0.000358      |
|    std                   | 0.531         |
|    value_loss            | 14.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.5311089  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 434         |
|    total_timesteps       | 1331200     |
| train/                   |             |
|    approx_kl             | 0.004477987 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 9.78        |
|    cost_values           | 3           |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 6490        |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.53        |
|    value_loss            | 23.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4206114   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 14           |
|    time_elapsed          | 468          |
|    total_timesteps       | 1333248      |
| train/                   |              |
|    approx_kl             | 0.0048182737 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.89         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 3            |
|    entropy               | -1.56        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00418      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.97         |
|    n_updates             | 6500         |
|    policy_gradient_loss  | -0.000368    |
|    std                   | 0.529        |
|    value_loss            | 28.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.37395388  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 502          |
|    total_timesteps       | 1335296      |
| train/                   |              |
|    approx_kl             | 0.0040722643 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.94         |
|    cost_value_loss       | 28.6         |
|    cost_values           | 3            |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0136       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.65         |
|    n_updates             | 6510         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.529        |
|    value_loss            | 2.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44403884  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 16           |
|    time_elapsed          | 536          |
|    total_timesteps       | 1337344      |
| train/                   |              |
|    approx_kl             | 0.0040824693 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.7          |
|    cost_value_loss       | 32.6         |
|    cost_values           | 3            |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0119       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.22         |
|    n_updates             | 6520         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.527        |
|    value_loss            | 4.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.31896198  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 570          |
|    total_timesteps       | 1339392      |
| train/                   |              |
|    approx_kl             | 0.0046562236 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.39         |
|    cost_value_loss       | 8.28         |
|    cost_values           | 3            |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00188      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.79         |
|    n_updates             | 6530         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 0.527        |
|    value_loss            | 0.708        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48210528  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 605          |
|    total_timesteps       | 1341440      |
| train/                   |              |
|    approx_kl             | 0.0022341558 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.47         |
|    cost_value_loss       | 22.4         |
|    cost_values           | 3            |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00558      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 6540         |
|    policy_gradient_loss  | -0.000208    |
|    std                   | 0.525        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.38897827  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 640          |
|    total_timesteps       | 1343488      |
| train/                   |              |
|    approx_kl             | 0.0035378737 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.83         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 2.99         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0.0121       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 6550         |
|    policy_gradient_loss  | -0.000574    |
|    std                   | 0.525        |
|    value_loss            | 3.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7171601   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 674          |
|    total_timesteps       | 1345536      |
| train/                   |              |
|    approx_kl             | 0.0077219764 |
|    clip_fraction         | 0.0863       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.54         |
|    cost_value_loss       | 31.1         |
|    cost_values           | 3            |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0106       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.25         |
|    n_updates             | 6560         |
|    policy_gradient_loss  | -0.000811    |
|    std                   | 0.525        |
|    value_loss            | 2.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6496832  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 709         |
|    total_timesteps       | 1347584     |
| train/                   |             |
|    approx_kl             | 0.004889589 |
|    clip_fraction         | 0.0614      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.89        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 3           |
|    entropy               | -1.54       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 6570        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.523       |
|    value_loss            | 4.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2126529   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 743          |
|    total_timesteps       | 1349632      |
| train/                   |              |
|    approx_kl             | 0.0025348999 |
|    clip_fraction         | 0.00122      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 10.1         |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00348      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 6580         |
|    policy_gradient_loss  | -9.32e-05    |
|    std                   | 0.524        |
|    value_loss            | 3.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5478925   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 778          |
|    total_timesteps       | 1351680      |
| train/                   |              |
|    approx_kl             | 0.0009293904 |
|    clip_fraction         | 0.00542      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.3          |
|    cost_value_loss       | 14.8         |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00343      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.95         |
|    n_updates             | 6590         |
|    policy_gradient_loss  | -0.000934    |
|    std                   | 0.523        |
|    value_loss            | 2.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6557722  |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 813         |
|    total_timesteps       | 1353728     |
| train/                   |             |
|    approx_kl             | 0.002807002 |
|    clip_fraction         | 0.0529      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.81        |
|    cost_value_loss       | 15          |
|    cost_values           | 2.99        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.81        |
|    n_updates             | 6600        |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.522       |
|    value_loss            | 1.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.43748397  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 847          |
|    total_timesteps       | 1355776      |
| train/                   |              |
|    approx_kl             | 0.0015383672 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.55         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 3            |
|    entropy               | -1.53        |
|    entropy_loss          | -1.54        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00363      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.44         |
|    n_updates             | 6610         |
|    policy_gradient_loss  | -0.000283    |
|    std                   | 0.521        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.31647378  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 881          |
|    total_timesteps       | 1357824      |
| train/                   |              |
|    approx_kl             | 0.0029167752 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.62         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 2.99         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00189      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.16         |
|    n_updates             | 6620         |
|    policy_gradient_loss  | -0.000802    |
|    std                   | 0.521        |
|    value_loss            | 16.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.92        |
| reward                   | -0.62306595 |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -466        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 915         |
|    total_timesteps       | 1359872     |
| train/                   |             |
|    approx_kl             | 0.007854492 |
|    clip_fraction         | 0.0633      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.86        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 3           |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 6630        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.521       |
|    value_loss            | 15.7        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.60126007   |
| rollout/                 |               |
|    ep_len_mean           | 937           |
|    ep_rew_mean           | -466          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 28            |
|    time_elapsed          | 950           |
|    total_timesteps       | 1361920       |
| train/                   |               |
|    approx_kl             | 0.00085388555 |
|    clip_fraction         | 9.77e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 6.92          |
|    cost_value_loss       | 29.4          |
|    cost_values           | 3             |
|    entropy               | -1.54         |
|    entropy_loss          | -1.53         |
|    explained_variance    | 1.79e-07      |
|    lagrangian_multiplier | 0.00612       |
|    learning_rate         | 0.0003        |
|    loss                  | 6.66          |
|    n_updates             | 6640          |
|    policy_gradient_loss  | -0.000103     |
|    std                   | 0.522         |
|    value_loss            | 11.1          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.30182463 |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 984         |
|    total_timesteps       | 1363968     |
| train/                   |             |
|    approx_kl             | 0.003792417 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.89        |
|    cost_value_loss       | 21          |
|    cost_values           | 3           |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 6650        |
|    policy_gradient_loss  | -0.000982   |
|    std                   | 0.523       |
|    value_loss            | 2.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.5372137   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1018         |
|    total_timesteps       | 1366016      |
| train/                   |              |
|    approx_kl             | 0.0042543365 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00476      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.59         |
|    n_updates             | 6660         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.523        |
|    value_loss            | 13.3         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.4872332 |
| rollout/                 |            |
|    ep_len_mean           | 931        |
|    ep_rew_mean           | -467       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 31         |
|    time_elapsed          | 1052       |
|    total_timesteps       | 1368064    |
| train/                   |            |
|    approx_kl             | 0.00412702 |
|    clip_fraction         | 0.0134     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.72       |
|    cost_value_loss       | 24.2       |
|    cost_values           | 3          |
|    entropy               | -1.54      |
|    entropy_loss          | -1.54      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.00135    |
|    learning_rate         | 0.0003     |
|    loss                  | 13.6       |
|    n_updates             | 6670       |
|    policy_gradient_loss  | -0.000394  |
|    std                   | 0.522      |
|    value_loss            | 15         |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.46893826 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 32          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 1370112     |
| train/                   |             |
|    approx_kl             | 0.001678119 |
|    clip_fraction         | 0.0163      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.29        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 3           |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00683     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 6680        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.522       |
|    value_loss            | 2.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.88970566  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1120         |
|    total_timesteps       | 1372160      |
| train/                   |              |
|    approx_kl             | 0.0054755104 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.26         |
|    cost_value_loss       | 30.1         |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0129       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.58         |
|    n_updates             | 6690         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.523        |
|    value_loss            | 1.95         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.70738286   |
| rollout/                 |               |
|    ep_len_mean           | 922           |
|    ep_rew_mean           | -460          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 34            |
|    time_elapsed          | 1155          |
|    total_timesteps       | 1374208       |
| train/                   |               |
|    approx_kl             | 0.00084026775 |
|    clip_fraction         | 0.0152        |
|    clip_range            | 0.2           |
|    cost_returns          | 4.46          |
|    cost_value_loss       | 8.5           |
|    cost_values           | 3             |
|    entropy               | -1.54         |
|    entropy_loss          | -1.54         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.92          |
|    n_updates             | 6700          |
|    policy_gradient_loss  | -0.00151      |
|    std                   | 0.523         |
|    value_loss            | 11.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 3.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.17         |
| reward                   | -0.46277735  |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1189         |
|    total_timesteps       | 1376256      |
| train/                   |              |
|    approx_kl             | 0.0006452423 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.67         |
|    cost_value_loss       | 9            |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00764      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.6          |
|    n_updates             | 6710         |
|    policy_gradient_loss  | -0.000636    |
|    std                   | 0.523        |
|    value_loss            | 29.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.60240984  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1223         |
|    total_timesteps       | 1378304      |
| train/                   |              |
|    approx_kl             | 0.0020385657 |
|    clip_fraction         | 0.0577       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.45         |
|    cost_value_loss       | 22.1         |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00849      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 6720         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.523        |
|    value_loss            | 24.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45202956  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1257         |
|    total_timesteps       | 1380352      |
| train/                   |              |
|    approx_kl             | 0.0068268757 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.64         |
|    cost_value_loss       | 30.8         |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.019        |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 6730         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.523        |
|    value_loss            | 16.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4427422  |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 38          |
|    time_elapsed          | 1291        |
|    total_timesteps       | 1382400     |
| train/                   |             |
|    approx_kl             | 0.001507097 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 20.8        |
|    cost_values           | 3           |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00766     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 6740        |
|    policy_gradient_loss  | -0.000353   |
|    std                   | 0.522       |
|    value_loss            | 6.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5052204   |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1325         |
|    total_timesteps       | 1384448      |
| train/                   |              |
|    approx_kl             | 0.0032228068 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.52         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 3            |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00703      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 6750         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.521        |
|    value_loss            | 4.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.36001438  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1360         |
|    total_timesteps       | 1386496      |
| train/                   |              |
|    approx_kl             | 0.0050771106 |
|    clip_fraction         | 0.00674      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.35         |
|    cost_value_loss       | 13.8         |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000677     |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 6760         |
|    policy_gradient_loss  | -0.000511    |
|    std                   | 0.522        |
|    value_loss            | 23.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.44157323  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1394         |
|    total_timesteps       | 1388544      |
| train/                   |              |
|    approx_kl             | 0.0040057497 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.64         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 3            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00423      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.48         |
|    n_updates             | 6770         |
|    policy_gradient_loss  | 0.000685     |
|    std                   | 0.522        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.36519584  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1428         |
|    total_timesteps       | 1390592      |
| train/                   |              |
|    approx_kl             | 0.0043874355 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 16.3         |
|    cost_values           | 3            |
|    entropy               | -1.53        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00886      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.17         |
|    n_updates             | 6780         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.521        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4097235   |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1463         |
|    total_timesteps       | 1392640      |
| train/                   |              |
|    approx_kl             | 0.0034828812 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.92         |
|    cost_value_loss       | 32.4         |
|    cost_values           | 3            |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0111       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 6790         |
|    policy_gradient_loss  | -0.000244    |
|    std                   | 0.52         |
|    value_loss            | 1.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6278871  |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 44          |
|    time_elapsed          | 1497        |
|    total_timesteps       | 1394688     |
| train/                   |             |
|    approx_kl             | 0.008091726 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.24        |
|    cost_value_loss       | 32.4        |
|    cost_values           | 2.99        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.8        |
|    n_updates             | 6800        |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 0.52        |
|    value_loss            | 20.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.63533443  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1531         |
|    total_timesteps       | 1396736      |
| train/                   |              |
|    approx_kl             | 0.0048109936 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.75         |
|    cost_value_loss       | 23.6         |
|    cost_values           | 2.99         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0516       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.38         |
|    n_updates             | 6810         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.52         |
|    value_loss            | 2.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.39036566 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 46          |
|    time_elapsed          | 1565        |
|    total_timesteps       | 1398784     |
| train/                   |             |
|    approx_kl             | 0.013412591 |
|    clip_fraction         | 0.085       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.49        |
|    cost_value_loss       | 23.2        |
|    cost_values           | 3           |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000104    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 6820        |
|    policy_gradient_loss  | -0.00471    |
|    std                   | 0.519       |
|    value_loss            | 4.88        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.42754427  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1600         |
|    total_timesteps       | 1400832      |
| train/                   |              |
|    approx_kl             | 0.0022874984 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.29         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00561      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 6830         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.52         |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40973395  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1633         |
|    total_timesteps       | 1402880      |
| train/                   |              |
|    approx_kl             | 0.0066667497 |
|    clip_fraction         | 0.0485       |
|    clip_range            | 0.2          |
|    cost_returns          | 7            |
|    cost_value_loss       | 27.6         |
|    cost_values           | 3            |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0127       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 6840         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.52         |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.44906452  |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 49           |
|    time_elapsed          | 1668         |
|    total_timesteps       | 1404928      |
| train/                   |              |
|    approx_kl             | 0.0062368466 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.69         |
|    cost_value_loss       | 4.84         |
|    cost_values           | 2.99         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00362      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.03         |
|    n_updates             | 6850         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.519        |
|    value_loss            | 19.5         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.01       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.01       |
| reward             | -0.7571572 |
| rollout/           |            |
|    ep_len_mean     | 878        |
|    ep_rew_mean     | -429       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1406976    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48595133 |
| rollout/                 |             |
|    ep_len_mean           | 878         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 1409024     |
| train/                   |             |
|    approx_kl             | 0.004688845 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 15          |
|    cost_values           | 3           |
|    entropy               | -1.52       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00795     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 6870        |
|    policy_gradient_loss  | -0.000862   |
|    std                   | 0.518       |
|    value_loss            | 3.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50112075  |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1411072      |
| train/                   |              |
|    approx_kl             | 0.0015989752 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.09         |
|    cost_value_loss       | 25.9         |
|    cost_values           | 3            |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0126       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 6880         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.519        |
|    value_loss            | 3.2          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5655453 |
| rollout/                 |            |
|    ep_len_mean           | 864        |
|    ep_rew_mean           | -422       |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 4          |
|    time_elapsed          | 128        |
|    total_timesteps       | 1413120    |
| train/                   |            |
|    approx_kl             | 0.00581182 |
|    clip_fraction         | 0.0119     |
|    clip_range            | 0.2        |
|    cost_returns          | 4.71       |
|    cost_value_loss       | 8.44       |
|    cost_values           | 3          |
|    entropy               | -1.52      |
|    entropy_loss          | -1.52      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.0047     |
|    learning_rate         | 0.0003     |
|    loss                  | 8.51       |
|    n_updates             | 6890       |
|    policy_gradient_loss  | -0.000545  |
|    std                   | 0.518      |
|    value_loss            | 25.5       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3972774  |
| rollout/                 |             |
|    ep_len_mean           | 864         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 161         |
|    total_timesteps       | 1415168     |
| train/                   |             |
|    approx_kl             | 0.010607334 |
|    clip_fraction         | 0.0256      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.07        |
|    cost_values           | 3           |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00791     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 6900        |
|    policy_gradient_loss  | -0.000197   |
|    std                   | 0.517       |
|    value_loss            | 12.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47294673  |
| rollout/                 |              |
|    ep_len_mean           | 866          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 1417216      |
| train/                   |              |
|    approx_kl             | 0.0023087207 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.25         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 3            |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00781      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.1          |
|    n_updates             | 6910         |
|    policy_gradient_loss  | -0.000649    |
|    std                   | 0.517        |
|    value_loss            | 2.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5822791   |
| rollout/                 |              |
|    ep_len_mean           | 875          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 1419264      |
| train/                   |              |
|    approx_kl             | 0.0036569294 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.82         |
|    cost_value_loss       | 18.8         |
|    cost_values           | 3            |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0106       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.13         |
|    n_updates             | 6920         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.516        |
|    value_loss            | 2.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.7344325  |
| rollout/                 |             |
|    ep_len_mean           | 867         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 265         |
|    total_timesteps       | 1421312     |
| train/                   |             |
|    approx_kl             | 0.004820042 |
|    clip_fraction         | 0.0063      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 19.4        |
|    cost_values           | 3           |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00603     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 6930        |
|    policy_gradient_loss  | -0.00088    |
|    std                   | 0.515       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.390024   |
| rollout/                 |             |
|    ep_len_mean           | 850         |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 300         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.004295907 |
|    clip_fraction         | 0.0721      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 6.13        |
|    cost_values           | 2.99        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 6940        |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 0.514       |
|    value_loss            | 20.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.71493435 |
| rollout/                 |             |
|    ep_len_mean           | 850         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 1425408     |
| train/                   |             |
|    approx_kl             | 0.005547561 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 15.6        |
|    cost_values           | 3           |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00613     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.53        |
|    n_updates             | 6950        |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.514       |
|    value_loss            | 25.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40798503  |
| rollout/                 |              |
|    ep_len_mean           | 843          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 1427456      |
| train/                   |              |
|    approx_kl             | 0.0024571721 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 3            |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 6960         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.514        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52728343  |
| rollout/                 |              |
|    ep_len_mean           | 843          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 1429504      |
| train/                   |              |
|    approx_kl             | 0.0023089293 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.08         |
|    cost_value_loss       | 7.44         |
|    cost_values           | 3            |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 6970         |
|    policy_gradient_loss  | -0.000149    |
|    std                   | 0.514        |
|    value_loss            | 24.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.18843748  |
| rollout/                 |              |
|    ep_len_mean           | 843          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 1431552      |
| train/                   |              |
|    approx_kl             | 0.0044734036 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.54         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 3            |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00403      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.16         |
|    n_updates             | 6980         |
|    policy_gradient_loss  | -0.000773    |
|    std                   | 0.514        |
|    value_loss            | 8.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.90479404  |
| rollout/                 |              |
|    ep_len_mean           | 843          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 1433600      |
| train/                   |              |
|    approx_kl             | 0.0036418901 |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.27         |
|    cost_value_loss       | 8.66         |
|    cost_values           | 2.99         |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 6990         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.512        |
|    value_loss            | 6.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.3722855   |
| rollout/                 |              |
|    ep_len_mean           | 836          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 507          |
|    total_timesteps       | 1435648      |
| train/                   |              |
|    approx_kl             | 0.0033122133 |
|    clip_fraction         | 0.0402       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 4.6          |
|    cost_values           | 3            |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00747      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 7000         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.51         |
|    value_loss            | 6.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5149936   |
| rollout/                 |              |
|    ep_len_mean           | 842          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 541          |
|    total_timesteps       | 1437696      |
| train/                   |              |
|    approx_kl             | 0.0042471313 |
|    clip_fraction         | 0.0468       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.39         |
|    cost_value_loss       | 8.65         |
|    cost_values           | 3            |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00387      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.37         |
|    n_updates             | 7010         |
|    policy_gradient_loss  | -0.000876    |
|    std                   | 0.509        |
|    value_loss            | 27.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.234         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.234         |
| reward                   | -0.3160403    |
| rollout/                 |               |
|    ep_len_mean           | 844           |
|    ep_rew_mean           | -427          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 17            |
|    time_elapsed          | 576           |
|    total_timesteps       | 1439744       |
| train/                   |               |
|    approx_kl             | 0.00035010392 |
|    clip_fraction         | 0.00518       |
|    clip_range            | 0.2           |
|    cost_returns          | 3.88          |
|    cost_value_loss       | 4.85          |
|    cost_values           | 3             |
|    entropy               | -1.47         |
|    entropy_loss          | -1.48         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.02          |
|    n_updates             | 7020          |
|    policy_gradient_loss  | -0.000318     |
|    std                   | 0.506         |
|    value_loss            | 7.3           |
--------------------------------------------
------------------------------------------
| avg_speed                | 4.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.01        |
| reward                   | -0.6379767  |
| rollout/                 |             |
|    ep_len_mean           | 847         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 610         |
|    total_timesteps       | 1441792     |
| train/                   |             |
|    approx_kl             | 0.005406199 |
|    clip_fraction         | 0.0793      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 3.46        |
|    cost_values           | 2.98        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 7030        |
|    policy_gradient_loss  | -0.00525    |
|    std                   | 0.506       |
|    value_loss            | 24.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.42         |
| reward                   | -0.46806073  |
| rollout/                 |              |
|    ep_len_mean           | 849          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 1443840      |
| train/                   |              |
|    approx_kl             | 0.0011202493 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 6.36         |
|    cost_values           | 2.96         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.63         |
|    n_updates             | 7040         |
|    policy_gradient_loss  | 9.56e-05     |
|    std                   | 0.507        |
|    value_loss            | 14.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8198112  |
| rollout/                 |             |
|    ep_len_mean           | 838         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 679         |
|    total_timesteps       | 1445888     |
| train/                   |             |
|    approx_kl             | 0.006735648 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.99        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.51        |
|    n_updates             | 7050        |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 0.507       |
|    value_loss            | 3.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31046513  |
| rollout/                 |              |
|    ep_len_mean           | 838          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 713          |
|    total_timesteps       | 1447936      |
| train/                   |              |
|    approx_kl             | 0.0030064064 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.17         |
|    cost_value_loss       | 19           |
|    cost_values           | 3            |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00685      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.68         |
|    n_updates             | 7060         |
|    policy_gradient_loss  | -0.000633    |
|    std                   | 0.507        |
|    value_loss            | 31.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.18        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.18        |
| reward                   | -0.42818514 |
| rollout/                 |             |
|    ep_len_mean           | 836         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 747         |
|    total_timesteps       | 1449984     |
| train/                   |             |
|    approx_kl             | 0.003311038 |
|    clip_fraction         | 0.00615     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.36        |
|    cost_value_loss       | 9.26        |
|    cost_values           | 3           |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 7070        |
|    policy_gradient_loss  | -0.000604   |
|    std                   | 0.507       |
|    value_loss            | 16.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.46075004 |
| rollout/                 |             |
|    ep_len_mean           | 828         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 782         |
|    total_timesteps       | 1452032     |
| train/                   |             |
|    approx_kl             | 0.006099177 |
|    clip_fraction         | 0.0361      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.65        |
|    cost_value_loss       | 15.7        |
|    cost_values           | 3           |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.0053      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.6         |
|    n_updates             | 7080        |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.506       |
|    value_loss            | 21.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.48838657 |
| rollout/                 |             |
|    ep_len_mean           | 811         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 816         |
|    total_timesteps       | 1454080     |
| train/                   |             |
|    approx_kl             | 0.00866207  |
|    clip_fraction         | 0.0484      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.49        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 3           |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00684     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 7090        |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 0.507       |
|    value_loss            | 19.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7173393   |
| rollout/                 |              |
|    ep_len_mean           | 820          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 850          |
|    total_timesteps       | 1456128      |
| train/                   |              |
|    approx_kl             | 0.0065551507 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.67         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 3            |
|    entropy               | -1.47        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00891      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.8          |
|    n_updates             | 7100         |
|    policy_gradient_loss  | -0.000382    |
|    std                   | 0.506        |
|    value_loss            | 31.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55660135  |
| rollout/                 |              |
|    ep_len_mean           | 824          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 884          |
|    total_timesteps       | 1458176      |
| train/                   |              |
|    approx_kl             | 0.0026191191 |
|    clip_fraction         | 0.00942      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.44         |
|    cost_value_loss       | 23.8         |
|    cost_values           | 3            |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.01         |
|    learning_rate         | 0.0003       |
|    loss                  | 4.82         |
|    n_updates             | 7110         |
|    policy_gradient_loss  | -0.000939    |
|    std                   | 0.505        |
|    value_loss            | 2.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.71907216 |
| rollout/                 |             |
|    ep_len_mean           | 825         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 918         |
|    total_timesteps       | 1460224     |
| train/                   |             |
|    approx_kl             | 0.006545925 |
|    clip_fraction         | 0.029       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.28        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 3           |
|    entropy               | -1.48       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00465     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.48        |
|    n_updates             | 7120        |
|    policy_gradient_loss  | -0.000737   |
|    std                   | 0.506       |
|    value_loss            | 19.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6850793   |
| rollout/                 |              |
|    ep_len_mean           | 825          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 952          |
|    total_timesteps       | 1462272      |
| train/                   |              |
|    approx_kl             | 0.0021761013 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.97         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 3            |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00316      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 7130         |
|    policy_gradient_loss  | -0.000679    |
|    std                   | 0.506        |
|    value_loss            | 5.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.57402813  |
| rollout/                 |              |
|    ep_len_mean           | 825          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 986          |
|    total_timesteps       | 1464320      |
| train/                   |              |
|    approx_kl             | 0.0043247757 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.07         |
|    cost_value_loss       | 14           |
|    cost_values           | 3            |
|    entropy               | -1.47        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00684      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.51         |
|    n_updates             | 7140         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.506        |
|    value_loss            | 6.78         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.80586904 |
| rollout/                 |             |
|    ep_len_mean           | 825         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 1466368     |
| train/                   |             |
|    approx_kl             | 0.004968229 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.92        |
|    cost_value_loss       | 7.38        |
|    cost_values           | 3           |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00255     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.06        |
|    n_updates             | 7150        |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 0.505       |
|    value_loss            | 4.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1094077  |
| rollout/                 |             |
|    ep_len_mean           | 834         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1054        |
|    total_timesteps       | 1468416     |
| train/                   |             |
|    approx_kl             | 0.005862006 |
|    clip_fraction         | 0.027       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 3           |
|    entropy               | -1.46       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.4         |
|    n_updates             | 7160        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.503       |
|    value_loss            | 6.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.57337356 |
| rollout/                 |             |
|    ep_len_mean           | 834         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 32          |
|    time_elapsed          | 1088        |
|    total_timesteps       | 1470464     |
| train/                   |             |
|    approx_kl             | 0.003438992 |
|    clip_fraction         | 0.00654     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 8.6         |
|    cost_values           | 3           |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00754     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 7170        |
|    policy_gradient_loss  | -0.000269   |
|    std                   | 0.505       |
|    value_loss            | 8.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.9499441  |
| rollout/                 |             |
|    ep_len_mean           | 832         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1123        |
|    total_timesteps       | 1472512     |
| train/                   |             |
|    approx_kl             | 0.004511427 |
|    clip_fraction         | 0.0251      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.96        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 3           |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0108      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.59        |
|    n_updates             | 7180        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.505       |
|    value_loss            | 14.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.41357714  |
| rollout/                 |              |
|    ep_len_mean           | 832          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1157         |
|    total_timesteps       | 1474560      |
| train/                   |              |
|    approx_kl             | 0.0039145183 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.54         |
|    cost_value_loss       | 17.7         |
|    cost_values           | 3            |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00209      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 7190         |
|    policy_gradient_loss  | -0.000813    |
|    std                   | 0.503        |
|    value_loss            | 24.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.66668063 |
| rollout/                 |             |
|    ep_len_mean           | 838         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1192        |
|    total_timesteps       | 1476608     |
| train/                   |             |
|    approx_kl             | 0.003948022 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 7.9         |
|    cost_values           | 2.99        |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00145     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.83        |
|    n_updates             | 7200        |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.501       |
|    value_loss            | 8.63        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.4284529 |
| rollout/                 |            |
|    ep_len_mean           | 838        |
|    ep_rew_mean           | -469       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 36         |
|    time_elapsed          | 1226       |
|    total_timesteps       | 1478656    |
| train/                   |            |
|    approx_kl             | 0.01373297 |
|    clip_fraction         | 0.0854     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.54       |
|    cost_value_loss       | 4.39       |
|    cost_values           | 3          |
|    entropy               | -1.44      |
|    entropy_loss          | -1.45      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0.00312    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.83       |
|    n_updates             | 7210       |
|    policy_gradient_loss  | -0.00365   |
|    std                   | 0.498      |
|    value_loss            | 26.8       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.2034577   |
| rollout/                 |              |
|    ep_len_mean           | 838          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1260         |
|    total_timesteps       | 1480704      |
| train/                   |              |
|    approx_kl             | 0.0030780248 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.33         |
|    cost_value_loss       | 15.8         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.5         |
|    n_updates             | 7220         |
|    policy_gradient_loss  | -0.000802    |
|    std                   | 0.496        |
|    value_loss            | 20.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6274643   |
| rollout/                 |              |
|    ep_len_mean           | 838          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1294         |
|    total_timesteps       | 1482752      |
| train/                   |              |
|    approx_kl             | 0.0032828257 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.09         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 7230         |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.496        |
|    value_loss            | 18.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5024138   |
| rollout/                 |              |
|    ep_len_mean           | 845          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1328         |
|    total_timesteps       | 1484800      |
| train/                   |              |
|    approx_kl             | 0.0028506308 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.52         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 2.99         |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0118       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.45         |
|    n_updates             | 7240         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.496        |
|    value_loss            | 24.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.97611547  |
| rollout/                 |              |
|    ep_len_mean           | 845          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1363         |
|    total_timesteps       | 1486848      |
| train/                   |              |
|    approx_kl             | 0.0024939594 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.9          |
|    cost_value_loss       | 15.6         |
|    cost_values           | 3            |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00184      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 7250         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.495        |
|    value_loss            | 7.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7157963   |
| rollout/                 |              |
|    ep_len_mean           | 854          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1397         |
|    total_timesteps       | 1488896      |
| train/                   |              |
|    approx_kl             | 0.0015254198 |
|    clip_fraction         | 0.0105       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.18         |
|    cost_value_loss       | 6.46         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.43        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 7260         |
|    policy_gradient_loss  | -0.000915    |
|    std                   | 0.497        |
|    value_loss            | 31           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.82380736  |
| rollout/                 |              |
|    ep_len_mean           | 854          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1432         |
|    total_timesteps       | 1490944      |
| train/                   |              |
|    approx_kl             | 0.0032410582 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.23         |
|    cost_value_loss       | 6.71         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0062       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 7270         |
|    policy_gradient_loss  | -0.000895    |
|    std                   | 0.496        |
|    value_loss            | 7.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.4353706   |
| rollout/                 |              |
|    ep_len_mean           | 854          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1466         |
|    total_timesteps       | 1492992      |
| train/                   |              |
|    approx_kl             | 0.0042430637 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 7.03         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00142      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.8          |
|    n_updates             | 7280         |
|    policy_gradient_loss  | -0.000897    |
|    std                   | 0.497        |
|    value_loss            | 23.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8468127   |
| rollout/                 |              |
|    ep_len_mean           | 854          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1500         |
|    total_timesteps       | 1495040      |
| train/                   |              |
|    approx_kl             | 0.0042680423 |
|    clip_fraction         | 0.00903      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.07         |
|    cost_value_loss       | 5.28         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 7290         |
|    policy_gradient_loss  | -0.000785    |
|    std                   | 0.497        |
|    value_loss            | 15.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4576784   |
| rollout/                 |              |
|    ep_len_mean           | 861          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1534         |
|    total_timesteps       | 1497088      |
| train/                   |              |
|    approx_kl             | 0.0026921984 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.07         |
|    cost_value_loss       | 7.67         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.000684     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 7300         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.496        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4748299   |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1569         |
|    total_timesteps       | 1499136      |
| train/                   |              |
|    approx_kl             | 0.0061197085 |
|    clip_fraction         | 0.0461       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.3          |
|    cost_value_loss       | 14.4         |
|    cost_values           | 3            |
|    entropy               | -1.43        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.96         |
|    n_updates             | 7310         |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 0.496        |
|    value_loss            | 3.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.59760517  |
| rollout/                 |              |
|    ep_len_mean           | 873          |
|    ep_rew_mean           | -508         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1602         |
|    total_timesteps       | 1501184      |
| train/                   |              |
|    approx_kl             | 0.0035535502 |
|    clip_fraction         | 0.0471       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.5          |
|    cost_value_loss       | 14.9         |
|    cost_values           | 3            |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00617      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.59         |
|    n_updates             | 7320         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.495        |
|    value_loss            | 4.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.70827967  |
| rollout/                 |              |
|    ep_len_mean           | 863          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1637         |
|    total_timesteps       | 1503232      |
| train/                   |              |
|    approx_kl             | 0.0013774676 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.27         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.43        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00736      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.84         |
|    n_updates             | 7330         |
|    policy_gradient_loss  | 0.000601     |
|    std                   | 0.496        |
|    value_loss            | 2.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.8201254  |
| rollout/                 |             |
|    ep_len_mean           | 863         |
|    ep_rew_mean           | -508        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 49          |
|    time_elapsed          | 1671        |
|    total_timesteps       | 1505280     |
| train/                   |             |
|    approx_kl             | 0.004613266 |
|    clip_fraction         | 0.0408      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 5.8         |
|    cost_values           | 3           |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 7340        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.497       |
|    value_loss            | 19.7        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.6179022 |
| rollout/           |            |
|    ep_len_mean     | 872        |
|    ep_rew_mean     | -515       |
| time/              |            |
|    fps             | 84         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1507328    |
-----------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.5168586  |
| rollout/                 |             |
|    ep_len_mean           | 872         |
|    ep_rew_mean           | -513        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 1509376     |
| train/                   |             |
|    approx_kl             | 0.004242525 |
|    clip_fraction         | 0.0138      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 3           |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00457     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.55        |
|    n_updates             | 7360        |
|    policy_gradient_loss  | -0.000383   |
|    std                   | 0.495       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.78127164  |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 1511424      |
| train/                   |              |
|    approx_kl             | 0.0026819115 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.76         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 3            |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00736      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.58         |
|    n_updates             | 7370         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.495        |
|    value_loss            | 7.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55551183 |
| rollout/                 |             |
|    ep_len_mean           | 889         |
|    ep_rew_mean           | -526        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 126         |
|    total_timesteps       | 1513472     |
| train/                   |             |
|    approx_kl             | 0.006530942 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 3           |
|    entropy               | -1.44       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00274     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.54        |
|    n_updates             | 7380        |
|    policy_gradient_loss  | -0.000588   |
|    std                   | 0.496       |
|    value_loss            | 5.88        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.91600746  |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 160          |
|    total_timesteps       | 1515520      |
| train/                   |              |
|    approx_kl             | 0.0015040569 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 5.6          |
|    cost_values           | 3            |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00248      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.32         |
|    n_updates             | 7390         |
|    policy_gradient_loss  | -0.000118    |
|    std                   | 0.495        |
|    value_loss            | 6.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5627685  |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -526        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 6           |
|    time_elapsed          | 194         |
|    total_timesteps       | 1517568     |
| train/                   |             |
|    approx_kl             | 0.005278917 |
|    clip_fraction         | 0.0173      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.37        |
|    cost_value_loss       | 2.89        |
|    cost_values           | 2.99        |
|    entropy               | -1.44       |
|    entropy_loss          | -1.43       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00455     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.29        |
|    n_updates             | 7400        |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.496       |
|    value_loss            | 12.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8873121   |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 228          |
|    total_timesteps       | 1519616      |
| train/                   |              |
|    approx_kl             | 0.0050065457 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.7          |
|    cost_value_loss       | 15.7         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 7410         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.497        |
|    value_loss            | 9.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5060539   |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -521         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 262          |
|    total_timesteps       | 1521664      |
| train/                   |              |
|    approx_kl             | 0.0026698546 |
|    clip_fraction         | 0.0494       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.77         |
|    cost_value_loss       | 16.2         |
|    cost_values           | 3            |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.1         |
|    n_updates             | 7420         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.496        |
|    value_loss            | 23.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.8528502  |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -518        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 9           |
|    time_elapsed          | 296         |
|    total_timesteps       | 1523712     |
| train/                   |             |
|    approx_kl             | 0.010146746 |
|    clip_fraction         | 0.0405      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 8.91        |
|    cost_values           | 3           |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00474     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 7430        |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.496       |
|    value_loss            | 8.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.5789777   |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -523         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 331          |
|    total_timesteps       | 1525760      |
| train/                   |              |
|    approx_kl             | 0.0024016483 |
|    clip_fraction         | 0.00483      |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 13           |
|    cost_values           | 3            |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.01         |
|    learning_rate         | 0.0003       |
|    loss                  | 3.82         |
|    n_updates             | 7440         |
|    policy_gradient_loss  | -0.000513    |
|    std                   | 0.493        |
|    value_loss            | 2.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7414154  |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -524        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 366         |
|    total_timesteps       | 1527808     |
| train/                   |             |
|    approx_kl             | 0.005233392 |
|    clip_fraction         | 0.029       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 8.01        |
|    cost_values           | 3           |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00571     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 7450        |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 0.492       |
|    value_loss            | 8.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6665713   |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -526         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 400          |
|    total_timesteps       | 1529856      |
| train/                   |              |
|    approx_kl             | 0.0031383093 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.59         |
|    cost_value_loss       | 9.37         |
|    cost_values           | 3            |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00734      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.96         |
|    n_updates             | 7460         |
|    policy_gradient_loss  | -0.000454    |
|    std                   | 0.491        |
|    value_loss            | 5.58         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25956565 |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -519        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 435         |
|    total_timesteps       | 1531904     |
| train/                   |             |
|    approx_kl             | 0.004204483 |
|    clip_fraction         | 0.0138      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 3           |
|    entropy               | -1.41       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00519     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 7470        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.491       |
|    value_loss            | 6.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54865634  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -518         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 14           |
|    time_elapsed          | 469          |
|    total_timesteps       | 1533952      |
| train/                   |              |
|    approx_kl             | 0.0053607514 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.53         |
|    cost_value_loss       | 14.4         |
|    cost_values           | 3            |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00391      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.73         |
|    n_updates             | 7480         |
|    policy_gradient_loss  | -0.00071     |
|    std                   | 0.491        |
|    value_loss            | 21.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.98         |
| reward                   | -0.41006324  |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -519         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 503          |
|    total_timesteps       | 1536000      |
| train/                   |              |
|    approx_kl             | 0.0072419834 |
|    clip_fraction         | 0.0505       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.82         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 3            |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00351      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.02         |
|    n_updates             | 7490         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.491        |
|    value_loss            | 4.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25147122 |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -516        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 537         |
|    total_timesteps       | 1538048     |
| train/                   |             |
|    approx_kl             | 0.004455893 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 3           |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00202     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.35        |
|    n_updates             | 7500        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.491       |
|    value_loss            | 19.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3819195   |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 571          |
|    total_timesteps       | 1540096      |
| train/                   |              |
|    approx_kl             | 0.0048057083 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.09         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 3            |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00871      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 7510         |
|    policy_gradient_loss  | -0.000801    |
|    std                   | 0.49         |
|    value_loss            | 6.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.74241686 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -524        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 605         |
|    total_timesteps       | 1542144     |
| train/                   |             |
|    approx_kl             | 0.002431562 |
|    clip_fraction         | 0.00977     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.34        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 3           |
|    entropy               | -1.4        |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00837     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 7520        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.488       |
|    value_loss            | 4.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.489814    |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -526         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 639          |
|    total_timesteps       | 1544192      |
| train/                   |              |
|    approx_kl             | 0.0026277008 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.98         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 3            |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 7530         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.489        |
|    value_loss            | 3.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5717725   |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -528         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 674          |
|    total_timesteps       | 1546240      |
| train/                   |              |
|    approx_kl             | 0.0037863082 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.66         |
|    cost_value_loss       | 4.04         |
|    cost_values           | 3            |
|    entropy               | -1.39        |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00225      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 7540         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.484        |
|    value_loss            | 21.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8603355   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 708          |
|    total_timesteps       | 1548288      |
| train/                   |              |
|    approx_kl             | 0.0037907748 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.38         |
|    cost_value_loss       | 9.19         |
|    cost_values           | 3            |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00175      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 7550         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.482        |
|    value_loss            | 3.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.60848475  |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 743          |
|    total_timesteps       | 1550336      |
| train/                   |              |
|    approx_kl             | 0.0027704323 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.48         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 3            |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0062       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.29         |
|    n_updates             | 7560         |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.483        |
|    value_loss            | 9.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7938909  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -540        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 777         |
|    total_timesteps       | 1552384     |
| train/                   |             |
|    approx_kl             | 0.005268274 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.72        |
|    cost_value_loss       | 15.3        |
|    cost_values           | 3           |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.93        |
|    n_updates             | 7570        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.483       |
|    value_loss            | 3.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7845542   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -540         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 812          |
|    total_timesteps       | 1554432      |
| train/                   |              |
|    approx_kl             | 0.0063029276 |
|    clip_fraction         | 0.0712       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.09         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 3            |
|    entropy               | -1.37        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00871      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.76         |
|    n_updates             | 7580         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.481        |
|    value_loss            | 2.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.435981   |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -527        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 25          |
|    time_elapsed          | 847         |
|    total_timesteps       | 1556480     |
| train/                   |             |
|    approx_kl             | 0.004328392 |
|    clip_fraction         | 0.0118      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.97        |
|    cost_value_loss       | 5.74        |
|    cost_values           | 3           |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000658    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 7590        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.48        |
|    value_loss            | 3.87        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.72487867  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -528         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 881          |
|    total_timesteps       | 1558528      |
| train/                   |              |
|    approx_kl             | 0.0041608615 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 14.4         |
|    cost_values           | 3            |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00484      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.99         |
|    n_updates             | 7600         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.479        |
|    value_loss            | 34.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.4367452  |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -528        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 915         |
|    total_timesteps       | 1560576     |
| train/                   |             |
|    approx_kl             | 0.002429651 |
|    clip_fraction         | 0.0117      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.69        |
|    cost_value_loss       | 4.22        |
|    cost_values           | 3           |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 7610        |
|    policy_gradient_loss  | -0.000528   |
|    std                   | 0.478       |
|    value_loss            | 5.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.47453347 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 949         |
|    total_timesteps       | 1562624     |
| train/                   |             |
|    approx_kl             | 0.004319109 |
|    clip_fraction         | 0.0642      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.1         |
|    cost_value_loss       | 17.8        |
|    cost_values           | 3           |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00336     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.52        |
|    n_updates             | 7620        |
|    policy_gradient_loss  | 0.00108     |
|    std                   | 0.477       |
|    value_loss            | 6.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48690698  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -526         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 984          |
|    total_timesteps       | 1564672      |
| train/                   |              |
|    approx_kl             | 0.0058250865 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.15         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 3            |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00675      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.17         |
|    n_updates             | 7630         |
|    policy_gradient_loss  | 0.000374     |
|    std                   | 0.478        |
|    value_loss            | 3.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25488594 |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -520        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1018        |
|    total_timesteps       | 1566720     |
| train/                   |             |
|    approx_kl             | 0.00556927  |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 8.87        |
|    cost_values           | 3           |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00707     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.82        |
|    n_updates             | 7640        |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.479       |
|    value_loss            | 4.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9126534   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -516         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1052         |
|    total_timesteps       | 1568768      |
| train/                   |              |
|    approx_kl             | 0.0032609855 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 2.5          |
|    cost_values           | 2.99         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.59         |
|    n_updates             | 7650         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.478        |
|    value_loss            | 5.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.31155926  |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1086         |
|    total_timesteps       | 1570816      |
| train/                   |              |
|    approx_kl             | 0.0037684895 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.14         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 3            |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00367      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.46         |
|    n_updates             | 7660         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.477        |
|    value_loss            | 7.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36219773 |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -505        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1120        |
|    total_timesteps       | 1572864     |
| train/                   |             |
|    approx_kl             | 0.008048016 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.2         |
|    cost_value_loss       | 8.23        |
|    cost_values           | 3           |
|    entropy               | -1.37       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00296     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.32        |
|    n_updates             | 7670        |
|    policy_gradient_loss  | -0.00045    |
|    std                   | 0.479       |
|    value_loss            | 19          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.40296927  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1155         |
|    total_timesteps       | 1574912      |
| train/                   |              |
|    approx_kl             | 0.0036043632 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.33         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 2.93         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0153       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 7680         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.48         |
|    value_loss            | 13           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.28614053  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1189         |
|    total_timesteps       | 1576960      |
| train/                   |              |
|    approx_kl             | 0.0018221843 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.65         |
|    cost_value_loss       | 23           |
|    cost_values           | 2.95         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00266      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.56         |
|    n_updates             | 7690         |
|    policy_gradient_loss  | -0.000221    |
|    std                   | 0.48         |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54464763  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1224         |
|    total_timesteps       | 1579008      |
| train/                   |              |
|    approx_kl             | 0.0042399517 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.38         |
|    cost_value_loss       | 7.52         |
|    cost_values           | 3            |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00337      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.9          |
|    n_updates             | 7700         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.479        |
|    value_loss            | 9.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32097468 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -493        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1259        |
|    total_timesteps       | 1581056     |
| train/                   |             |
|    approx_kl             | 0.004955735 |
|    clip_fraction         | 0.0187      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.98        |
|    cost_value_loss       | 33.3        |
|    cost_values           | 2.99        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17          |
|    n_updates             | 7710        |
|    policy_gradient_loss  | -0.000968   |
|    std                   | 0.478       |
|    value_loss            | 2.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.73628145 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -495        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 38          |
|    time_elapsed          | 1293        |
|    total_timesteps       | 1583104     |
| train/                   |             |
|    approx_kl             | 0.027473902 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.26        |
|    cost_value_loss       | 22.7        |
|    cost_values           | 2.99        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.4        |
|    n_updates             | 7720        |
|    policy_gradient_loss  | 0.00159     |
|    std                   | 0.478       |
|    value_loss            | 14.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.46352196 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -492        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 39          |
|    time_elapsed          | 1327        |
|    total_timesteps       | 1585152     |
| train/                   |             |
|    approx_kl             | 0.008921682 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.51        |
|    cost_value_loss       | 14          |
|    cost_values           | 3           |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0175      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.48        |
|    n_updates             | 7730        |
|    policy_gradient_loss  | 0.00065     |
|    std                   | 0.478       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6106842  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 40          |
|    time_elapsed          | 1361        |
|    total_timesteps       | 1587200     |
| train/                   |             |
|    approx_kl             | 0.008801318 |
|    clip_fraction         | 0.0773      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.83        |
|    cost_value_loss       | 16.7        |
|    cost_values           | 3           |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00673     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 7740        |
|    policy_gradient_loss  | 0.00141     |
|    std                   | 0.479       |
|    value_loss            | 3.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.28169996  |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1395         |
|    total_timesteps       | 1589248      |
| train/                   |              |
|    approx_kl             | 0.0127293235 |
|    clip_fraction         | 0.0555       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 13.4         |
|    cost_values           | 3            |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00304      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.02         |
|    n_updates             | 7750         |
|    policy_gradient_loss  | -0.000306    |
|    std                   | 0.479        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4624948   |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1430         |
|    total_timesteps       | 1591296      |
| train/                   |              |
|    approx_kl             | 0.0034239753 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.27         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 3            |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00377      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.88         |
|    n_updates             | 7760         |
|    policy_gradient_loss  | 0.000276     |
|    std                   | 0.477        |
|    value_loss            | 4.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5594884  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 43          |
|    time_elapsed          | 1465        |
|    total_timesteps       | 1593344     |
| train/                   |             |
|    approx_kl             | 0.006534108 |
|    clip_fraction         | 0.0393      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.99        |
|    cost_value_loss       | 19          |
|    cost_values           | 3           |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0142      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.82        |
|    n_updates             | 7770        |
|    policy_gradient_loss  | -0.00176    |
|    std                   | 0.478       |
|    value_loss            | 1.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.3171123  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 44          |
|    time_elapsed          | 1499        |
|    total_timesteps       | 1595392     |
| train/                   |             |
|    approx_kl             | 0.002127578 |
|    clip_fraction         | 0.00591     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.27        |
|    cost_value_loss       | 20.5        |
|    cost_values           | 3           |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000484    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 7780        |
|    policy_gradient_loss  | -0.000399   |
|    std                   | 0.479       |
|    value_loss            | 3.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4895485   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1534         |
|    total_timesteps       | 1597440      |
| train/                   |              |
|    approx_kl             | 0.0023831483 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.32         |
|    cost_value_loss       | 9.24         |
|    cost_values           | 3            |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 7790         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.477        |
|    value_loss            | 15           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.7011345  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 46          |
|    time_elapsed          | 1569        |
|    total_timesteps       | 1599488     |
| train/                   |             |
|    approx_kl             | 0.005796155 |
|    clip_fraction         | 0.0566      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 19          |
|    cost_values           | 3           |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00492     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.75        |
|    n_updates             | 7800        |
|    policy_gradient_loss  | -0.000649   |
|    std                   | 0.475       |
|    value_loss            | 17.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.69553524 |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 47          |
|    time_elapsed          | 1603        |
|    total_timesteps       | 1601536     |
| train/                   |             |
|    approx_kl             | 0.00404546  |
|    clip_fraction         | 0.0671      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.11        |
|    cost_value_loss       | 18.3        |
|    cost_values           | 3           |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00533     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.04        |
|    n_updates             | 7810        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 0.474       |
|    value_loss            | 16.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48845702  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1637         |
|    total_timesteps       | 1603584      |
| train/                   |              |
|    approx_kl             | 0.0059041367 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.05         |
|    cost_value_loss       | 17.7         |
|    cost_values           | 3            |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0117       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 7820         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.473        |
|    value_loss            | 7.98         |
-------------------------------------------
----------------------------------------
| avg_speed                | 8.04      |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8.04      |
| reward                   | -0.727351 |
| rollout/                 |           |
|    ep_len_mean           | 907       |
|    ep_rew_mean           | -468      |
| time/                    |           |
|    fps                   | 60        |
|    iterations            | 49        |
|    time_elapsed          | 1671      |
|    total_timesteps       | 1605632   |
| train/                   |           |
|    approx_kl             | 0.0023787 |
|    clip_fraction         | 0.000732  |
|    clip_range            | 0.2       |
|    cost_returns          | 6.44      |
|    cost_value_loss       | 21.2      |
|    cost_values           | 3         |
|    entropy               | -1.35     |
|    entropy_loss          | -1.34     |
|    explained_variance    | 0         |
|    lagrangian_multiplier | 0.00283   |
|    learning_rate         | 0.0003    |
|    loss                  | 10.7      |
|    n_updates             | 7830      |
|    policy_gradient_loss  | -0.000493 |
|    std                   | 0.475     |
|    value_loss            | 17.6      |
----------------------------------------
-----------------------------------
| avg_speed          | 8.02       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.02       |
| reward             | -0.7700214 |
| rollout/           |            |
|    ep_len_mean     | 907        |
|    ep_rew_mean     | -465       |
| time/              |            |
|    fps             | 84         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1607680    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.54584914  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 1609728      |
| train/                   |              |
|    approx_kl             | 0.0037718117 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.26         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 3            |
|    entropy               | -1.34        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00741      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 7850         |
|    policy_gradient_loss  | -0.000517    |
|    std                   | 0.474        |
|    value_loss            | 16.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42310402  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 1611776      |
| train/                   |              |
|    approx_kl             | 0.0042614704 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 6.41         |
|    cost_values           | 3            |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0106       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.67         |
|    n_updates             | 7860         |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.472        |
|    value_loss            | 9.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35014677 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 127         |
|    total_timesteps       | 1613824     |
| train/                   |             |
|    approx_kl             | 0.002394757 |
|    clip_fraction         | 0.0131      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.77        |
|    cost_value_loss       | 23.3        |
|    cost_values           | 3           |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 7870        |
|    policy_gradient_loss  | -0.000296   |
|    std                   | 0.471       |
|    value_loss            | 3.3         |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.4826645 |
| rollout/                 |            |
|    ep_len_mean           | 908        |
|    ep_rew_mean           | -468       |
| time/                    |            |
|    fps                   | 62         |
|    iterations            | 5          |
|    time_elapsed          | 162        |
|    total_timesteps       | 1615872    |
| train/                   |            |
|    approx_kl             | 0.00415219 |
|    clip_fraction         | 0.00884    |
|    clip_range            | 0.2        |
|    cost_returns          | 4.71       |
|    cost_value_loss       | 12.4       |
|    cost_values           | 3          |
|    entropy               | -1.32      |
|    entropy_loss          | -1.33      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.00571    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.1        |
|    n_updates             | 7880       |
|    policy_gradient_loss  | -0.00198   |
|    std                   | 0.469      |
|    value_loss            | 3.31       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5869352 |
| rollout/                 |            |
|    ep_len_mean           | 908        |
|    ep_rew_mean           | -470       |
| time/                    |            |
|    fps                   | 62         |
|    iterations            | 6          |
|    time_elapsed          | 197        |
|    total_timesteps       | 1617920    |
| train/                   |            |
|    approx_kl             | 0.00352081 |
|    clip_fraction         | 0.0103     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.03       |
|    cost_value_loss       | 12         |
|    cost_values           | 3          |
|    entropy               | -1.33      |
|    entropy_loss          | -1.33      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0.00473    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.69       |
|    n_updates             | 7890       |
|    policy_gradient_loss  | -0.000771  |
|    std                   | 0.471      |
|    value_loss            | 25.2       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.61498135  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1619968      |
| train/                   |              |
|    approx_kl             | 0.0021770173 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.48         |
|    cost_value_loss       | 9.7          |
|    cost_values           | 3            |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00604      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 7900         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.47         |
|    value_loss            | 6.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.61463374 |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 1622016     |
| train/                   |             |
|    approx_kl             | 0.003262693 |
|    clip_fraction         | 0.0269      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 12.6        |
|    cost_values           | 3           |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00507     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.06        |
|    n_updates             | 7910        |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 0.47        |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8118757   |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 1624064      |
| train/                   |              |
|    approx_kl             | 0.0039049631 |
|    clip_fraction         | 0.0442       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.56         |
|    cost_value_loss       | 11           |
|    cost_values           | 3            |
|    entropy               | -1.32        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00588      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 7920         |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 0.469        |
|    value_loss            | 6.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.35385236 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -482        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 1626112     |
| train/                   |             |
|    approx_kl             | 0.004542836 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.84        |
|    cost_value_loss       | 19.3        |
|    cost_values           | 3           |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.5        |
|    n_updates             | 7930        |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.467       |
|    value_loss            | 7.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.62351644 |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 1628160     |
| train/                   |             |
|    approx_kl             | 0.003854633 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.2         |
|    cost_value_loss       | 6.23        |
|    cost_values           | 3           |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00443     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.08        |
|    n_updates             | 7940        |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.466       |
|    value_loss            | 29.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53847945  |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 1630208      |
| train/                   |              |
|    approx_kl             | 0.0038998576 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.07         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 3            |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 7950         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.465        |
|    value_loss            | 11.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5759697  |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 439         |
|    total_timesteps       | 1632256     |
| train/                   |             |
|    approx_kl             | 0.007434915 |
|    clip_fraction         | 0.0702      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 5.54        |
|    cost_values           | 3           |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00473     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.46        |
|    n_updates             | 7960        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.465       |
|    value_loss            | 25.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.44432235  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1634304      |
| train/                   |              |
|    approx_kl             | 0.0037111691 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.17         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 3            |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.000288     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.55         |
|    n_updates             | 7970         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.463        |
|    value_loss            | 3.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5561279   |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1636352      |
| train/                   |              |
|    approx_kl             | 0.0047699884 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.11         |
|    cost_value_loss       | 5.7          |
|    cost_values           | 3            |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00162      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.3          |
|    n_updates             | 7980         |
|    policy_gradient_loss  | -0.000709    |
|    std                   | 0.463        |
|    value_loss            | 5.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.57245094  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 1638400      |
| train/                   |              |
|    approx_kl             | 0.0072634807 |
|    clip_fraction         | 0.0489       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.99         |
|    cost_value_loss       | 17           |
|    cost_values           | 3            |
|    entropy               | -1.29        |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00887      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.54         |
|    n_updates             | 7990         |
|    policy_gradient_loss  | 0.000181     |
|    std                   | 0.462        |
|    value_loss            | 4.25         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5808193 |
| rollout/                 |            |
|    ep_len_mean           | 905        |
|    ep_rew_mean           | -486       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 17         |
|    time_elapsed          | 578        |
|    total_timesteps       | 1640448    |
| train/                   |            |
|    approx_kl             | 0.00931197 |
|    clip_fraction         | 0.0678     |
|    clip_range            | 0.2        |
|    cost_returns          | 4.78       |
|    cost_value_loss       | 8.37       |
|    cost_values           | 3          |
|    entropy               | -1.29      |
|    entropy_loss          | -1.29      |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0.00839    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.45       |
|    n_updates             | 8000       |
|    policy_gradient_loss  | -0.0014    |
|    std                   | 0.462      |
|    value_loss            | 3.96       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0146289   |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 612          |
|    total_timesteps       | 1642496      |
| train/                   |              |
|    approx_kl             | 0.0049718414 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 6.39         |
|    cost_values           | 3            |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00438      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 8010         |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.461        |
|    value_loss            | 7.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.7526123  |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 647         |
|    total_timesteps       | 1644544     |
| train/                   |             |
|    approx_kl             | 0.001780263 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 6.3         |
|    cost_value_loss       | 22.2        |
|    cost_values           | 3           |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.4        |
|    n_updates             | 8020        |
|    policy_gradient_loss  | -0.000372   |
|    std                   | 0.46        |
|    value_loss            | 7.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.19         |
| reward                   | -0.6581209   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 1646592      |
| train/                   |              |
|    approx_kl             | 0.0051893676 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.25         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 3            |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00615      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.74         |
|    n_updates             | 8030         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.46         |
|    value_loss            | 28.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.49815413 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -501        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 717         |
|    total_timesteps       | 1648640     |
| train/                   |             |
|    approx_kl             | 0.005600205 |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.66        |
|    cost_value_loss       | 5.5         |
|    cost_values           | 2.98        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00395     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.66        |
|    n_updates             | 8040        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.459       |
|    value_loss            | 18.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48134297 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -500        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 752         |
|    total_timesteps       | 1650688     |
| train/                   |             |
|    approx_kl             | 0.005531678 |
|    clip_fraction         | 0.0453      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.95        |
|    cost_value_loss       | 7.21        |
|    cost_values           | 3           |
|    entropy               | -1.27       |
|    entropy_loss          | -1.28       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 8050        |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 0.457       |
|    value_loss            | 6.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.27770466  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 786          |
|    total_timesteps       | 1652736      |
| train/                   |              |
|    approx_kl             | 0.0043927706 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.53         |
|    cost_value_loss       | 11           |
|    cost_values           | 3            |
|    entropy               | -1.26        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00371      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.92         |
|    n_updates             | 8060         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.455        |
|    value_loss            | 6.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.872331   |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -499        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 821         |
|    total_timesteps       | 1654784     |
| train/                   |             |
|    approx_kl             | 0.001257983 |
|    clip_fraction         | 0.00542     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.75        |
|    cost_value_loss       | 6.47        |
|    cost_values           | 3           |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00366     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 8070        |
|    policy_gradient_loss  | 3.43e-05    |
|    std                   | 0.454       |
|    value_loss            | 9.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.08         |
| reward                   | -0.6419129   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 855          |
|    total_timesteps       | 1656832      |
| train/                   |              |
|    approx_kl             | 0.0025453174 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.59         |
|    cost_value_loss       | 9.15         |
|    cost_values           | 3            |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00573      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.64         |
|    n_updates             | 8080         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.454        |
|    value_loss            | 24.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.86         |
| reward                   | -0.33181527  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -508         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 890          |
|    total_timesteps       | 1658880      |
| train/                   |              |
|    approx_kl             | 0.0045582345 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 6.56         |
|    cost_values           | 3            |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00488      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.95         |
|    n_updates             | 8090         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.453        |
|    value_loss            | 6.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.2949578   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 925          |
|    total_timesteps       | 1660928      |
| train/                   |              |
|    approx_kl             | 0.0042892243 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.18         |
|    cost_value_loss       | 18.7         |
|    cost_values           | 3            |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 8100         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.453        |
|    value_loss            | 3.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.9142329  |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -509        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 960         |
|    total_timesteps       | 1662976     |
| train/                   |             |
|    approx_kl             | 0.007090332 |
|    clip_fraction         | 0.0162      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 9.8         |
|    cost_values           | 3           |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00524     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 8110        |
|    policy_gradient_loss  | -0.000123   |
|    std                   | 0.453       |
|    value_loss            | 8.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8688967  |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -517        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 994         |
|    total_timesteps       | 1665024     |
| train/                   |             |
|    approx_kl             | 0.004744584 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 3.48        |
|    cost_values           | 3           |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000664    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 8120        |
|    policy_gradient_loss  | -0.0008     |
|    std                   | 0.451       |
|    value_loss            | 26.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.81029844  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 1667072      |
| train/                   |              |
|    approx_kl             | 0.0019480343 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.29         |
|    cost_value_loss       | 8.08         |
|    cost_values           | 3            |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.3          |
|    n_updates             | 8130         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.45         |
|    value_loss            | 9.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.673        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.673        |
| reward                   | -0.45389464  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -526         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 1669120      |
| train/                   |              |
|    approx_kl             | 0.0045920103 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.22         |
|    cost_value_loss       | 3.55         |
|    cost_values           | 2.95         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.76         |
|    n_updates             | 8140         |
|    policy_gradient_loss  | -0.000769    |
|    std                   | 0.45         |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.67088544  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1096         |
|    total_timesteps       | 1671168      |
| train/                   |              |
|    approx_kl             | 0.0036637178 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.07         |
|    cost_value_loss       | 6.06         |
|    cost_values           | 2.96         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.59         |
|    n_updates             | 8150         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.449        |
|    value_loss            | 5.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.43620482  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -531         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1130         |
|    total_timesteps       | 1673216      |
| train/                   |              |
|    approx_kl             | 0.0049072616 |
|    clip_fraction         | 0.0543       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.66         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 3            |
|    entropy               | -1.23        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.8         |
|    n_updates             | 8160         |
|    policy_gradient_loss  | -0.000634    |
|    std                   | 0.449        |
|    value_loss            | 41.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.938185    |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -529         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1165         |
|    total_timesteps       | 1675264      |
| train/                   |              |
|    approx_kl             | 0.0031102519 |
|    clip_fraction         | 0.00474      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.71         |
|    cost_value_loss       | 4.58         |
|    cost_values           | 2.98         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 8170         |
|    policy_gradient_loss  | -0.00045     |
|    std                   | 0.449        |
|    value_loss            | 19.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.5877557    |
| rollout/                 |               |
|    ep_len_mean           | 909           |
|    ep_rew_mean           | -532          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 35            |
|    time_elapsed          | 1199          |
|    total_timesteps       | 1677312       |
| train/                   |               |
|    approx_kl             | 0.00083024777 |
|    clip_fraction         | 0.0104        |
|    clip_range            | 0.2           |
|    cost_returns          | 3.64          |
|    cost_value_loss       | 3.6           |
|    cost_values           | 2.99          |
|    entropy               | -1.23         |
|    entropy_loss          | -1.24         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0.000604      |
|    learning_rate         | 0.0003        |
|    loss                  | 14.9          |
|    n_updates             | 8180          |
|    policy_gradient_loss  | -0.000383     |
|    std                   | 0.448         |
|    value_loss            | 31.9          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6982757  |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -536        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1234        |
|    total_timesteps       | 1679360     |
| train/                   |             |
|    approx_kl             | 0.005272417 |
|    clip_fraction         | 0.0304      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.75        |
|    cost_value_loss       | 15.9        |
|    cost_values           | 3           |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00762     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 8190        |
|    policy_gradient_loss  | -0.00302    |
|    std                   | 0.448       |
|    value_loss            | 3.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8232219   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1268         |
|    total_timesteps       | 1681408      |
| train/                   |              |
|    approx_kl             | 0.0013349043 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.26         |
|    cost_value_loss       | 11           |
|    cost_values           | 3            |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0084       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.01         |
|    n_updates             | 8200         |
|    policy_gradient_loss  | -0.000142    |
|    std                   | 0.448        |
|    value_loss            | 6.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1390579  |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -539        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1303        |
|    total_timesteps       | 1683456     |
| train/                   |             |
|    approx_kl             | 0.002387239 |
|    clip_fraction         | 0.00181     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.93        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 3           |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00629     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.39        |
|    n_updates             | 8210        |
|    policy_gradient_loss  | -0.000273   |
|    std                   | 0.449       |
|    value_loss            | 7.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0929       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0929       |
| reward                   | -0.42680886  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -539         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 1685504      |
| train/                   |              |
|    approx_kl             | 0.0031487532 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.57         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 3            |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 8220         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.449        |
|    value_loss            | 14.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6936223   |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1371         |
|    total_timesteps       | 1687552      |
| train/                   |              |
|    approx_kl             | 0.0030032815 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 3            |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00652      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.96         |
|    n_updates             | 8230         |
|    policy_gradient_loss  | -0.000387    |
|    std                   | 0.449        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.9698082  |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -538        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1405        |
|    total_timesteps       | 1689600     |
| train/                   |             |
|    approx_kl             | 0.004632419 |
|    clip_fraction         | 0.00972     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.5         |
|    cost_value_loss       | 15.4        |
|    cost_values           | 3           |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00406     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 8240        |
|    policy_gradient_loss  | -0.000893   |
|    std                   | 0.449       |
|    value_loss            | 38.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.69307464 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -544        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1440        |
|    total_timesteps       | 1691648     |
| train/                   |             |
|    approx_kl             | 0.004627581 |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 3.19        |
|    cost_values           | 2.95        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 8250        |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.449       |
|    value_loss            | 7.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.83389413  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -536         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1474         |
|    total_timesteps       | 1693696      |
| train/                   |              |
|    approx_kl             | 0.0030965758 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.96         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00568      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.28         |
|    n_updates             | 8260         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.449        |
|    value_loss            | 7.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4534496   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -542         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1508         |
|    total_timesteps       | 1695744      |
| train/                   |              |
|    approx_kl             | 0.0034304443 |
|    clip_fraction         | 0.00186      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 12           |
|    cost_values           | 3            |
|    entropy               | -1.23        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 8270         |
|    policy_gradient_loss  | -4.1e-05     |
|    std                   | 0.449        |
|    value_loss            | 21.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7153253   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1542         |
|    total_timesteps       | 1697792      |
| train/                   |              |
|    approx_kl             | 0.0064983144 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.46         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 2.99         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.7          |
|    n_updates             | 8280         |
|    policy_gradient_loss  | -2.29e-06    |
|    std                   | 0.448        |
|    value_loss            | 3.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.752        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.752        |
| reward                   | -0.3863021   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1577         |
|    total_timesteps       | 1699840      |
| train/                   |              |
|    approx_kl             | 0.0028738105 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.45         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 3            |
|    entropy               | -1.22        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 8290         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.446        |
|    value_loss            | 5.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6949798  |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -540        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1611        |
|    total_timesteps       | 1701888     |
| train/                   |             |
|    approx_kl             | 0.003301166 |
|    clip_fraction         | 0.029       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 3           |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000815    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.31        |
|    n_updates             | 8300        |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.446       |
|    value_loss            | 4.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.1          |
| reward                   | -0.25454268  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1645         |
|    total_timesteps       | 1703936      |
| train/                   |              |
|    approx_kl             | 0.0047536884 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.44         |
|    cost_value_loss       | 22.1         |
|    cost_values           | 3            |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00559      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.89         |
|    n_updates             | 8310         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.446        |
|    value_loss            | 22.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.4331988  |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -531        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1680        |
|    total_timesteps       | 1705984     |
| train/                   |             |
|    approx_kl             | 0.011353124 |
|    clip_fraction         | 0.0666      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 5.24        |
|    cost_values           | 3           |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00256     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 8320        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.446       |
|    value_loss            | 33.8        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.46513012 |
| rollout/           |             |
|    ep_len_mean     | 895         |
|    ep_rew_mean     | -529        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1708032     |
------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5511219   |
| rollout/                 |              |
|    ep_len_mean           | 871          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1710080      |
| train/                   |              |
|    approx_kl             | 0.0023638008 |
|    clip_fraction         | 0.0502       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.81         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 2.99         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 8340         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.444        |
|    value_loss            | 4.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3239862   |
| rollout/                 |              |
|    ep_len_mean           | 863          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1712128      |
| train/                   |              |
|    approx_kl             | 0.0039032623 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.83         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00279      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 8350         |
|    policy_gradient_loss  | -0.000514    |
|    std                   | 0.444        |
|    value_loss            | 52.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6296959   |
| rollout/                 |              |
|    ep_len_mean           | 871          |
|    ep_rew_mean           | -508         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 1714176      |
| train/                   |              |
|    approx_kl             | 0.0039021592 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.78         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 3            |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 8360         |
|    policy_gradient_loss  | -0.000182    |
|    std                   | 0.444        |
|    value_loss            | 19           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.37724462  |
| rollout/                 |              |
|    ep_len_mean           | 871          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 1716224      |
| train/                   |              |
|    approx_kl             | 0.0012761836 |
|    clip_fraction         | 0.00576      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 9.79         |
|    cost_values           | 3            |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00152      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.56         |
|    n_updates             | 8370         |
|    policy_gradient_loss  | -0.000495    |
|    std                   | 0.444        |
|    value_loss            | 5.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.80794317  |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 195          |
|    total_timesteps       | 1718272      |
| train/                   |              |
|    approx_kl             | 0.0051624198 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.11         |
|    cost_value_loss       | 7.11         |
|    cost_values           | 3            |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00343      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.11         |
|    n_updates             | 8380         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.443        |
|    value_loss            | 15.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.30303055 |
| rollout/                 |             |
|    ep_len_mean           | 878         |
|    ep_rew_mean           | -514        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 229         |
|    total_timesteps       | 1720320     |
| train/                   |             |
|    approx_kl             | 0.008481793 |
|    clip_fraction         | 0.0837      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.7         |
|    cost_value_loss       | 4.54        |
|    cost_values           | 3           |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 8390        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.442       |
|    value_loss            | 25.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6300761   |
| rollout/                 |              |
|    ep_len_mean           | 872          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 264          |
|    total_timesteps       | 1722368      |
| train/                   |              |
|    approx_kl             | 0.0023042993 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.55         |
|    cost_value_loss       | 8.96         |
|    cost_values           | 3            |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00725      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 8400         |
|    policy_gradient_loss  | 0.000135     |
|    std                   | 0.442        |
|    value_loss            | 9.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36751115 |
| rollout/                 |             |
|    ep_len_mean           | 872         |
|    ep_rew_mean           | -515        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 298         |
|    total_timesteps       | 1724416     |
| train/                   |             |
|    approx_kl             | 0.005245259 |
|    clip_fraction         | 0.0375      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 7.99        |
|    cost_values           | 3           |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00389     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.14        |
|    n_updates             | 8410        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.444       |
|    value_loss            | 36.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.6444523  |
| rollout/                 |             |
|    ep_len_mean           | 864         |
|    ep_rew_mean           | -511        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 334         |
|    total_timesteps       | 1726464     |
| train/                   |             |
|    approx_kl             | 0.003921751 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 2.99        |
|    cost_values           | 2.97        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 8420        |
|    policy_gradient_loss  | -0.000966   |
|    std                   | 0.442       |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.43989927  |
| rollout/                 |              |
|    ep_len_mean           | 864          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 1728512      |
| train/                   |              |
|    approx_kl             | 0.0030762292 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.2          |
|    cost_value_loss       | 7.44         |
|    cost_values           | 3            |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0075       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.51         |
|    n_updates             | 8430         |
|    policy_gradient_loss  | -0.000278    |
|    std                   | 0.442        |
|    value_loss            | 28.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.66237533 |
| rollout/                 |             |
|    ep_len_mean           | 868         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 404         |
|    total_timesteps       | 1730560     |
| train/                   |             |
|    approx_kl             | 0.004242587 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.86        |
|    cost_value_loss       | 5.43        |
|    cost_values           | 3           |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00502     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.66        |
|    n_updates             | 8440        |
|    policy_gradient_loss  | -0.00196    |
|    std                   | 0.443       |
|    value_loss            | 5.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.46437004  |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 1732608      |
| train/                   |              |
|    approx_kl             | 0.0063541224 |
|    clip_fraction         | 0.0446       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 5.12         |
|    cost_values           | 3            |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00125      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.29         |
|    n_updates             | 8450         |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 0.441        |
|    value_loss            | 6.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4597221   |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 1734656      |
| train/                   |              |
|    approx_kl             | 0.0043082684 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.64         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 3            |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0057       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.92         |
|    n_updates             | 8460         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.441        |
|    value_loss            | 3.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5147267   |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -502         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1736704      |
| train/                   |              |
|    approx_kl             | 0.0029871846 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 13           |
|    cost_values           | 3            |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00911      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.02         |
|    n_updates             | 8470         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.441        |
|    value_loss            | 5.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52473646  |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 542          |
|    total_timesteps       | 1738752      |
| train/                   |              |
|    approx_kl             | 0.0015683696 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.02         |
|    cost_value_loss       | 20           |
|    cost_values           | 3            |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00852      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 8480         |
|    policy_gradient_loss  | -0.000959    |
|    std                   | 0.442        |
|    value_loss            | 4.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.59043497 |
| rollout/                 |             |
|    ep_len_mean           | 868         |
|    ep_rew_mean           | -501        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 577         |
|    total_timesteps       | 1740800     |
| train/                   |             |
|    approx_kl             | 0.00404164  |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 17.6        |
|    cost_values           | 3           |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00287     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.8         |
|    n_updates             | 8490        |
|    policy_gradient_loss  | -0.001      |
|    std                   | 0.441       |
|    value_loss            | 1.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5604839   |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 612          |
|    total_timesteps       | 1742848      |
| train/                   |              |
|    approx_kl             | 0.0055753114 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.19         |
|    cost_value_loss       | 8.66         |
|    cost_values           | 3            |
|    entropy               | -1.19        |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0029       |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 8500         |
|    policy_gradient_loss  | -0.00063     |
|    std                   | 0.44         |
|    value_loss            | 7.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6196491   |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 646          |
|    total_timesteps       | 1744896      |
| train/                   |              |
|    approx_kl             | 0.0045941193 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.48         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 3            |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0031       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.99         |
|    n_updates             | 8510         |
|    policy_gradient_loss  | -0.000741    |
|    std                   | 0.442        |
|    value_loss            | 6.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.50637496  |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 1746944      |
| train/                   |              |
|    approx_kl             | 0.0025966493 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.91         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 3            |
|    entropy               | -1.21        |
|    entropy_loss          | -1.2         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0093       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.91         |
|    n_updates             | 8520         |
|    policy_gradient_loss  | -0.000642    |
|    std                   | 0.443        |
|    value_loss            | 3.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.7289681   |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -497         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 1748992      |
| train/                   |              |
|    approx_kl             | 0.0026454148 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.86         |
|    cost_value_loss       | 12           |
|    cost_values           | 3            |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.79         |
|    n_updates             | 8530         |
|    policy_gradient_loss  | -0.000778    |
|    std                   | 0.441        |
|    value_loss            | 3.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8555619   |
| rollout/                 |              |
|    ep_len_mean           | 871          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 749          |
|    total_timesteps       | 1751040      |
| train/                   |              |
|    approx_kl             | 0.0019981524 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.54         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 3            |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00679      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.85         |
|    n_updates             | 8540         |
|    policy_gradient_loss  | -0.000256    |
|    std                   | 0.44         |
|    value_loss            | 19.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6622616   |
| rollout/                 |              |
|    ep_len_mean           | 871          |
|    ep_rew_mean           | -497         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 783          |
|    total_timesteps       | 1753088      |
| train/                   |              |
|    approx_kl             | 0.0041025546 |
|    clip_fraction         | 0.00859      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.94         |
|    cost_value_loss       | 5.6          |
|    cost_values           | 3            |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 8550         |
|    policy_gradient_loss  | -3.98e-05    |
|    std                   | 0.439        |
|    value_loss            | 28.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48164278 |
| rollout/                 |             |
|    ep_len_mean           | 871         |
|    ep_rew_mean           | -495        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 818         |
|    total_timesteps       | 1755136     |
| train/                   |             |
|    approx_kl             | 0.010139571 |
|    clip_fraction         | 0.0996      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 14.2        |
|    cost_values           | 3           |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.68        |
|    n_updates             | 8560        |
|    policy_gradient_loss  | -0.000831   |
|    std                   | 0.438       |
|    value_loss            | 3.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5704666   |
| rollout/                 |              |
|    ep_len_mean           | 871          |
|    ep_rew_mean           | -492         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 852          |
|    total_timesteps       | 1757184      |
| train/                   |              |
|    approx_kl             | 0.0032820879 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.91         |
|    cost_value_loss       | 17.9         |
|    cost_values           | 3            |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00835      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.86         |
|    n_updates             | 8570         |
|    policy_gradient_loss  | -0.000155    |
|    std                   | 0.438        |
|    value_loss            | 6.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.63532484  |
| rollout/                 |              |
|    ep_len_mean           | 870          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 1759232      |
| train/                   |              |
|    approx_kl             | 0.0032424312 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.15         |
|    cost_value_loss       | 21.4         |
|    cost_values           | 3            |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0111       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.24         |
|    n_updates             | 8580         |
|    policy_gradient_loss  | -0.000788    |
|    std                   | 0.437        |
|    value_loss            | 1.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46369472  |
| rollout/                 |              |
|    ep_len_mean           | 866          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 921          |
|    total_timesteps       | 1761280      |
| train/                   |              |
|    approx_kl             | 0.0027547886 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.01         |
|    cost_value_loss       | 17.8         |
|    cost_values           | 2.92         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0122       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.08         |
|    n_updates             | 8590         |
|    policy_gradient_loss  | 7.96e-05     |
|    std                   | 0.437        |
|    value_loss            | 28.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.6654779   |
| rollout/                 |              |
|    ep_len_mean           | 866          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 956          |
|    total_timesteps       | 1763328      |
| train/                   |              |
|    approx_kl             | 0.0072199344 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 12.5         |
|    cost_values           | 2.99         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0217       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.66         |
|    n_updates             | 8600         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.438        |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.41628784 |
| rollout/                 |             |
|    ep_len_mean           | 866         |
|    ep_rew_mean           | -481        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 991         |
|    total_timesteps       | 1765376     |
| train/                   |             |
|    approx_kl             | 0.0070217   |
|    clip_fraction         | 0.0169      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.03        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 3           |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000884    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 8610        |
|    policy_gradient_loss  | -0.000215   |
|    std                   | 0.438       |
|    value_loss            | 2.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7125386   |
| rollout/                 |              |
|    ep_len_mean           | 866          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 1767424      |
| train/                   |              |
|    approx_kl             | 0.0027193134 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.51         |
|    cost_value_loss       | 22.9         |
|    cost_values           | 2.99         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00993      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.81         |
|    n_updates             | 8620         |
|    policy_gradient_loss  | 0.000802     |
|    std                   | 0.439        |
|    value_loss            | 4.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.33275887  |
| rollout/                 |              |
|    ep_len_mean           | 866          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1061         |
|    total_timesteps       | 1769472      |
| train/                   |              |
|    approx_kl             | 0.0040399297 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.23         |
|    cost_value_loss       | 8.58         |
|    cost_values           | 3            |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00236      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.95         |
|    n_updates             | 8630         |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 0.439        |
|    value_loss            | 2.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.45865774 |
| rollout/                 |             |
|    ep_len_mean           | 866         |
|    ep_rew_mean           | -476        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1096        |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.006142996 |
|    clip_fraction         | 0.0788      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.38        |
|    cost_value_loss       | 3.45        |
|    cost_values           | 3           |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 8640        |
|    policy_gradient_loss  | -0.00397    |
|    std                   | 0.436       |
|    value_loss            | 6.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.52419144  |
| rollout/                 |              |
|    ep_len_mean           | 866          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1130         |
|    total_timesteps       | 1773568      |
| train/                   |              |
|    approx_kl             | 0.0033278414 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.21         |
|    cost_value_loss       | 21.9         |
|    cost_values           | 3            |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 8650         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.435        |
|    value_loss            | 5.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.6723321   |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1165         |
|    total_timesteps       | 1775616      |
| train/                   |              |
|    approx_kl             | 0.0027016138 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.92         |
|    cost_value_loss       | 11.5         |
|    cost_values           | 2.94         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.85         |
|    n_updates             | 8660         |
|    policy_gradient_loss  | -0.000963    |
|    std                   | 0.435        |
|    value_loss            | 2.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55219984  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1200         |
|    total_timesteps       | 1777664      |
| train/                   |              |
|    approx_kl             | 0.0051275864 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.86         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 2.99         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0127       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 8670         |
|    policy_gradient_loss  | -1.37e-05    |
|    std                   | 0.434        |
|    value_loss            | 2.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4710974  |
| rollout/                 |             |
|    ep_len_mean           | 885         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1234        |
|    total_timesteps       | 1779712     |
| train/                   |             |
|    approx_kl             | 0.003964223 |
|    clip_fraction         | 0.00405     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 3           |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000319    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.85        |
|    n_updates             | 8680        |
|    policy_gradient_loss  | -0.000511   |
|    std                   | 0.433       |
|    value_loss            | 4.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4424662   |
| rollout/                 |              |
|    ep_len_mean           | 886          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1268         |
|    total_timesteps       | 1781760      |
| train/                   |              |
|    approx_kl             | 0.0040213787 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 12           |
|    cost_values           | 2.95         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.9          |
|    n_updates             | 8690         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.433        |
|    value_loss            | 1.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5674578  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1303        |
|    total_timesteps       | 1783808     |
| train/                   |             |
|    approx_kl             | 0.020237846 |
|    clip_fraction         | 0.0867      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.95        |
|    cost_value_loss       | 19.7        |
|    cost_values           | 3           |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.0202      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.53        |
|    n_updates             | 8700        |
|    policy_gradient_loss  | -0.00203    |
|    std                   | 0.432       |
|    value_loss            | 18.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.045        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.045        |
| reward                   | -0.42675412  |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 1785856      |
| train/                   |              |
|    approx_kl             | 0.0144560635 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.89         |
|    cost_value_loss       | 18.8         |
|    cost_values           | 2.99         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00995      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.38         |
|    n_updates             | 8710         |
|    policy_gradient_loss  | 0.000252     |
|    std                   | 0.432        |
|    value_loss            | 4.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.93         |
| reward                   | -0.4997171   |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1372         |
|    total_timesteps       | 1787904      |
| train/                   |              |
|    approx_kl             | 0.0014149735 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 12.2         |
|    cost_values           | 2.98         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23           |
|    n_updates             | 8720         |
|    policy_gradient_loss  | -0.000297    |
|    std                   | 0.432        |
|    value_loss            | 26.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.415865    |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1406         |
|    total_timesteps       | 1789952      |
| train/                   |              |
|    approx_kl             | 0.0040792655 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.92         |
|    cost_value_loss       | 8.57         |
|    cost_values           | 2.94         |
|    entropy               | -1.15        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 8730         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.431        |
|    value_loss            | 1.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6446586  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1441        |
|    total_timesteps       | 1792000     |
| train/                   |             |
|    approx_kl             | 0.007889928 |
|    clip_fraction         | 0.0248      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.9         |
|    cost_value_loss       | 15.7        |
|    cost_values           | 2.91        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 8740        |
|    policy_gradient_loss  | -0.000925   |
|    std                   | 0.43        |
|    value_loss            | 11          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5131012  |
| rollout/                 |             |
|    ep_len_mean           | 893         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1475        |
|    total_timesteps       | 1794048     |
| train/                   |             |
|    approx_kl             | 0.005764707 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.13        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.99        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.84        |
|    n_updates             | 8750        |
|    policy_gradient_loss  | -0.000954   |
|    std                   | 0.43        |
|    value_loss            | 3.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.56905246  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1510         |
|    total_timesteps       | 1796096      |
| train/                   |              |
|    approx_kl             | 0.0052983393 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.95         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 3            |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 8760         |
|    policy_gradient_loss  | -0.000688    |
|    std                   | 0.43         |
|    value_loss            | 2.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.52345645  |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1544         |
|    total_timesteps       | 1798144      |
| train/                   |              |
|    approx_kl             | 0.0018638689 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.55         |
|    cost_value_loss       | 3.58         |
|    cost_values           | 2.97         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000149     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.23         |
|    n_updates             | 8770         |
|    policy_gradient_loss  | -3.03e-05    |
|    std                   | 0.432        |
|    value_loss            | 3.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.49089596  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1578         |
|    total_timesteps       | 1800192      |
| train/                   |              |
|    approx_kl             | 0.0016767356 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.43         |
|    cost_value_loss       | 23.5         |
|    cost_values           | 2.99         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.7         |
|    n_updates             | 8780         |
|    policy_gradient_loss  | 0.000224     |
|    std                   | 0.433        |
|    value_loss            | 13.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.66         |
| reward                   | -0.24360976  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1612         |
|    total_timesteps       | 1802240      |
| train/                   |              |
|    approx_kl             | 0.0018487041 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.4          |
|    cost_value_loss       | 9.1          |
|    cost_values           | 3            |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0076       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.87         |
|    n_updates             | 8790         |
|    policy_gradient_loss  | 0.000192     |
|    std                   | 0.433        |
|    value_loss            | 7            |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.42671287 |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1646        |
|    total_timesteps       | 1804288     |
| train/                   |             |
|    approx_kl             | 0.00405752  |
|    clip_fraction         | 0.0291      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.12        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.91        |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0328      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.57        |
|    n_updates             | 8800        |
|    policy_gradient_loss  | -0.00202    |
|    std                   | 0.433       |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.68482566 |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1681        |
|    total_timesteps       | 1806336     |
| train/                   |             |
|    approx_kl             | 0.002096752 |
|    clip_fraction         | 0.000293    |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.87        |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 8810        |
|    policy_gradient_loss  | 0.000197    |
|    std                   | 0.432       |
|    value_loss            | 13.5        |
------------------------------------------
-----------------------------------
| avg_speed          | 8.01       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.01       |
| reward             | -0.5024391 |
| rollout/           |            |
|    ep_len_mean     | 914        |
|    ep_rew_mean     | -475       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1808384    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.68344134 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 1810432     |
| train/                   |             |
|    approx_kl             | 0.008117879 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.11        |
|    cost_value_loss       | 19.9        |
|    cost_values           | 3           |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 8830        |
|    policy_gradient_loss  | 0.000244    |
|    std                   | 0.432       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.51826435  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1812480      |
| train/                   |              |
|    approx_kl             | 0.0050213416 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.13         |
|    cost_value_loss       | 4.72         |
|    cost_values           | 3            |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000976     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 8840         |
|    policy_gradient_loss  | 7.51e-05     |
|    std                   | 0.432        |
|    value_loss            | 6.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4075147   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 1814528      |
| train/                   |              |
|    approx_kl             | 0.0027208985 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.75         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 3            |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00976      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 8850         |
|    policy_gradient_loss  | -0.000386    |
|    std                   | 0.432        |
|    value_loss            | 5.61         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -0.41103926 |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -466        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 1816576     |
| train/                   |             |
|    approx_kl             | 0.004053984 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 7.95        |
|    cost_values           | 2.96        |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 8860        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.432       |
|    value_loss            | 2.88        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.29         |
| reward                   | -0.30687624  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 1818624      |
| train/                   |              |
|    approx_kl             | 0.0036933827 |
|    clip_fraction         | 0.00762      |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 9.71         |
|    cost_values           | 3            |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00722      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.6          |
|    n_updates             | 8870         |
|    policy_gradient_loss  | -0.000616    |
|    std                   | 0.43         |
|    value_loss            | 15.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.83647865  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 1820672      |
| train/                   |              |
|    approx_kl             | 0.0020202282 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.84         |
|    cost_value_loss       | 19.8         |
|    cost_values           | 3            |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 8880         |
|    policy_gradient_loss  | -0.000668    |
|    std                   | 0.431        |
|    value_loss            | 4.1          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.6304707 |
| rollout/                 |            |
|    ep_len_mean           | 906        |
|    ep_rew_mean           | -460       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 8          |
|    time_elapsed          | 265        |
|    total_timesteps       | 1822720    |
| train/                   |            |
|    approx_kl             | 0.01147209 |
|    clip_fraction         | 0.0759     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.14       |
|    cost_value_loss       | 14         |
|    cost_values           | 3          |
|    entropy               | -1.15      |
|    entropy_loss          | -1.15      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0.0156     |
|    learning_rate         | 0.0003     |
|    loss                  | 4.93       |
|    n_updates             | 8890       |
|    policy_gradient_loss  | -0.00202   |
|    std                   | 0.43       |
|    value_loss            | 29.8       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.54245865 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 299         |
|    total_timesteps       | 1824768     |
| train/                   |             |
|    approx_kl             | 0.003412958 |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 13.3        |
|    cost_values           | 3           |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00442     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.65        |
|    n_updates             | 8900        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.429       |
|    value_loss            | 9.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.50598675  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 1826816      |
| train/                   |              |
|    approx_kl             | 0.0047450187 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.04         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 2.97         |
|    entropy               | -1.14        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0212       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.38         |
|    n_updates             | 8910         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.428        |
|    value_loss            | 4.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42283523  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 1828864      |
| train/                   |              |
|    approx_kl             | 0.0059332373 |
|    clip_fraction         | 0.0785       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.99         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 3            |
|    entropy               | -1.14        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0123       |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 8920         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.428        |
|    value_loss            | 17.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.91         |
| reward                   | -0.35204533  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 1830912      |
| train/                   |              |
|    approx_kl             | 0.0016867475 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 8.51         |
|    cost_values           | 3            |
|    entropy               | -1.14        |
|    entropy_loss          | -1.14        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00853      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.4          |
|    n_updates             | 8930         |
|    policy_gradient_loss  | -0.000765    |
|    std                   | 0.429        |
|    value_loss            | 1.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66124487  |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 1832960      |
| train/                   |              |
|    approx_kl             | 0.0032913035 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.84         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 3            |
|    entropy               | -1.15        |
|    entropy_loss          | -1.14        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00602      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.46         |
|    n_updates             | 8940         |
|    policy_gradient_loss  | -0.000765    |
|    std                   | 0.429        |
|    value_loss            | 15.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.30302718 |
| rollout/                 |             |
|    ep_len_mean           | 880         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 473         |
|    total_timesteps       | 1835008     |
| train/                   |             |
|    approx_kl             | 0.005177022 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.36        |
|    cost_value_loss       | 14          |
|    cost_values           | 3           |
|    entropy               | -1.14       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00633     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.77        |
|    n_updates             | 8950        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.429       |
|    value_loss            | 27.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.46         |
| reward                   | -0.40882194  |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1837056      |
| train/                   |              |
|    approx_kl             | 0.0011170607 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.61         |
|    cost_value_loss       | 23.5         |
|    cost_values           | 2.99         |
|    entropy               | -1.14        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 8960         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.428        |
|    value_loss            | 3.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.36        |
| reward                   | -0.49777347 |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 542         |
|    total_timesteps       | 1839104     |
| train/                   |             |
|    approx_kl             | 0.011090396 |
|    clip_fraction         | 0.0294      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.98        |
|    cost_value_loss       | 19.5        |
|    cost_values           | 2.99        |
|    entropy               | -1.14       |
|    entropy_loss          | -1.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 8970        |
|    policy_gradient_loss  | 1.19e-06    |
|    std                   | 0.427       |
|    value_loss            | 3.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.85516614 |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 577         |
|    total_timesteps       | 1841152     |
| train/                   |             |
|    approx_kl             | 0.009455035 |
|    clip_fraction         | 0.0314      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.24        |
|    cost_value_loss       | 32.7        |
|    cost_values           | 3           |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.021       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 8980        |
|    policy_gradient_loss  | -0.000282   |
|    std                   | 0.427       |
|    value_loss            | 0.593       |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.91         |
| reward                   | -0.5220121   |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 611          |
|    total_timesteps       | 1843200      |
| train/                   |              |
|    approx_kl             | 0.0031592324 |
|    clip_fraction         | 0.00464      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.28         |
|    cost_value_loss       | 24.1         |
|    cost_values           | 2.99         |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0079       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 8990         |
|    policy_gradient_loss  | -0.000607    |
|    std                   | 0.426        |
|    value_loss            | 4.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -0.7077175   |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 1845248      |
| train/                   |              |
|    approx_kl             | 0.0036414568 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.81         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 2.99         |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 9000         |
|    policy_gradient_loss  | -0.000711    |
|    std                   | 0.427        |
|    value_loss            | 16.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.43114108 |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 679         |
|    total_timesteps       | 1847296     |
| train/                   |             |
|    approx_kl             | 0.006290881 |
|    clip_fraction         | 0.0113      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 20.5        |
|    cost_values           | 3           |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00719     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.35        |
|    n_updates             | 9010        |
|    policy_gradient_loss  | -0.000194   |
|    std                   | 0.426       |
|    value_loss            | 8.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.68         |
| reward                   | -0.5448006   |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 713          |
|    total_timesteps       | 1849344      |
| train/                   |              |
|    approx_kl             | 0.0022505573 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.77         |
|    cost_value_loss       | 23.8         |
|    cost_values           | 2.99         |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.16         |
|    n_updates             | 9020         |
|    policy_gradient_loss  | 0.000113     |
|    std                   | 0.426        |
|    value_loss            | 15.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.7339257   |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 748          |
|    total_timesteps       | 1851392      |
| train/                   |              |
|    approx_kl             | 0.0035018995 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.83         |
|    cost_value_loss       | 5.43         |
|    cost_values           | 3            |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.87         |
|    n_updates             | 9030         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.427        |
|    value_loss            | 2.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.98359936 |
| rollout/                 |             |
|    ep_len_mean           | 905         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 782         |
|    total_timesteps       | 1853440     |
| train/                   |             |
|    approx_kl             | 0.003975973 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 20.3        |
|    cost_values           | 3           |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.5        |
|    n_updates             | 9040        |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.427       |
|    value_loss            | 16.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.40020102  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 816          |
|    total_timesteps       | 1855488      |
| train/                   |              |
|    approx_kl             | 0.0059889937 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.07         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 3            |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000313     |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 9050         |
|    policy_gradient_loss  | -0.00043     |
|    std                   | 0.426        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5482462   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 851          |
|    total_timesteps       | 1857536      |
| train/                   |              |
|    approx_kl             | 0.0017937104 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.68         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 3            |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0016       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.54         |
|    n_updates             | 9060         |
|    policy_gradient_loss  | 4.63e-05     |
|    std                   | 0.426        |
|    value_loss            | 19           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6520961   |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 885          |
|    total_timesteps       | 1859584      |
| train/                   |              |
|    approx_kl             | 0.0072681755 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 6.73         |
|    cost_values           | 2.96         |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0263       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.68         |
|    n_updates             | 9070         |
|    policy_gradient_loss  | -0.000386    |
|    std                   | 0.425        |
|    value_loss            | 14.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.53475183 |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 920         |
|    total_timesteps       | 1861632     |
| train/                   |             |
|    approx_kl             | 0.008023021 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.99        |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.0144      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 9080        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.424       |
|    value_loss            | 19.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.24         |
| reward                   | -0.5633387   |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 954          |
|    total_timesteps       | 1863680      |
| train/                   |              |
|    approx_kl             | 0.0035707736 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.63         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 3            |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.95         |
|    n_updates             | 9090         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.423        |
|    value_loss            | 7.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5249873   |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 988          |
|    total_timesteps       | 1865728      |
| train/                   |              |
|    approx_kl             | 0.0024926118 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.07         |
|    cost_value_loss       | 7.47         |
|    cost_values           | 3            |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00188      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.49         |
|    n_updates             | 9100         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.422        |
|    value_loss            | 19.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.27937052  |
| rollout/                 |              |
|    ep_len_mean           | 872          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1023         |
|    total_timesteps       | 1867776      |
| train/                   |              |
|    approx_kl             | 0.0020681683 |
|    clip_fraction         | 0.0737       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.38         |
|    cost_value_loss       | 21.1         |
|    cost_values           | 3            |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00591      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 9110         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 0.421        |
|    value_loss            | 16           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6401727   |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1057         |
|    total_timesteps       | 1869824      |
| train/                   |              |
|    approx_kl             | 0.0056413147 |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 11.5         |
|    cost_values           | 3            |
|    entropy               | -1.1         |
|    entropy_loss          | -1.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 9120         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.42         |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.6915367   |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1091         |
|    total_timesteps       | 1871872      |
| train/                   |              |
|    approx_kl             | 0.0019748807 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.08         |
|    cost_value_loss       | 5.95         |
|    cost_values           | 3            |
|    entropy               | -1.11        |
|    entropy_loss          | -1.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00178      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.96         |
|    n_updates             | 9130         |
|    policy_gradient_loss  | -0.00025     |
|    std                   | 0.421        |
|    value_loss            | 3.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.57015425  |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1126         |
|    total_timesteps       | 1873920      |
| train/                   |              |
|    approx_kl             | 0.0048612165 |
|    clip_fraction         | 0.0735       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.48         |
|    cost_value_loss       | 22           |
|    cost_values           | 2.99         |
|    entropy               | -1.1         |
|    entropy_loss          | -1.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00391      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 9140         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.42         |
|    value_loss            | 4.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.54634845  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1160         |
|    total_timesteps       | 1875968      |
| train/                   |              |
|    approx_kl             | 0.0050533693 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.07         |
|    cost_value_loss       | 8.61         |
|    cost_values           | 3            |
|    entropy               | -1.09        |
|    entropy_loss          | -1.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.39         |
|    n_updates             | 9150         |
|    policy_gradient_loss  | -0.0007      |
|    std                   | 0.418        |
|    value_loss            | 5.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.33110514  |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1195         |
|    total_timesteps       | 1878016      |
| train/                   |              |
|    approx_kl             | 0.0012472211 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 3.68         |
|    cost_values           | 3            |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00433      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.91         |
|    n_updates             | 9160         |
|    policy_gradient_loss  | 0.000463     |
|    std                   | 0.417        |
|    value_loss            | 2.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.39230722  |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1229         |
|    total_timesteps       | 1880064      |
| train/                   |              |
|    approx_kl             | 0.0023993747 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.17         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 3            |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00678      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.42         |
|    n_updates             | 9170         |
|    policy_gradient_loss  | -0.000624    |
|    std                   | 0.418        |
|    value_loss            | 25.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.6780434   |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1263         |
|    total_timesteps       | 1882112      |
| train/                   |              |
|    approx_kl             | 0.0042434987 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.9          |
|    cost_value_loss       | 12           |
|    cost_values           | 3            |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.2          |
|    n_updates             | 9180         |
|    policy_gradient_loss  | -0.000657    |
|    std                   | 0.417        |
|    value_loss            | 1.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5253379   |
| rollout/                 |              |
|    ep_len_mean           | 877          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1297         |
|    total_timesteps       | 1884160      |
| train/                   |              |
|    approx_kl             | 0.0008234045 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.1          |
|    cost_value_loss       | 6.08         |
|    cost_values           | 2.99         |
|    entropy               | -1.07        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.24         |
|    n_updates             | 9190         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.414        |
|    value_loss            | 8.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.39984816  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1331         |
|    total_timesteps       | 1886208      |
| train/                   |              |
|    approx_kl             | 0.0051209116 |
|    clip_fraction         | 0.057        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.74         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 2.92         |
|    entropy               | -1.07        |
|    entropy_loss          | -1.07        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00617      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.84         |
|    n_updates             | 9200         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.414        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3771472  |
| rollout/                 |             |
|    ep_len_mean           | 883         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1366        |
|    total_timesteps       | 1888256     |
| train/                   |             |
|    approx_kl             | 0.010025838 |
|    clip_fraction         | 0.0439      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 9.38        |
|    cost_values           | 3           |
|    entropy               | -1.07       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.81        |
|    n_updates             | 9210        |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.414       |
|    value_loss            | 7.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.42419183  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1400         |
|    total_timesteps       | 1890304      |
| train/                   |              |
|    approx_kl             | 0.0018434746 |
|    clip_fraction         | 0.00273      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 2.88         |
|    entropy               | -1.07        |
|    entropy_loss          | -1.07        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 9220         |
|    policy_gradient_loss  | 6.82e-06     |
|    std                   | 0.413        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46525443  |
| rollout/                 |              |
|    ep_len_mean           | 882          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1434         |
|    total_timesteps       | 1892352      |
| train/                   |              |
|    approx_kl             | 0.0068832757 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 12           |
|    cost_values           | 2.96         |
|    entropy               | -1.07        |
|    entropy_loss          | -1.07        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.003        |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 9230         |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 0.413        |
|    value_loss            | 1.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.56215656 |
| rollout/                 |             |
|    ep_len_mean           | 882         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1468        |
|    total_timesteps       | 1894400     |
| train/                   |             |
|    approx_kl             | 0.005491662 |
|    clip_fraction         | 0.0535      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 12          |
|    cost_values           | 2.91        |
|    entropy               | -1.06       |
|    entropy_loss          | -1.07       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0169      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.01        |
|    n_updates             | 9240        |
|    policy_gradient_loss  | 0.000165    |
|    std                   | 0.412       |
|    value_loss            | 20.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.612052    |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1502         |
|    total_timesteps       | 1896448      |
| train/                   |              |
|    approx_kl             | 0.0031444777 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.26         |
|    cost_value_loss       | 14.3         |
|    cost_values           | 3            |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.03         |
|    n_updates             | 9250         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.412        |
|    value_loss            | 1.83         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18091258 |
| rollout/                 |             |
|    ep_len_mean           | 879         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1536        |
|    total_timesteps       | 1898496     |
| train/                   |             |
|    approx_kl             | 0.004169857 |
|    clip_fraction         | 0.00645     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 3           |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0111      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 9260        |
|    policy_gradient_loss  | -0.000795   |
|    std                   | 0.412       |
|    value_loss            | 19.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.58967596 |
| rollout/                 |             |
|    ep_len_mean           | 879         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1571        |
|    total_timesteps       | 1900544     |
| train/                   |             |
|    approx_kl             | 0.01115803  |
|    clip_fraction         | 0.0524      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 9.18        |
|    cost_values           | 3           |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0.0132      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.41        |
|    n_updates             | 9270        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.411       |
|    value_loss            | 4.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5417136   |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1605         |
|    total_timesteps       | 1902592      |
| train/                   |              |
|    approx_kl             | 0.0037009069 |
|    clip_fraction         | 0.0502       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.94         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 3            |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.7          |
|    n_updates             | 9280         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.41         |
|    value_loss            | 2.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.69477457  |
| rollout/                 |              |
|    ep_len_mean           | 886          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1639         |
|    total_timesteps       | 1904640      |
| train/                   |              |
|    approx_kl             | 0.0024505076 |
|    clip_fraction         | 0.00415      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.94         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 2.99         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000337     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.62         |
|    n_updates             | 9290         |
|    policy_gradient_loss  | 0.000162     |
|    std                   | 0.41         |
|    value_loss            | 1.74         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7755768  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1673        |
|    total_timesteps       | 1906688     |
| train/                   |             |
|    approx_kl             | 0.005311498 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 15          |
|    cost_values           | 3           |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0113      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.82        |
|    n_updates             | 9300        |
|    policy_gradient_loss  | -0.000888   |
|    std                   | 0.41        |
|    value_loss            | 2.68        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 8.02        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.69230235 |
| rollout/           |             |
|    ep_len_mean     | 892         |
|    ep_rew_mean     | -446        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1908736     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47564834  |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1910784      |
| train/                   |              |
|    approx_kl             | 0.0034575548 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.44         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 3            |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00933      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 9320         |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.41         |
|    value_loss            | 8            |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2674532  |
| rollout/                 |             |
|    ep_len_mean           | 893         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1912832     |
| train/                   |             |
|    approx_kl             | 0.009753982 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.15        |
|    cost_value_loss       | 19.6        |
|    cost_values           | 3           |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000492    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 9330        |
|    policy_gradient_loss  | 0.000803    |
|    std                   | 0.41        |
|    value_loss            | 16.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.84894055  |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 1914880      |
| train/                   |              |
|    approx_kl             | 0.0030150716 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.34         |
|    cost_value_loss       | 7.55         |
|    cost_values           | 3            |
|    entropy               | -1.04        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00722      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.45         |
|    n_updates             | 9340         |
|    policy_gradient_loss  | -0.000951    |
|    std                   | 0.408        |
|    value_loss            | 3.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.43506193  |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 1916928      |
| train/                   |              |
|    approx_kl             | 0.0028055739 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.74         |
|    cost_value_loss       | 7.88         |
|    cost_values           | 3            |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0092       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.24         |
|    n_updates             | 9350         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.407        |
|    value_loss            | 20.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33490193 |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 196         |
|    total_timesteps       | 1918976     |
| train/                   |             |
|    approx_kl             | 0.003946905 |
|    clip_fraction         | 0.0734      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.67        |
|    cost_value_loss       | 15.6        |
|    cost_values           | 3           |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000419    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 9360        |
|    policy_gradient_loss  | 0.000715    |
|    std                   | 0.405       |
|    value_loss            | 16.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.27         |
| reward                   | -0.31187686  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 1921024      |
| train/                   |              |
|    approx_kl             | 0.0022003555 |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.69         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 9370         |
|    policy_gradient_loss  | -0.000598    |
|    std                   | 0.404        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.16         |
| reward                   | -0.34709692  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 1923072      |
| train/                   |              |
|    approx_kl             | 0.0037086406 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.13         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00223      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.7          |
|    n_updates             | 9380         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.403        |
|    value_loss            | 14.5         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.6690706 |
| rollout/                 |            |
|    ep_len_mean           | 899        |
|    ep_rew_mean           | -451       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 9          |
|    time_elapsed          | 300        |
|    total_timesteps       | 1925120    |
| train/                   |            |
|    approx_kl             | 0.00229704 |
|    clip_fraction         | 0.0127     |
|    clip_range            | 0.2        |
|    cost_returns          | 4.55       |
|    cost_value_loss       | 9.08       |
|    cost_values           | 2.99       |
|    entropy               | -1.02      |
|    entropy_loss          | -1.02      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.4        |
|    n_updates             | 9390       |
|    policy_gradient_loss  | -0.00101   |
|    std                   | 0.403      |
|    value_loss            | 2.03       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4770393  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 334         |
|    total_timesteps       | 1927168     |
| train/                   |             |
|    approx_kl             | 0.004237799 |
|    clip_fraction         | 0.0438      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.39        |
|    cost_value_loss       | 21.4        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.006       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.01        |
|    n_updates             | 9400        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.403       |
|    value_loss            | 16.8        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.7950462 |
| rollout/                 |            |
|    ep_len_mean           | 899        |
|    ep_rew_mean           | -455       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 11         |
|    time_elapsed          | 368        |
|    total_timesteps       | 1929216    |
| train/                   |            |
|    approx_kl             | 0.00383981 |
|    clip_fraction         | 0.0216     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.45       |
|    cost_value_loss       | 14.7       |
|    cost_values           | 3          |
|    entropy               | -1.02      |
|    entropy_loss          | -1.02      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.0047     |
|    learning_rate         | 0.0003     |
|    loss                  | 5.24       |
|    n_updates             | 9410       |
|    policy_gradient_loss  | -0.00157   |
|    std                   | 0.403      |
|    value_loss            | 7.6        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.7680868  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -457        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 12          |
|    time_elapsed          | 402         |
|    total_timesteps       | 1931264     |
| train/                   |             |
|    approx_kl             | 0.001552012 |
|    clip_fraction         | 0.0287      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.02        |
|    n_updates             | 9420        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.403       |
|    value_loss            | 6.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5189478   |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 437          |
|    total_timesteps       | 1933312      |
| train/                   |              |
|    approx_kl             | 0.0036801628 |
|    clip_fraction         | 0.0676       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.89         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000764     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.01         |
|    n_updates             | 9430         |
|    policy_gradient_loss  | 0.000276     |
|    std                   | 0.402        |
|    value_loss            | 4.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42515355  |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 1935360      |
| train/                   |              |
|    approx_kl             | 0.0053266725 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 8.15         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 9440         |
|    policy_gradient_loss  | -0.000682    |
|    std                   | 0.405        |
|    value_loss            | 22.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.2073146  |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 508         |
|    total_timesteps       | 1937408     |
| train/                   |             |
|    approx_kl             | 0.004629351 |
|    clip_fraction         | 0.044       |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 13.4        |
|    cost_values           | 3           |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00871     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 9450        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.406       |
|    value_loss            | 15.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.5632533  |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 543         |
|    total_timesteps       | 1939456     |
| train/                   |             |
|    approx_kl             | 0.004178772 |
|    clip_fraction         | 0.0109      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 7.91        |
|    cost_values           | 3           |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00741     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.34        |
|    n_updates             | 9460        |
|    policy_gradient_loss  | -0.00025    |
|    std                   | 0.407       |
|    value_loss            | 1.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.34282666  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 578          |
|    total_timesteps       | 1941504      |
| train/                   |              |
|    approx_kl             | 0.0031821723 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.86         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00594      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.94         |
|    n_updates             | 9470         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.406        |
|    value_loss            | 5.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.63750726  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 613          |
|    total_timesteps       | 1943552      |
| train/                   |              |
|    approx_kl             | 0.0026887567 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.77         |
|    cost_value_loss       | 5.65         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0025       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.08         |
|    n_updates             | 9480         |
|    policy_gradient_loss  | -0.000392    |
|    std                   | 0.405        |
|    value_loss            | 1.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.4779149   |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 648          |
|    total_timesteps       | 1945600      |
| train/                   |              |
|    approx_kl             | 0.0031411697 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.84         |
|    cost_value_loss       | 19.9         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.49         |
|    n_updates             | 9490         |
|    policy_gradient_loss  | -0.000169    |
|    std                   | 0.405        |
|    value_loss            | 3.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.57002413  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 684          |
|    total_timesteps       | 1947648      |
| train/                   |              |
|    approx_kl             | 0.0018415279 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00923      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.08         |
|    n_updates             | 9500         |
|    policy_gradient_loss  | -0.00016     |
|    std                   | 0.405        |
|    value_loss            | 4.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.59065723 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 718         |
|    total_timesteps       | 1949696     |
| train/                   |             |
|    approx_kl             | 0.004549219 |
|    clip_fraction         | 0.00874     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.85        |
|    cost_value_loss       | 22.1        |
|    cost_values           | 3           |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.0106      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.5         |
|    n_updates             | 9510        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.405       |
|    value_loss            | 2.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49567398  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 752          |
|    total_timesteps       | 1951744      |
| train/                   |              |
|    approx_kl             | 0.0023890724 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0037       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.9          |
|    n_updates             | 9520         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.405        |
|    value_loss            | 16.6         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.7686865 |
| rollout/                 |            |
|    ep_len_mean           | 905        |
|    ep_rew_mean           | -463       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 23         |
|    time_elapsed          | 786        |
|    total_timesteps       | 1953792    |
| train/                   |            |
|    approx_kl             | 0.00292108 |
|    clip_fraction         | 0.00928    |
|    clip_range            | 0.2        |
|    cost_returns          | 5.74       |
|    cost_value_loss       | 17.5       |
|    cost_values           | 3          |
|    entropy               | -1.04      |
|    entropy_loss          | -1.03      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 10.1       |
|    n_updates             | 9530       |
|    policy_gradient_loss  | -0.00077   |
|    std                   | 0.407      |
|    value_loss            | 2.49       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.68195766 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 821         |
|    total_timesteps       | 1955840     |
| train/                   |             |
|    approx_kl             | 0.007444104 |
|    clip_fraction         | 0.093       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 3           |
|    entropy               | -1.03       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.0054      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.22        |
|    n_updates             | 9540        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.406       |
|    value_loss            | 18.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.70536417   |
| rollout/                 |               |
|    ep_len_mean           | 906           |
|    ep_rew_mean           | -463          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 25            |
|    time_elapsed          | 855           |
|    total_timesteps       | 1957888       |
| train/                   |               |
|    approx_kl             | 0.00039885478 |
|    clip_fraction         | 0.0105        |
|    clip_range            | 0.2           |
|    cost_returns          | 6.49          |
|    cost_value_loss       | 21            |
|    cost_values           | 2.99          |
|    entropy               | -1.03         |
|    entropy_loss          | -1.03         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.0221        |
|    learning_rate         | 0.0003        |
|    loss                  | 4.68          |
|    n_updates             | 9550          |
|    policy_gradient_loss  | 0.000992      |
|    std                   | 0.406         |
|    value_loss            | 18.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.37321544  |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 890          |
|    total_timesteps       | 1959936      |
| train/                   |              |
|    approx_kl             | 0.0027710076 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.6          |
|    cost_value_loss       | 14.5         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.39         |
|    n_updates             | 9560         |
|    policy_gradient_loss  | 0.000407     |
|    std                   | 0.406        |
|    value_loss            | 3.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2738551  |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 924         |
|    total_timesteps       | 1961984     |
| train/                   |             |
|    approx_kl             | 0.004240786 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 3           |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0041      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 9570        |
|    policy_gradient_loss  | -0.00092    |
|    std                   | 0.405       |
|    value_loss            | 11.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.65077925  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 1964032      |
| train/                   |              |
|    approx_kl             | 0.0051696035 |
|    clip_fraction         | 0.0752       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 5.29         |
|    cost_values           | 2.99         |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.000509     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 9580         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.404        |
|    value_loss            | 17.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.65361327 |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 992         |
|    total_timesteps       | 1966080     |
| train/                   |             |
|    approx_kl             | 0.007223423 |
|    clip_fraction         | 0.0346      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 12.4        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.9        |
|    n_updates             | 9590        |
|    policy_gradient_loss  | -0.00235    |
|    std                   | 0.403       |
|    value_loss            | 21.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.7363473  |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1026        |
|    total_timesteps       | 1968128     |
| train/                   |             |
|    approx_kl             | 0.004854517 |
|    clip_fraction         | 0.0284      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 3           |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00793     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 9600        |
|    policy_gradient_loss  | -0.00251    |
|    std                   | 0.401       |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48970798 |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1060        |
|    total_timesteps       | 1970176     |
| train/                   |             |
|    approx_kl             | 0.006311753 |
|    clip_fraction         | 0.0282      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 7.92        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.01       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00052     |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 9610        |
|    policy_gradient_loss  | -0.00302    |
|    std                   | 0.403       |
|    value_loss            | 30.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.09         |
| reward                   | -0.32589224  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1095         |
|    total_timesteps       | 1972224      |
| train/                   |              |
|    approx_kl             | 0.0060937935 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.03         |
|    cost_value_loss       | 5.79         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 9620         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.404        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.75         |
| reward                   | -0.29848915  |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1128         |
|    total_timesteps       | 1974272      |
| train/                   |              |
|    approx_kl             | 0.0032843528 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.77         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 9630         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.404        |
|    value_loss            | 3.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34443188 |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1163        |
|    total_timesteps       | 1976320     |
| train/                   |             |
|    approx_kl             | 0.004250606 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 8.63        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00761     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 9640        |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.404       |
|    value_loss            | 12.6        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.6890786 |
| rollout/                 |            |
|    ep_len_mean           | 898        |
|    ep_rew_mean           | -471       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 35         |
|    time_elapsed          | 1197       |
|    total_timesteps       | 1978368    |
| train/                   |            |
|    approx_kl             | 0.00702912 |
|    clip_fraction         | 0.0661     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.82       |
|    cost_value_loss       | 16.2       |
|    cost_values           | 3          |
|    entropy               | -1.02      |
|    entropy_loss          | -1.02      |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0.00834    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.64       |
|    n_updates             | 9650       |
|    policy_gradient_loss  | -0.0027    |
|    std                   | 0.404      |
|    value_loss            | 18.8       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.72        |
| reward                   | -0.20696212 |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1231        |
|    total_timesteps       | 1980416     |
| train/                   |             |
|    approx_kl             | 0.003686787 |
|    clip_fraction         | 0.0185      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 5.49        |
|    cost_values           | 3           |
|    entropy               | -1.03       |
|    entropy_loss          | -1.02       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0.00459     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.56        |
|    n_updates             | 9660        |
|    policy_gradient_loss  | -0.000568   |
|    std                   | 0.405       |
|    value_loss            | 4.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.62436885  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1266         |
|    total_timesteps       | 1982464      |
| train/                   |              |
|    approx_kl             | 0.0016696155 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.92         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 3            |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 9670         |
|    policy_gradient_loss  | -0.000661    |
|    std                   | 0.406        |
|    value_loss            | 19.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.19505925  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1301         |
|    total_timesteps       | 1984512      |
| train/                   |              |
|    approx_kl             | 0.0043023704 |
|    clip_fraction         | 0.00928      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.89         |
|    cost_value_loss       | 4.63         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00554      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 9680         |
|    policy_gradient_loss  | -0.000439    |
|    std                   | 0.404        |
|    value_loss            | 5.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5810524   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1335         |
|    total_timesteps       | 1986560      |
| train/                   |              |
|    approx_kl             | 0.0022669164 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.46         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0019       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 9690         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.403        |
|    value_loss            | 8            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5015895   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1370         |
|    total_timesteps       | 1988608      |
| train/                   |              |
|    approx_kl             | 0.0016815487 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00561      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.62         |
|    n_updates             | 9700         |
|    policy_gradient_loss  | -0.000739    |
|    std                   | 0.404        |
|    value_loss            | 38.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5278185   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1404         |
|    total_timesteps       | 1990656      |
| train/                   |              |
|    approx_kl             | 0.0024567398 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.28         |
|    cost_value_loss       | 23.2         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 9710         |
|    policy_gradient_loss  | -0.000309    |
|    std                   | 0.403        |
|    value_loss            | 4.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6329936   |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1438         |
|    total_timesteps       | 1992704      |
| train/                   |              |
|    approx_kl             | 0.0026573343 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.35         |
|    cost_value_loss       | 8.59         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00239      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.22         |
|    n_updates             | 9720         |
|    policy_gradient_loss  | -0.000313    |
|    std                   | 0.403        |
|    value_loss            | 8.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.32390064 |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1473        |
|    total_timesteps       | 1994752     |
| train/                   |             |
|    approx_kl             | 0.004742034 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00324     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.34        |
|    n_updates             | 9730        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.403       |
|    value_loss            | 7.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.74740064  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1507         |
|    total_timesteps       | 1996800      |
| train/                   |              |
|    approx_kl             | 0.0051993295 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.53         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00454      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.33         |
|    n_updates             | 9740         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.403        |
|    value_loss            | 5.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6011493   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1541         |
|    total_timesteps       | 1998848      |
| train/                   |              |
|    approx_kl             | 0.0017116764 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.06         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00683      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 9750         |
|    policy_gradient_loss  | 7.1e-05      |
|    std                   | 0.403        |
|    value_loss            | 17           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.43990558 |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -481        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1576        |
|    total_timesteps       | 2000896     |
| train/                   |             |
|    approx_kl             | 0.004011374 |
|    clip_fraction         | 0.0161      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.99        |
|    cost_value_loss       | 19          |
|    cost_values           | 3           |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00896     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 9760        |
|    policy_gradient_loss  | -0.000558   |
|    std                   | 0.402       |
|    value_loss            | 4.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66173327  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1610         |
|    total_timesteps       | 2002944      |
| train/                   |              |
|    approx_kl             | 0.0035091587 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.91         |
|    cost_value_loss       | 22.3         |
|    cost_values           | 3            |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0132       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 9770         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.402        |
|    value_loss            | 3.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.197166    |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1645         |
|    total_timesteps       | 2004992      |
| train/                   |              |
|    approx_kl             | 0.0051842043 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.85         |
|    cost_value_loss       | 18.9         |
|    cost_values           | 2.99         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00173      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.47         |
|    n_updates             | 9780         |
|    policy_gradient_loss  | -0.000564    |
|    std                   | 0.402        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42421472  |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1680         |
|    total_timesteps       | 2007040      |
| train/                   |              |
|    approx_kl             | 0.0055198567 |
|    clip_fraction         | 0.0626       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.98         |
|    cost_value_loss       | 18.6         |
|    cost_values           | 3            |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00335      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.34         |
|    n_updates             | 9790         |
|    policy_gradient_loss  | -0.0057      |
|    std                   | 0.402        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------
| avg_speed          | 8.04        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.04        |
| reward             | -0.71234775 |
| rollout/           |             |
|    ep_len_mean     | 906         |
|    ep_rew_mean     | -484        |
| time/              |             |
|    fps             | 82          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2009088     |
------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.6011482   |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2011136      |
| train/                   |              |
|    approx_kl             | 0.0033096645 |
|    clip_fraction         | 0.0488       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 13.9         |
|    cost_values           | 3            |
|    entropy               | -1.01        |
|    entropy_loss          | -1.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.73         |
|    n_updates             | 9810         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.403        |
|    value_loss            | 4.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.43167484 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 2013184     |
| train/                   |             |
|    approx_kl             | 0.005988274 |
|    clip_fraction         | 0.0412      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 9.56        |
|    cost_values           | 3           |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.000136    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.54        |
|    n_updates             | 9820        |
|    policy_gradient_loss  | -0.00365    |
|    std                   | 0.402       |
|    value_loss            | 6.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34803352 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 2015232     |
| train/                   |             |
|    approx_kl             | 0.003912946 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.86        |
|    cost_value_loss       | 18.6        |
|    cost_values           | 3           |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00861     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 9830        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.402       |
|    value_loss            | 5.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31286547 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 2017280     |
| train/                   |             |
|    approx_kl             | 0.004433716 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.05        |
|    cost_value_loss       | 28.2        |
|    cost_values           | 3           |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0129      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 9840        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.402       |
|    value_loss            | 2.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48648274 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 2019328     |
| train/                   |             |
|    approx_kl             | 0.001744504 |
|    clip_fraction         | 0.0835      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.09        |
|    cost_value_loss       | 35.9        |
|    cost_values           | 3           |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0413      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.71        |
|    n_updates             | 9850        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.403       |
|    value_loss            | 2.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.74629253  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 2021376      |
| train/                   |              |
|    approx_kl             | 0.0046246573 |
|    clip_fraction         | 0.0248       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.42         |
|    cost_value_loss       | 25           |
|    cost_values           | 2.99         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.01        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 9860         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.403        |
|    value_loss            | 2.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6080716   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 2023424      |
| train/                   |              |
|    approx_kl             | 0.0058808457 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.86         |
|    cost_value_loss       | 24.4         |
|    cost_values           | 2.99         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.8         |
|    n_updates             | 9870         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.403        |
|    value_loss            | 19.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7281884  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -481        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 302         |
|    total_timesteps       | 2025472     |
| train/                   |             |
|    approx_kl             | 0.007673566 |
|    clip_fraction         | 0.051       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.93        |
|    cost_value_loss       | 5.76        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00311     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.85        |
|    n_updates             | 9880        |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.403       |
|    value_loss            | 23.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5329076  |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 336         |
|    total_timesteps       | 2027520     |
| train/                   |             |
|    approx_kl             | 0.005070797 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.1         |
|    cost_value_loss       | 30.1        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00189     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 9890        |
|    policy_gradient_loss  | -0.00035    |
|    std                   | 0.403       |
|    value_loss            | 5.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.57615185 |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 371         |
|    total_timesteps       | 2029568     |
| train/                   |             |
|    approx_kl             | 0.004365591 |
|    clip_fraction         | 0.032       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.35        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 3           |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00499     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.84        |
|    n_updates             | 9900        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.403       |
|    value_loss            | 6.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.51707685  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 406          |
|    total_timesteps       | 2031616      |
| train/                   |              |
|    approx_kl             | 0.0025407851 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.45         |
|    cost_value_loss       | 24.5         |
|    cost_values           | 3            |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0136       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 9910         |
|    policy_gradient_loss  | -0.000557    |
|    std                   | 0.402        |
|    value_loss            | 4.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4033873   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 2033664      |
| train/                   |              |
|    approx_kl             | 0.0042048176 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.12         |
|    cost_value_loss       | 22.2         |
|    cost_values           | 2.99         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 9920         |
|    policy_gradient_loss  | -0.000794    |
|    std                   | 0.402        |
|    value_loss            | 2.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.32106307  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 475          |
|    total_timesteps       | 2035712      |
| train/                   |              |
|    approx_kl             | 0.0024101117 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.36         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 3            |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00512      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.9          |
|    n_updates             | 9930         |
|    policy_gradient_loss  | -0.000133    |
|    std                   | 0.402        |
|    value_loss            | 5.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3868818   |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 509          |
|    total_timesteps       | 2037760      |
| train/                   |              |
|    approx_kl             | 0.0027124416 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.14         |
|    cost_value_loss       | 26.7         |
|    cost_values           | 3            |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0178       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.53         |
|    n_updates             | 9940         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.402        |
|    value_loss            | 13.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5805683  |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 543         |
|    total_timesteps       | 2039808     |
| train/                   |             |
|    approx_kl             | 0.002352437 |
|    clip_fraction         | 0.00532     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.16        |
|    cost_value_loss       | 19          |
|    cost_values           | 3           |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0134      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 9950        |
|    policy_gradient_loss  | -3.89e-05   |
|    std                   | 0.402       |
|    value_loss            | 1.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.66989344 |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 577         |
|    total_timesteps       | 2041856     |
| train/                   |             |
|    approx_kl             | 0.004439129 |
|    clip_fraction         | 0.0303      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 2.99        |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.5        |
|    n_updates             | 9960        |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.402       |
|    value_loss            | 17.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.42715383 |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 612         |
|    total_timesteps       | 2043904     |
| train/                   |             |
|    approx_kl             | 0.0045532   |
|    clip_fraction         | 0.0107      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 16.1        |
|    cost_values           | 3           |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0113      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 9970        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.403       |
|    value_loss            | 4.99        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.7651576 |
| rollout/                 |            |
|    ep_len_mean           | 920        |
|    ep_rew_mean           | -480       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 19         |
|    time_elapsed          | 646        |
|    total_timesteps       | 2045952    |
| train/                   |            |
|    approx_kl             | 0.00638966 |
|    clip_fraction         | 0.0291     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.72       |
|    cost_value_loss       | 17.7       |
|    cost_values           | 3          |
|    entropy               | -1         |
|    entropy_loss          | -1.01      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.0094     |
|    learning_rate         | 0.0003     |
|    loss                  | 4.22       |
|    n_updates             | 9980       |
|    policy_gradient_loss  | -0.00175   |
|    std                   | 0.401      |
|    value_loss            | 2.55       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.329        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.329        |
| reward                   | -0.47638825  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 2048000      |
| train/                   |              |
|    approx_kl             | 0.0026600189 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 3            |
|    entropy               | -1.02        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 9990         |
|    policy_gradient_loss  | -0.000207    |
|    std                   | 0.403        |
|    value_loss            | 20.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.21         |
| reward                   | -0.42002514  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 714          |
|    total_timesteps       | 2050048      |
| train/                   |              |
|    approx_kl             | 0.0050050993 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 18           |
|    cost_values           | 3            |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00519      |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 10000        |
|    policy_gradient_loss  | -0.000317    |
|    std                   | 0.402        |
|    value_loss            | 2.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.38        |
| reward                   | -0.24060985 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 749         |
|    total_timesteps       | 2052096     |
| train/                   |             |
|    approx_kl             | 0.005703494 |
|    clip_fraction         | 0.0336      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 3           |
|    entropy               | -1          |
|    entropy_loss          | -1.01       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.0037      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.51        |
|    n_updates             | 10010       |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.401       |
|    value_loss            | 3.23        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.51275617   |
| rollout/                 |               |
|    ep_len_mean           | 932           |
|    ep_rew_mean           | -485          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 23            |
|    time_elapsed          | 783           |
|    total_timesteps       | 2054144       |
| train/                   |               |
|    approx_kl             | 0.00061237975 |
|    clip_fraction         | 0.00972       |
|    clip_range            | 0.2           |
|    cost_returns          | 6.41          |
|    cost_value_loss       | 24.1          |
|    cost_values           | 3             |
|    entropy               | -1            |
|    entropy_loss          | -1            |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0.0138        |
|    learning_rate         | 0.0003        |
|    loss                  | 4.3           |
|    n_updates             | 10020         |
|    policy_gradient_loss  | -0.000351     |
|    std                   | 0.4           |
|    value_loss            | 2.68          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.481433    |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 818          |
|    total_timesteps       | 2056192      |
| train/                   |              |
|    approx_kl             | 0.0023006136 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.05         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 3            |
|    entropy               | -0.99        |
|    entropy_loss          | -0.996       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00952      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.77         |
|    n_updates             | 10030        |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.398        |
|    value_loss            | 1.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.6414954   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 852          |
|    total_timesteps       | 2058240      |
| train/                   |              |
|    approx_kl             | 0.0066732145 |
|    clip_fraction         | 0.0476       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.85         |
|    cost_value_loss       | 3.82         |
|    cost_values           | 2.86         |
|    entropy               | -0.977       |
|    entropy_loss          | -0.983       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 10040        |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.395        |
|    value_loss            | 14.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.21135052 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -482        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 887         |
|    total_timesteps       | 2060288     |
| train/                   |             |
|    approx_kl             | 0.002371965 |
|    clip_fraction         | 0.076       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.45        |
|    cost_value_loss       | 29.9        |
|    cost_values           | 2.97        |
|    entropy               | -0.975      |
|    entropy_loss          | -0.975      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00776     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.34        |
|    n_updates             | 10050       |
|    policy_gradient_loss  | -0.000247   |
|    std                   | 0.395       |
|    value_loss            | 13.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5127046   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 922          |
|    total_timesteps       | 2062336      |
| train/                   |              |
|    approx_kl             | 0.0041257953 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.06         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 2.93         |
|    entropy               | -0.974       |
|    entropy_loss          | -0.974       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0159       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.41         |
|    n_updates             | 10060        |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.395        |
|    value_loss            | 1.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.41354498 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 956         |
|    total_timesteps       | 2064384     |
| train/                   |             |
|    approx_kl             | 0.004061711 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 21.9        |
|    cost_values           | 2.99        |
|    entropy               | -0.975      |
|    entropy_loss          | -0.975      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.8        |
|    n_updates             | 10070       |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.395       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.30552143  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 990          |
|    total_timesteps       | 2066432      |
| train/                   |              |
|    approx_kl             | 0.0026488292 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.03         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 3            |
|    entropy               | -0.965       |
|    entropy_loss          | -0.971       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0015       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.62         |
|    n_updates             | 10080        |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.393        |
|    value_loss            | 1.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.68491215  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1025         |
|    total_timesteps       | 2068480      |
| train/                   |              |
|    approx_kl             | 0.0012757337 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.24         |
|    cost_value_loss       | 7.14         |
|    cost_values           | 3            |
|    entropy               | -0.959       |
|    entropy_loss          | -0.961       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.64         |
|    n_updates             | 10090        |
|    policy_gradient_loss  | -0.000863    |
|    std                   | 0.392        |
|    value_loss            | 2.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.3924865  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1060        |
|    total_timesteps       | 2070528     |
| train/                   |             |
|    approx_kl             | 0.015288693 |
|    clip_fraction         | 0.0848      |
|    clip_range            | 0.2         |
|    cost_returns          | 6           |
|    cost_value_loss       | 20.2        |
|    cost_values           | 3           |
|    entropy               | -0.955      |
|    entropy_loss          | -0.956      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00376     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.32        |
|    n_updates             | 10100       |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.391       |
|    value_loss            | 5.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.2322822   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1094         |
|    total_timesteps       | 2072576      |
| train/                   |              |
|    approx_kl             | 0.0027578343 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.28         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 2.87         |
|    entropy               | -0.955       |
|    entropy_loss          | -0.954       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.56         |
|    n_updates             | 10110        |
|    policy_gradient_loss  | -0.000793    |
|    std                   | 0.391        |
|    value_loss            | 4.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40632862 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1129        |
|    total_timesteps       | 2074624     |
| train/                   |             |
|    approx_kl             | 0.004000697 |
|    clip_fraction         | 0.0113      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.89        |
|    cost_value_loss       | 18.8        |
|    cost_values           | 3           |
|    entropy               | -0.956      |
|    entropy_loss          | -0.956      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00738     |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 10120       |
|    policy_gradient_loss  | -0.000944   |
|    std                   | 0.391       |
|    value_loss            | 6.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5304393   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 2076672      |
| train/                   |              |
|    approx_kl             | 0.0070902267 |
|    clip_fraction         | 0.051        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.48         |
|    cost_value_loss       | 39.1         |
|    cost_values           | 3            |
|    entropy               | -0.957       |
|    entropy_loss          | -0.957       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.3         |
|    n_updates             | 10130        |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 0.391        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.5075975  |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1199        |
|    total_timesteps       | 2078720     |
| train/                   |             |
|    approx_kl             | 0.007124697 |
|    clip_fraction         | 0.0723      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.36        |
|    cost_value_loss       | 14.9        |
|    cost_values           | 2.99        |
|    entropy               | -0.955      |
|    entropy_loss          | -0.956      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.1        |
|    n_updates             | 10140       |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.391       |
|    value_loss            | 24          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.54851776 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1234        |
|    total_timesteps       | 2080768     |
| train/                   |             |
|    approx_kl             | 0.004160285 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.89        |
|    cost_value_loss       | 35.2        |
|    cost_values           | 3           |
|    entropy               | -0.95       |
|    entropy_loss          | -0.952      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.039       |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 10150       |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.39        |
|    value_loss            | 1.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5560685  |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1269        |
|    total_timesteps       | 2082816     |
| train/                   |             |
|    approx_kl             | 0.005568099 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.54        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 2.99        |
|    entropy               | -0.951      |
|    entropy_loss          | -0.95       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0064      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 10160       |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.39        |
|    value_loss            | 2.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49838147  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1304         |
|    total_timesteps       | 2084864      |
| train/                   |              |
|    approx_kl             | 0.0013137317 |
|    clip_fraction         | 0.0481       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 3            |
|    entropy               | -0.953       |
|    entropy_loss          | -0.953       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.7          |
|    n_updates             | 10170        |
|    policy_gradient_loss  | -5.42e-05    |
|    std                   | 0.391        |
|    value_loss            | 1.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.32195216  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1339         |
|    total_timesteps       | 2086912      |
| train/                   |              |
|    approx_kl             | 0.0052312375 |
|    clip_fraction         | 0.075        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.77         |
|    cost_value_loss       | 28.2         |
|    cost_values           | 3            |
|    entropy               | -0.957       |
|    entropy_loss          | -0.956       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.024        |
|    learning_rate         | 0.0003       |
|    loss                  | 3.95         |
|    n_updates             | 10180        |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.391        |
|    value_loss            | 1.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.32965642  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1374         |
|    total_timesteps       | 2088960      |
| train/                   |              |
|    approx_kl             | 0.0005295243 |
|    clip_fraction         | 0.0636       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.21         |
|    cost_value_loss       | 23           |
|    cost_values           | 2.99         |
|    entropy               | -0.958       |
|    entropy_loss          | -0.957       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0207       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.91         |
|    n_updates             | 10190        |
|    policy_gradient_loss  | -0.000309    |
|    std                   | 0.392        |
|    value_loss            | 4.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41644436  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1408         |
|    total_timesteps       | 2091008      |
| train/                   |              |
|    approx_kl             | 0.0029852684 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.55         |
|    cost_value_loss       | 17           |
|    cost_values           | 2.89         |
|    entropy               | -0.955       |
|    entropy_loss          | -0.957       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.17         |
|    n_updates             | 10200        |
|    policy_gradient_loss  | -0.000818    |
|    std                   | 0.391        |
|    value_loss            | 2.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4036383   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1442         |
|    total_timesteps       | 2093056      |
| train/                   |              |
|    approx_kl             | 0.0058375783 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.2          |
|    cost_value_loss       | 13           |
|    cost_values           | 3            |
|    entropy               | -0.953       |
|    entropy_loss          | -0.954       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0111       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 10210        |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 0.391        |
|    value_loss            | 0.979        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5338898  |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1476        |
|    total_timesteps       | 2095104     |
| train/                   |             |
|    approx_kl             | 0.008101027 |
|    clip_fraction         | 0.0645      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.64        |
|    cost_value_loss       | 27.3        |
|    cost_values           | 2.96        |
|    entropy               | -0.952      |
|    entropy_loss          | -0.952      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.6        |
|    n_updates             | 10220       |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 0.39        |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.615101    |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1510         |
|    total_timesteps       | 2097152      |
| train/                   |              |
|    approx_kl             | 0.0026561422 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 2.99         |
|    entropy               | -0.948       |
|    entropy_loss          | -0.95        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00548      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.2          |
|    n_updates             | 10230        |
|    policy_gradient_loss  | -0.000334    |
|    std                   | 0.39         |
|    value_loss            | 1.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7056785   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1544         |
|    total_timesteps       | 2099200      |
| train/                   |              |
|    approx_kl             | 0.0025262334 |
|    clip_fraction         | 0.00796      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.8          |
|    cost_value_loss       | 19.5         |
|    cost_values           | 3            |
|    entropy               | -0.946       |
|    entropy_loss          | -0.947       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 10240        |
|    policy_gradient_loss  | 7.47e-05     |
|    std                   | 0.389        |
|    value_loss            | 3.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4228543   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1578         |
|    total_timesteps       | 2101248      |
| train/                   |              |
|    approx_kl             | 0.0038576103 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.84         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 3            |
|    entropy               | -0.939       |
|    entropy_loss          | -0.944       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00511      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.09         |
|    n_updates             | 10250        |
|    policy_gradient_loss  | -0.000644    |
|    std                   | 0.388        |
|    value_loss            | 2.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45974615  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1613         |
|    total_timesteps       | 2103296      |
| train/                   |              |
|    approx_kl             | 0.0035387315 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.11         |
|    cost_value_loss       | 27.4         |
|    cost_values           | 3            |
|    entropy               | -0.934       |
|    entropy_loss          | -0.936       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00453      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 10260        |
|    policy_gradient_loss  | 4.33e-05     |
|    std                   | 0.387        |
|    value_loss            | 3.18         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.621912     |
| rollout/                 |               |
|    ep_len_mean           | 938           |
|    ep_rew_mean           | -449          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 48            |
|    time_elapsed          | 1647          |
|    total_timesteps       | 2105344       |
| train/                   |               |
|    approx_kl             | 5.3209893e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 7.66          |
|    cost_value_loss       | 36            |
|    cost_values           | 2.99          |
|    entropy               | -0.932        |
|    entropy_loss          | -0.933        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 19.8          |
|    n_updates             | 10270         |
|    policy_gradient_loss  | -0.000119     |
|    std                   | 0.387         |
|    value_loss            | 2.31          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45120645  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1682         |
|    total_timesteps       | 2107392      |
| train/                   |              |
|    approx_kl             | 0.0033671767 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.54         |
|    cost_value_loss       | 23           |
|    cost_values           | 3            |
|    entropy               | -0.933       |
|    entropy_loss          | -0.933       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 10280        |
|    policy_gradient_loss  | -0.000132    |
|    std                   | 0.387        |
|    value_loss            | 1.63         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 8           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.35208157 |
| rollout/           |             |
|    ep_len_mean     | 938         |
|    ep_rew_mean     | -451        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2109440     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40964857  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2111488      |
| train/                   |              |
|    approx_kl             | 0.0021191342 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 3            |
|    entropy               | -0.938       |
|    entropy_loss          | -0.939       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00389      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 10300        |
|    policy_gradient_loss  | 0.000302     |
|    std                   | 0.388        |
|    value_loss            | 3.9          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7125734  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 3           |
|    time_elapsed          | 92          |
|    total_timesteps       | 2113536     |
| train/                   |             |
|    approx_kl             | 0.008397933 |
|    clip_fraction         | 0.0919      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.64        |
|    cost_value_loss       | 27.8        |
|    cost_values           | 2.99        |
|    entropy               | -0.937      |
|    entropy_loss          | -0.937      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0222      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 10310       |
|    policy_gradient_loss  | -0.000288   |
|    std                   | 0.388       |
|    value_loss            | 14.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6866533   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 2115584      |
| train/                   |              |
|    approx_kl             | 0.0015954184 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.17         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 3            |
|    entropy               | -0.936       |
|    entropy_loss          | -0.937       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00899      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.01         |
|    n_updates             | 10320        |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.387        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4308274   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 2117632      |
| train/                   |              |
|    approx_kl             | 0.0029266076 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.68         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 3            |
|    entropy               | -0.938       |
|    entropy_loss          | -0.937       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0146       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.91         |
|    n_updates             | 10330        |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.388        |
|    value_loss            | 3.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.74         |
| reward                   | -0.45946336  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 2119680      |
| train/                   |              |
|    approx_kl             | 0.0007027783 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.03         |
|    cost_value_loss       | 20.6         |
|    cost_values           | 3            |
|    entropy               | -0.945       |
|    entropy_loss          | -0.941       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0141       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.1          |
|    n_updates             | 10340        |
|    policy_gradient_loss  | 0.000188     |
|    std                   | 0.389        |
|    value_loss            | 3.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5140236   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 2121728      |
| train/                   |              |
|    approx_kl             | 0.0051026316 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.09         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 2.99         |
|    entropy               | -0.947       |
|    entropy_loss          | -0.947       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00486      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.18         |
|    n_updates             | 10350        |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.389        |
|    value_loss            | 3.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.64918905 |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 265         |
|    total_timesteps       | 2123776     |
| train/                   |             |
|    approx_kl             | 0.003988337 |
|    clip_fraction         | 0.0629      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.91        |
|    cost_value_loss       | 25.5        |
|    cost_values           | 3           |
|    entropy               | -0.946      |
|    entropy_loss          | -0.946      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0206      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.53        |
|    n_updates             | 10360       |
|    policy_gradient_loss  | -0.00303    |
|    std                   | 0.389       |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5024596   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 2125824      |
| train/                   |              |
|    approx_kl             | 0.0020292914 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.3          |
|    cost_value_loss       | 20.9         |
|    cost_values           | 3            |
|    entropy               | -0.943       |
|    entropy_loss          | -0.945       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0064       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.04         |
|    n_updates             | 10370        |
|    policy_gradient_loss  | -0.000373    |
|    std                   | 0.388        |
|    value_loss            | 1.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.46732956  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 2127872      |
| train/                   |              |
|    approx_kl             | 0.0029639408 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 8.85         |
|    cost_values           | 2.99         |
|    entropy               | -0.927       |
|    entropy_loss          | -0.934       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.38         |
|    n_updates             | 10380        |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.386        |
|    value_loss            | 7.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4408645  |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 2129920     |
| train/                   |             |
|    approx_kl             | 0.006721733 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.89        |
|    cost_value_loss       | 26.1        |
|    cost_values           | 3           |
|    entropy               | -0.926      |
|    entropy_loss          | -0.925      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.8        |
|    n_updates             | 10390       |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.385       |
|    value_loss            | 22.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4268035  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 403         |
|    total_timesteps       | 2131968     |
| train/                   |             |
|    approx_kl             | 0.005446065 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.06        |
|    cost_value_loss       | 20.8        |
|    cost_values           | 3           |
|    entropy               | -0.927      |
|    entropy_loss          | -0.926      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.0121      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.64        |
|    n_updates             | 10400       |
|    policy_gradient_loss  | -5.32e-05   |
|    std                   | 0.386       |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50654083  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 2134016      |
| train/                   |              |
|    approx_kl             | 0.0024465213 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.37         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 3            |
|    entropy               | -0.927       |
|    entropy_loss          | -0.928       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.61         |
|    n_updates             | 10410        |
|    policy_gradient_loss  | -0.000972    |
|    std                   | 0.385        |
|    value_loss            | 3.94         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.68025106   |
| rollout/                 |               |
|    ep_len_mean           | 927           |
|    ep_rew_mean           | -444          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 14            |
|    time_elapsed          | 473           |
|    total_timesteps       | 2136064       |
| train/                   |               |
|    approx_kl             | 0.00043169744 |
|    clip_fraction         | 0.0219        |
|    clip_range            | 0.2           |
|    cost_returns          | 7.31          |
|    cost_value_loss       | 27.1          |
|    cost_values           | 3             |
|    entropy               | -0.928        |
|    entropy_loss          | -0.927        |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 15.5          |
|    n_updates             | 10420         |
|    policy_gradient_loss  | -9.69e-05     |
|    std                   | 0.386         |
|    value_loss            | 3.73          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3603663  |
| rollout/                 |             |
|    ep_len_mean           | 920         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 508         |
|    total_timesteps       | 2138112     |
| train/                   |             |
|    approx_kl             | 0.007109468 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.58        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 2.99        |
|    entropy               | -0.931      |
|    entropy_loss          | -0.93       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 10430       |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.386       |
|    value_loss            | 1.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4664164   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 2140160      |
| train/                   |              |
|    approx_kl             | 0.0044926945 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.54         |
|    cost_value_loss       | 21.6         |
|    cost_values           | 3            |
|    entropy               | -0.93        |
|    entropy_loss          | -0.931       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0146       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.76         |
|    n_updates             | 10440        |
|    policy_gradient_loss  | -0.00065     |
|    std                   | 0.386        |
|    value_loss            | 20.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.58554965  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 578          |
|    total_timesteps       | 2142208      |
| train/                   |              |
|    approx_kl             | 0.0030461901 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.02         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 3            |
|    entropy               | -0.924       |
|    entropy_loss          | -0.927       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.3         |
|    n_updates             | 10450        |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.385        |
|    value_loss            | 19           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.68202883 |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 613         |
|    total_timesteps       | 2144256     |
| train/                   |             |
|    approx_kl             | 0.006642241 |
|    clip_fraction         | 0.0275      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.82        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 3           |
|    entropy               | -0.917      |
|    entropy_loss          | -0.921      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00853     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 10460       |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 0.383       |
|    value_loss            | 2.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42444125  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 648          |
|    total_timesteps       | 2146304      |
| train/                   |              |
|    approx_kl             | 0.0028538404 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.78         |
|    cost_value_loss       | 24.9         |
|    cost_values           | 3            |
|    entropy               | -0.918       |
|    entropy_loss          | -0.916       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 10470        |
|    policy_gradient_loss  | -0.000841    |
|    std                   | 0.384        |
|    value_loss            | 18.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.33         |
| reward                   | -0.41252318  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 2148352      |
| train/                   |              |
|    approx_kl             | 0.0021811887 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.24         |
|    cost_value_loss       | 25.9         |
|    cost_values           | 3            |
|    entropy               | -0.917       |
|    entropy_loss          | -0.918       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00932      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 10480        |
|    policy_gradient_loss  | -0.000326    |
|    std                   | 0.383        |
|    value_loss            | 18.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.46         |
| reward                   | -0.61464465  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 717          |
|    total_timesteps       | 2150400      |
| train/                   |              |
|    approx_kl             | 0.0001936028 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.27         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 3            |
|    entropy               | -0.914       |
|    entropy_loss          | -0.916       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.000655     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 10490        |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 0.383        |
|    value_loss            | 19.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5102131   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 752          |
|    total_timesteps       | 2152448      |
| train/                   |              |
|    approx_kl             | 0.0031467197 |
|    clip_fraction         | 0.0278       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 7.82         |
|    cost_values           | 3            |
|    entropy               | -0.912       |
|    entropy_loss          | -0.914       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.69         |
|    n_updates             | 10500        |
|    policy_gradient_loss  | -0.000955    |
|    std                   | 0.382        |
|    value_loss            | 2.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.40329653  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 787          |
|    total_timesteps       | 2154496      |
| train/                   |              |
|    approx_kl             | 0.0040020645 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.69         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 3            |
|    entropy               | -0.907       |
|    entropy_loss          | -0.911       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00225      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.13         |
|    n_updates             | 10510        |
|    policy_gradient_loss  | -0.000204    |
|    std                   | 0.381        |
|    value_loss            | 7.38         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.6843896 |
| rollout/                 |            |
|    ep_len_mean           | 901        |
|    ep_rew_mean           | -453       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 24         |
|    time_elapsed          | 822        |
|    total_timesteps       | 2156544    |
| train/                   |            |
|    approx_kl             | 0.00980089 |
|    clip_fraction         | 0.0351     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.83       |
|    cost_value_loss       | 25.7       |
|    cost_values           | 3          |
|    entropy               | -0.9       |
|    entropy_loss          | -0.903     |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0.0137     |
|    learning_rate         | 0.0003     |
|    loss                  | 4.4        |
|    n_updates             | 10520      |
|    policy_gradient_loss  | -0.000413  |
|    std                   | 0.38       |
|    value_loss            | 2.76       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.68105024  |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 856          |
|    total_timesteps       | 2158592      |
| train/                   |              |
|    approx_kl             | 0.0055739256 |
|    clip_fraction         | 0.0485       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 14.3         |
|    cost_values           | 2.99         |
|    entropy               | -0.903       |
|    entropy_loss          | -0.9         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0144       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 10530        |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.381        |
|    value_loss            | 18.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42899102 |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 890         |
|    total_timesteps       | 2160640     |
| train/                   |             |
|    approx_kl             | 0.009032448 |
|    clip_fraction         | 0.0431      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.57        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 3           |
|    entropy               | -0.897      |
|    entropy_loss          | -0.902      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00734     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 10540       |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.38        |
|    value_loss            | 1.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.330968    |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 925          |
|    total_timesteps       | 2162688      |
| train/                   |              |
|    approx_kl             | 0.0033448972 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 14.7         |
|    cost_values           | 3            |
|    entropy               | -0.892       |
|    entropy_loss          | -0.894       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00972      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.87         |
|    n_updates             | 10550        |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.379        |
|    value_loss            | 2.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.37842995 |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 959         |
|    total_timesteps       | 2164736     |
| train/                   |             |
|    approx_kl             | 0.007872176 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.62        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 3           |
|    entropy               | -0.892      |
|    entropy_loss          | -0.892      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0077      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.42        |
|    n_updates             | 10560       |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.379       |
|    value_loss            | 44.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.3693357  |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 993         |
|    total_timesteps       | 2166784     |
| train/                   |             |
|    approx_kl             | 0.005974346 |
|    clip_fraction         | 0.0489      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.55        |
|    cost_value_loss       | 15.5        |
|    cost_values           | 3           |
|    entropy               | -0.885      |
|    entropy_loss          | -0.89       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.0145      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 10570       |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.377       |
|    value_loss            | 1.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.45015168  |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 2168832      |
| train/                   |              |
|    approx_kl             | 0.0031323517 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 1.53         |
|    cost_values           | 2.94         |
|    entropy               | -0.888       |
|    entropy_loss          | -0.884       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.77         |
|    n_updates             | 10580        |
|    policy_gradient_loss  | 0.000337     |
|    std                   | 0.378        |
|    value_loss            | 6.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.14178444 |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1062        |
|    total_timesteps       | 2170880     |
| train/                   |             |
|    approx_kl             | 0.006747775 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.1         |
|    cost_value_loss       | 17.1        |
|    cost_values           | 2.98        |
|    entropy               | -0.89       |
|    entropy_loss          | -0.89       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.93        |
|    n_updates             | 10590       |
|    policy_gradient_loss  | -0.000264   |
|    std                   | 0.378       |
|    value_loss            | 3.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.08        |
| reward                   | -0.4037456  |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1097        |
|    total_timesteps       | 2172928     |
| train/                   |             |
|    approx_kl             | 0.008276322 |
|    clip_fraction         | 0.0483      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.98        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 3           |
|    entropy               | -0.885      |
|    entropy_loss          | -0.888      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 10600       |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.377       |
|    value_loss            | 15.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34950438 |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1132        |
|    total_timesteps       | 2174976     |
| train/                   |             |
|    approx_kl             | 0.00432905  |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.63        |
|    cost_value_loss       | 17.6        |
|    cost_values           | 3           |
|    entropy               | -0.883      |
|    entropy_loss          | -0.884      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0123      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 10610       |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.377       |
|    value_loss            | 14.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6664636  |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1167        |
|    total_timesteps       | 2177024     |
| train/                   |             |
|    approx_kl             | 0.004427353 |
|    clip_fraction         | 0.00811     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 9.34        |
|    cost_values           | 2.99        |
|    entropy               | -0.88       |
|    entropy_loss          | -0.882      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0032      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.36        |
|    n_updates             | 10620       |
|    policy_gradient_loss  | -0.00028    |
|    std                   | 0.376       |
|    value_loss            | 14          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.39236715  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1202         |
|    total_timesteps       | 2179072      |
| train/                   |              |
|    approx_kl             | 0.0031186708 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.25         |
|    cost_value_loss       | 20.4         |
|    cost_values           | 3            |
|    entropy               | -0.874       |
|    entropy_loss          | -0.877       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 10630        |
|    policy_gradient_loss  | -0.000459    |
|    std                   | 0.375        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7552878   |
| rollout/                 |              |
|    ep_len_mean           | 882          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1237         |
|    total_timesteps       | 2181120      |
| train/                   |              |
|    approx_kl             | 0.0028699283 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.04         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 2.99         |
|    entropy               | -0.873       |
|    entropy_loss          | -0.873       |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 10640        |
|    policy_gradient_loss  | -0.000808    |
|    std                   | 0.375        |
|    value_loss            | 4.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6246746   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 2183168      |
| train/                   |              |
|    approx_kl             | 0.0040794816 |
|    clip_fraction         | 0.081        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.16         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 3            |
|    entropy               | -0.874       |
|    entropy_loss          | -0.874       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00564      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.92         |
|    n_updates             | 10650        |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.375        |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3361643  |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1306        |
|    total_timesteps       | 2185216     |
| train/                   |             |
|    approx_kl             | 0.003695177 |
|    clip_fraction         | 0.0144      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.17        |
|    cost_value_loss       | 19.8        |
|    cost_values           | 3           |
|    entropy               | -0.871      |
|    entropy_loss          | -0.873      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 10660       |
|    policy_gradient_loss  | -0.000336   |
|    std                   | 0.375       |
|    value_loss            | 4.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.25630656  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1341         |
|    total_timesteps       | 2187264      |
| train/                   |              |
|    approx_kl             | 0.0032451828 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 11.9         |
|    cost_values           | 3            |
|    entropy               | -0.867       |
|    entropy_loss          | -0.869       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00628      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 10670        |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.374        |
|    value_loss            | 6.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55005    |
| rollout/                 |             |
|    ep_len_mean           | 876         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1375        |
|    total_timesteps       | 2189312     |
| train/                   |             |
|    approx_kl             | 0.004904001 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.88        |
|    cost_value_loss       | 24          |
|    cost_values           | 3           |
|    entropy               | -0.865      |
|    entropy_loss          | -0.866      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.5        |
|    n_updates             | 10680       |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.374       |
|    value_loss            | 14.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3801609   |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1409         |
|    total_timesteps       | 2191360      |
| train/                   |              |
|    approx_kl             | 0.0055171726 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.96         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 3            |
|    entropy               | -0.865       |
|    entropy_loss          | -0.865       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 10690        |
|    policy_gradient_loss  | 1.31e-05     |
|    std                   | 0.374        |
|    value_loss            | 26           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72793114  |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1444         |
|    total_timesteps       | 2193408      |
| train/                   |              |
|    approx_kl             | 0.0035403385 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.33         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 3            |
|    entropy               | -0.86        |
|    entropy_loss          | -0.862       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.52         |
|    n_updates             | 10700        |
|    policy_gradient_loss  | -0.000759    |
|    std                   | 0.373        |
|    value_loss            | 2.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6197242   |
| rollout/                 |              |
|    ep_len_mean           | 876          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1479         |
|    total_timesteps       | 2195456      |
| train/                   |              |
|    approx_kl             | 0.0030480032 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.22         |
|    cost_value_loss       | 21.5         |
|    cost_values           | 3            |
|    entropy               | -0.86        |
|    entropy_loss          | -0.861       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0236       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 10710        |
|    policy_gradient_loss  | -0.000153    |
|    std                   | 0.373        |
|    value_loss            | 15.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.4040114  |
| rollout/                 |             |
|    ep_len_mean           | 876         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1513        |
|    total_timesteps       | 2197504     |
| train/                   |             |
|    approx_kl             | 0.004775223 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.01        |
|    cost_value_loss       | 25.6        |
|    cost_values           | 2.99        |
|    entropy               | -0.859      |
|    entropy_loss          | -0.86       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0207      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.03        |
|    n_updates             | 10720       |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.372       |
|    value_loss            | 3.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.53741145  |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1548         |
|    total_timesteps       | 2199552      |
| train/                   |              |
|    approx_kl             | 0.0020740982 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.23         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 3            |
|    entropy               | -0.854       |
|    entropy_loss          | -0.856       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00356      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.78         |
|    n_updates             | 10730        |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.372        |
|    value_loss            | 6.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.665648    |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1583         |
|    total_timesteps       | 2201600      |
| train/                   |              |
|    approx_kl             | 0.0024662297 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 3            |
|    entropy               | -0.852       |
|    entropy_loss          | -0.854       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 10740        |
|    policy_gradient_loss  | -0.00089     |
|    std                   | 0.371        |
|    value_loss            | 6.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5823704   |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1618         |
|    total_timesteps       | 2203648      |
| train/                   |              |
|    approx_kl             | 0.0032370132 |
|    clip_fraction         | 0.0331       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.02         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 3            |
|    entropy               | -0.85        |
|    entropy_loss          | -0.85        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00753      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.97         |
|    n_updates             | 10750        |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.371        |
|    value_loss            | 17.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6343371   |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1652         |
|    total_timesteps       | 2205696      |
| train/                   |              |
|    approx_kl             | 0.0014784619 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.75         |
|    cost_value_loss       | 28.7         |
|    cost_values           | 3            |
|    entropy               | -0.847       |
|    entropy_loss          | -0.849       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0173       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 10760        |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.37         |
|    value_loss            | 2.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.05         |
| reward                   | -0.3465136   |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1687         |
|    total_timesteps       | 2207744      |
| train/                   |              |
|    approx_kl             | 0.0035849637 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.8          |
|    cost_value_loss       | 18.7         |
|    cost_values           | 3            |
|    entropy               | -0.842       |
|    entropy_loss          | -0.844       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 10770        |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.369        |
|    value_loss            | 4.83         |
-------------------------------------------
------------------------------------
| avg_speed          | 6.81        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 6.81        |
| reward             | -0.48188934 |
| rollout/           |             |
|    ep_len_mean     | 887         |
|    ep_rew_mean     | -462        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2209792     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3084937   |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2211840      |
| train/                   |              |
|    approx_kl             | 0.0037853115 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.05         |
|    cost_value_loss       | 7.15         |
|    cost_values           | 3            |
|    entropy               | -0.836       |
|    entropy_loss          | -0.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0086       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 10790        |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.368        |
|    value_loss            | 4.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5737002  |
| rollout/                 |             |
|    ep_len_mean           | 885         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 2213888     |
| train/                   |             |
|    approx_kl             | 0.002605136 |
|    clip_fraction         | 0.0223      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.41        |
|    cost_value_loss       | 22.4        |
|    cost_values           | 3           |
|    entropy               | -0.835      |
|    entropy_loss          | -0.836      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 10800       |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.368       |
|    value_loss            | 14.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.370599   |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 127         |
|    total_timesteps       | 2215936     |
| train/                   |             |
|    approx_kl             | 0.005392846 |
|    clip_fraction         | 0.0515      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 12.4        |
|    cost_values           | 3           |
|    entropy               | -0.83       |
|    entropy_loss          | -0.833      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.94        |
|    n_updates             | 10810       |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.367       |
|    value_loss            | 4.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5849428   |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 2217984      |
| train/                   |              |
|    approx_kl             | 0.0031015459 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.96         |
|    cost_value_loss       | 5.39         |
|    cost_values           | 3            |
|    entropy               | -0.828       |
|    entropy_loss          | -0.829       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00329      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.83         |
|    n_updates             | 10820        |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.367        |
|    value_loss            | 14.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.37        |
| reward                   | -0.41950768 |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 2220032     |
| train/                   |             |
|    approx_kl             | 0.002738728 |
|    clip_fraction         | 0.0516      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.16        |
|    cost_value_loss       | 20.2        |
|    cost_values           | 3           |
|    entropy               | -0.828      |
|    entropy_loss          | -0.829      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.000359    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.78        |
|    n_updates             | 10830       |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.367       |
|    value_loss            | 1.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.54033655  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 2222080      |
| train/                   |              |
|    approx_kl             | 0.0017085173 |
|    clip_fraction         | 0.0718       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.4          |
|    cost_value_loss       | 14.4         |
|    cost_values           | 3            |
|    entropy               | -0.822       |
|    entropy_loss          | -0.825       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00284      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.09         |
|    n_updates             | 10840        |
|    policy_gradient_loss  | 0.000311     |
|    std                   | 0.366        |
|    value_loss            | 17           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.40200847  |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 2224128      |
| train/                   |              |
|    approx_kl             | 0.0052633807 |
|    clip_fraction         | 0.0656       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.4          |
|    cost_value_loss       | 23.6         |
|    cost_values           | 3            |
|    entropy               | -0.821       |
|    entropy_loss          | -0.821       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00298      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.34         |
|    n_updates             | 10850        |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.365        |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.17636825  |
| rollout/                 |              |
|    ep_len_mean           | 873          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 2226176      |
| train/                   |              |
|    approx_kl             | 0.0010610335 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.52         |
|    cost_value_loss       | 6.8          |
|    cost_values           | 3            |
|    entropy               | -0.817       |
|    entropy_loss          | -0.82        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00205      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.46         |
|    n_updates             | 10860        |
|    policy_gradient_loss  | -0.000808    |
|    std                   | 0.365        |
|    value_loss            | 22.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.3698639   |
| rollout/                 |              |
|    ep_len_mean           | 872          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 2228224      |
| train/                   |              |
|    approx_kl             | 0.0059882705 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.35         |
|    cost_value_loss       | 22.6         |
|    cost_values           | 3            |
|    entropy               | -0.815       |
|    entropy_loss          | -0.815       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.6         |
|    n_updates             | 10870        |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.364        |
|    value_loss            | 27.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5022891   |
| rollout/                 |              |
|    ep_len_mean           | 872          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 2230272      |
| train/                   |              |
|    approx_kl             | 0.0052759554 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.96         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 3            |
|    entropy               | -0.809       |
|    entropy_loss          | -0.813       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0108       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 10880        |
|    policy_gradient_loss  | -2.15e-05    |
|    std                   | 0.363        |
|    value_loss            | 25.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.69028205 |
| rollout/                 |             |
|    ep_len_mean           | 880         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 405         |
|    total_timesteps       | 2232320     |
| train/                   |             |
|    approx_kl             | 0.004214824 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 17.8        |
|    cost_values           | 3           |
|    entropy               | -0.805      |
|    entropy_loss          | -0.807      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 10890       |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.363       |
|    value_loss            | 7.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.44282743 |
| rollout/                 |             |
|    ep_len_mean           | 880         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 440         |
|    total_timesteps       | 2234368     |
| train/                   |             |
|    approx_kl             | 0.008313056 |
|    clip_fraction         | 0.0555      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.72        |
|    cost_value_loss       | 33          |
|    cost_values           | 3           |
|    entropy               | -0.809      |
|    entropy_loss          | -0.807      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.8        |
|    n_updates             | 10900       |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.363       |
|    value_loss            | 18.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.16464774  |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 475          |
|    total_timesteps       | 2236416      |
| train/                   |              |
|    approx_kl             | 0.0041949074 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.91         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 3            |
|    entropy               | -0.812       |
|    entropy_loss          | -0.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00677      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.59         |
|    n_updates             | 10910        |
|    policy_gradient_loss  | -0.000939    |
|    std                   | 0.364        |
|    value_loss            | 11.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.35        |
| reward                   | -0.48151693 |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 510         |
|    total_timesteps       | 2238464     |
| train/                   |             |
|    approx_kl             | 0.003031497 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 7.44        |
|    cost_values           | 3           |
|    entropy               | -0.814      |
|    entropy_loss          | -0.813      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00964     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.48        |
|    n_updates             | 10920       |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.364       |
|    value_loss            | 4.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.48498097 |
| rollout/                 |             |
|    ep_len_mean           | 884         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 545         |
|    total_timesteps       | 2240512     |
| train/                   |             |
|    approx_kl             | 0.005674936 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.13        |
|    cost_value_loss       | 19.1        |
|    cost_values           | 3           |
|    entropy               | -0.814      |
|    entropy_loss          | -0.814      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 10930       |
|    policy_gradient_loss  | -5.99e-05   |
|    std                   | 0.364       |
|    value_loss            | 13.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.561811   |
| rollout/                 |             |
|    ep_len_mean           | 884         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 579         |
|    total_timesteps       | 2242560     |
| train/                   |             |
|    approx_kl             | 0.018667914 |
|    clip_fraction         | 0.0946      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 3           |
|    entropy               | -0.81       |
|    entropy_loss          | -0.812      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 10940       |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 0.363       |
|    value_loss            | 19.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7289724   |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 614          |
|    total_timesteps       | 2244608      |
| train/                   |              |
|    approx_kl             | 0.0027506913 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.18         |
|    cost_value_loss       | 16.2         |
|    cost_values           | 3            |
|    entropy               | -0.803       |
|    entropy_loss          | -0.806       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00155      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.26         |
|    n_updates             | 10950        |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.362        |
|    value_loss            | 3.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3937564   |
| rollout/                 |              |
|    ep_len_mean           | 883          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 649          |
|    total_timesteps       | 2246656      |
| train/                   |              |
|    approx_kl             | 0.0053111776 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 18.2         |
|    cost_values           | 2.99         |
|    entropy               | -0.798       |
|    entropy_loss          | -0.801       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00727      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.58         |
|    n_updates             | 10960        |
|    policy_gradient_loss  | 0.000331     |
|    std                   | 0.361        |
|    value_loss            | 2.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2713352   |
| rollout/                 |              |
|    ep_len_mean           | 883          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 683          |
|    total_timesteps       | 2248704      |
| train/                   |              |
|    approx_kl             | 0.0028297997 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.74         |
|    cost_value_loss       | 27.3         |
|    cost_values           | 3            |
|    entropy               | -0.793       |
|    entropy_loss          | -0.796       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00587      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 10970        |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.36         |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.36660624  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 718          |
|    total_timesteps       | 2250752      |
| train/                   |              |
|    approx_kl             | 0.0051554665 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.7          |
|    cost_value_loss       | 19.1         |
|    cost_values           | 3            |
|    entropy               | -0.789       |
|    entropy_loss          | -0.791       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00532      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.03         |
|    n_updates             | 10980        |
|    policy_gradient_loss  | -0.000627    |
|    std                   | 0.36         |
|    value_loss            | 3.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45424306  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 752          |
|    total_timesteps       | 2252800      |
| train/                   |              |
|    approx_kl             | 0.0068021165 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 6.73         |
|    cost_values           | 2.96         |
|    entropy               | -0.786       |
|    entropy_loss          | -0.788       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.71         |
|    n_updates             | 10990        |
|    policy_gradient_loss  | -0.00474     |
|    std                   | 0.359        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.64375657  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 787          |
|    total_timesteps       | 2254848      |
| train/                   |              |
|    approx_kl             | 0.0022210898 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.74         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 2.87         |
|    entropy               | -0.783       |
|    entropy_loss          | -0.784       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.58         |
|    n_updates             | 11000        |
|    policy_gradient_loss  | -0.000596    |
|    std                   | 0.358        |
|    value_loss            | 1.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48638725  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 821          |
|    total_timesteps       | 2256896      |
| train/                   |              |
|    approx_kl             | 0.0047137463 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.91         |
|    cost_value_loss       | 32.7         |
|    cost_values           | 3            |
|    entropy               | -0.782       |
|    entropy_loss          | -0.782       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0373       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.72         |
|    n_updates             | 11010        |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.358        |
|    value_loss            | 2.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42048368  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 856          |
|    total_timesteps       | 2258944      |
| train/                   |              |
|    approx_kl             | 0.0032499305 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.5          |
|    cost_value_loss       | 23.9         |
|    cost_values           | 3            |
|    entropy               | -0.782       |
|    entropy_loss          | -0.782       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 11020        |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.358        |
|    value_loss            | 5.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.64199805  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 891          |
|    total_timesteps       | 2260992      |
| train/                   |              |
|    approx_kl             | 0.0024973322 |
|    clip_fraction         | 0.035        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.12         |
|    cost_value_loss       | 27.9         |
|    cost_values           | 3            |
|    entropy               | -0.782       |
|    entropy_loss          | -0.782       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 11030        |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.358        |
|    value_loss            | 1.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6642574   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 926          |
|    total_timesteps       | 2263040      |
| train/                   |              |
|    approx_kl             | 0.0073188827 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.82         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 3            |
|    entropy               | -0.786       |
|    entropy_loss          | -0.784       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00945      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 11040        |
|    policy_gradient_loss  | -0.000763    |
|    std                   | 0.359        |
|    value_loss            | 2.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55179137  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 961          |
|    total_timesteps       | 2265088      |
| train/                   |              |
|    approx_kl             | 0.0024719974 |
|    clip_fraction         | 0.00977      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 3            |
|    entropy               | -0.787       |
|    entropy_loss          | -0.787       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00597      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.05         |
|    n_updates             | 11050        |
|    policy_gradient_loss  | -0.000528    |
|    std                   | 0.359        |
|    value_loss            | 4.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6187324   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 996          |
|    total_timesteps       | 2267136      |
| train/                   |              |
|    approx_kl             | 0.0040153544 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.49         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 3            |
|    entropy               | -0.782       |
|    entropy_loss          | -0.785       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00743      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.5          |
|    n_updates             | 11060        |
|    policy_gradient_loss  | -0.000146    |
|    std                   | 0.358        |
|    value_loss            | 2.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.53386533 |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1031        |
|    total_timesteps       | 2269184     |
| train/                   |             |
|    approx_kl             | 0.004344909 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.82        |
|    cost_value_loss       | 19.3        |
|    cost_values           | 3           |
|    entropy               | -0.783      |
|    entropy_loss          | -0.781      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.47        |
|    n_updates             | 11070       |
|    policy_gradient_loss  | -0.000874   |
|    std                   | 0.359       |
|    value_loss            | 0.877       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.35550275  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1065         |
|    total_timesteps       | 2271232      |
| train/                   |              |
|    approx_kl             | 0.0017647299 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 2.99         |
|    entropy               | -0.782       |
|    entropy_loss          | -0.784       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0113       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.28         |
|    n_updates             | 11080        |
|    policy_gradient_loss  | 1.07e-05     |
|    std                   | 0.358        |
|    value_loss            | 6.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.81988007 |
| rollout/                 |             |
|    ep_len_mean           | 920         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1100        |
|    total_timesteps       | 2273280     |
| train/                   |             |
|    approx_kl             | 0.007029634 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.31        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 3           |
|    entropy               | -0.783      |
|    entropy_loss          | -0.783      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00412     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.21        |
|    n_updates             | 11090       |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.359       |
|    value_loss            | 20.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.5335148   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1134         |
|    total_timesteps       | 2275328      |
| train/                   |              |
|    approx_kl             | 0.0043062354 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 17.9         |
|    cost_values           | 3            |
|    entropy               | -0.789       |
|    entropy_loss          | -0.786       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0073       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.67         |
|    n_updates             | 11100        |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.36         |
|    value_loss            | 4.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.29624465  |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1168         |
|    total_timesteps       | 2277376      |
| train/                   |              |
|    approx_kl             | 0.0031609845 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 3            |
|    entropy               | -0.795       |
|    entropy_loss          | -0.792       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.56         |
|    n_updates             | 11110        |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.361        |
|    value_loss            | 6.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.5540176   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1203         |
|    total_timesteps       | 2279424      |
| train/                   |              |
|    approx_kl             | 0.0045605577 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.08         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 3            |
|    entropy               | -0.797       |
|    entropy_loss          | -0.797       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00173      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 11120        |
|    policy_gradient_loss  | -0.000352    |
|    std                   | 0.361        |
|    value_loss            | 3.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.60511386 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1237        |
|    total_timesteps       | 2281472     |
| train/                   |             |
|    approx_kl             | 0.007896039 |
|    clip_fraction         | 0.0751      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.06        |
|    cost_value_loss       | 9.62        |
|    cost_values           | 3           |
|    entropy               | -0.791      |
|    entropy_loss          | -0.794      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0033      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.07        |
|    n_updates             | 11130       |
|    policy_gradient_loss  | -0.00318    |
|    std                   | 0.36        |
|    value_loss            | 28          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49415743  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 2283520      |
| train/                   |              |
|    approx_kl             | 0.0005002999 |
|    clip_fraction         | 0.00386      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.33         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 3            |
|    entropy               | -0.791       |
|    entropy_loss          | -0.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 11140        |
|    policy_gradient_loss  | -0.000153    |
|    std                   | 0.36         |
|    value_loss            | 2.83         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7490771  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1307        |
|    total_timesteps       | 2285568     |
| train/                   |             |
|    approx_kl             | 0.001206638 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.57        |
|    cost_value_loss       | 22.8        |
|    cost_values           | 3           |
|    entropy               | -0.792      |
|    entropy_loss          | -0.793      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0241      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.74        |
|    n_updates             | 11150       |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.36        |
|    value_loss            | 2.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.77777433  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1342         |
|    total_timesteps       | 2287616      |
| train/                   |              |
|    approx_kl             | 0.0059466134 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.94         |
|    cost_value_loss       | 19.4         |
|    cost_values           | 3            |
|    entropy               | -0.784       |
|    entropy_loss          | -0.789       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0177       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.83         |
|    n_updates             | 11160        |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.359        |
|    value_loss            | 3.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.66708255  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1378         |
|    total_timesteps       | 2289664      |
| train/                   |              |
|    approx_kl             | 0.0054290174 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.28         |
|    cost_value_loss       | 20.1         |
|    cost_values           | 2.99         |
|    entropy               | -0.782       |
|    entropy_loss          | -0.782       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0126       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.18         |
|    n_updates             | 11170        |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.359        |
|    value_loss            | 3.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7283976   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1412         |
|    total_timesteps       | 2291712      |
| train/                   |              |
|    approx_kl             | 0.0018942582 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.07         |
|    cost_value_loss       | 18.3         |
|    cost_values           | 3            |
|    entropy               | -0.778       |
|    entropy_loss          | -0.781       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.000129     |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 11180        |
|    policy_gradient_loss  | -0.000739    |
|    std                   | 0.358        |
|    value_loss            | 6.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.8440016  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1447        |
|    total_timesteps       | 2293760     |
| train/                   |             |
|    approx_kl             | 0.005387675 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 14.6        |
|    cost_values           | 3           |
|    entropy               | -0.776      |
|    entropy_loss          | -0.777      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00354     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 11190       |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.357       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.46824667 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1482        |
|    total_timesteps       | 2295808     |
| train/                   |             |
|    approx_kl             | 0.007961849 |
|    clip_fraction         | 0.0504      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 8.1         |
|    cost_values           | 3           |
|    entropy               | -0.77       |
|    entropy_loss          | -0.774      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00308     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 11200       |
|    policy_gradient_loss  | -0.00298    |
|    std                   | 0.356       |
|    value_loss            | 8.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.73561144 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -476        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1517        |
|    total_timesteps       | 2297856     |
| train/                   |             |
|    approx_kl             | 0.006000858 |
|    clip_fraction         | 0.052       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 8.64        |
|    cost_values           | 3           |
|    entropy               | -0.773      |
|    entropy_loss          | -0.77       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00788     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 11210       |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.357       |
|    value_loss            | 19.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5552609   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1552         |
|    total_timesteps       | 2299904      |
| train/                   |              |
|    approx_kl             | 0.0042764796 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.01         |
|    cost_value_loss       | 19.9         |
|    cost_values           | 3            |
|    entropy               | -0.771       |
|    entropy_loss          | -0.773       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00258      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.64         |
|    n_updates             | 11220        |
|    policy_gradient_loss  | -0.000796    |
|    std                   | 0.357        |
|    value_loss            | 5.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.1542963   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1587         |
|    total_timesteps       | 2301952      |
| train/                   |              |
|    approx_kl             | 0.0023553842 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.07         |
|    cost_value_loss       | 19           |
|    cost_values           | 2.99         |
|    entropy               | -0.766       |
|    entropy_loss          | -0.768       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00159      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.05         |
|    n_updates             | 11230        |
|    policy_gradient_loss  | -0.000222    |
|    std                   | 0.356        |
|    value_loss            | 3.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5112306   |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1621         |
|    total_timesteps       | 2304000      |
| train/                   |              |
|    approx_kl             | 0.0040272814 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.58         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 3            |
|    entropy               | -0.77        |
|    entropy_loss          | -0.767       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00879      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.99         |
|    n_updates             | 11240        |
|    policy_gradient_loss  | -6.66e-05    |
|    std                   | 0.357        |
|    value_loss            | 2.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.75676847 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1656        |
|    total_timesteps       | 2306048     |
| train/                   |             |
|    approx_kl             | 0.002718425 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.96        |
|    cost_value_loss       | 20.2        |
|    cost_values           | 3           |
|    entropy               | -0.768      |
|    entropy_loss          | -0.77       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00872     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.67        |
|    n_updates             | 11250       |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.356       |
|    value_loss            | 15.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.3606457   |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1691         |
|    total_timesteps       | 2308096      |
| train/                   |              |
|    approx_kl             | 0.0021439963 |
|    clip_fraction         | 0.00332      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.57         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 3            |
|    entropy               | -0.761       |
|    entropy_loss          | -0.764       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00838      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 11260        |
|    policy_gradient_loss  | -0.000181    |
|    std                   | 0.355        |
|    value_loss            | 2.58         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
-----------------------------------
| avg_speed          | 7.91       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.91       |
| reward             | -0.6375915 |
| rollout/           |            |
|    ep_len_mean     | 912        |
|    ep_rew_mean     | -473       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2310144    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41921142  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2312192      |
| train/                   |              |
|    approx_kl             | 0.0052635185 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.95         |
|    cost_value_loss       | 27.3         |
|    cost_values           | 3            |
|    entropy               | -0.758       |
|    entropy_loss          | -0.758       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 11280        |
|    policy_gradient_loss  | -0.000793    |
|    std                   | 0.354        |
|    value_loss            | 3.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.3635723  |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 94          |
|    total_timesteps       | 2314240     |
| train/                   |             |
|    approx_kl             | 0.005541919 |
|    clip_fraction         | 0.0424      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.94        |
|    cost_value_loss       | 15.1        |
|    cost_values           | 3           |
|    entropy               | -0.751      |
|    entropy_loss          | -0.756      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00506     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 11290       |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.353       |
|    value_loss            | 3.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45640555  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 2316288      |
| train/                   |              |
|    approx_kl             | 0.0052478937 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 8.97         |
|    cost_values           | 3            |
|    entropy               | -0.744       |
|    entropy_loss          | -0.747       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00814      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.51         |
|    n_updates             | 11300        |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.352        |
|    value_loss            | 2.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45349908  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 2318336      |
| train/                   |              |
|    approx_kl             | 0.0047636656 |
|    clip_fraction         | 0.0418       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.37         |
|    cost_value_loss       | 23.1         |
|    cost_values           | 3            |
|    entropy               | -0.741       |
|    entropy_loss          | -0.743       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0136       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 11310        |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.351        |
|    value_loss            | 2.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5281598   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 199          |
|    total_timesteps       | 2320384      |
| train/                   |              |
|    approx_kl             | 0.0056318976 |
|    clip_fraction         | 0.0487       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.53         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 3            |
|    entropy               | -0.744       |
|    entropy_loss          | -0.742       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00406      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 11320        |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.352        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.58587056  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 234          |
|    total_timesteps       | 2322432      |
| train/                   |              |
|    approx_kl             | 0.0025691527 |
|    clip_fraction         | 0.053        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 9.96         |
|    cost_values           | 3            |
|    entropy               | -0.745       |
|    entropy_loss          | -0.745       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0016       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 11330        |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.352        |
|    value_loss            | 15.9         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.4398827 |
| rollout/                 |            |
|    ep_len_mean           | 939        |
|    ep_rew_mean           | -484       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 8          |
|    time_elapsed          | 269        |
|    total_timesteps       | 2324480    |
| train/                   |            |
|    approx_kl             | 0.0025518  |
|    clip_fraction         | 0.0202     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.32       |
|    cost_value_loss       | 14.8       |
|    cost_values           | 3          |
|    entropy               | -0.744     |
|    entropy_loss          | -0.745     |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0.00348    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.28       |
|    n_updates             | 11340      |
|    policy_gradient_loss  | -0.000806  |
|    std                   | 0.352      |
|    value_loss            | 3.33       |
-----------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.5797607    |
| rollout/                 |               |
|    ep_len_mean           | 939           |
|    ep_rew_mean           | -485          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 9             |
|    time_elapsed          | 304           |
|    total_timesteps       | 2326528       |
| train/                   |               |
|    approx_kl             | 0.00029890865 |
|    clip_fraction         | 0.00645       |
|    clip_range            | 0.2           |
|    cost_returns          | 5.63          |
|    cost_value_loss       | 16.4          |
|    cost_values           | 3             |
|    entropy               | -0.747        |
|    entropy_loss          | -0.745        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00848       |
|    learning_rate         | 0.0003        |
|    loss                  | 4.45          |
|    n_updates             | 11350         |
|    policy_gradient_loss  | 0.000297      |
|    std                   | 0.352         |
|    value_loss            | 5.66          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.60017824  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 2328576      |
| train/                   |              |
|    approx_kl             | 0.0041749366 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.1          |
|    cost_value_loss       | 20.4         |
|    cost_values           | 3            |
|    entropy               | -0.748       |
|    entropy_loss          | -0.748       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00571      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.62         |
|    n_updates             | 11360        |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.352        |
|    value_loss            | 6.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.68         |
| reward                   | -0.55698234  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 372          |
|    total_timesteps       | 2330624      |
| train/                   |              |
|    approx_kl             | 0.0028801821 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.01         |
|    cost_value_loss       | 21.4         |
|    cost_values           | 3            |
|    entropy               | -0.746       |
|    entropy_loss          | -0.747       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 11370        |
|    policy_gradient_loss  | 2.35e-05     |
|    std                   | 0.352        |
|    value_loss            | 2.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4972358   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 406          |
|    total_timesteps       | 2332672      |
| train/                   |              |
|    approx_kl             | 0.0063964054 |
|    clip_fraction         | 0.0322       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.62         |
|    cost_value_loss       | 5.52         |
|    cost_values           | 3            |
|    entropy               | -0.736       |
|    entropy_loss          | -0.742       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00367      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.52         |
|    n_updates             | 11380        |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.35         |
|    value_loss            | 30.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49839735  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 441          |
|    total_timesteps       | 2334720      |
| train/                   |              |
|    approx_kl             | 0.0065775476 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.78         |
|    cost_value_loss       | 26.4         |
|    cost_values           | 3            |
|    entropy               | -0.728       |
|    entropy_loss          | -0.731       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 11390        |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.349        |
|    value_loss            | 2.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49106959  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 2336768      |
| train/                   |              |
|    approx_kl             | 0.0020708437 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.91         |
|    cost_value_loss       | 27.3         |
|    cost_values           | 3            |
|    entropy               | -0.727       |
|    entropy_loss          | -0.727       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00824      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.34         |
|    n_updates             | 11400        |
|    policy_gradient_loss  | 0.000112     |
|    std                   | 0.348        |
|    value_loss            | 2.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.76478183  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 510          |
|    total_timesteps       | 2338816      |
| train/                   |              |
|    approx_kl             | 0.0055481903 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.47         |
|    cost_value_loss       | 21.9         |
|    cost_values           | 3            |
|    entropy               | -0.725       |
|    entropy_loss          | -0.725       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0115       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.61         |
|    n_updates             | 11410        |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.348        |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3435845   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 545          |
|    total_timesteps       | 2340864      |
| train/                   |              |
|    approx_kl             | 0.0044390364 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.31         |
|    cost_value_loss       | 28.3         |
|    cost_values           | 3            |
|    entropy               | -0.724       |
|    entropy_loss          | -0.725       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 11420        |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.348        |
|    value_loss            | 6.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.57777685  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 579          |
|    total_timesteps       | 2342912      |
| train/                   |              |
|    approx_kl             | 0.0011913208 |
|    clip_fraction         | 0.0857       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.71         |
|    cost_value_loss       | 15           |
|    cost_values           | 3            |
|    entropy               | -0.728       |
|    entropy_loss          | -0.726       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00524      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.09         |
|    n_updates             | 11430        |
|    policy_gradient_loss  | -0.000277    |
|    std                   | 0.349        |
|    value_loss            | 6.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.67447793 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -492        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 613         |
|    total_timesteps       | 2344960     |
| train/                   |             |
|    approx_kl             | 0.005118803 |
|    clip_fraction         | 0.0443      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.63        |
|    cost_value_loss       | 16.7        |
|    cost_values           | 3           |
|    entropy               | -0.731      |
|    entropy_loss          | -0.731      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000752    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.63        |
|    n_updates             | 11440       |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.349       |
|    value_loss            | 4.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7086404   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 648          |
|    total_timesteps       | 2347008      |
| train/                   |              |
|    approx_kl             | 0.0011257573 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.39         |
|    cost_value_loss       | 9.55         |
|    cost_values           | 3            |
|    entropy               | -0.725       |
|    entropy_loss          | -0.727       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.63         |
|    n_updates             | 11450        |
|    policy_gradient_loss  | -0.00023     |
|    std                   | 0.348        |
|    value_loss            | 3.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.49202055  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 2349056      |
| train/                   |              |
|    approx_kl             | 0.0037655688 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 3            |
|    entropy               | -0.723       |
|    entropy_loss          | -0.724       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00163      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.02         |
|    n_updates             | 11460        |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.348        |
|    value_loss            | 7.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.6246831  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -497        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 717         |
|    total_timesteps       | 2351104     |
| train/                   |             |
|    approx_kl             | 0.005467183 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 6.89        |
|    cost_values           | 3           |
|    entropy               | -0.726      |
|    entropy_loss          | -0.724      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00357     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.23        |
|    n_updates             | 11470       |
|    policy_gradient_loss  | -0.000698   |
|    std                   | 0.348       |
|    value_loss            | 18.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.62164277 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -492        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 752         |
|    total_timesteps       | 2353152     |
| train/                   |             |
|    approx_kl             | 0.003358208 |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.77        |
|    cost_value_loss       | 15          |
|    cost_values           | 3           |
|    entropy               | -0.728      |
|    entropy_loss          | -0.727      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00787     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.03        |
|    n_updates             | 11480       |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.349       |
|    value_loss            | 1.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.7373501   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 786          |
|    total_timesteps       | 2355200      |
| train/                   |              |
|    approx_kl             | 0.0029564863 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.11         |
|    cost_value_loss       | 24.2         |
|    cost_values           | 2.99         |
|    entropy               | -0.727       |
|    entropy_loss          | -0.728       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0124       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.27         |
|    n_updates             | 11490        |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.349        |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.36         |
| reward                   | -0.47214645  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 821          |
|    total_timesteps       | 2357248      |
| train/                   |              |
|    approx_kl             | 0.0035820804 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.86         |
|    cost_value_loss       | 6.43         |
|    cost_values           | 2.99         |
|    entropy               | -0.723       |
|    entropy_loss          | -0.725       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0025       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 11500        |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.348        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.54472613  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 856          |
|    total_timesteps       | 2359296      |
| train/                   |              |
|    approx_kl             | 0.0028054356 |
|    clip_fraction         | 0.00698      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 3            |
|    entropy               | -0.719       |
|    entropy_loss          | -0.721       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00191      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.31         |
|    n_updates             | 11510        |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.347        |
|    value_loss            | 15.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.4800253  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -493        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 890         |
|    total_timesteps       | 2361344     |
| train/                   |             |
|    approx_kl             | 0.004696591 |
|    clip_fraction         | 0.0458      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.56        |
|    cost_value_loss       | 19.8        |
|    cost_values           | 3           |
|    entropy               | -0.717      |
|    entropy_loss          | -0.718      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0124      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 11520       |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 0.347       |
|    value_loss            | 20.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.7462428   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 925          |
|    total_timesteps       | 2363392      |
| train/                   |              |
|    approx_kl             | 0.0031515094 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 9.71         |
|    cost_values           | 3            |
|    entropy               | -0.716       |
|    entropy_loss          | -0.716       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.81         |
|    n_updates             | 11530        |
|    policy_gradient_loss  | -0.000724    |
|    std                   | 0.347        |
|    value_loss            | 3.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.6318689  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -496        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 959         |
|    total_timesteps       | 2365440     |
| train/                   |             |
|    approx_kl             | 0.002810231 |
|    clip_fraction         | 0.0105      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.88        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 3           |
|    entropy               | -0.715      |
|    entropy_loss          | -0.716      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00627     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 11540       |
|    policy_gradient_loss  | -0.000301   |
|    std                   | 0.347       |
|    value_loss            | 6.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5629825  |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 993         |
|    total_timesteps       | 2367488     |
| train/                   |             |
|    approx_kl             | 0.008182205 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.93        |
|    cost_value_loss       | 5.56        |
|    cost_values           | 3           |
|    entropy               | -0.716      |
|    entropy_loss          | -0.715      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00246     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.12        |
|    n_updates             | 11550       |
|    policy_gradient_loss  | -0.000271   |
|    std                   | 0.347       |
|    value_loss            | 23.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.8145248   |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 2369536      |
| train/                   |              |
|    approx_kl             | 0.0018469947 |
|    clip_fraction         | 0.0944       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.38         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 3            |
|    entropy               | -0.72        |
|    entropy_loss          | -0.719       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 11560        |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.348        |
|    value_loss            | 16.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8091641  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -501        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1062        |
|    total_timesteps       | 2371584     |
| train/                   |             |
|    approx_kl             | 0.007954141 |
|    clip_fraction         | 0.0135      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 3           |
|    entropy               | -0.726      |
|    entropy_loss          | -0.723      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00267     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.44        |
|    n_updates             | 11570       |
|    policy_gradient_loss  | -0.000323   |
|    std                   | 0.349       |
|    value_loss            | 6.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5031346   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1097         |
|    total_timesteps       | 2373632      |
| train/                   |              |
|    approx_kl             | 0.0046818517 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.12         |
|    cost_value_loss       | 6.98         |
|    cost_values           | 3            |
|    entropy               | -0.717       |
|    entropy_loss          | -0.723       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.46         |
|    n_updates             | 11580        |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.347        |
|    value_loss            | 7.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55678904  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1132         |
|    total_timesteps       | 2375680      |
| train/                   |              |
|    approx_kl             | 0.0005621372 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.58         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 3            |
|    entropy               | -0.717       |
|    entropy_loss          | -0.716       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 11590        |
|    policy_gradient_loss  | 0.000187     |
|    std                   | 0.347        |
|    value_loss            | 3.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5064085   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1167         |
|    total_timesteps       | 2377728      |
| train/                   |              |
|    approx_kl             | 0.0026422867 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.13         |
|    cost_value_loss       | 5.77         |
|    cost_values           | 2.99         |
|    entropy               | -0.714       |
|    entropy_loss          | -0.716       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00607      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.65         |
|    n_updates             | 11600        |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.346        |
|    value_loss            | 7.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9108631   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1203         |
|    total_timesteps       | 2379776      |
| train/                   |              |
|    approx_kl             | 0.0028766363 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 3            |
|    entropy               | -0.71        |
|    entropy_loss          | -0.711       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.68         |
|    n_updates             | 11610        |
|    policy_gradient_loss  | 6.79e-05     |
|    std                   | 0.346        |
|    value_loss            | 3.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.543        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.543        |
| reward                   | -0.42110166  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1237         |
|    total_timesteps       | 2381824      |
| train/                   |              |
|    approx_kl             | 0.0059759314 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.84         |
|    cost_value_loss       | 6.36         |
|    cost_values           | 2.99         |
|    entropy               | -0.708       |
|    entropy_loss          | -0.709       |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0.00173      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.42         |
|    n_updates             | 11620        |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 0.345        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6624793   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 2383872      |
| train/                   |              |
|    approx_kl             | 0.0041252812 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.82         |
|    cost_value_loss       | 3.9          |
|    cost_values           | 3            |
|    entropy               | -0.699       |
|    entropy_loss          | -0.705       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00459      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.78         |
|    n_updates             | 11630        |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.344        |
|    value_loss            | 8.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.16         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.16         |
| reward                   | -0.39901406  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1307         |
|    total_timesteps       | 2385920      |
| train/                   |              |
|    approx_kl             | 0.0043242928 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.4          |
|    cost_value_loss       | 13.1         |
|    cost_values           | 2.99         |
|    entropy               | -0.697       |
|    entropy_loss          | -0.697       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 11640        |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.343        |
|    value_loss            | 19.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.8          |
| reward                   | -0.5684871   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1342         |
|    total_timesteps       | 2387968      |
| train/                   |              |
|    approx_kl             | 0.0071515595 |
|    clip_fraction         | 0.0424       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.38         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 3            |
|    entropy               | -0.694       |
|    entropy_loss          | -0.696       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.5         |
|    n_updates             | 11650        |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.343        |
|    value_loss            | 60.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.826827    |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1377         |
|    total_timesteps       | 2390016      |
| train/                   |              |
|    approx_kl             | 0.0028371536 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.75         |
|    cost_value_loss       | 4.56         |
|    cost_values           | 3            |
|    entropy               | -0.695       |
|    entropy_loss          | -0.694       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.29         |
|    n_updates             | 11660        |
|    policy_gradient_loss  | -0.000677    |
|    std                   | 0.343        |
|    value_loss            | 8.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.35146418  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1411         |
|    total_timesteps       | 2392064      |
| train/                   |              |
|    approx_kl             | 0.0005779774 |
|    clip_fraction         | 0.0425       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.8          |
|    cost_value_loss       | 16.6         |
|    cost_values           | 3            |
|    entropy               | -0.698       |
|    entropy_loss          | -0.696       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0127       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.01         |
|    n_updates             | 11670        |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.344        |
|    value_loss            | 18.8         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.4133832    |
| rollout/                 |               |
|    ep_len_mean           | 898           |
|    ep_rew_mean           | -488          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 42            |
|    time_elapsed          | 1446          |
|    total_timesteps       | 2394112       |
| train/                   |               |
|    approx_kl             | 0.00038621816 |
|    clip_fraction         | 0.0311        |
|    clip_range            | 0.2           |
|    cost_returns          | 4.72          |
|    cost_value_loss       | 9.06          |
|    cost_values           | 3             |
|    entropy               | -0.69         |
|    entropy_loss          | -0.695        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.83          |
|    n_updates             | 11680         |
|    policy_gradient_loss  | 1.28e-05      |
|    std                   | 0.342         |
|    value_loss            | 5.07          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.78121495  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1480         |
|    total_timesteps       | 2396160      |
| train/                   |              |
|    approx_kl             | 0.0005427579 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.89         |
|    cost_value_loss       | 5.47         |
|    cost_values           | 3            |
|    entropy               | -0.688       |
|    entropy_loss          | -0.688       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00289      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.54         |
|    n_updates             | 11690        |
|    policy_gradient_loss  | -2.56e-05    |
|    std                   | 0.342        |
|    value_loss            | 3.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5190697   |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1515         |
|    total_timesteps       | 2398208      |
| train/                   |              |
|    approx_kl             | 0.0017404356 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.25         |
|    cost_value_loss       | 14.2         |
|    cost_values           | 2.99         |
|    entropy               | -0.682       |
|    entropy_loss          | -0.687       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 11700        |
|    policy_gradient_loss  | 0.000193     |
|    std                   | 0.341        |
|    value_loss            | 6.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7212484  |
| rollout/                 |             |
|    ep_len_mean           | 887         |
|    ep_rew_mean           | -482        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1549        |
|    total_timesteps       | 2400256     |
| train/                   |             |
|    approx_kl             | 0.007175083 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.99        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 3           |
|    entropy               | -0.682      |
|    entropy_loss          | -0.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0102      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 11710       |
|    policy_gradient_loss  | 8.23e-05    |
|    std                   | 0.341       |
|    value_loss            | 21.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4751885  |
| rollout/                 |             |
|    ep_len_mean           | 887         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1584        |
|    total_timesteps       | 2402304     |
| train/                   |             |
|    approx_kl             | 0.007574873 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 9.13        |
|    cost_values           | 3           |
|    entropy               | -0.686      |
|    entropy_loss          | -0.684      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00274     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.87        |
|    n_updates             | 11720       |
|    policy_gradient_loss  | 0.000449    |
|    std                   | 0.342       |
|    value_loss            | 23.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.65731156  |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1619         |
|    total_timesteps       | 2404352      |
| train/                   |              |
|    approx_kl             | 0.0026046757 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.77         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 3            |
|    entropy               | -0.685       |
|    entropy_loss          | -0.686       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00844      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.49         |
|    n_updates             | 11730        |
|    policy_gradient_loss  | -0.000853    |
|    std                   | 0.341        |
|    value_loss            | 5.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.79329884  |
| rollout/                 |              |
|    ep_len_mean           | 882          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1653         |
|    total_timesteps       | 2406400      |
| train/                   |              |
|    approx_kl             | 0.0030922247 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.6          |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.99         |
|    entropy               | -0.683       |
|    entropy_loss          | -0.684       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0104       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.8          |
|    n_updates             | 11740        |
|    policy_gradient_loss  | -0.000784    |
|    std                   | 0.341        |
|    value_loss            | 5.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6895524   |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1688         |
|    total_timesteps       | 2408448      |
| train/                   |              |
|    approx_kl             | 0.0044420683 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -0.679       |
|    entropy_loss          | -0.681       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0122       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.84         |
|    n_updates             | 11750        |
|    policy_gradient_loss  | -0.00078     |
|    std                   | 0.34         |
|    value_loss            | 17.4         |
-------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.37886265 |
| rollout/           |             |
|    ep_len_mean     | 891         |
|    ep_rew_mean     | -494        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2410496     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8614778   |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2412544      |
| train/                   |              |
|    approx_kl             | 0.0056254887 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.07         |
|    cost_value_loss       | 18           |
|    cost_values           | 3            |
|    entropy               | -0.672       |
|    entropy_loss          | -0.677       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 11770        |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.339        |
|    value_loss            | 5.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0686       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0686       |
| reward                   | -0.37653238  |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 2414592      |
| train/                   |              |
|    approx_kl             | 0.0034206293 |
|    clip_fraction         | 0.0359       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.92         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 3            |
|    entropy               | -0.667       |
|    entropy_loss          | -0.669       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 11780        |
|    policy_gradient_loss  | 0.000432     |
|    std                   | 0.338        |
|    value_loss            | 41.1         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 4.68       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.68       |
| reward                   | -0.547492  |
| rollout/                 |            |
|    ep_len_mean           | 887        |
|    ep_rew_mean           | -486       |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 4          |
|    time_elapsed          | 128        |
|    total_timesteps       | 2416640    |
| train/                   |            |
|    approx_kl             | 0.00645725 |
|    clip_fraction         | 0.0374     |
|    clip_range            | 0.2        |
|    cost_returns          | 5          |
|    cost_value_loss       | 11.7       |
|    cost_values           | 3          |
|    entropy               | -0.668     |
|    entropy_loss          | -0.668     |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.29       |
|    n_updates             | 11790      |
|    policy_gradient_loss  | -0.00197   |
|    std                   | 0.338      |
|    value_loss            | 5.77       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.41965583 |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -489        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 2418688     |
| train/                   |             |
|    approx_kl             | 0.002219127 |
|    clip_fraction         | 0.000537    |
|    clip_range            | 0.2         |
|    cost_returns          | 5.55        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 3           |
|    entropy               | -0.669      |
|    entropy_loss          | -0.668      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00638     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 11800       |
|    policy_gradient_loss  | -7.58e-05   |
|    std                   | 0.339       |
|    value_loss            | 18.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.42541116 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 2420736     |
| train/                   |             |
|    approx_kl             | 0.00613646  |
|    clip_fraction         | 0.0434      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.94        |
|    cost_value_loss       | 6.46        |
|    cost_values           | 3           |
|    entropy               | -0.675      |
|    entropy_loss          | -0.673      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00346     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.35        |
|    n_updates             | 11810       |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 0.34        |
|    value_loss            | 1.89        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.689505     |
| rollout/                 |               |
|    ep_len_mean           | 898           |
|    ep_rew_mean           | -490          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 7             |
|    time_elapsed          | 231           |
|    total_timesteps       | 2422784       |
| train/                   |               |
|    approx_kl             | 0.00047276122 |
|    clip_fraction         | 0.0371        |
|    clip_range            | 0.2           |
|    cost_returns          | 4.43          |
|    cost_value_loss       | 10.4          |
|    cost_values           | 3             |
|    entropy               | -0.673        |
|    entropy_loss          | -0.675        |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0.00484       |
|    learning_rate         | 0.0003        |
|    loss                  | 4.86          |
|    n_updates             | 11820         |
|    policy_gradient_loss  | -0.000419     |
|    std                   | 0.339         |
|    value_loss            | 15.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.34004006  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 2424832      |
| train/                   |              |
|    approx_kl             | 0.0072291465 |
|    clip_fraction         | 0.0663       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.08         |
|    cost_value_loss       | 9.87         |
|    cost_values           | 3            |
|    entropy               | -0.664       |
|    entropy_loss          | -0.669       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0084       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.72         |
|    n_updates             | 11830        |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.338        |
|    value_loss            | 3.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.58058345 |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 301         |
|    total_timesteps       | 2426880     |
| train/                   |             |
|    approx_kl             | 0.006764205 |
|    clip_fraction         | 0.0456      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.9         |
|    cost_value_loss       | 5.22        |
|    cost_values           | 3           |
|    entropy               | -0.647      |
|    entropy_loss          | -0.656      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00647     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.23        |
|    n_updates             | 11840       |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.335       |
|    value_loss            | 3.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.38674173  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -492         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 335          |
|    total_timesteps       | 2428928      |
| train/                   |              |
|    approx_kl             | 0.0015864607 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.01         |
|    cost_value_loss       | 19.6         |
|    cost_values           | 3            |
|    entropy               | -0.643       |
|    entropy_loss          | -0.644       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0141       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.95         |
|    n_updates             | 11850        |
|    policy_gradient_loss  | -0.000986    |
|    std                   | 0.334        |
|    value_loss            | 15.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.6189979   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 2430976      |
| train/                   |              |
|    approx_kl             | 0.0041474234 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.36         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 3            |
|    entropy               | -0.639       |
|    entropy_loss          | -0.641       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.07         |
|    n_updates             | 11860        |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.334        |
|    value_loss            | 8.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.47452426 |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -488        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 404         |
|    total_timesteps       | 2433024     |
| train/                   |             |
|    approx_kl             | 0.006433326 |
|    clip_fraction         | 0.0651      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.07        |
|    cost_value_loss       | 19.5        |
|    cost_values           | 3           |
|    entropy               | -0.638      |
|    entropy_loss          | -0.639      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00754     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.2         |
|    n_updates             | 11870       |
|    policy_gradient_loss  | -0.00332    |
|    std                   | 0.333       |
|    value_loss            | 30.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.31720603 |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 438         |
|    total_timesteps       | 2435072     |
| train/                   |             |
|    approx_kl             | 0.005182905 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.12        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 3           |
|    entropy               | -0.634      |
|    entropy_loss          | -0.636      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 11880       |
|    policy_gradient_loss  | -0.00439    |
|    std                   | 0.333       |
|    value_loss            | 8.45        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.618424  |
| rollout/                 |            |
|    ep_len_mean           | 890        |
|    ep_rew_mean           | -484       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 14         |
|    time_elapsed          | 473        |
|    total_timesteps       | 2437120    |
| train/                   |            |
|    approx_kl             | 0.00710346 |
|    clip_fraction         | 0.0541     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.89       |
|    cost_value_loss       | 17.2       |
|    cost_values           | 3          |
|    entropy               | -0.636     |
|    entropy_loss          | -0.634     |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0.0217     |
|    learning_rate         | 0.0003     |
|    loss                  | 3.49       |
|    n_updates             | 11890      |
|    policy_gradient_loss  | -0.000472  |
|    std                   | 0.333      |
|    value_loss            | 1.37       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5683314  |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 507         |
|    total_timesteps       | 2439168     |
| train/                   |             |
|    approx_kl             | 0.009795783 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.45        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 3           |
|    entropy               | -0.638      |
|    entropy_loss          | -0.637      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.06        |
|    n_updates             | 11900       |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.333       |
|    value_loss            | 2.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42313758  |
| rollout/                 |              |
|    ep_len_mean           | 895          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 541          |
|    total_timesteps       | 2441216      |
| train/                   |              |
|    approx_kl             | 0.0048055453 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.24         |
|    cost_value_loss       | 18.7         |
|    cost_values           | 3            |
|    entropy               | -0.637       |
|    entropy_loss          | -0.637       |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0.00946      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.3          |
|    n_updates             | 11910        |
|    policy_gradient_loss  | -0.000912    |
|    std                   | 0.333        |
|    value_loss            | 3.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.7156598   |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 576          |
|    total_timesteps       | 2443264      |
| train/                   |              |
|    approx_kl             | 0.0022259713 |
|    clip_fraction         | 0.00527      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.8          |
|    cost_value_loss       | 19.6         |
|    cost_values           | 3            |
|    entropy               | -0.631       |
|    entropy_loss          | -0.635       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 11920        |
|    policy_gradient_loss  | -0.000808    |
|    std                   | 0.332        |
|    value_loss            | 2.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5206499   |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 610          |
|    total_timesteps       | 2445312      |
| train/                   |              |
|    approx_kl             | 0.0089797815 |
|    clip_fraction         | 0.0431       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.75         |
|    cost_value_loss       | 18.8         |
|    cost_values           | 3            |
|    entropy               | -0.629       |
|    entropy_loss          | -0.63        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.98         |
|    n_updates             | 11930        |
|    policy_gradient_loss  | 0.000733     |
|    std                   | 0.332        |
|    value_loss            | 1.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.5290935   |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 2447360      |
| train/                   |              |
|    approx_kl             | 0.0021911343 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.33         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 3            |
|    entropy               | -0.625       |
|    entropy_loss          | -0.627       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0141       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.22         |
|    n_updates             | 11940        |
|    policy_gradient_loss  | 0.000185     |
|    std                   | 0.332        |
|    value_loss            | 6.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.8          |
| reward                   | -0.44783562  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 2449408      |
| train/                   |              |
|    approx_kl             | 0.0021604833 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 9.34         |
|    cost_values           | 3            |
|    entropy               | -0.62        |
|    entropy_loss          | -0.623       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00385      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.01         |
|    n_updates             | 11950        |
|    policy_gradient_loss  | -0.000722    |
|    std                   | 0.331        |
|    value_loss            | 2.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.47647244  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 2451456      |
| train/                   |              |
|    approx_kl             | 0.0089675225 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.49         |
|    cost_value_loss       | 16           |
|    cost_values           | 3            |
|    entropy               | -0.615       |
|    entropy_loss          | -0.617       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00183      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.81         |
|    n_updates             | 11960        |
|    policy_gradient_loss  | -0.000232    |
|    std                   | 0.33         |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -0.38037938  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 750          |
|    total_timesteps       | 2453504      |
| train/                   |              |
|    approx_kl             | 0.0033188334 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.64         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 2.99         |
|    entropy               | -0.618       |
|    entropy_loss          | -0.616       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 11970        |
|    policy_gradient_loss  | -0.000604    |
|    std                   | 0.33         |
|    value_loss            | 2.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.27         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.27         |
| reward                   | -0.4882916   |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 784          |
|    total_timesteps       | 2455552      |
| train/                   |              |
|    approx_kl             | 0.0045040743 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.86         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.95         |
|    entropy               | -0.615       |
|    entropy_loss          | -0.617       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 11980        |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.33         |
|    value_loss            | 16           |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.02        |
| reward                   | -0.45434764 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 819         |
|    total_timesteps       | 2457600     |
| train/                   |             |
|    approx_kl             | 0.008419437 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 19.9        |
|    cost_values           | 3           |
|    entropy               | -0.612      |
|    entropy_loss          | -0.614      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00635     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 11990       |
|    policy_gradient_loss  | -0.000659   |
|    std                   | 0.33        |
|    value_loss            | 1.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.64         |
| reward                   | -0.46609136  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 854          |
|    total_timesteps       | 2459648      |
| train/                   |              |
|    approx_kl             | 0.0062623844 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.14         |
|    cost_value_loss       | 5.54         |
|    cost_values           | 2.9          |
|    entropy               | -0.609       |
|    entropy_loss          | -0.611       |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.29         |
|    n_updates             | 12000        |
|    policy_gradient_loss  | -0.000369    |
|    std                   | 0.329        |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.22        |
| reward                   | -0.4860799  |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -476        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 888         |
|    total_timesteps       | 2461696     |
| train/                   |             |
|    approx_kl             | 0.015145352 |
|    clip_fraction         | 0.0443      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.35        |
|    cost_value_loss       | 30.1        |
|    cost_values           | 2.99        |
|    entropy               | -0.61       |
|    entropy_loss          | -0.609      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.9        |
|    n_updates             | 12010       |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.329       |
|    value_loss            | 3           |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.74         |
| reward                   | -0.35828254  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 922          |
|    total_timesteps       | 2463744      |
| train/                   |              |
|    approx_kl             | 0.0031721587 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 8.13         |
|    cost_values           | 3            |
|    entropy               | -0.61        |
|    entropy_loss          | -0.611       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00248      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.72         |
|    n_updates             | 12020        |
|    policy_gradient_loss  | -0.00054     |
|    std                   | 0.329        |
|    value_loss            | 3.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.08         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.08         |
| reward                   | -0.49212566  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 956          |
|    total_timesteps       | 2465792      |
| train/                   |              |
|    approx_kl             | 0.0033498155 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.47         |
|    cost_value_loss       | 7.46         |
|    cost_values           | 2.99         |
|    entropy               | -0.612       |
|    entropy_loss          | -0.611       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00433      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.27         |
|    n_updates             | 12030        |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.33         |
|    value_loss            | 0.519        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.4685725   |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 991          |
|    total_timesteps       | 2467840      |
| train/                   |              |
|    approx_kl             | 0.0012773619 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.39         |
|    cost_value_loss       | 8.53         |
|    cost_values           | 3            |
|    entropy               | -0.605       |
|    entropy_loss          | -0.609       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00742      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 12040        |
|    policy_gradient_loss  | -4.95e-05    |
|    std                   | 0.328        |
|    value_loss            | 2            |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.24240625 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 2469888     |
| train/                   |             |
|    approx_kl             | 0.002883482 |
|    clip_fraction         | 0.0114      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.65        |
|    cost_value_loss       | 24.2        |
|    cost_values           | 2.95        |
|    entropy               | -0.603      |
|    entropy_loss          | -0.603      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 12050       |
|    policy_gradient_loss  | -0.000144   |
|    std                   | 0.328       |
|    value_loss            | 2.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.6256579  |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -466        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 2471936     |
| train/                   |             |
|    approx_kl             | 0.003139813 |
|    clip_fraction         | 0.0123      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.52        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 2.99        |
|    entropy               | -0.605      |
|    entropy_loss          | -0.604      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.0203      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 12060       |
|    policy_gradient_loss  | -0.000907   |
|    std                   | 0.328       |
|    value_loss            | 4.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.34824932 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1093        |
|    total_timesteps       | 2473984     |
| train/                   |             |
|    approx_kl             | 0.006479309 |
|    clip_fraction         | 0.0382      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.81        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.96        |
|    entropy               | -0.605      |
|    entropy_loss          | -0.605      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.89        |
|    n_updates             | 12070       |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.329       |
|    value_loss            | 2.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.260878   |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1128        |
|    total_timesteps       | 2476032     |
| train/                   |             |
|    approx_kl             | 0.002398164 |
|    clip_fraction         | 0.000488    |
|    clip_range            | 0.2         |
|    cost_returns          | 4.83        |
|    cost_value_loss       | 9.8         |
|    cost_values           | 2.97        |
|    entropy               | -0.607      |
|    entropy_loss          | -0.606      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 12080       |
|    policy_gradient_loss  | 9.21e-05    |
|    std                   | 0.329       |
|    value_loss            | 5.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.24508023  |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1162         |
|    total_timesteps       | 2478080      |
| train/                   |              |
|    approx_kl             | 0.0025907191 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.52         |
|    cost_value_loss       | 31.3         |
|    cost_values           | 3            |
|    entropy               | -0.609       |
|    entropy_loss          | -0.608       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 12090        |
|    policy_gradient_loss  | -0.000676    |
|    std                   | 0.329        |
|    value_loss            | 2.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.33        |
| reward                   | -0.60978156 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1197        |
|    total_timesteps       | 2480128     |
| train/                   |             |
|    approx_kl             | 0.002261782 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.79        |
|    cost_value_loss       | 3.36        |
|    cost_values           | 2.96        |
|    entropy               | -0.61       |
|    entropy_loss          | -0.61       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.01        |
|    n_updates             | 12100       |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.33        |
|    value_loss            | 2.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.58        |
| reward                   | -0.4153715  |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1231        |
|    total_timesteps       | 2482176     |
| train/                   |             |
|    approx_kl             | 0.006772509 |
|    clip_fraction         | 0.0616      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.29        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.99        |
|    entropy               | -0.605      |
|    entropy_loss          | -0.608      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0136      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 12110       |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 0.329       |
|    value_loss            | 5.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.9          |
| reward                   | -0.5183347   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1266         |
|    total_timesteps       | 2484224      |
| train/                   |              |
|    approx_kl             | 0.0025775693 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.22         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -0.62        |
|    entropy_loss          | -0.611       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 8.73e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.85         |
|    n_updates             | 12120        |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.331        |
|    value_loss            | 1.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.309        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.309        |
| reward                   | -0.56168556  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1300         |
|    total_timesteps       | 2486272      |
| train/                   |              |
|    approx_kl             | 0.0014018855 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.11         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 3            |
|    entropy               | -0.618       |
|    entropy_loss          | -0.62        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00424      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.5          |
|    n_updates             | 12130        |
|    policy_gradient_loss  | 0.000268     |
|    std                   | 0.331        |
|    value_loss            | 0.518        |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.61        |
| reward                   | -0.360675   |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1335        |
|    total_timesteps       | 2488320     |
| train/                   |             |
|    approx_kl             | 0.005809385 |
|    clip_fraction         | 0.0316      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 11          |
|    cost_values           | 2.99        |
|    entropy               | -0.619      |
|    entropy_loss          | -0.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.24        |
|    n_updates             | 12140       |
|    policy_gradient_loss  | -0.000214   |
|    std                   | 0.331       |
|    value_loss            | 2.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.68        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.68        |
| reward                   | -0.48886997 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -476        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1370        |
|    total_timesteps       | 2490368     |
| train/                   |             |
|    approx_kl             | 0.006611039 |
|    clip_fraction         | 0.0503      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 5.06        |
|    cost_values           | 2.99        |
|    entropy               | -0.606      |
|    entropy_loss          | -0.614      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00229     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.97        |
|    n_updates             | 12150       |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.329       |
|    value_loss            | 1.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.06         |
| reward                   | -0.535349    |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1405         |
|    total_timesteps       | 2492416      |
| train/                   |              |
|    approx_kl             | 0.0023690287 |
|    clip_fraction         | 0.0422       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 8.74         |
|    cost_values           | 2.95         |
|    entropy               | -0.6         |
|    entropy_loss          | -0.602       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.42         |
|    n_updates             | 12160        |
|    policy_gradient_loss  | -0.000615    |
|    std                   | 0.328        |
|    value_loss            | 2.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.28522533  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1440         |
|    total_timesteps       | 2494464      |
| train/                   |              |
|    approx_kl             | 0.0036324568 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 4.61         |
|    cost_values           | 2.76         |
|    entropy               | -0.6         |
|    entropy_loss          | -0.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.43         |
|    n_updates             | 12170        |
|    policy_gradient_loss  | -0.00092     |
|    std                   | 0.328        |
|    value_loss            | 9.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.1         |
| reward                   | -0.4698349  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -466        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1475        |
|    total_timesteps       | 2496512     |
| train/                   |             |
|    approx_kl             | 0.009635494 |
|    clip_fraction         | 0.0729      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.03        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.95        |
|    entropy               | -0.6        |
|    entropy_loss          | -0.6        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00221     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.13        |
|    n_updates             | 12180       |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.328       |
|    value_loss            | 9.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33458915 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1509        |
|    total_timesteps       | 2498560     |
| train/                   |             |
|    approx_kl             | 0.003923225 |
|    clip_fraction         | 0.0148      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 8.01        |
|    cost_values           | 2.89        |
|    entropy               | -0.6        |
|    entropy_loss          | -0.601      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.48        |
|    n_updates             | 12190       |
|    policy_gradient_loss  | -0.000278   |
|    std                   | 0.328       |
|    value_loss            | 9.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.41782188  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1544         |
|    total_timesteps       | 2500608      |
| train/                   |              |
|    approx_kl             | 0.0035194296 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.71         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 2.99         |
|    entropy               | -0.599       |
|    entropy_loss          | -0.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 12200        |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.328        |
|    value_loss            | 9.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.33         |
| reward                   | -0.4116767   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1579         |
|    total_timesteps       | 2502656      |
| train/                   |              |
|    approx_kl             | 0.0009887007 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 3            |
|    entropy               | -0.598       |
|    entropy_loss          | -0.599       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00122      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.48         |
|    n_updates             | 12210        |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.328        |
|    value_loss            | 2.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.291       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.291       |
| reward                   | -0.25026083 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1614        |
|    total_timesteps       | 2504704     |
| train/                   |             |
|    approx_kl             | 0.002369857 |
|    clip_fraction         | 0.00503     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.77        |
|    cost_value_loss       | 35.7        |
|    cost_values           | 3           |
|    entropy               | -0.597      |
|    entropy_loss          | -0.597      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.8        |
|    n_updates             | 12220       |
|    policy_gradient_loss  | -0.000713   |
|    std                   | 0.328       |
|    value_loss            | 14          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.108       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.108       |
| reward                   | -0.535805   |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1649        |
|    total_timesteps       | 2506752     |
| train/                   |             |
|    approx_kl             | 0.004855089 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.9         |
|    cost_value_loss       | 10.5        |
|    cost_values           | 3           |
|    entropy               | -0.599      |
|    entropy_loss          | -0.598      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00382     |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 12230       |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.328       |
|    value_loss            | 1.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.36         |
| reward                   | -0.48592246  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1684         |
|    total_timesteps       | 2508800      |
| train/                   |              |
|    approx_kl             | 0.0034570037 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.86         |
|    cost_value_loss       | 19.6         |
|    cost_values           | 3            |
|    entropy               | -0.598       |
|    entropy_loss          | -0.597       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0152       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.86         |
|    n_updates             | 12240        |
|    policy_gradient_loss  | 0.000517     |
|    std                   | 0.328        |
|    value_loss            | 1.78         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
-----------------------------------
| avg_speed          | 6.92       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 6.92       |
| reward             | -0.4200329 |
| rollout/           |            |
|    ep_len_mean     | 958        |
|    ep_rew_mean     | -451       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2510848    |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.23506278  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 2512896      |
| train/                   |              |
|    approx_kl             | 8.162373e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.72         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 3            |
|    entropy               | -0.601       |
|    entropy_loss          | -0.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00849      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.65         |
|    n_updates             | 12260        |
|    policy_gradient_loss  | -3.46e-05    |
|    std                   | 0.329        |
|    value_loss            | 2.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.46738592  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 2514944      |
| train/                   |              |
|    approx_kl             | 0.0042485897 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.93         |
|    cost_value_loss       | 29.9         |
|    cost_values           | 3            |
|    entropy               | -0.605       |
|    entropy_loss          | -0.604       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0164       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 12270        |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 0.329        |
|    value_loss            | 4.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6270362  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 129         |
|    total_timesteps       | 2516992     |
| train/                   |             |
|    approx_kl             | 0.004633821 |
|    clip_fraction         | 0.0304      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 17.3        |
|    cost_values           | 3           |
|    entropy               | -0.6        |
|    entropy_loss          | -0.604      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.0161      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.69        |
|    n_updates             | 12280       |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.328       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2164687  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 164         |
|    total_timesteps       | 2519040     |
| train/                   |             |
|    approx_kl             | 0.004115709 |
|    clip_fraction         | 0.0144      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 15.3        |
|    cost_values           | 3           |
|    entropy               | -0.6        |
|    entropy_loss          | -0.599      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.58        |
|    n_updates             | 12290       |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.328       |
|    value_loss            | 3.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37491804 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 6           |
|    time_elapsed          | 199         |
|    total_timesteps       | 2521088     |
| train/                   |             |
|    approx_kl             | 0.002759772 |
|    clip_fraction         | 0.0342      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.7         |
|    cost_value_loss       | 19.3        |
|    cost_values           | 3           |
|    entropy               | -0.604      |
|    entropy_loss          | -0.602      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13          |
|    n_updates             | 12300       |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.329       |
|    value_loss            | 6.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.433       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.433       |
| reward                   | -0.28543398 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 234         |
|    total_timesteps       | 2523136     |
| train/                   |             |
|    approx_kl             | 0.003941311 |
|    clip_fraction         | 0.0606      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 5.88        |
|    cost_values           | 2.95        |
|    entropy               | -0.603      |
|    entropy_loss          | -0.604      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.34        |
|    n_updates             | 12310       |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.329       |
|    value_loss            | 10.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.461        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.461        |
| reward                   | -0.42465627  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 8            |
|    time_elapsed          | 269          |
|    total_timesteps       | 2525184      |
| train/                   |              |
|    approx_kl             | 0.0018721585 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 2.98         |
|    entropy               | -0.606       |
|    entropy_loss          | -0.605       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0142       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 12320        |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.329        |
|    value_loss            | 3.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.48971662  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 2527232      |
| train/                   |              |
|    approx_kl             | 0.0022895455 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 8.83         |
|    cost_values           | 2.89         |
|    entropy               | -0.599       |
|    entropy_loss          | -0.604       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.013        |
|    learning_rate         | 0.0003       |
|    loss                  | 3.3          |
|    n_updates             | 12330        |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.328        |
|    value_loss            | 1.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.601        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.601        |
| reward                   | -0.52707326  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 2529280      |
| train/                   |              |
|    approx_kl             | 0.0013754156 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.7          |
|    cost_value_loss       | 8.8          |
|    cost_values           | 3            |
|    entropy               | -0.6         |
|    entropy_loss          | -0.599       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0136       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.27         |
|    n_updates             | 12340        |
|    policy_gradient_loss  | 1.83e-05     |
|    std                   | 0.328        |
|    value_loss            | 1.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.229       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.229       |
| reward                   | -0.2510692  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 372         |
|    total_timesteps       | 2531328     |
| train/                   |             |
|    approx_kl             | 0.004578154 |
|    clip_fraction         | 0.0224      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 1.07        |
|    cost_values           | 2.94        |
|    entropy               | -0.589      |
|    entropy_loss          | -0.596      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.16        |
|    n_updates             | 12350       |
|    policy_gradient_loss  | -0.000497   |
|    std                   | 0.326       |
|    value_loss            | 1.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.75         |
| reward                   | -0.33352533  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 406          |
|    total_timesteps       | 2533376      |
| train/                   |              |
|    approx_kl             | 0.0049537565 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.59         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 3            |
|    entropy               | -0.586       |
|    entropy_loss          | -0.586       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.31         |
|    n_updates             | 12360        |
|    policy_gradient_loss  | -0.000787    |
|    std                   | 0.326        |
|    value_loss            | 0.946        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.741        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.741        |
| reward                   | -0.61443937  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 2535424      |
| train/                   |              |
|    approx_kl             | 0.0038937763 |
|    clip_fraction         | 0.0286       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.1          |
|    cost_value_loss       | 3.22         |
|    cost_values           | 2.82         |
|    entropy               | -0.587       |
|    entropy_loss          | -0.587       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.14         |
|    n_updates             | 12370        |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.326        |
|    value_loss            | 1.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.45         |
| reward                   | -0.56779754  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 2537472      |
| train/                   |              |
|    approx_kl             | 0.0038835108 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.8          |
|    cost_value_loss       | 1.69         |
|    cost_values           | 2.78         |
|    entropy               | -0.576       |
|    entropy_loss          | -0.583       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.08         |
|    n_updates             | 12380        |
|    policy_gradient_loss  | -0.000427    |
|    std                   | 0.325        |
|    value_loss            | 0.937        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.22         |
| reward                   | -0.44105446  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 509          |
|    total_timesteps       | 2539520      |
| train/                   |              |
|    approx_kl             | 0.0022695046 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.59         |
|    cost_value_loss       | 13.2         |
|    cost_values           | 2.88         |
|    entropy               | -0.575       |
|    entropy_loss          | -0.575       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 12390        |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.325        |
|    value_loss            | 2.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.19         |
| reward                   | -0.42663574  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 2541568      |
| train/                   |              |
|    approx_kl             | 0.0017457588 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 1.55         |
|    cost_values           | 2.9          |
|    entropy               | -0.56        |
|    entropy_loss          | -0.57        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.1          |
|    n_updates             | 12400        |
|    policy_gradient_loss  | -0.000118    |
|    std                   | 0.323        |
|    value_loss            | 0.754        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.31         |
| reward                   | -0.39823434  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 2543616      |
| train/                   |              |
|    approx_kl             | 0.0043280236 |
|    clip_fraction         | 0.0876       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 7.22         |
|    cost_values           | 2.84         |
|    entropy               | -0.552       |
|    entropy_loss          | -0.555       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.82         |
|    n_updates             | 12410        |
|    policy_gradient_loss  | 0.000133     |
|    std                   | 0.322        |
|    value_loss            | 0.793        |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.01        |
| reward                   | -0.5046767  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 612         |
|    total_timesteps       | 2545664     |
| train/                   |             |
|    approx_kl             | 0.004543547 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 3.17        |
|    cost_values           | 3           |
|    entropy               | -0.547      |
|    entropy_loss          | -0.55       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0102      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.89        |
|    n_updates             | 12420       |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.321       |
|    value_loss            | 1.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.6712898   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 646          |
|    total_timesteps       | 2547712      |
| train/                   |              |
|    approx_kl             | 0.0037271732 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.58         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 3            |
|    entropy               | -0.547       |
|    entropy_loss          | -0.547       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00193      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.42         |
|    n_updates             | 12430        |
|    policy_gradient_loss  | -0.000505    |
|    std                   | 0.32         |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21762967 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 680         |
|    total_timesteps       | 2549760     |
| train/                   |             |
|    approx_kl             | 0.003476314 |
|    clip_fraction         | 0.002       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 0.796       |
|    cost_values           | 3           |
|    entropy               | -0.545      |
|    entropy_loss          | -0.546      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.969       |
|    n_updates             | 12440       |
|    policy_gradient_loss  | -0.000119   |
|    std                   | 0.32        |
|    value_loss            | 4.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.38705426  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 2551808      |
| train/                   |              |
|    approx_kl             | 0.0034640082 |
|    clip_fraction         | 0.0688       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 9.72         |
|    cost_values           | 2.97         |
|    entropy               | -0.542       |
|    entropy_loss          | -0.542       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.32         |
|    n_updates             | 12450        |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.32         |
|    value_loss            | 3.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.94         |
| reward                   | -0.18542399  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 750          |
|    total_timesteps       | 2553856      |
| train/                   |              |
|    approx_kl             | 0.0070910444 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.62         |
|    cost_value_loss       | 16.9         |
|    cost_values           | 2.98         |
|    entropy               | -0.544       |
|    entropy_loss          | -0.543       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0121       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.61         |
|    n_updates             | 12460        |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.32         |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.628       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.628       |
| reward                   | -0.44437698 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 784         |
|    total_timesteps       | 2555904     |
| train/                   |             |
|    approx_kl             | 0.005026646 |
|    clip_fraction         | 0.0329      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.08        |
|    cost_value_loss       | 4.12        |
|    cost_values           | 2.97        |
|    entropy               | -0.54       |
|    entropy_loss          | -0.542      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00238     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.88        |
|    n_updates             | 12470       |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 0.319       |
|    value_loss            | 1.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0954      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0954      |
| reward                   | -0.37584475 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 819         |
|    total_timesteps       | 2557952     |
| train/                   |             |
|    approx_kl             | 0.002125804 |
|    clip_fraction         | 0.0277      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 1.3         |
|    cost_values           | 3           |
|    entropy               | -0.541      |
|    entropy_loss          | -0.539      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 1.81e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 0.755       |
|    n_updates             | 12480       |
|    policy_gradient_loss  | -0.000956   |
|    std                   | 0.32        |
|    value_loss            | 0.274       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.767        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.767        |
| reward                   | -0.49253422  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 853          |
|    total_timesteps       | 2560000      |
| train/                   |              |
|    approx_kl             | 0.0036757626 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.32         |
|    cost_value_loss       | 3.41         |
|    cost_values           | 2.99         |
|    entropy               | -0.532       |
|    entropy_loss          | -0.538       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00254      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.8          |
|    n_updates             | 12490        |
|    policy_gradient_loss  | -0.000332    |
|    std                   | 0.318        |
|    value_loss            | 1.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.55        |
| reward                   | -0.41006032 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 887         |
|    total_timesteps       | 2562048     |
| train/                   |             |
|    approx_kl             | 0.008533552 |
|    clip_fraction         | 0.0741      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 2.11        |
|    cost_values           | 2.88        |
|    entropy               | -0.527      |
|    entropy_loss          | -0.528      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.74        |
|    n_updates             | 12500       |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 0.317       |
|    value_loss            | 9.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.579        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.579        |
| reward                   | -0.37364745  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 922          |
|    total_timesteps       | 2564096      |
| train/                   |              |
|    approx_kl             | 0.0041311146 |
|    clip_fraction         | 0.0375       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.39         |
|    cost_value_loss       | 3.02         |
|    cost_values           | 2.98         |
|    entropy               | -0.523       |
|    entropy_loss          | -0.526       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00248      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.51         |
|    n_updates             | 12510        |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.317        |
|    value_loss            | 0.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.887        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.887        |
| reward                   | -0.5149899   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 957          |
|    total_timesteps       | 2566144      |
| train/                   |              |
|    approx_kl             | 0.0033965101 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 5.78         |
|    cost_values           | 3            |
|    entropy               | -0.522       |
|    entropy_loss          | -0.522       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.02         |
|    n_updates             | 12520        |
|    policy_gradient_loss  | 0.000345     |
|    std                   | 0.317        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.08         |
| reward                   | -0.55381006  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 991          |
|    total_timesteps       | 2568192      |
| train/                   |              |
|    approx_kl             | 0.0072911545 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.64         |
|    cost_value_loss       | 2.48         |
|    cost_values           | 2.98         |
|    entropy               | -0.527       |
|    entropy_loss          | -0.524       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0093       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.87         |
|    n_updates             | 12530        |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.317        |
|    value_loss            | 2.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0047       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0047       |
| reward                   | -0.4165565   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1026         |
|    total_timesteps       | 2570240      |
| train/                   |              |
|    approx_kl             | 0.0026956468 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 2.37         |
|    cost_values           | 3            |
|    entropy               | -0.526       |
|    entropy_loss          | -0.527       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00168      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.17         |
|    n_updates             | 12540        |
|    policy_gradient_loss  | -0.000674    |
|    std                   | 0.317        |
|    value_loss            | 1.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.749        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.749        |
| reward                   | -0.47775376  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1060         |
|    total_timesteps       | 2572288      |
| train/                   |              |
|    approx_kl             | 0.0041617095 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 0.548        |
|    cost_values           | 2.83         |
|    entropy               | -0.537       |
|    entropy_loss          | -0.53        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.319        |
|    n_updates             | 12550        |
|    policy_gradient_loss  | -0.000967    |
|    std                   | 0.319        |
|    value_loss            | 0.199        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.02         |
| reward                   | -0.36090505  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1094         |
|    total_timesteps       | 2574336      |
| train/                   |              |
|    approx_kl             | 0.0064557167 |
|    clip_fraction         | 0.0538       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 0.73         |
|    cost_values           | 2.57         |
|    entropy               | -0.54        |
|    entropy_loss          | -0.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.03         |
|    n_updates             | 12560        |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 0.319        |
|    value_loss            | 1.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.24         |
| reward                   | -0.35802203  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1128         |
|    total_timesteps       | 2576384      |
| train/                   |              |
|    approx_kl             | 0.0041641803 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 2.76         |
|    cost_values           | 2.52         |
|    entropy               | -0.537       |
|    entropy_loss          | -0.539       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.31         |
|    n_updates             | 12570        |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.318        |
|    value_loss            | 1.83         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.9         |
| reward                   | -0.43043992 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1163        |
|    total_timesteps       | 2578432     |
| train/                   |             |
|    approx_kl             | 0.00386823  |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 1.14        |
|    cost_values           | 2.59        |
|    entropy               | -0.531      |
|    entropy_loss          | -0.534      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.05        |
|    n_updates             | 12580       |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.318       |
|    value_loss            | 1.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.5719132   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1197         |
|    total_timesteps       | 2580480      |
| train/                   |              |
|    approx_kl             | 0.0013541656 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 2.66         |
|    entropy               | -0.521       |
|    entropy_loss          | -0.527       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.46         |
|    n_updates             | 12590        |
|    policy_gradient_loss  | -0.000946    |
|    std                   | 0.316        |
|    value_loss            | 1.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -0.25932214  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1231         |
|    total_timesteps       | 2582528      |
| train/                   |              |
|    approx_kl             | 0.0054715127 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 2.88         |
|    entropy               | -0.519       |
|    entropy_loss          | -0.519       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 12600        |
|    policy_gradient_loss  | -0.000983    |
|    std                   | 0.316        |
|    value_loss            | 2.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.33477578  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1266         |
|    total_timesteps       | 2584576      |
| train/                   |              |
|    approx_kl             | 0.0037666839 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.11         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 2.99         |
|    entropy               | -0.517       |
|    entropy_loss          | -0.518       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00849      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 12610        |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.316        |
|    value_loss            | 2.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5094818  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1300        |
|    total_timesteps       | 2586624     |
| train/                   |             |
|    approx_kl             | 0.004967012 |
|    clip_fraction         | 0.0372      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 3           |
|    entropy               | -0.516      |
|    entropy_loss          | -0.517      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.83        |
|    n_updates             | 12620       |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.315       |
|    value_loss            | 1.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.53880847 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1335        |
|    total_timesteps       | 2588672     |
| train/                   |             |
|    approx_kl             | 0.002996944 |
|    clip_fraction         | 0.0206      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 8.25        |
|    cost_values           | 2.99        |
|    entropy               | -0.514      |
|    entropy_loss          | -0.515      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00755     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.27        |
|    n_updates             | 12630       |
|    policy_gradient_loss  | -0.00114    |
|    std                   | 0.315       |
|    value_loss            | 1.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.63147414  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1369         |
|    total_timesteps       | 2590720      |
| train/                   |              |
|    approx_kl             | 0.0027528252 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.25         |
|    cost_value_loss       | 7.99         |
|    cost_values           | 3            |
|    entropy               | -0.512       |
|    entropy_loss          | -0.514       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00605      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.44         |
|    n_updates             | 12640        |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.315        |
|    value_loss            | 0.873        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.58184433  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1403         |
|    total_timesteps       | 2592768      |
| train/                   |              |
|    approx_kl             | 0.0020316697 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.69         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 3            |
|    entropy               | -0.509       |
|    entropy_loss          | -0.511       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.57         |
|    n_updates             | 12650        |
|    policy_gradient_loss  | -0.000773    |
|    std                   | 0.314        |
|    value_loss            | 3.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.36         |
| reward                   | -0.6514145   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1438         |
|    total_timesteps       | 2594816      |
| train/                   |              |
|    approx_kl             | 0.0009935608 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.25         |
|    cost_value_loss       | 8.07         |
|    cost_values           | 3            |
|    entropy               | -0.509       |
|    entropy_loss          | -0.509       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00677      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.34         |
|    n_updates             | 12660        |
|    policy_gradient_loss  | -4.64e-05    |
|    std                   | 0.314        |
|    value_loss            | 4.46         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.03        |
| reward                   | -0.36217624 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1473        |
|    total_timesteps       | 2596864     |
| train/                   |             |
|    approx_kl             | 0.003060311 |
|    clip_fraction         | 0.00898     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.28        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 3           |
|    entropy               | -0.511      |
|    entropy_loss          | -0.51       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00439     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 12670       |
|    policy_gradient_loss  | 0.000172    |
|    std                   | 0.315       |
|    value_loss            | 0.621       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.58953094  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1507         |
|    total_timesteps       | 2598912      |
| train/                   |              |
|    approx_kl             | 0.0014220227 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.47         |
|    cost_value_loss       | 9.73         |
|    cost_values           | 3            |
|    entropy               | -0.511       |
|    entropy_loss          | -0.511       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.69         |
|    n_updates             | 12680        |
|    policy_gradient_loss  | -0.000253    |
|    std                   | 0.315        |
|    value_loss            | 2.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.86        |
| reward                   | -0.4879117  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1541        |
|    total_timesteps       | 2600960     |
| train/                   |             |
|    approx_kl             | 0.007870115 |
|    clip_fraction         | 0.0411      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 8.39        |
|    cost_values           | 2.94        |
|    entropy               | -0.51       |
|    entropy_loss          | -0.511      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00506     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.12        |
|    n_updates             | 12690       |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.314       |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.3113449   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1575         |
|    total_timesteps       | 2603008      |
| train/                   |              |
|    approx_kl             | 0.0019218692 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.6          |
|    cost_value_loss       | 4.75         |
|    cost_values           | 3            |
|    entropy               | -0.504       |
|    entropy_loss          | -0.508       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.71         |
|    n_updates             | 12700        |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.314        |
|    value_loss            | 1.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.5280392   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1610         |
|    total_timesteps       | 2605056      |
| train/                   |              |
|    approx_kl             | 0.0028635557 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.81         |
|    cost_value_loss       | 36.6         |
|    cost_values           | 3            |
|    entropy               | -0.5         |
|    entropy_loss          | -0.501       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0152       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.87         |
|    n_updates             | 12710        |
|    policy_gradient_loss  | 4.97e-05     |
|    std                   | 0.313        |
|    value_loss            | 4.24         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.59          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 7.59          |
| reward                   | -0.38311252   |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -442          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 48            |
|    time_elapsed          | 1644          |
|    total_timesteps       | 2607104       |
| train/                   |               |
|    approx_kl             | 0.00018651574 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 7.31          |
|    cost_value_loss       | 31.1          |
|    cost_values           | 2.97          |
|    entropy               | -0.501        |
|    entropy_loss          | -0.501        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.0136        |
|    learning_rate         | 0.0003        |
|    loss                  | 4.53          |
|    n_updates             | 12720         |
|    policy_gradient_loss  | 1.61e-05      |
|    std                   | 0.313         |
|    value_loss            | 1.45          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6317321  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1679        |
|    total_timesteps       | 2609152     |
| train/                   |             |
|    approx_kl             | 0.004493173 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 3           |
|    entropy               | -0.498      |
|    entropy_loss          | -0.499      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0127      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.4         |
|    n_updates             | 12730       |
|    policy_gradient_loss  | -0.00335    |
|    std                   | 0.313       |
|    value_loss            | 0.813       |
------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.6898386 |
| rollout/           |            |
|    ep_len_mean     | 993        |
|    ep_rew_mean     | -442       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2611200    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.44888666  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2613248      |
| train/                   |              |
|    approx_kl             | 0.0019799382 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.94         |
|    cost_value_loss       | 0.835        |
|    cost_values           | 2.91         |
|    entropy               | -0.51        |
|    entropy_loss          | -0.501       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.83         |
|    n_updates             | 12750        |
|    policy_gradient_loss  | 0.000212     |
|    std                   | 0.315        |
|    value_loss            | 6.77         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.39487326   |
| rollout/                 |               |
|    ep_len_mean           | 993           |
|    ep_rew_mean           | -445          |
| time/                    |               |
|    fps                   | 65            |
|    iterations            | 3             |
|    time_elapsed          | 93            |
|    total_timesteps       | 2615296       |
| train/                   |               |
|    approx_kl             | 0.00092985894 |
|    clip_fraction         | 0.0245        |
|    clip_range            | 0.2           |
|    cost_returns          | 4.73          |
|    cost_value_loss       | 11.4          |
|    cost_values           | 2.96          |
|    entropy               | -0.514        |
|    entropy_loss          | -0.513        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.57          |
|    n_updates             | 12760         |
|    policy_gradient_loss  | -3.88e-05     |
|    std                   | 0.315         |
|    value_loss            | 5.51          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31605092  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2617344      |
| train/                   |              |
|    approx_kl             | 0.0034146975 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.41         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 2.99         |
|    entropy               | -0.515       |
|    entropy_loss          | -0.514       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00403      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.36         |
|    n_updates             | 12770        |
|    policy_gradient_loss  | -9.66e-05    |
|    std                   | 0.315        |
|    value_loss            | 0.942        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.46602112 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 2619392     |
| train/                   |             |
|    approx_kl             | 0.00272444  |
|    clip_fraction         | 0.0273      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 1.24        |
|    cost_values           | 2.92        |
|    entropy               | -0.517      |
|    entropy_loss          | -0.515      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.52        |
|    n_updates             | 12780       |
|    policy_gradient_loss  | -0.000142   |
|    std                   | 0.315       |
|    value_loss            | 5.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32758847 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 2621440     |
| train/                   |             |
|    approx_kl             | 0.002522376 |
|    clip_fraction         | 0.00591     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 0.933       |
|    cost_values           | 2.75        |
|    entropy               | -0.517      |
|    entropy_loss          | -0.517      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.853       |
|    n_updates             | 12790       |
|    policy_gradient_loss  | 1.52e-05    |
|    std                   | 0.315       |
|    value_loss            | 0.649       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.30274594  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 2623488      |
| train/                   |              |
|    approx_kl             | 0.0014136402 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.4          |
|    cost_value_loss       | 7.61         |
|    cost_values           | 2.87         |
|    entropy               | -0.516       |
|    entropy_loss          | -0.517       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 12800        |
|    policy_gradient_loss  | 0.000312     |
|    std                   | 0.315        |
|    value_loss            | 5.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.35495517  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 2625536      |
| train/                   |              |
|    approx_kl             | 0.0037177568 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.13         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 2.95         |
|    entropy               | -0.52        |
|    entropy_loss          | -0.517       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.4          |
|    n_updates             | 12810        |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.316        |
|    value_loss            | 0.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.659962    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 2627584      |
| train/                   |              |
|    approx_kl             | 0.0033485638 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.89         |
|    cost_value_loss       | 23.6         |
|    cost_values           | 3            |
|    entropy               | -0.521       |
|    entropy_loss          | -0.521       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00262      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.77         |
|    n_updates             | 12820        |
|    policy_gradient_loss  | -0.000453    |
|    std                   | 0.316        |
|    value_loss            | 2.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.6685666   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 2629632      |
| train/                   |              |
|    approx_kl             | 0.0052225157 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 6.03         |
|    cost_values           | 3            |
|    entropy               | -0.519       |
|    entropy_loss          | -0.521       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0106       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.4          |
|    n_updates             | 12830        |
|    policy_gradient_loss  | -0.000774    |
|    std                   | 0.315        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.53021055  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 2631680      |
| train/                   |              |
|    approx_kl             | 0.0046574567 |
|    clip_fraction         | 0.0253       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 0.707        |
|    cost_values           | 2.86         |
|    entropy               | -0.515       |
|    entropy_loss          | -0.517       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.58         |
|    n_updates             | 12840        |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.315        |
|    value_loss            | 6.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.24379031  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 2633728      |
| train/                   |              |
|    approx_kl             | 0.0032117022 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.05         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 2.78         |
|    entropy               | -0.513       |
|    entropy_loss          | -0.513       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00446      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 12850        |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.314        |
|    value_loss            | 4.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.40762588  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 437          |
|    total_timesteps       | 2635776      |
| train/                   |              |
|    approx_kl             | 0.0011127007 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 7.05         |
|    cost_value_loss       | 30.8         |
|    cost_values           | 2.99         |
|    entropy               | -0.514       |
|    entropy_loss          | -0.513       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00881      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.4          |
|    n_updates             | 12860        |
|    policy_gradient_loss  | 0.000108     |
|    std                   | 0.314        |
|    value_loss            | 2.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.47534284  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 472          |
|    total_timesteps       | 2637824      |
| train/                   |              |
|    approx_kl             | 0.0007636127 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 1.4          |
|    cost_values           | 2.99         |
|    entropy               | -0.508       |
|    entropy_loss          | -0.512       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.52         |
|    n_updates             | 12870        |
|    policy_gradient_loss  | 2.02e-05     |
|    std                   | 0.314        |
|    value_loss            | 1.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5219752   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 2639872      |
| train/                   |              |
|    approx_kl             | 0.0025050486 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.19         |
|    cost_value_loss       | 2.3          |
|    cost_values           | 2.97         |
|    entropy               | -0.508       |
|    entropy_loss          | -0.508       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.29         |
|    n_updates             | 12880        |
|    policy_gradient_loss  | -0.000563    |
|    std                   | 0.313        |
|    value_loss            | 2.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.25123638 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 540         |
|    total_timesteps       | 2641920     |
| train/                   |             |
|    approx_kl             | 0.005011544 |
|    clip_fraction         | 0.00889     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.66        |
|    cost_value_loss       | 20.3        |
|    cost_values           | 2.99        |
|    entropy               | -0.508      |
|    entropy_loss          | -0.508      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00337     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.69        |
|    n_updates             | 12890       |
|    policy_gradient_loss  | -0.000821   |
|    std                   | 0.313       |
|    value_loss            | 1.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.15432642 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 575         |
|    total_timesteps       | 2643968     |
| train/                   |             |
|    approx_kl             | 0.004738763 |
|    clip_fraction         | 0.0121      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.79        |
|    cost_value_loss       | 3.96        |
|    cost_values           | 3           |
|    entropy               | -0.507      |
|    entropy_loss          | -0.508      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00766     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.03        |
|    n_updates             | 12900       |
|    policy_gradient_loss  | -4.99e-05   |
|    std                   | 0.313       |
|    value_loss            | 2.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.597583    |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 609          |
|    total_timesteps       | 2646016      |
| train/                   |              |
|    approx_kl             | 0.0037705374 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.73         |
|    cost_value_loss       | 17           |
|    cost_values           | 3            |
|    entropy               | -0.504       |
|    entropy_loss          | -0.505       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00324      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.31         |
|    n_updates             | 12910        |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.313        |
|    value_loss            | 1.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.36091164  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 644          |
|    total_timesteps       | 2648064      |
| train/                   |              |
|    approx_kl             | 0.0040526967 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 1.48         |
|    cost_values           | 2.89         |
|    entropy               | -0.501       |
|    entropy_loss          | -0.502       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 12920        |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.312        |
|    value_loss            | 20.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.34246755 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 678         |
|    total_timesteps       | 2650112     |
| train/                   |             |
|    approx_kl             | 0.001828332 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 6.72        |
|    cost_value_loss       | 27.7        |
|    cost_values           | 2.88        |
|    entropy               | -0.501      |
|    entropy_loss          | -0.5        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 12930       |
|    policy_gradient_loss  | -0.000804   |
|    std                   | 0.312       |
|    value_loss            | 3.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.5798107   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 712          |
|    total_timesteps       | 2652160      |
| train/                   |              |
|    approx_kl             | 0.0038350397 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 1.58         |
|    cost_values           | 2.99         |
|    entropy               | -0.492       |
|    entropy_loss          | -0.497       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00165      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.34         |
|    n_updates             | 12940        |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.311        |
|    value_loss            | 1.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.47731966  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 747          |
|    total_timesteps       | 2654208      |
| train/                   |              |
|    approx_kl             | 0.0014310465 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.11         |
|    cost_value_loss       | 5.56         |
|    cost_values           | 3            |
|    entropy               | -0.484       |
|    entropy_loss          | -0.488       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00044      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 12950        |
|    policy_gradient_loss  | -0.000511    |
|    std                   | 0.31         |
|    value_loss            | 3.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.44805062 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 782         |
|    total_timesteps       | 2656256     |
| train/                   |             |
|    approx_kl             | 0.004920006 |
|    clip_fraction         | 0.00918     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 0.972       |
|    cost_values           | 2.97        |
|    entropy               | -0.48       |
|    entropy_loss          | -0.482      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.04        |
|    n_updates             | 12960       |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.309       |
|    value_loss            | 2.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.54         |
| reward                   | -0.5234124   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 818          |
|    total_timesteps       | 2658304      |
| train/                   |              |
|    approx_kl             | 0.0038928427 |
|    clip_fraction         | 0.00449      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 2.98         |
|    entropy               | -0.474       |
|    entropy_loss          | -0.476       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.74         |
|    n_updates             | 12970        |
|    policy_gradient_loss  | -0.000354    |
|    std                   | 0.308        |
|    value_loss            | 1.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42583743  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 853          |
|    total_timesteps       | 2660352      |
| train/                   |              |
|    approx_kl             | 0.0027434633 |
|    clip_fraction         | 0.0327       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.82         |
|    cost_value_loss       | 13.8         |
|    cost_values           | 2.99         |
|    entropy               | -0.474       |
|    entropy_loss          | -0.474       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00954      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.8          |
|    n_updates             | 12980        |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.308        |
|    value_loss            | 1.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3605223   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 888          |
|    total_timesteps       | 2662400      |
| train/                   |              |
|    approx_kl             | 0.0032326872 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.35         |
|    cost_value_loss       | 2.32         |
|    cost_values           | 2.99         |
|    entropy               | -0.471       |
|    entropy_loss          | -0.473       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.45         |
|    n_updates             | 12990        |
|    policy_gradient_loss  | -0.000937    |
|    std                   | 0.308        |
|    value_loss            | 1.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -0.6308291   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 923          |
|    total_timesteps       | 2664448      |
| train/                   |              |
|    approx_kl             | 0.0027401573 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 6.77         |
|    cost_value_loss       | 21.5         |
|    cost_values           | 3            |
|    entropy               | -0.468       |
|    entropy_loss          | -0.469       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00321      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.89         |
|    n_updates             | 13000        |
|    policy_gradient_loss  | -0.000602    |
|    std                   | 0.307        |
|    value_loss            | 0.775        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.805       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.805       |
| reward                   | -0.26567635 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 958         |
|    total_timesteps       | 2666496     |
| train/                   |             |
|    approx_kl             | 0.004659389 |
|    clip_fraction         | 0.0709      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 2.8         |
|    cost_values           | 2.96        |
|    entropy               | -0.468      |
|    entropy_loss          | -0.468      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.00308     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.87        |
|    n_updates             | 13010       |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.307       |
|    value_loss            | 9.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.486        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.486        |
| reward                   | -0.343751    |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 993          |
|    total_timesteps       | 2668544      |
| train/                   |              |
|    approx_kl             | 0.0037124911 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.98         |
|    cost_value_loss       | 17.8         |
|    cost_values           | 3            |
|    entropy               | -0.469       |
|    entropy_loss          | -0.469       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 13020        |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.308        |
|    value_loss            | 3.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.86         |
| reward                   | -0.2695854   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 2670592      |
| train/                   |              |
|    approx_kl             | 0.0020790761 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.62         |
|    cost_value_loss       | 5.26         |
|    cost_values           | 3            |
|    entropy               | -0.472       |
|    entropy_loss          | -0.471       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.46         |
|    n_updates             | 13030        |
|    policy_gradient_loss  | 4.03e-05     |
|    std                   | 0.308        |
|    value_loss            | 3.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.5565676   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 2672640      |
| train/                   |              |
|    approx_kl             | 0.0025304863 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 6.65         |
|    cost_values           | 3            |
|    entropy               | -0.472       |
|    entropy_loss          | -0.472       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00122      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.67         |
|    n_updates             | 13040        |
|    policy_gradient_loss  | -0.00058     |
|    std                   | 0.308        |
|    value_loss            | 2.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.06        |
| reward                   | -0.51594585 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1098        |
|    total_timesteps       | 2674688     |
| train/                   |             |
|    approx_kl             | 0.005748882 |
|    clip_fraction         | 0.0107      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.75        |
|    cost_value_loss       | 3.84        |
|    cost_values           | 2.93        |
|    entropy               | -0.47       |
|    entropy_loss          | -0.471      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 13050       |
|    policy_gradient_loss  | -0.000817   |
|    std                   | 0.308       |
|    value_loss            | 17.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.62        |
| reward                   | -0.49970457 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1133        |
|    total_timesteps       | 2676736     |
| train/                   |             |
|    approx_kl             | 0.005246517 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 8.21        |
|    cost_values           | 2.97        |
|    entropy               | -0.469      |
|    entropy_loss          | -0.469      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 13060       |
|    policy_gradient_loss  | -0.000585   |
|    std                   | 0.307       |
|    value_loss            | 1.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.41184902  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1167         |
|    total_timesteps       | 2678784      |
| train/                   |              |
|    approx_kl             | 0.0014136458 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.59         |
|    cost_value_loss       | 2.88         |
|    cost_values           | 3            |
|    entropy               | -0.471       |
|    entropy_loss          | -0.469       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00749      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.78         |
|    n_updates             | 13070        |
|    policy_gradient_loss  | -0.00097     |
|    std                   | 0.308        |
|    value_loss            | 1.88         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.41303748 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1202        |
|    total_timesteps       | 2680832     |
| train/                   |             |
|    approx_kl             | 0.002730421 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 8.43        |
|    cost_values           | 3           |
|    entropy               | -0.472      |
|    entropy_loss          | -0.472      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00784     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.51        |
|    n_updates             | 13080       |
|    policy_gradient_loss  | -0.000208   |
|    std                   | 0.308       |
|    value_loss            | 2.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.57236373  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1238         |
|    total_timesteps       | 2682880      |
| train/                   |              |
|    approx_kl             | 0.0021999893 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.61         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 3            |
|    entropy               | -0.472       |
|    entropy_loss          | -0.472       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00808      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 13090        |
|    policy_gradient_loss  | -0.000112    |
|    std                   | 0.308        |
|    value_loss            | 1.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.46567535  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 2684928      |
| train/                   |              |
|    approx_kl             | 0.0032343883 |
|    clip_fraction         | 0.0286       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 18.3         |
|    cost_values           | 3            |
|    entropy               | -0.473       |
|    entropy_loss          | -0.472       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00936      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.31         |
|    n_updates             | 13100        |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.308        |
|    value_loss            | 1.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3202873   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1307         |
|    total_timesteps       | 2686976      |
| train/                   |              |
|    approx_kl             | 0.0038652245 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 5.88         |
|    cost_values           | 3            |
|    entropy               | -0.472       |
|    entropy_loss          | -0.472       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.24         |
|    n_updates             | 13110        |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.308        |
|    value_loss            | 2.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.468       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.468       |
| reward                   | -0.31603274 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1341        |
|    total_timesteps       | 2689024     |
| train/                   |             |
|    approx_kl             | 0.005227737 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.18        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 3           |
|    entropy               | -0.47       |
|    entropy_loss          | -0.471      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00832     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.81        |
|    n_updates             | 13120       |
|    policy_gradient_loss  | -0.000575   |
|    std                   | 0.308       |
|    value_loss            | 2.57        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.24         |
| reward                   | -0.27589887  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1376         |
|    total_timesteps       | 2691072      |
| train/                   |              |
|    approx_kl             | 0.0051264535 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.8          |
|    cost_value_loss       | 9.83         |
|    cost_values           | 3            |
|    entropy               | -0.468       |
|    entropy_loss          | -0.469       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.78         |
|    n_updates             | 13130        |
|    policy_gradient_loss  | -0.000882    |
|    std                   | 0.307        |
|    value_loss            | 2.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.48        |
| reward                   | -0.41965088 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1410        |
|    total_timesteps       | 2693120     |
| train/                   |             |
|    approx_kl             | 0.004699993 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.97        |
|    cost_value_loss       | 18.3        |
|    cost_values           | 3           |
|    entropy               | -0.468      |
|    entropy_loss          | -0.468      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.94        |
|    n_updates             | 13140       |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.307       |
|    value_loss            | 2.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.82         |
| reward                   | -0.23904343  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1445         |
|    total_timesteps       | 2695168      |
| train/                   |              |
|    approx_kl             | 0.0038953396 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.15         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 3            |
|    entropy               | -0.465       |
|    entropy_loss          | -0.467       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00704      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.68         |
|    n_updates             | 13150        |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.307        |
|    value_loss            | 1.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.1          |
| reward                   | -0.5272993   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1479         |
|    total_timesteps       | 2697216      |
| train/                   |              |
|    approx_kl             | 0.0021903133 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.19         |
|    cost_value_loss       | 21.9         |
|    cost_values           | 2.99         |
|    entropy               | -0.464       |
|    entropy_loss          | -0.465       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0127       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.99         |
|    n_updates             | 13160        |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.307        |
|    value_loss            | 1.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.84        |
| reward                   | -0.52940136 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1513        |
|    total_timesteps       | 2699264     |
| train/                   |             |
|    approx_kl             | 0.005832234 |
|    clip_fraction         | 0.0298      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.45        |
|    cost_value_loss       | 23.8        |
|    cost_values           | 3           |
|    entropy               | -0.464      |
|    entropy_loss          | -0.464      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0134      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 13170       |
|    policy_gradient_loss  | -0.000185   |
|    std                   | 0.307       |
|    value_loss            | 8.59        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.85       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.85       |
| reward                   | -0.3420627 |
| rollout/                 |            |
|    ep_len_mean           | 975        |
|    ep_rew_mean           | -428       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 45         |
|    time_elapsed          | 1548       |
|    total_timesteps       | 2701312    |
| train/                   |            |
|    approx_kl             | 0.00886825 |
|    clip_fraction         | 0.0449     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.62       |
|    cost_value_loss       | 5.18       |
|    cost_values           | 3          |
|    entropy               | -0.47      |
|    entropy_loss          | -0.467     |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.00357    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.12       |
|    n_updates             | 13180      |
|    policy_gradient_loss  | -0.00156   |
|    std                   | 0.308      |
|    value_loss            | 1.18       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.56843656 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1583        |
|    total_timesteps       | 2703360     |
| train/                   |             |
|    approx_kl             | 0.002086948 |
|    clip_fraction         | 0.051       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.37        |
|    cost_value_loss       | 22.3        |
|    cost_values           | 3           |
|    entropy               | -0.471      |
|    entropy_loss          | -0.471      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0102      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.8         |
|    n_updates             | 13190       |
|    policy_gradient_loss  | -0.000476   |
|    std                   | 0.308       |
|    value_loss            | 6.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.5308122  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1617        |
|    total_timesteps       | 2705408     |
| train/                   |             |
|    approx_kl             | 0.002131382 |
|    clip_fraction         | 0.000391    |
|    clip_range            | 0.2         |
|    cost_returns          | 7.69        |
|    cost_value_loss       | 33.5        |
|    cost_values           | 3           |
|    entropy               | -0.472      |
|    entropy_loss          | -0.472      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.0114      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 13200       |
|    policy_gradient_loss  | -3.78e-05   |
|    std                   | 0.308       |
|    value_loss            | 2.16        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5223848 |
| rollout/                 |            |
|    ep_len_mean           | 975        |
|    ep_rew_mean           | -430       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 48         |
|    time_elapsed          | 1651       |
|    total_timesteps       | 2707456    |
| train/                   |            |
|    approx_kl             | 0.00123783 |
|    clip_fraction         | 9.77e-05   |
|    clip_range            | 0.2        |
|    cost_returns          | 3.84       |
|    cost_value_loss       | 4.51       |
|    cost_values           | 2.98       |
|    entropy               | -0.476     |
|    entropy_loss          | -0.474     |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0.0118     |
|    learning_rate         | 0.0003     |
|    loss                  | 3.43       |
|    n_updates             | 13210      |
|    policy_gradient_loss  | 8.9e-05    |
|    std                   | 0.309      |
|    value_loss            | 9.94       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50214064  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1685         |
|    total_timesteps       | 2709504      |
| train/                   |              |
|    approx_kl             | 0.0041709677 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.37         |
|    cost_value_loss       | 3.23         |
|    cost_values           | 2.89         |
|    entropy               | -0.477       |
|    entropy_loss          | -0.477       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.3          |
|    n_updates             | 13220        |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.309        |
|    value_loss            | 1.88         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.35488626 |
| rollout/           |             |
|    ep_len_mean     | 975         |
|    ep_rew_mean     | -431        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2711552     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.376066   |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 2713600     |
| train/                   |             |
|    approx_kl             | 0.002569059 |
|    clip_fraction         | 0.00171     |
|    clip_range            | 0.2         |
|    cost_returns          | 7.43        |
|    cost_value_loss       | 31.2        |
|    cost_values           | 3           |
|    entropy               | -0.475      |
|    entropy_loss          | -0.476      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.7        |
|    n_updates             | 13240       |
|    policy_gradient_loss  | 0.000243    |
|    std                   | 0.309       |
|    value_loss            | 2.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.44115186 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 3           |
|    time_elapsed          | 92          |
|    total_timesteps       | 2715648     |
| train/                   |             |
|    approx_kl             | 0.001993901 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.5         |
|    cost_value_loss       | 4.51        |
|    cost_values           | 3           |
|    entropy               | -0.474      |
|    entropy_loss          | -0.474      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00343     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.44        |
|    n_updates             | 13250       |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.308       |
|    value_loss            | 3.27        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.13       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.13       |
| reward                   | -0.5834082 |
| rollout/                 |            |
|    ep_len_mean           | 969        |
|    ep_rew_mean           | -429       |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 4          |
|    time_elapsed          | 127        |
|    total_timesteps       | 2717696    |
| train/                   |            |
|    approx_kl             | 0.00745023 |
|    clip_fraction         | 0.0684     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.27       |
|    cost_value_loss       | 2.06       |
|    cost_values           | 3          |
|    entropy               | -0.473     |
|    entropy_loss          | -0.473     |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 4.84       |
|    n_updates             | 13260      |
|    policy_gradient_loss  | -0.00134   |
|    std                   | 0.308      |
|    value_loss            | 10.7       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6769723   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 2719744      |
| train/                   |              |
|    approx_kl             | 0.0018679915 |
|    clip_fraction         | 0.0952       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.74         |
|    cost_value_loss       | 26.1         |
|    cost_values           | 3            |
|    entropy               | -0.474       |
|    entropy_loss          | -0.474       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00948      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.99         |
|    n_updates             | 13270        |
|    policy_gradient_loss  | 0.00224      |
|    std                   | 0.309        |
|    value_loss            | 1.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.61875886  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 195          |
|    total_timesteps       | 2721792      |
| train/                   |              |
|    approx_kl             | 0.0057813386 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 3            |
|    entropy               | -0.472       |
|    entropy_loss          | -0.473       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.011        |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 13280        |
|    policy_gradient_loss  | -0.000964    |
|    std                   | 0.308        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.63917047  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 2723840      |
| train/                   |              |
|    approx_kl             | 0.0033379905 |
|    clip_fraction         | 0.00566      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.66         |
|    cost_value_loss       | 17.4         |
|    cost_values           | 3            |
|    entropy               | -0.473       |
|    entropy_loss          | -0.472       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00472      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.84         |
|    n_updates             | 13290        |
|    policy_gradient_loss  | -0.000569    |
|    std                   | 0.309        |
|    value_loss            | 4.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4879457   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 2725888      |
| train/                   |              |
|    approx_kl             | 0.0037133666 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.73         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 3            |
|    entropy               | -0.473       |
|    entropy_loss          | -0.473       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.013        |
|    learning_rate         | 0.0003       |
|    loss                  | 4            |
|    n_updates             | 13300        |
|    policy_gradient_loss  | -0.000444    |
|    std                   | 0.309        |
|    value_loss            | 1.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.35449785  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 2727936      |
| train/                   |              |
|    approx_kl             | 0.0026350694 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.85         |
|    cost_value_loss       | 32.4         |
|    cost_values           | 2.99         |
|    entropy               | -0.473       |
|    entropy_loss          | -0.473       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.3         |
|    n_updates             | 13310        |
|    policy_gradient_loss  | -0.000426    |
|    std                   | 0.309        |
|    value_loss            | 4.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.20471202  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 2729984      |
| train/                   |              |
|    approx_kl             | 0.0033618435 |
|    clip_fraction         | 0.00186      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.56         |
|    cost_value_loss       | 25.5         |
|    cost_values           | 3            |
|    entropy               | -0.474       |
|    entropy_loss          | -0.473       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0269       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.74         |
|    n_updates             | 13320        |
|    policy_gradient_loss  | -0.000389    |
|    std                   | 0.309        |
|    value_loss            | 2.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2516099   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 2732032      |
| train/                   |              |
|    approx_kl             | 0.0025802033 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 15.8         |
|    cost_values           | 2.95         |
|    entropy               | -0.472       |
|    entropy_loss          | -0.473       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00117      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.36         |
|    n_updates             | 13330        |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.308        |
|    value_loss            | 1.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.4118037   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 2734080      |
| train/                   |              |
|    approx_kl             | 0.0072082104 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.24         |
|    cost_value_loss       | 20.1         |
|    cost_values           | 2.97         |
|    entropy               | -0.47        |
|    entropy_loss          | -0.471       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00805      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.53         |
|    n_updates             | 13340        |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.308        |
|    value_loss            | 23.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.42793995  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 2736128      |
| train/                   |              |
|    approx_kl             | 0.0033076922 |
|    clip_fraction         | 0.0498       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.84         |
|    cost_value_loss       | 20           |
|    cost_values           | 3            |
|    entropy               | -0.468       |
|    entropy_loss          | -0.469       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0132       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.56         |
|    n_updates             | 13350        |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.308        |
|    value_loss            | 27.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7531511  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 472         |
|    total_timesteps       | 2738176     |
| train/                   |             |
|    approx_kl             | 0.003807168 |
|    clip_fraction         | 0.0207      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 2.99        |
|    entropy               | -0.465      |
|    entropy_loss          | -0.467      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.87        |
|    n_updates             | 13360       |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.307       |
|    value_loss            | 2.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.58347946  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 2740224      |
| train/                   |              |
|    approx_kl             | 0.0047598267 |
|    clip_fraction         | 0.00708      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.11         |
|    cost_value_loss       | 21.8         |
|    cost_values           | 3            |
|    entropy               | -0.465       |
|    entropy_loss          | -0.465       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.33         |
|    n_updates             | 13370        |
|    policy_gradient_loss  | -0.000689    |
|    std                   | 0.307        |
|    value_loss            | 4.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29529035 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 542         |
|    total_timesteps       | 2742272     |
| train/                   |             |
|    approx_kl             | 0.003917916 |
|    clip_fraction         | 0.0269      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 17.8        |
|    cost_values           | 3           |
|    entropy               | -0.462      |
|    entropy_loss          | -0.464      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 13380       |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.307       |
|    value_loss            | 5.54        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.32783246   |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -442          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 17            |
|    time_elapsed          | 576           |
|    total_timesteps       | 2744320       |
| train/                   |               |
|    approx_kl             | 0.00089324004 |
|    clip_fraction         | 0.0402        |
|    clip_range            | 0.2           |
|    cost_returns          | 6.93          |
|    cost_value_loss       | 24.3          |
|    cost_values           | 3             |
|    entropy               | -0.464        |
|    entropy_loss          | -0.462        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00416       |
|    learning_rate         | 0.0003        |
|    loss                  | 6.24          |
|    n_updates             | 13390         |
|    policy_gradient_loss  | -0.00185      |
|    std                   | 0.307         |
|    value_loss            | 2.25          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.56529063  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 611          |
|    total_timesteps       | 2746368      |
| train/                   |              |
|    approx_kl             | 0.0021670116 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.62         |
|    cost_value_loss       | 15.8         |
|    cost_values           | 3            |
|    entropy               | -0.463       |
|    entropy_loss          | -0.464       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.57         |
|    n_updates             | 13400        |
|    policy_gradient_loss  | 0.000757     |
|    std                   | 0.307        |
|    value_loss            | 1.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.20559502  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 2748416      |
| train/                   |              |
|    approx_kl             | 0.0036508883 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.75         |
|    cost_value_loss       | 17.5         |
|    cost_values           | 3            |
|    entropy               | -0.462       |
|    entropy_loss          | -0.463       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0209       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.55         |
|    n_updates             | 13410        |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.307        |
|    value_loss            | 3.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4656732  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 679         |
|    total_timesteps       | 2750464     |
| train/                   |             |
|    approx_kl             | 0.002840013 |
|    clip_fraction         | 0.0288      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 7.14        |
|    cost_values           | 2.95        |
|    entropy               | -0.462      |
|    entropy_loss          | -0.462      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.000979    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 13420       |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.307       |
|    value_loss            | 17.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.33645138  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 714          |
|    total_timesteps       | 2752512      |
| train/                   |              |
|    approx_kl             | 0.0042063803 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.09         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 3            |
|    entropy               | -0.462       |
|    entropy_loss          | -0.462       |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 13430        |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.307        |
|    value_loss            | 2.41         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6561655  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 749         |
|    total_timesteps       | 2754560     |
| train/                   |             |
|    approx_kl             | 0.007288783 |
|    clip_fraction         | 0.058       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 7.13        |
|    cost_values           | 2.99        |
|    entropy               | -0.456      |
|    entropy_loss          | -0.46       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.86        |
|    n_updates             | 13440       |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 0.306       |
|    value_loss            | 1.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.420654    |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 783          |
|    total_timesteps       | 2756608      |
| train/                   |              |
|    approx_kl             | 0.0025506509 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.37         |
|    cost_value_loss       | 18.9         |
|    cost_values           | 3            |
|    entropy               | -0.452       |
|    entropy_loss          | -0.454       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00427      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.7          |
|    n_updates             | 13450        |
|    policy_gradient_loss  | -0.000594    |
|    std                   | 0.305        |
|    value_loss            | 6.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.85608923 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 818         |
|    total_timesteps       | 2758656     |
| train/                   |             |
|    approx_kl             | 0.002962037 |
|    clip_fraction         | 0.00117     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.95        |
|    entropy               | -0.449      |
|    entropy_loss          | -0.45       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.3        |
|    n_updates             | 13460       |
|    policy_gradient_loss  | 3.42e-05    |
|    std                   | 0.305       |
|    value_loss            | 19.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.69849885  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 852          |
|    total_timesteps       | 2760704      |
| train/                   |              |
|    approx_kl             | 0.0010658416 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.57         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 3            |
|    entropy               | -0.445       |
|    entropy_loss          | -0.447       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 13470        |
|    policy_gradient_loss  | -0.000129    |
|    std                   | 0.304        |
|    value_loss            | 9.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.608667    |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 2762752      |
| train/                   |              |
|    approx_kl             | 0.0063023847 |
|    clip_fraction         | 0.0646       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.66         |
|    cost_value_loss       | 7.24         |
|    cost_values           | 3            |
|    entropy               | -0.447       |
|    entropy_loss          | -0.446       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0144       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.38         |
|    n_updates             | 13480        |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 0.305        |
|    value_loss            | 5.61         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.56829435   |
| rollout/                 |               |
|    ep_len_mean           | 951           |
|    ep_rew_mean           | -453          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 27            |
|    time_elapsed          | 921           |
|    total_timesteps       | 2764800       |
| train/                   |               |
|    approx_kl             | 0.00022899403 |
|    clip_fraction         | 0.00142       |
|    clip_range            | 0.2           |
|    cost_returns          | 5.01          |
|    cost_value_loss       | 10.6          |
|    cost_values           | 2.99          |
|    entropy               | -0.445        |
|    entropy_loss          | -0.447        |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.3          |
|    n_updates             | 13490         |
|    policy_gradient_loss  | -0.000242     |
|    std                   | 0.305         |
|    value_loss            | 13.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 3.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.82         |
| reward                   | -0.37563273  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 955          |
|    total_timesteps       | 2766848      |
| train/                   |              |
|    approx_kl             | 0.0033409547 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.51         |
|    cost_value_loss       | 22.4         |
|    cost_values           | 3            |
|    entropy               | -0.444       |
|    entropy_loss          | -0.445       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0164       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.99         |
|    n_updates             | 13500        |
|    policy_gradient_loss  | -0.000577    |
|    std                   | 0.304        |
|    value_loss            | 1.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.8          |
| reward                   | -0.3986246   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 989          |
|    total_timesteps       | 2768896      |
| train/                   |              |
|    approx_kl             | 0.0021919645 |
|    clip_fraction         | 0.00503      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 7.71         |
|    cost_values           | 2.99         |
|    entropy               | -0.442       |
|    entropy_loss          | -0.443       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.11         |
|    n_updates             | 13510        |
|    policy_gradient_loss  | -0.000664    |
|    std                   | 0.304        |
|    value_loss            | 18.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.36125135  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1025         |
|    total_timesteps       | 2770944      |
| train/                   |              |
|    approx_kl             | 0.0049144654 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.27         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 3            |
|    entropy               | -0.441       |
|    entropy_loss          | -0.442       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.99         |
|    n_updates             | 13520        |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.304        |
|    value_loss            | 1.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.45881894 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1060        |
|    total_timesteps       | 2772992     |
| train/                   |             |
|    approx_kl             | 0.005234076 |
|    clip_fraction         | 0.0548      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.69        |
|    cost_value_loss       | 22.3        |
|    cost_values           | 3           |
|    entropy               | -0.443      |
|    entropy_loss          | -0.442      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00584     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.3         |
|    n_updates             | 13530       |
|    policy_gradient_loss  | 0.00109     |
|    std                   | 0.304       |
|    value_loss            | 2.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.49177277  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1095         |
|    total_timesteps       | 2775040      |
| train/                   |              |
|    approx_kl             | 0.0045468863 |
|    clip_fraction         | 0.0448       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.05         |
|    cost_value_loss       | 20.3         |
|    cost_values           | 3            |
|    entropy               | -0.442       |
|    entropy_loss          | -0.443       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0136       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.06         |
|    n_updates             | 13540        |
|    policy_gradient_loss  | -0.000214    |
|    std                   | 0.304        |
|    value_loss            | 3.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55240536  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1129         |
|    total_timesteps       | 2777088      |
| train/                   |              |
|    approx_kl             | 0.0045994874 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.37         |
|    cost_value_loss       | 28.4         |
|    cost_values           | 3            |
|    entropy               | -0.437       |
|    entropy_loss          | -0.439       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 13550        |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.303        |
|    value_loss            | 1.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.53373545  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 2779136      |
| train/                   |              |
|    approx_kl             | 0.0013455087 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.03         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 3            |
|    entropy               | -0.439       |
|    entropy_loss          | -0.438       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 13560        |
|    policy_gradient_loss  | 4.67e-05     |
|    std                   | 0.304        |
|    value_loss            | 2.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3007804   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1199         |
|    total_timesteps       | 2781184      |
| train/                   |              |
|    approx_kl             | 0.0031587887 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.41         |
|    cost_value_loss       | 22           |
|    cost_values           | 3            |
|    entropy               | -0.44        |
|    entropy_loss          | -0.439       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00716      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.28         |
|    n_updates             | 13570        |
|    policy_gradient_loss  | -0.000784    |
|    std                   | 0.304        |
|    value_loss            | 4.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6008752  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1233        |
|    total_timesteps       | 2783232     |
| train/                   |             |
|    approx_kl             | 0.008091232 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 19.5        |
|    cost_values           | 3           |
|    entropy               | -0.438      |
|    entropy_loss          | -0.439      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 13580       |
|    policy_gradient_loss  | -0.000343   |
|    std                   | 0.304       |
|    value_loss            | 13.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.44587868 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1267        |
|    total_timesteps       | 2785280     |
| train/                   |             |
|    approx_kl             | 0.004343421 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.06        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 3           |
|    entropy               | -0.431      |
|    entropy_loss          | -0.435      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 13590       |
|    policy_gradient_loss  | -0.002      |
|    std                   | 0.302       |
|    value_loss            | 13.8        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.38096058   |
| rollout/                 |               |
|    ep_len_mean           | 934           |
|    ep_rew_mean           | -454          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1302          |
|    total_timesteps       | 2787328       |
| train/                   |               |
|    approx_kl             | 0.00023265523 |
|    clip_fraction         | 0.0394        |
|    clip_range            | 0.2           |
|    cost_returns          | 5.69          |
|    cost_value_loss       | 15.4          |
|    cost_values           | 3             |
|    entropy               | -0.434        |
|    entropy_loss          | -0.432        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00386       |
|    learning_rate         | 0.0003        |
|    loss                  | 5.39          |
|    n_updates             | 13600         |
|    policy_gradient_loss  | -0.000259     |
|    std                   | 0.303         |
|    value_loss            | 3.53          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.29377633  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1336         |
|    total_timesteps       | 2789376      |
| train/                   |              |
|    approx_kl             | 0.0026144672 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.84         |
|    cost_value_loss       | 25.9         |
|    cost_values           | 3            |
|    entropy               | -0.436       |
|    entropy_loss          | -0.435       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00204      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 13610        |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.303        |
|    value_loss            | 2.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.122       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.122       |
| reward                   | -0.51229036 |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1371        |
|    total_timesteps       | 2791424     |
| train/                   |             |
|    approx_kl             | 0.003958937 |
|    clip_fraction         | 0.0375      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.71        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 3           |
|    entropy               | -0.432      |
|    entropy_loss          | -0.435      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00729     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.6         |
|    n_updates             | 13620       |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.302       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38843423 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -458        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1405        |
|    total_timesteps       | 2793472     |
| train/                   |             |
|    approx_kl             | 0.004338864 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.2         |
|    cost_value_loss       | 19.6        |
|    cost_values           | 3           |
|    entropy               | -0.427      |
|    entropy_loss          | -0.429      |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0.00787     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 13630       |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.302       |
|    value_loss            | 6.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3918932   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1439         |
|    total_timesteps       | 2795520      |
| train/                   |              |
|    approx_kl             | 0.0031795027 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.96         |
|    cost_value_loss       | 22.4         |
|    cost_values           | 3            |
|    entropy               | -0.425       |
|    entropy_loss          | -0.426       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0136       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.4          |
|    n_updates             | 13640        |
|    policy_gradient_loss  | -0.000263    |
|    std                   | 0.302        |
|    value_loss            | 14.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32266068 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1474        |
|    total_timesteps       | 2797568     |
| train/                   |             |
|    approx_kl             | 0.000500337 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.83        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 3           |
|    entropy               | -0.428      |
|    entropy_loss          | -0.426      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00491     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.06        |
|    n_updates             | 13650       |
|    policy_gradient_loss  | -0.000426   |
|    std                   | 0.302       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3709655   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1508         |
|    total_timesteps       | 2799616      |
| train/                   |              |
|    approx_kl             | 0.0038605197 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.69         |
|    cost_value_loss       | 5.14         |
|    cost_values           | 3            |
|    entropy               | -0.421       |
|    entropy_loss          | -0.426       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.5          |
|    n_updates             | 13660        |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.301        |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.62882215 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1542        |
|    total_timesteps       | 2801664     |
| train/                   |             |
|    approx_kl             | 0.003138816 |
|    clip_fraction         | 0.00601     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 9.56        |
|    cost_values           | 3           |
|    entropy               | -0.418      |
|    entropy_loss          | -0.418      |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0.00281     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.19        |
|    n_updates             | 13670       |
|    policy_gradient_loss  | -0.000218   |
|    std                   | 0.3         |
|    value_loss            | 7.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57207865  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1576         |
|    total_timesteps       | 2803712      |
| train/                   |              |
|    approx_kl             | 0.0014190006 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.83         |
|    cost_value_loss       | 25.2         |
|    cost_values           | 3            |
|    entropy               | -0.419       |
|    entropy_loss          | -0.418       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0135       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.33         |
|    n_updates             | 13680        |
|    policy_gradient_loss  | -3.95e-05    |
|    std                   | 0.3          |
|    value_loss            | 1.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.28441823  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1611         |
|    total_timesteps       | 2805760      |
| train/                   |              |
|    approx_kl             | 0.0019304589 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.74         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 2.99         |
|    entropy               | -0.417       |
|    entropy_loss          | -0.418       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00737      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.51         |
|    n_updates             | 13690        |
|    policy_gradient_loss  | -0.000833    |
|    std                   | 0.3          |
|    value_loss            | 2.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.5894497  |
| rollout/                 |             |
|    ep_len_mean           | 932         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1645        |
|    total_timesteps       | 2807808     |
| train/                   |             |
|    approx_kl             | 0.005681731 |
|    clip_fraction         | 0.0424      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.99        |
|    entropy               | -0.414      |
|    entropy_loss          | -0.416      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.65        |
|    n_updates             | 13700       |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.3         |
|    value_loss            | 7.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67790186  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1680         |
|    total_timesteps       | 2809856      |
| train/                   |              |
|    approx_kl             | 0.0004582758 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.06         |
|    cost_value_loss       | 20.5         |
|    cost_values           | 3            |
|    entropy               | -0.414       |
|    entropy_loss          | -0.413       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00846      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.08         |
|    n_updates             | 13710        |
|    policy_gradient_loss  | -0.000485    |
|    std                   | 0.3          |
|    value_loss            | 13.7         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.6712676 |
| rollout/           |            |
|    ep_len_mean     | 910        |
|    ep_rew_mean     | -445       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2811904    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5588337   |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2813952      |
| train/                   |              |
|    approx_kl             | 0.0019028771 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.13         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 3            |
|    entropy               | -0.397       |
|    entropy_loss          | -0.399       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27           |
|    n_updates             | 13730        |
|    policy_gradient_loss  | -0.00036     |
|    std                   | 0.297        |
|    value_loss            | 28.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.44776186  |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 2816000      |
| train/                   |              |
|    approx_kl             | 0.0019012529 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 3.73         |
|    cost_values           | 3            |
|    entropy               | -0.402       |
|    entropy_loss          | -0.399       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0115       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 13740        |
|    policy_gradient_loss  | -0.000252    |
|    std                   | 0.298        |
|    value_loss            | 23.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3943947  |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 127         |
|    total_timesteps       | 2818048     |
| train/                   |             |
|    approx_kl             | 0.005202029 |
|    clip_fraction         | 0.037       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.27        |
|    cost_value_loss       | 28.2        |
|    cost_values           | 3           |
|    entropy               | -0.401      |
|    entropy_loss          | -0.402      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0186      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 13750       |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.298       |
|    value_loss            | 3.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.18444668  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 2820096      |
| train/                   |              |
|    approx_kl             | 0.0034948313 |
|    clip_fraction         | 0.00937      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.38         |
|    cost_value_loss       | 21.6         |
|    cost_values           | 2.99         |
|    entropy               | -0.4         |
|    entropy_loss          | -0.4         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00451      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 13760        |
|    policy_gradient_loss  | 2.83e-05     |
|    std                   | 0.298        |
|    value_loss            | 2.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.61553425 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 195         |
|    total_timesteps       | 2822144     |
| train/                   |             |
|    approx_kl             | 0.005830437 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.93        |
|    cost_value_loss       | 24.7        |
|    cost_values           | 2.99        |
|    entropy               | -0.398      |
|    entropy_loss          | -0.399      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00666     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.02        |
|    n_updates             | 13770       |
|    policy_gradient_loss  | -0.00144    |
|    std                   | 0.297       |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.76         |
| reward                   | -0.6255317   |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 2824192      |
| train/                   |              |
|    approx_kl             | 0.0049349363 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.78         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 3            |
|    entropy               | -0.397       |
|    entropy_loss          | -0.397       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.4          |
|    n_updates             | 13780        |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.297        |
|    value_loss            | 3.1          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.57        |
| reward                   | -0.4126569  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 264         |
|    total_timesteps       | 2826240     |
| train/                   |             |
|    approx_kl             | 0.011780692 |
|    clip_fraction         | 0.0924      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.03        |
|    cost_value_loss       | 26          |
|    cost_values           | 2.99        |
|    entropy               | -0.396      |
|    entropy_loss          | -0.397      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.4        |
|    n_updates             | 13790       |
|    policy_gradient_loss  | -0.000119   |
|    std                   | 0.297       |
|    value_loss            | 5.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.5959579   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 298          |
|    total_timesteps       | 2828288      |
| train/                   |              |
|    approx_kl             | 0.0041894247 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.54         |
|    cost_value_loss       | 22.4         |
|    cost_values           | 3            |
|    entropy               | -0.396       |
|    entropy_loss          | -0.396       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.013        |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 13800        |
|    policy_gradient_loss  | -0.00049     |
|    std                   | 0.297        |
|    value_loss            | 7.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.541186    |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 333          |
|    total_timesteps       | 2830336      |
| train/                   |              |
|    approx_kl             | 0.0027382711 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.17         |
|    cost_value_loss       | 21.1         |
|    cost_values           | 3            |
|    entropy               | -0.394       |
|    entropy_loss          | -0.395       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 13810        |
|    policy_gradient_loss  | -0.000174    |
|    std                   | 0.297        |
|    value_loss            | 0.967        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.47286645  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 367          |
|    total_timesteps       | 2832384      |
| train/                   |              |
|    approx_kl             | 0.0046496294 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 2.99         |
|    entropy               | -0.39        |
|    entropy_loss          | -0.393       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00674      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 13820        |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.296        |
|    value_loss            | 5.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7465339  |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 12          |
|    time_elapsed          | 401         |
|    total_timesteps       | 2834432     |
| train/                   |             |
|    approx_kl             | 0.005354218 |
|    clip_fraction         | 0.0169      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.82        |
|    cost_value_loss       | 18.8        |
|    cost_values           | 2.91        |
|    entropy               | -0.386      |
|    entropy_loss          | -0.388      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.6        |
|    n_updates             | 13830       |
|    policy_gradient_loss  | -0.000843   |
|    std                   | 0.295       |
|    value_loss            | 14.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.64062464 |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 435         |
|    total_timesteps       | 2836480     |
| train/                   |             |
|    approx_kl             | 0.00270965  |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.99        |
|    entropy               | -0.381      |
|    entropy_loss          | -0.384      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.69        |
|    n_updates             | 13840       |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.295       |
|    value_loss            | 4.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -0.46900257  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 470          |
|    total_timesteps       | 2838528      |
| train/                   |              |
|    approx_kl             | 0.0016357409 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.44         |
|    cost_value_loss       | 21.7         |
|    cost_values           | 3            |
|    entropy               | -0.383       |
|    entropy_loss          | -0.382       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0181       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.86         |
|    n_updates             | 13850        |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.295        |
|    value_loss            | 4.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32007903 |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 504         |
|    total_timesteps       | 2840576     |
| train/                   |             |
|    approx_kl             | 0.000970944 |
|    clip_fraction         | 0.035       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.66        |
|    cost_value_loss       | 17.8        |
|    cost_values           | 3           |
|    entropy               | -0.387      |
|    entropy_loss          | -0.385      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.69        |
|    n_updates             | 13860       |
|    policy_gradient_loss  | -0.000612   |
|    std                   | 0.296       |
|    value_loss            | 1.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3725985   |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 539          |
|    total_timesteps       | 2842624      |
| train/                   |              |
|    approx_kl             | 0.0077457917 |
|    clip_fraction         | 0.06         |
|    clip_range            | 0.2          |
|    cost_returns          | 7.46         |
|    cost_value_loss       | 28.2         |
|    cost_values           | 3            |
|    entropy               | -0.389       |
|    entropy_loss          | -0.388       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0022       |
|    learning_rate         | 0.0003       |
|    loss                  | 15.4         |
|    n_updates             | 13870        |
|    policy_gradient_loss  | -0.000228    |
|    std                   | 0.296        |
|    value_loss            | 14.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5051974   |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 573          |
|    total_timesteps       | 2844672      |
| train/                   |              |
|    approx_kl             | 0.0070311814 |
|    clip_fraction         | 0.0537       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.04         |
|    cost_value_loss       | 25.5         |
|    cost_values           | 3            |
|    entropy               | -0.39        |
|    entropy_loss          | -0.389       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00849      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 13880        |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.296        |
|    value_loss            | 14.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.576704   |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 607         |
|    total_timesteps       | 2846720     |
| train/                   |             |
|    approx_kl             | 0.003215144 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.84        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.92        |
|    entropy               | -0.39       |
|    entropy_loss          | -0.389      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 13890       |
|    policy_gradient_loss  | -0.000919   |
|    std                   | 0.296       |
|    value_loss            | 14.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6328269   |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 642          |
|    total_timesteps       | 2848768      |
| train/                   |              |
|    approx_kl             | 0.0028200592 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.37         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 3            |
|    entropy               | -0.39        |
|    entropy_loss          | -0.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00594      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.94         |
|    n_updates             | 13900        |
|    policy_gradient_loss  | -0.000981    |
|    std                   | 0.296        |
|    value_loss            | 6.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40432826  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 677          |
|    total_timesteps       | 2850816      |
| train/                   |              |
|    approx_kl             | 0.0076071145 |
|    clip_fraction         | 0.0523       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.06         |
|    cost_value_loss       | 29.6         |
|    cost_values           | 3            |
|    entropy               | -0.391       |
|    entropy_loss          | -0.391       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0208       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.13         |
|    n_updates             | 13910        |
|    policy_gradient_loss  | -0.0007      |
|    std                   | 0.296        |
|    value_loss            | 4.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4797854   |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 711          |
|    total_timesteps       | 2852864      |
| train/                   |              |
|    approx_kl             | 0.0035595484 |
|    clip_fraction         | 0.0675       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.85         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 3            |
|    entropy               | -0.388       |
|    entropy_loss          | -0.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0064       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.13         |
|    n_updates             | 13920        |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.296        |
|    value_loss            | 14.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41137436  |
| rollout/                 |              |
|    ep_len_mean           | 886          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 745          |
|    total_timesteps       | 2854912      |
| train/                   |              |
|    approx_kl             | 0.0024839342 |
|    clip_fraction         | 0.0439       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.49         |
|    cost_value_loss       | 8.72         |
|    cost_values           | 2.97         |
|    entropy               | -0.384       |
|    entropy_loss          | -0.385       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 13930        |
|    policy_gradient_loss  | -9.48e-05    |
|    std                   | 0.295        |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.33674014  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 780          |
|    total_timesteps       | 2856960      |
| train/                   |              |
|    approx_kl             | 0.0027487455 |
|    clip_fraction         | 0.0689       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.02         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 3            |
|    entropy               | -0.383       |
|    entropy_loss          | -0.383       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00549      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.79         |
|    n_updates             | 13940        |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.295        |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7408292   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 815          |
|    total_timesteps       | 2859008      |
| train/                   |              |
|    approx_kl             | 0.0009760505 |
|    clip_fraction         | 0.0849       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.4          |
|    cost_value_loss       | 22.1         |
|    cost_values           | 3            |
|    entropy               | -0.38        |
|    entropy_loss          | -0.382       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 13950        |
|    policy_gradient_loss  | 0.000491     |
|    std                   | 0.295        |
|    value_loss            | 5.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.56913674  |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 849          |
|    total_timesteps       | 2861056      |
| train/                   |              |
|    approx_kl             | 0.0032204166 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 2.99         |
|    entropy               | -0.371       |
|    entropy_loss          | -0.376       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00185      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 13960        |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.293        |
|    value_loss            | 3.65         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.53215337 |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 883         |
|    total_timesteps       | 2863104     |
| train/                   |             |
|    approx_kl             | 0.006342349 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 11          |
|    cost_values           | 3           |
|    entropy               | -0.364      |
|    entropy_loss          | -0.367      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0113      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.86        |
|    n_updates             | 13970       |
|    policy_gradient_loss  | -0.000153   |
|    std                   | 0.292       |
|    value_loss            | 19.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.67818785  |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 918          |
|    total_timesteps       | 2865152      |
| train/                   |              |
|    approx_kl             | 0.0019897479 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.18         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 3            |
|    entropy               | -0.361       |
|    entropy_loss          | -0.362       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00571      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 13980        |
|    policy_gradient_loss  | -0.000251    |
|    std                   | 0.292        |
|    value_loss            | 2.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.70770454  |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 952          |
|    total_timesteps       | 2867200      |
| train/                   |              |
|    approx_kl             | 0.0075463336 |
|    clip_fraction         | 0.0484       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.49         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 3            |
|    entropy               | -0.358       |
|    entropy_loss          | -0.36        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.015        |
|    learning_rate         | 0.0003       |
|    loss                  | 3.9          |
|    n_updates             | 13990        |
|    policy_gradient_loss  | -0.000429    |
|    std                   | 0.291        |
|    value_loss            | 1.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.49920076 |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 987         |
|    total_timesteps       | 2869248     |
| train/                   |             |
|    approx_kl             | 0.004428483 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.25        |
|    cost_value_loss       | 6.47        |
|    cost_values           | 3           |
|    entropy               | -0.361      |
|    entropy_loss          | -0.359      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00853     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.65        |
|    n_updates             | 14000       |
|    policy_gradient_loss  | -0.00092    |
|    std                   | 0.292       |
|    value_loss            | 6.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4213694  |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 2871296     |
| train/                   |             |
|    approx_kl             | 0.006013875 |
|    clip_fraction         | 0.0286      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.49        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 3           |
|    entropy               | -0.363      |
|    entropy_loss          | -0.362      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0139      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 14010       |
|    policy_gradient_loss  | -0.000925   |
|    std                   | 0.293       |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.40883553  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1056         |
|    total_timesteps       | 2873344      |
| train/                   |              |
|    approx_kl             | 0.0041621868 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.36         |
|    cost_value_loss       | 6.39         |
|    cost_values           | 3            |
|    entropy               | -0.364       |
|    entropy_loss          | -0.365       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.51         |
|    n_updates             | 14020        |
|    policy_gradient_loss  | 0.000355     |
|    std                   | 0.292        |
|    value_loss            | 6.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52570754  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1091         |
|    total_timesteps       | 2875392      |
| train/                   |              |
|    approx_kl             | 0.0034692883 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.07         |
|    cost_value_loss       | 7.94         |
|    cost_values           | 3            |
|    entropy               | -0.366       |
|    entropy_loss          | -0.364       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00286      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.75         |
|    n_updates             | 14030        |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.293        |
|    value_loss            | 7.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44804555  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1125         |
|    total_timesteps       | 2877440      |
| train/                   |              |
|    approx_kl             | 0.0040595746 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.66         |
|    cost_value_loss       | 23.2         |
|    cost_values           | 3            |
|    entropy               | -0.368       |
|    entropy_loss          | -0.368       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0195       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 14040        |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.293        |
|    value_loss            | 2.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.38443854  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1159         |
|    total_timesteps       | 2879488      |
| train/                   |              |
|    approx_kl             | 0.0032030153 |
|    clip_fraction         | 0.00571      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.45         |
|    cost_value_loss       | 10           |
|    cost_values           | 3            |
|    entropy               | -0.366       |
|    entropy_loss          | -0.367       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00847      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.7          |
|    n_updates             | 14050        |
|    policy_gradient_loss  | -0.000611    |
|    std                   | 0.293        |
|    value_loss            | 7.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47446162  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1194         |
|    total_timesteps       | 2881536      |
| train/                   |              |
|    approx_kl             | 0.0061682165 |
|    clip_fraction         | 0.0141       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 4.29         |
|    cost_values           | 2.98         |
|    entropy               | -0.364       |
|    entropy_loss          | -0.366       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.8          |
|    n_updates             | 14060        |
|    policy_gradient_loss  | -0.000332    |
|    std                   | 0.293        |
|    value_loss            | 3.2          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5957341    |
| rollout/                 |               |
|    ep_len_mean           | 903           |
|    ep_rew_mean           | -460          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 36            |
|    time_elapsed          | 1228          |
|    total_timesteps       | 2883584       |
| train/                   |               |
|    approx_kl             | 2.5525049e-05 |
|    clip_fraction         | 0.0231        |
|    clip_range            | 0.2           |
|    cost_returns          | 6.01          |
|    cost_value_loss       | 18.3          |
|    cost_values           | 3             |
|    entropy               | -0.359        |
|    entropy_loss          | -0.361        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.6          |
|    n_updates             | 14070         |
|    policy_gradient_loss  | -0.001        |
|    std                   | 0.292         |
|    value_loss            | 5             |
--------------------------------------------
--------------------------------------------
| avg_speed                | 1.34          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.34          |
| reward                   | -0.3172994    |
| rollout/                 |               |
|    ep_len_mean           | 899           |
|    ep_rew_mean           | -460          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 37            |
|    time_elapsed          | 1262          |
|    total_timesteps       | 2885632       |
| train/                   |               |
|    approx_kl             | 0.00090412307 |
|    clip_fraction         | 0.0125        |
|    clip_range            | 0.2           |
|    cost_returns          | 5.63          |
|    cost_value_loss       | 17.6          |
|    cost_values           | 3             |
|    entropy               | -0.355        |
|    entropy_loss          | -0.357        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.0113        |
|    learning_rate         | 0.0003        |
|    loss                  | 3.96          |
|    n_updates             | 14080         |
|    policy_gradient_loss  | -0.000815     |
|    std                   | 0.291         |
|    value_loss            | 2.65          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55355376 |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -457        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 38          |
|    time_elapsed          | 1296        |
|    total_timesteps       | 2887680     |
| train/                   |             |
|    approx_kl             | 0.002925656 |
|    clip_fraction         | 0.0798      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.51        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 3           |
|    entropy               | -0.35       |
|    entropy_loss          | -0.352      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00524     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.91        |
|    n_updates             | 14090       |
|    policy_gradient_loss  | 0.00124     |
|    std                   | 0.291       |
|    value_loss            | 15.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3451408  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 39          |
|    time_elapsed          | 1330        |
|    total_timesteps       | 2889728     |
| train/                   |             |
|    approx_kl             | 0.009071325 |
|    clip_fraction         | 0.0698      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.43        |
|    cost_value_loss       | 22.1        |
|    cost_values           | 3           |
|    entropy               | -0.349      |
|    entropy_loss          | -0.349      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00936     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.5         |
|    n_updates             | 14100       |
|    policy_gradient_loss  | -0.000181   |
|    std                   | 0.29        |
|    value_loss            | 26.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7381528   |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1365         |
|    total_timesteps       | 2891776      |
| train/                   |              |
|    approx_kl             | 0.0030475138 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 3            |
|    entropy               | -0.347       |
|    entropy_loss          | -0.348       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0163       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 14110        |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.29         |
|    value_loss            | 24           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.02         |
| reward                   | -0.35815185  |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1400         |
|    total_timesteps       | 2893824      |
| train/                   |              |
|    approx_kl             | 5.567039e-05 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.07         |
|    cost_value_loss       | 7.67         |
|    cost_values           | 2.99         |
|    entropy               | -0.341       |
|    entropy_loss          | -0.345       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00894      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.09         |
|    n_updates             | 14120        |
|    policy_gradient_loss  | -0.000657    |
|    std                   | 0.289        |
|    value_loss            | 18.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5702146   |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1435         |
|    total_timesteps       | 2895872      |
| train/                   |              |
|    approx_kl             | 0.0063988687 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.15         |
|    cost_value_loss       | 14           |
|    cost_values           | 3            |
|    entropy               | -0.327       |
|    entropy_loss          | -0.335       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0135       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.7          |
|    n_updates             | 14130        |
|    policy_gradient_loss  | -0.000519    |
|    std                   | 0.287        |
|    value_loss            | 3.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.34765562  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1470         |
|    total_timesteps       | 2897920      |
| train/                   |              |
|    approx_kl             | 0.0006061151 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 3            |
|    entropy               | -0.321       |
|    entropy_loss          | -0.323       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.52         |
|    n_updates             | 14140        |
|    policy_gradient_loss  | 0.000929     |
|    std                   | 0.287        |
|    value_loss            | 5.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6465275   |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1504         |
|    total_timesteps       | 2899968      |
| train/                   |              |
|    approx_kl             | 5.825475e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.33         |
|    cost_value_loss       | 3.32         |
|    cost_values           | 3            |
|    entropy               | -0.319       |
|    entropy_loss          | -0.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0061       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.17         |
|    n_updates             | 14150        |
|    policy_gradient_loss  | 0.00037      |
|    std                   | 0.286        |
|    value_loss            | 19.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.52341354   |
| rollout/                 |               |
|    ep_len_mean           | 903           |
|    ep_rew_mean           | -475          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 45            |
|    time_elapsed          | 1539          |
|    total_timesteps       | 2902016       |
| train/                   |               |
|    approx_kl             | 8.7564316e-05 |
|    clip_fraction         | 0.0331        |
|    clip_range            | 0.2           |
|    cost_returns          | 5.87          |
|    cost_value_loss       | 15.7          |
|    cost_values           | 3             |
|    entropy               | -0.317        |
|    entropy_loss          | -0.318        |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.9          |
|    n_updates             | 14160         |
|    policy_gradient_loss  | -0.00151      |
|    std                   | 0.286         |
|    value_loss            | 6.83          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.58958864 |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1574        |
|    total_timesteps       | 2904064     |
| train/                   |             |
|    approx_kl             | 0.009044893 |
|    clip_fraction         | 0.0707      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.52        |
|    cost_value_loss       | 15          |
|    cost_values           | 3           |
|    entropy               | -0.313      |
|    entropy_loss          | -0.315      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.0066      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 14170       |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 0.285       |
|    value_loss            | 6.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.35         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.35         |
| reward                   | -0.5667375   |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1609         |
|    total_timesteps       | 2906112      |
| train/                   |              |
|    approx_kl             | 0.0025468485 |
|    clip_fraction         | 0.0658       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.1          |
|    cost_value_loss       | 6.84         |
|    cost_values           | 3            |
|    entropy               | -0.312       |
|    entropy_loss          | -0.313       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00166      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.79         |
|    n_updates             | 14180        |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.285        |
|    value_loss            | 16.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.31625062  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1643         |
|    total_timesteps       | 2908160      |
| train/                   |              |
|    approx_kl             | 0.0057031848 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.02         |
|    cost_value_loss       | 13.8         |
|    cost_values           | 3            |
|    entropy               | -0.307       |
|    entropy_loss          | -0.308       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 14190        |
|    policy_gradient_loss  | -0.000404    |
|    std                   | 0.285        |
|    value_loss            | 24           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5386559  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1678        |
|    total_timesteps       | 2910208     |
| train/                   |             |
|    approx_kl             | 0.003455198 |
|    clip_fraction         | 0.00225     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.59        |
|    cost_value_loss       | 16.3        |
|    cost_values           | 3           |
|    entropy               | -0.31       |
|    entropy_loss          | -0.308      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00679     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.42        |
|    n_updates             | 14200       |
|    policy_gradient_loss  | 4.31e-06    |
|    std                   | 0.285       |
|    value_loss            | 4.14        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/x99x1ok7
------------------------------------
| avg_speed          | 7.17        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.17        |
| reward             | -0.40709534 |
| rollout/           |             |
|    ep_len_mean     | 890         |
|    ep_rew_mean     | -467        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2912256     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.33677676  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2914304      |
| train/                   |              |
|    approx_kl             | 0.0066833585 |
|    clip_fraction         | 0.0457       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.17         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 2.85         |
|    entropy               | -0.312       |
|    entropy_loss          | -0.312       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 14220        |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.285        |
|    value_loss            | 26.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.46098757  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 2916352      |
| train/                   |              |
|    approx_kl             | 0.0014765892 |
|    clip_fraction         | 0.0439       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.87         |
|    cost_value_loss       | 9.91         |
|    cost_values           | 2.92         |
|    entropy               | -0.309       |
|    entropy_loss          | -0.311       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00549      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.75         |
|    n_updates             | 14230        |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.285        |
|    value_loss            | 2.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7005     |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 127         |
|    total_timesteps       | 2918400     |
| train/                   |             |
|    approx_kl             | 0.006601167 |
|    clip_fraction         | 0.0336      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 3           |
|    entropy               | -0.304      |
|    entropy_loss          | -0.306      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.32        |
|    n_updates             | 14240       |
|    policy_gradient_loss  | -0.000623   |
|    std                   | 0.284       |
|    value_loss            | 5.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.37192196  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 2920448      |
| train/                   |              |
|    approx_kl             | 0.0019694339 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.16         |
|    cost_value_loss       | 7.68         |
|    cost_values           | 2.99         |
|    entropy               | -0.302       |
|    entropy_loss          | -0.303       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00545      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.71         |
|    n_updates             | 14250        |
|    policy_gradient_loss  | -0.000812    |
|    std                   | 0.284        |
|    value_loss            | 3.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.38639605  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 195          |
|    total_timesteps       | 2922496      |
| train/                   |              |
|    approx_kl             | 0.0077035255 |
|    clip_fraction         | 0.0493       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.32         |
|    cost_value_loss       | 9.15         |
|    cost_values           | 3            |
|    entropy               | -0.303       |
|    entropy_loss          | -0.302       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.27         |
|    n_updates             | 14260        |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.284        |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.37443867 |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 229         |
|    total_timesteps       | 2924544     |
| train/                   |             |
|    approx_kl             | 0.005580034 |
|    clip_fraction         | 0.0613      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.84        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 2.99        |
|    entropy               | -0.301      |
|    entropy_loss          | -0.303      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.54        |
|    n_updates             | 14270       |
|    policy_gradient_loss  | -0.002      |
|    std                   | 0.284       |
|    value_loss            | 7.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.37566787  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 263          |
|    total_timesteps       | 2926592      |
| train/                   |              |
|    approx_kl             | 0.0037151205 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.17         |
|    cost_value_loss       | 8.95         |
|    cost_values           | 2.98         |
|    entropy               | -0.3         |
|    entropy_loss          | -0.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00409      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.71         |
|    n_updates             | 14280        |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.284        |
|    value_loss            | 2.95         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.61816907 |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 298         |
|    total_timesteps       | 2928640     |
| train/                   |             |
|    approx_kl             | 0.011088368 |
|    clip_fraction         | 0.0633      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.57        |
|    cost_value_loss       | 20.8        |
|    cost_values           | 3           |
|    entropy               | -0.294      |
|    entropy_loss          | -0.297      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 14290       |
|    policy_gradient_loss  | -0.00075    |
|    std                   | 0.283       |
|    value_loss            | 4.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.19155109  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 332          |
|    total_timesteps       | 2930688      |
| train/                   |              |
|    approx_kl             | 0.0026076147 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 10.8         |
|    cost_values           | 3            |
|    entropy               | -0.295       |
|    entropy_loss          | -0.295       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.06         |
|    n_updates             | 14300        |
|    policy_gradient_loss  | -0.000756    |
|    std                   | 0.283        |
|    value_loss            | 3.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.7          |
| reward                   | -0.47461167  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 366          |
|    total_timesteps       | 2932736      |
| train/                   |              |
|    approx_kl             | 0.0044178944 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 9.45         |
|    cost_values           | 2.99         |
|    entropy               | -0.29        |
|    entropy_loss          | -0.293       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00277      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 14310        |
|    policy_gradient_loss  | -0.000224    |
|    std                   | 0.282        |
|    value_loss            | 28.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.49820307  |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 401          |
|    total_timesteps       | 2934784      |
| train/                   |              |
|    approx_kl             | 0.0069866152 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.87         |
|    cost_value_loss       | 25.3         |
|    cost_values           | 3            |
|    entropy               | -0.288       |
|    entropy_loss          | -0.288       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0279       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.69         |
|    n_updates             | 14320        |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.282        |
|    value_loss            | 3.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47046077  |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 436          |
|    total_timesteps       | 2936832      |
| train/                   |              |
|    approx_kl             | 0.0016533474 |
|    clip_fraction         | 0.0578       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.95         |
|    cost_value_loss       | 18.2         |
|    cost_values           | 2.99         |
|    entropy               | -0.285       |
|    entropy_loss          | -0.287       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.7         |
|    n_updates             | 14330        |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 0.282        |
|    value_loss            | 15.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.53300387  |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 471          |
|    total_timesteps       | 2938880      |
| train/                   |              |
|    approx_kl             | 0.0026264372 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.3          |
|    cost_value_loss       | 12.6         |
|    cost_values           | 3            |
|    entropy               | -0.287       |
|    entropy_loss          | -0.286       |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0.00139      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.03         |
|    n_updates             | 14340        |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.282        |
|    value_loss            | 2.69         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.910811   |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 506         |
|    total_timesteps       | 2940928     |
| train/                   |             |
|    approx_kl             | 0.004122293 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 3           |
|    entropy               | -0.278      |
|    entropy_loss          | -0.283      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.3        |
|    n_updates             | 14350       |
|    policy_gradient_loss  | -0.000349   |
|    std                   | 0.281       |
|    value_loss            | 26.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6264395  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 541         |
|    total_timesteps       | 2942976     |
| train/                   |             |
|    approx_kl             | 0.005217622 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 15.5        |
|    cost_values           | 3           |
|    entropy               | -0.271      |
|    entropy_loss          | -0.274      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0081      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.91        |
|    n_updates             | 14360       |
|    policy_gradient_loss  | -0.00311    |
|    std                   | 0.28        |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.626236    |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 575          |
|    total_timesteps       | 2945024      |
| train/                   |              |
|    approx_kl             | 0.0049209767 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.18         |
|    cost_value_loss       | 7.76         |
|    cost_values           | 3            |
|    entropy               | -0.265       |
|    entropy_loss          | -0.268       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00163      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.38         |
|    n_updates             | 14370        |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.279        |
|    value_loss            | 23.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28666416 |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 609         |
|    total_timesteps       | 2947072     |
| train/                   |             |
|    approx_kl             | 0.005785522 |
|    clip_fraction         | 0.0352      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 3           |
|    entropy               | -0.26       |
|    entropy_loss          | -0.262      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.49        |
|    n_updates             | 14380       |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.278       |
|    value_loss            | 2.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7075009  |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 644         |
|    total_timesteps       | 2949120     |
| train/                   |             |
|    approx_kl             | 0.002840091 |
|    clip_fraction         | 0.0339      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 3           |
|    entropy               | -0.26       |
|    entropy_loss          | -0.26       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.34        |
|    n_updates             | 14390       |
|    policy_gradient_loss  | 0.000182    |
|    std                   | 0.278       |
|    value_loss            | 2.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.38622117 |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 679         |
|    total_timesteps       | 2951168     |
| train/                   |             |
|    approx_kl             | 0.007958653 |
|    clip_fraction         | 0.0382      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.17        |
|    cost_value_loss       | 21.3        |
|    cost_values           | 3           |
|    entropy               | -0.259      |
|    entropy_loss          | -0.26       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00906     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 14400       |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.278       |
|    value_loss            | 15.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4432734  |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 715         |
|    total_timesteps       | 2953216     |
| train/                   |             |
|    approx_kl             | 0.011611475 |
|    clip_fraction         | 0.0459      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.02        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 3           |
|    entropy               | -0.263      |
|    entropy_loss          | -0.26       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00595     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.46        |
|    n_updates             | 14410       |
|    policy_gradient_loss  | -0.000249   |
|    std                   | 0.278       |
|    value_loss            | 2.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.38284117  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 750          |
|    total_timesteps       | 2955264      |
| train/                   |              |
|    approx_kl             | 0.0026517613 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.9          |
|    cost_value_loss       | 17.7         |
|    cost_values           | 3            |
|    entropy               | -0.268       |
|    entropy_loss          | -0.265       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0124       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.29         |
|    n_updates             | 14420        |
|    policy_gradient_loss  | -3.07e-06    |
|    std                   | 0.279        |
|    value_loss            | 7.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.58421147 |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 785         |
|    total_timesteps       | 2957312     |
| train/                   |             |
|    approx_kl             | 0.00711181  |
|    clip_fraction         | 0.0465      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.77        |
|    cost_value_loss       | 24.2        |
|    cost_values           | 2.99        |
|    entropy               | -0.27       |
|    entropy_loss          | -0.27       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00454     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 14430       |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.279       |
|    value_loss            | 1.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.98        |
| reward                   | -0.29241842 |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 820         |
|    total_timesteps       | 2959360     |
| train/                   |             |
|    approx_kl             | 0.004259764 |
|    clip_fraction         | 0.0319      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 7.2         |
|    cost_values           | 2.99        |
|    entropy               | -0.266      |
|    entropy_loss          | -0.268      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00433     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.36        |
|    n_updates             | 14440       |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 0.278       |
|    value_loss            | 1.92        |
------------------------------------------
--------------------------------------------
| avg_speed                | 5.91          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.91          |
| reward                   | -0.49664706   |
| rollout/                 |               |
|    ep_len_mean           | 903           |
|    ep_rew_mean           | -471          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 25            |
|    time_elapsed          | 855           |
|    total_timesteps       | 2961408       |
| train/                   |               |
|    approx_kl             | 0.00049048604 |
|    clip_fraction         | 0.0111        |
|    clip_range            | 0.2           |
|    cost_returns          | 6.35          |
|    cost_value_loss       | 20.8          |
|    cost_values           | 2.99          |
|    entropy               | -0.266        |
|    entropy_loss          | -0.266        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.0138        |
|    learning_rate         | 0.0003        |
|    loss                  | 3.94          |
|    n_updates             | 14450         |
|    policy_gradient_loss  | -5.37e-05     |
|    std                   | 0.278         |
|    value_loss            | 1.94          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38394025 |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 890         |
|    total_timesteps       | 2963456     |
| train/                   |             |
|    approx_kl             | 0.011070624 |
|    clip_fraction         | 0.0702      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 14.9        |
|    cost_values           | 3           |
|    entropy               | -0.258      |
|    entropy_loss          | -0.262      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00115     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.37        |
|    n_updates             | 14460       |
|    policy_gradient_loss  | 0.00134     |
|    std                   | 0.277       |
|    value_loss            | 2.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5203604   |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 926          |
|    total_timesteps       | 2965504      |
| train/                   |              |
|    approx_kl             | 0.0057158647 |
|    clip_fraction         | 0.0708       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.02         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 3            |
|    entropy               | -0.254       |
|    entropy_loss          | -0.255       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00497      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.93         |
|    n_updates             | 14470        |
|    policy_gradient_loss  | -0.00437     |
|    std                   | 0.277        |
|    value_loss            | 3.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.38782197  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 960          |
|    total_timesteps       | 2967552      |
| train/                   |              |
|    approx_kl             | 0.0038442363 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.98         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 2.93         |
|    entropy               | -0.253       |
|    entropy_loss          | -0.253       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.9         |
|    n_updates             | 14480        |
|    policy_gradient_loss  | -0.00041     |
|    std                   | 0.277        |
|    value_loss            | 27.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.60916334  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 994          |
|    total_timesteps       | 2969600      |
| train/                   |              |
|    approx_kl             | 0.0014034768 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 6.74         |
|    cost_values           | 2.98         |
|    entropy               | -0.25        |
|    entropy_loss          | -0.252       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0064       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.57         |
|    n_updates             | 14490        |
|    policy_gradient_loss  | -9.54e-05    |
|    std                   | 0.276        |
|    value_loss            | 3.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.30743963  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 2971648      |
| train/                   |              |
|    approx_kl             | 0.0077198893 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.79         |
|    cost_value_loss       | 22.5         |
|    cost_values           | 3            |
|    entropy               | -0.252       |
|    entropy_loss          | -0.251       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00172      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 14500        |
|    policy_gradient_loss  | 0.000141     |
|    std                   | 0.276        |
|    value_loss            | 1.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.29000744  |
| rollout/                 |              |
|    ep_len_mean           | 890          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 2973696      |
| train/                   |              |
|    approx_kl             | 0.0024674067 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.83         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 3            |
|    entropy               | -0.248       |
|    entropy_loss          | -0.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.95         |
|    n_updates             | 14510        |
|    policy_gradient_loss  | -0.000443    |
|    std                   | 0.276        |
|    value_loss            | 5.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6492951  |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1097        |
|    total_timesteps       | 2975744     |
| train/                   |             |
|    approx_kl             | 0.008061478 |
|    clip_fraction         | 0.0332      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.36        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 3           |
|    entropy               | -0.248      |
|    entropy_loss          | -0.247      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00444     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.79        |
|    n_updates             | 14520       |
|    policy_gradient_loss  | 0.000312    |
|    std                   | 0.276       |
|    value_loss            | 3.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5343716  |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1132        |
|    total_timesteps       | 2977792     |
| train/                   |             |
|    approx_kl             | 0.004874965 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.17        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 3           |
|    entropy               | -0.249      |
|    entropy_loss          | -0.249      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0126      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 14530       |
|    policy_gradient_loss  | 0.00184     |
|    std                   | 0.276       |
|    value_loss            | 9.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.704292    |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1167         |
|    total_timesteps       | 2979840      |
| train/                   |              |
|    approx_kl             | 0.0019941186 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 3            |
|    entropy               | -0.238       |
|    entropy_loss          | -0.243       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.0105       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.84         |
|    n_updates             | 14540        |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.274        |
|    value_loss            | 1.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2732772  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1201        |
|    total_timesteps       | 2981888     |
| train/                   |             |
|    approx_kl             | 0.014304784 |
|    clip_fraction         | 0.0636      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 9.77        |
|    cost_values           | 3           |
|    entropy               | -0.234      |
|    entropy_loss          | -0.235      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00814     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.01        |
|    n_updates             | 14550       |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.274       |
|    value_loss            | 14.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.26606223  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1236         |
|    total_timesteps       | 2983936      |
| train/                   |              |
|    approx_kl             | 0.0065356833 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 14.3         |
|    cost_values           | 3            |
|    entropy               | -0.235       |
|    entropy_loss          | -0.234       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.0158       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 14560        |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.274        |
|    value_loss            | 8.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.32        |
| reward                   | -0.36977077 |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1271        |
|    total_timesteps       | 2985984     |
| train/                   |             |
|    approx_kl             | 0.005268501 |
|    clip_fraction         | 0.0593      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 15.1        |
|    cost_values           | 2.99        |
|    entropy               | -0.231      |
|    entropy_loss          | -0.234      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0.000136    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.54        |
|    n_updates             | 14570       |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 0.273       |
|    value_loss            | 5.29        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.4008634 |
| rollout/                 |            |
|    ep_len_mean           | 911        |
|    ep_rew_mean           | -461       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 38         |
|    time_elapsed          | 1305       |
|    total_timesteps       | 2988032    |
| train/                   |            |
|    approx_kl             | 0.00528019 |
|    clip_fraction         | 0.0227     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.9        |
|    cost_value_loss       | 16.9       |
|    cost_values           | 2.99       |
|    entropy               | -0.23      |
|    entropy_loss          | -0.23      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 15         |
|    n_updates             | 14580      |
|    policy_gradient_loss  | -0.000553  |
|    std                   | 0.273      |
|    value_loss            | 15.2       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3879764  |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -458        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1340        |
|    total_timesteps       | 2990080     |
| train/                   |             |
|    approx_kl             | 0.004253069 |
|    clip_fraction         | 0.00376     |
|    clip_range            | 0.2         |
|    cost_returns          | 7.1         |
|    cost_value_loss       | 27          |
|    cost_values           | 2.99        |
|    entropy               | -0.233      |
|    entropy_loss          | -0.231      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.016       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 14590       |
|    policy_gradient_loss  | -0.000545   |
|    std                   | 0.274       |
|    value_loss            | 2.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7689062  |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1375        |
|    total_timesteps       | 2992128     |
| train/                   |             |
|    approx_kl             | 0.004634843 |
|    clip_fraction         | 0.0105      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.55        |
|    cost_value_loss       | 3.29        |
|    cost_values           | 2.99        |
|    entropy               | -0.24       |
|    entropy_loss          | -0.236      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.71        |
|    n_updates             | 14600       |
|    policy_gradient_loss  | 0.000108    |
|    std                   | 0.275       |
|    value_loss            | 2.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.73         |
| reward                   | -0.58708304  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1409         |
|    total_timesteps       | 2994176      |
| train/                   |              |
|    approx_kl             | 0.0065120147 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.49         |
|    cost_value_loss       | 5.84         |
|    cost_values           | 3            |
|    entropy               | -0.239       |
|    entropy_loss          | -0.24        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 14610        |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.274        |
|    value_loss            | 20.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.78         |
| reward                   | -0.6295425   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1444         |
|    total_timesteps       | 2996224      |
| train/                   |              |
|    approx_kl             | 0.0035511479 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.39         |
|    cost_value_loss       | 8.16         |
|    cost_values           | 3            |
|    entropy               | -0.236       |
|    entropy_loss          | -0.238       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00475      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.61         |
|    n_updates             | 14620        |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.274        |
|    value_loss            | 3.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48460346 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1479        |
|    total_timesteps       | 2998272     |
| train/                   |             |
|    approx_kl             | 0.004649017 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 9.7         |
|    cost_values           | 3           |
|    entropy               | -0.238      |
|    entropy_loss          | -0.237      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00547     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 14630       |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.274       |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50981826  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1514         |
|    total_timesteps       | 3000320      |
| train/                   |              |
|    approx_kl             | 0.0025177535 |
|    clip_fraction         | 0.0594       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.71         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 3            |
|    entropy               | -0.235       |
|    entropy_loss          | -0.237       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 14640        |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.274        |
|    value_loss            | 26.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38555765 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1549        |
|    total_timesteps       | 3002368     |
| train/                   |             |
|    approx_kl             | 0.002938332 |
|    clip_fraction         | 0.0131      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.39        |
|    cost_value_loss       | 21.4        |
|    cost_values           | 3           |
|    entropy               | -0.229      |
|    entropy_loss          | -0.232      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0114      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 14650       |
|    policy_gradient_loss  | -0.000166   |
|    std                   | 0.273       |
|    value_loss            | 3.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.26385933  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1584         |
|    total_timesteps       | 3004416      |
| train/                   |              |
|    approx_kl             | 0.0028283312 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.89         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 3            |
|    entropy               | -0.228       |
|    entropy_loss          | -0.228       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00854      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.49         |
|    n_updates             | 14660        |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.273        |
|    value_loss            | 15.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.98          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.98          |
| reward                   | -0.32436875   |
| rollout/                 |               |
|    ep_len_mean           | 902           |
|    ep_rew_mean           | -453          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 47            |
|    time_elapsed          | 1619          |
|    total_timesteps       | 3006464       |
| train/                   |               |
|    approx_kl             | 0.00036800443 |
|    clip_fraction         | 0.0389        |
|    clip_range            | 0.2           |
|    cost_returns          | 6.56          |
|    cost_value_loss       | 25.3          |
|    cost_values           | 2.99          |
|    entropy               | -0.225        |
|    entropy_loss          | -0.226        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.016         |
|    learning_rate         | 0.0003        |
|    loss                  | 4.21          |
|    n_updates             | 14670         |
|    policy_gradient_loss  | -0.000991     |
|    std                   | 0.272         |
|    value_loss            | 2.99          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.35481828  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1653         |
|    total_timesteps       | 3008512      |
| train/                   |              |
|    approx_kl             | 0.0038143524 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.21         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 3            |
|    entropy               | -0.223       |
|    entropy_loss          | -0.224       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00957      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.97         |
|    n_updates             | 14680        |
|    policy_gradient_loss  | -0.000869    |
|    std                   | 0.272        |
|    value_loss            | 20.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72043276  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1688         |
|    total_timesteps       | 3010560      |
| train/                   |              |
|    approx_kl             | 0.0027573395 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.38         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 3            |
|    entropy               | -0.222       |
|    entropy_loss          | -0.222       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00652      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.32         |
|    n_updates             | 14690        |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.272        |
|    value_loss            | 16.6         |
-------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.5119724273681641
Final reward: -0.5124005675315857
Final reward: -0.5132960677146912
Final reward: -0.5148720145225525
Final reward: -0.5168333649635315
Final reward: -0.5195320248603821
Final reward: -0.5234718918800354
Final reward: -0.5281450748443604
Final reward: -0.5342278480529785
Final reward: -0.5414925813674927
Final reward: -0.5502868890762329
Final reward: -0.5605159997940063
Final reward: -0.5717124938964844
Final reward: -0.5835422873497009
Final reward: -0.5953472852706909
Final reward: -0.6059722304344177
Final reward: -0.6144793629646301
Final reward: -0.6196344494819641
Final reward: -0.6203970909118652
Final reward: -0.6264504194259644
Final reward: -0.6268336772918701
Final reward: -0.6199122667312622
Final reward: -0.6064891815185547
Final reward: -0.5876207947731018
Final reward: -0.565212070941925
Final reward: -0.5431951284408569
Final reward: -0.5245153903961182
Final reward: -0.5247202515602112
Final reward: -0.5390850901603699
Final reward: -0.5598541498184204
Final reward: -0.5846139788627625
Final reward: -0.6070708632469177
Final reward: -0.6228669285774231
Final reward: -0.6279280781745911
Final reward: -0.6356978416442871
Final reward: -0.6290279030799866
Final reward: -0.6072003841400146
Final reward: -0.5758657455444336
Final reward: -0.5410809516906738
Final reward: -0.524348795413971
Final reward: -0.5294736623764038
Final reward: -0.5560266971588135
Final reward: -0.5899322032928467
Final reward: -0.6166922450065613
Final reward: -0.626474916934967
Final reward: -0.6307219862937927
Final reward: -0.6144781112670898
Final reward: -0.5768155455589294
Final reward: -0.5346352458000183
Final reward: -0.5047888159751892
Final reward: -0.5279426574707031
Final reward: -0.5682536363601685
Final reward: -0.5989852547645569
Final reward: -0.6119405031204224
Final reward: -0.6058405041694641
Final reward: -0.5635857582092285
Final reward: -0.5119677782058716
Final reward: -0.4659448266029358
Final reward: -0.4958011209964752
Final reward: -0.5447818636894226
Final reward: -0.5728444457054138
Final reward: -0.5843883752822876
Final reward: -0.5511226058006287
Final reward: -0.49718865752220154
Final reward: -0.43582239747047424
Final reward: -0.46668824553489685
Final reward: -0.5213062167167664
Final reward: -0.5512683987617493
Final reward: -0.5625610947608948
Final reward: -0.517349123954773
Final reward: -0.44275030493736267
Final reward: -0.44671547412872314
Final reward: -0.5076517462730408
Final reward: -0.5480483770370483
Final reward: -0.5612516403198242
Final reward: -0.5270722508430481
Final reward: -0.44748616218566895
Final reward: -0.4515962302684784
Final reward: -0.5212529301643372
Final reward: -0.5624946355819702
Final reward: -0.5689429640769958
Final reward: -0.5010388493537903
Final reward: -0.45824652910232544
Final reward: -0.5119572281837463
Final reward: -0.57215815782547
Final reward: -0.5970325469970703
Final reward: -0.5535894632339478
Final reward: -0.4829850494861603
Final reward: -0.5325110554695129
Final reward: -0.5872716307640076
Final reward: -0.5992390513420105
Final reward: -0.5284193754196167
Final reward: -0.4746759533882141
Final reward: -0.5319898724555969
Final reward: -0.5769572854042053
Final reward: -0.5693978071212769
Final reward: -0.4928062856197357
Final reward: -0.46706950664520264
Final reward: -0.5363091826438904
Final reward: -0.5697603821754456
Final reward: -0.5541443824768066
Final reward: -0.46824169158935547
Final reward: -0.4534676671028137
Final reward: -0.5229910016059875
Final reward: -0.5631700158119202
Final reward: -0.5323518514633179
Final reward: -0.4444507956504822
Final reward: -0.492493212223053
Final reward: -0.5596981048583984
Final reward: -0.5858433842658997
Final reward: -0.5291191339492798
Final reward: -0.447701096534729
Final reward: -0.49806147813796997
Final reward: -0.55396568775177
Final reward: -0.5598212480545044
Final reward: -0.4773571789264679
Final reward: -0.4519384503364563
Final reward: -0.5240644812583923
Final reward: -0.5596948862075806
Final reward: -0.5158519148826599
Final reward: -0.43581342697143555
Final reward: -0.49168121814727783
Final reward: -0.5450440049171448
Final reward: -0.5471748113632202
Final reward: -0.4618242084980011
Final reward: -0.4301380217075348
Final reward: -0.5048579573631287
Final reward: -0.5425362586975098
Final reward: -0.5060321092605591
Final reward: -0.41443002223968506
Final reward: -0.4657350182533264
Final reward: -0.5333123207092285
Final reward: -0.5527523159980774
Final reward: -0.47922107577323914
Final reward: -0.4405193328857422
Final reward: -0.5188425183296204
Final reward: -0.5823308229446411
Final reward: -0.6049015522003174
Final reward: -0.5453037619590759
Final reward: -0.49894648790359497
Final reward: -0.561121940612793
Final reward: -0.6004471182823181
Final reward: -0.5761358737945557
Final reward: -0.4970102310180664
Final reward: -0.43549585342407227
Final reward: -0.48323047161102295
Final reward: -0.5430920720100403
Final reward: -0.5495417714118958
Final reward: -0.47817742824554443
Final reward: -0.43399691581726074
Final reward: -0.5063854455947876
Final reward: -0.5485039949417114
Final reward: -0.5566294193267822
Final reward: -0.4732901155948639
Final reward: -0.4620943069458008
Final reward: -0.5334687829017639
Final reward: -0.5628632307052612
Final reward: -0.518293559551239
Final reward: -0.4216112196445465
Final reward: -0.44100844860076904
Final reward: -0.5175594091415405
Final reward: -0.545876145362854
Final reward: -0.5383240580558777
Final reward: -0.44647306203842163
Final reward: -0.4615464210510254
Final reward: -0.5313387513160706
Final reward: -0.5539788007736206
Final reward: -0.4863920509815216
Final reward: -0.4105668365955353
Final reward: -0.4763006865978241
Final reward: -0.5321593880653381
Final reward: -0.5391917824745178
Final reward: -0.46733358502388
Final reward: -0.4170989990234375
Final reward: -0.4908488392829895
Final reward: -0.536140501499176
Final reward: -0.5448686480522156
Final reward: -0.46146324276924133
Final reward: -0.4274883568286896
Final reward: -0.5023914575576782
Final reward: -0.5413076877593994
Final reward: -0.5010043382644653
Final reward: -0.4011981189250946
Final reward: -0.4484829604625702
Final reward: -0.5247598886489868
Final reward: -0.5555194020271301
Final reward: -0.500485897064209
Final reward: -0.4123222827911377
Final reward: -0.4603707492351532
Final reward: -0.5237250328063965
Final reward: -0.5344038009643555
Final reward: -0.44882893562316895
Final reward: -0.4251764118671417
Final reward: -0.5013508200645447
Final reward: -0.5643472075462341
Final reward: -0.5822179317474365
Final reward: -0.5123884081840515
Final reward: -0.4775431156158447
Final reward: -0.5472246408462524
Final reward: -0.5873612761497498
Final reward: -0.5634538531303406
Final reward: -0.4851199686527252
Final reward: -0.45026493072509766
Final reward: -0.5046249032020569
Final reward: -0.5651823282241821
Final reward: -0.5830670595169067
Final reward: -0.5146844387054443
Final reward: -0.45158663392066956
Final reward: -0.5154159069061279
Final reward: -0.5604196786880493
Final reward: -0.5471010208129883
Final reward: -0.45689618587493896
Final reward: -0.48210379481315613
Final reward: -0.5476419925689697
Final reward: -0.5656976699829102
Final reward: -0.4934529960155487
Final reward: -0.45741182565689087
Final reward: -0.5275021195411682
Final reward: -0.5658174753189087
Final reward: -0.5304034948348999
Final reward: -0.44647955894470215
Final reward: -0.49918854236602783
Final reward: -0.5569644570350647
Final reward: -0.5655611157417297
Final reward: -0.4879079759120941
Final reward: -0.42111659049987793
Final reward: -0.48884016275405884
Final reward: -0.5360342860221863
Final reward: -0.5226808786392212
Final reward: -0.43178144097328186
Final reward: -0.42174866795539856
Final reward: -0.504921555519104
Final reward: -0.5461093783378601
Final reward: -0.512703001499176
Final reward: -0.4221722483634949
Final reward: -0.47557926177978516
Final reward: -0.5370984673500061
Final reward: -0.5449310541152954
Final reward: -0.4739452600479126
Final reward: -0.36967548727989197
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.41935470700263977
Final reward: -0.489013671875
Final reward: -0.5018202066421509
Final reward: -0.41071659326553345
Final reward: -0.3847275972366333
Final reward: -0.4672776758670807
Final reward: -0.5108945369720459
Final reward: -0.47376519441604614
Final reward: -0.3750710189342499
Final reward: -0.4346795976161957
Final reward: -0.4972608685493469
Final reward: -0.5031684041023254
Final reward: -0.40721607208251953
Final reward: -0.3969847857952118
Final reward: -0.4763871431350708
Final reward: -0.5179125666618347
Final reward: -0.4759242534637451
Final reward: -0.3682672381401062
Final reward: -0.3940432071685791
Final reward: -0.47282159328460693
Final reward: -0.4921727776527405
Final reward: -0.4281347990036011
Final reward: -0.3358445167541504
Final reward: -0.3896704316139221
Final reward: -0.4638617932796478
Final reward: -0.4774668514728546
Final reward: -0.38476675748825073
Final reward: -0.2781231999397278
Final reward: -0.36292704939842224
Final reward: -0.437654048204422
Final reward: -0.45213010907173157
Final reward: -0.34924814105033875
Final reward: -0.30974820256233215
Final reward: -0.4167787432670593
Final reward: -0.4965640604496002
Final reward: -0.5162466764450073
Final reward: -0.5168003439903259
Final reward: -0.42134925723075867
Final reward: -0.42901313304901123
Final reward: -0.5047863125801086
Final reward: -0.532167911529541
Final reward: -0.46626728773117065
Final reward: -0.38098686933517456
Final reward: -0.4487232267856598
Final reward: -0.5021965503692627
Final reward: -0.49957236647605896
Final reward: -0.39890962839126587
Final reward: -0.4152151048183441
Final reward: -0.49169889092445374
Final reward: -0.5118178129196167
Final reward: -0.4613361358642578
Final reward: -0.37435832619667053
Final reward: -0.4437524378299713
Final reward: -0.5138700008392334
Final reward: -0.5324720144271851
Final reward: -0.45463064312934875
Final reward: -0.41606372594833374
Final reward: -0.492214173078537
Final reward: -0.5308483839035034
Final reward: -0.5072650909423828
Final reward: -0.4101460576057434
Final reward: -0.4438198506832123
Final reward: -0.5237374901771545
Final reward: -0.5603575706481934
Final reward: -0.5190728902816772
Final reward: -0.4386189579963684
Final reward: -0.4955127239227295
Final reward: -0.5473546385765076
Final reward: -0.5481830835342407
Final reward: -0.46487754583358765
Final reward: -0.39836180210113525
Final reward: -0.46339789032936096
Final reward: -0.5264779925346375
Final reward: -0.5449569821357727
Final reward: -0.4692581295967102
Final reward: -0.4318161904811859
Final reward: -0.5055369734764099
Final reward: -0.5400004982948303
Final reward: -0.5375779867172241
Final reward: -0.44820651412010193
Final reward: -0.43498870730400085
Final reward: -0.5102956891059875
Final reward: -0.5428346395492554
Final reward: -0.4876352846622467
Final reward: -0.38778188824653625
Final reward: -0.4125942587852478
Final reward: -0.4911317229270935
Final reward: -0.5223548412322998
Final reward: -0.4595840275287628
Final reward: -0.3466572165489197
Final reward: -0.3749833106994629
Final reward: -0.4599960148334503
Final reward: -0.4969620704650879
Final reward: -0.43908950686454773
Final reward: -0.3541729748249054
Final reward: -0.4290608763694763
Final reward: -0.48332977294921875
Final reward: -0.4758108854293823
Final reward: -0.36815115809440613
Final reward: -0.3932580053806305
Final reward: -0.4722733497619629
Final reward: -0.49321821331977844
Final reward: -0.4223307967185974
Final reward: -0.3528417944908142
Final reward: -0.4356595277786255
Final reward: -0.4885376989841461
Final reward: -0.47475409507751465
Final reward: -0.3703555166721344
Final reward: -0.3652724325656891
Final reward: -0.4511392414569855
Final reward: -0.49331459403038025
Final reward: -0.4448482096195221
Final reward: -0.33306679129600525
Final reward: -0.32356318831443787
Final reward: -0.4190819561481476
Final reward: -0.45624876022338867
Final reward: -0.3859383463859558
Final reward: -0.29584118723869324
Final reward: -0.38584190607070923
Final reward: -0.443061500787735
Final reward: -0.4357391893863678
Final reward: -0.3147306442260742
Final reward: -0.3424778878688812
Final reward: -0.4401656985282898
Final reward: -0.48016074299812317
Final reward: -0.4235280454158783
Final reward: -0.3298218548297882
Final reward: -0.40756458044052124
Final reward: -0.46713343262672424
Final reward: -0.44901567697525024
Final reward: -0.4194510579109192
Final reward: -0.29280367493629456
Final reward: -0.35424742102622986
Final reward: -0.43722477555274963
Final reward: -0.45563605427742004
Final reward: -0.35695764422416687
Final reward: -0.3157987892627716
Final reward: -0.4107731580734253
Final reward: -0.45903733372688293
Final reward: -0.4126153588294983
Final reward: -0.29003360867500305
Final reward: -0.26535844802856445
Final reward: -0.349796324968338
Final reward: -0.40417277812957764
Final reward: -0.34941571950912476
Final reward: -0.21448585391044617
Final reward: -0.3086438775062561
Final reward: -0.365212082862854
Final reward: -0.3905821144580841
Final reward: -0.27410343289375305
Final reward: -0.29776206612586975
Final reward: -0.34447768330574036
Final reward: -0.4269133508205414
Final reward: -0.4355408549308777
Final reward: -0.3637789487838745
Final reward: -0.25436732172966003
Final reward: -0.34451451897621155
Final reward: -0.4206923842430115
Final reward: -0.4270448088645935
Final reward: -0.31161418557167053
Final reward: -0.28221049904823303
Final reward: -0.3949924111366272
Final reward: -0.44924575090408325
Final reward: -0.41811636090278625
Final reward: -0.2958739399909973
Final reward: -0.2767663896083832
Final reward: -0.3761674463748932
Final reward: -0.42160725593566895
Final reward: -0.35310453176498413
Final reward: -0.22417137026786804
Final reward: -0.3002290725708008
Final reward: -0.3719725012779236
Final reward: -0.4197702705860138
Final reward: -0.3542228639125824
Final reward: -0.24766100943088531
Final reward: -0.34045717120170593
Final reward: -0.34183353185653687
Final reward: -0.3768921494483948
Final reward: -0.2674473226070404
Final reward: -0.3224029242992401
Final reward: -0.30496418476104736
Final reward: -0.36588382720947266
Final reward: -0.35991623997688293
Final reward: -0.2260356992483139
Final reward: -0.3287055492401123
Final reward: -0.34001830220222473
Final reward: -0.3715875744819641
Final reward: -0.3129344880580902
Final reward: -0.27424073219299316
Final reward: -0.36786365509033203
Final reward: -0.3331027925014496
Final reward: -0.35097238421440125
Final reward: -0.3192751705646515
Final reward: -0.3008360266685486
Final reward: -0.3783949613571167
Final reward: -0.31556788086891174
Final reward: -0.3498181700706482
Final reward: -0.26816892623901367
Final reward: -0.3674394488334656
Final reward: -0.39593061804771423
Final reward: -0.301459938287735
Final reward: -0.3021889925003052
Final reward: -0.33096155524253845
Final reward: -0.40581434965133667
Final reward: -0.34411466121673584
Final reward: -0.33382704854011536
Final reward: -0.27362948656082153
Final reward: -0.37256908416748047
Final reward: -0.3904729187488556
Final reward: -0.3167206645011902
Final reward: -0.3218653202056885
Final reward: -0.33337414264678955
Final reward: -0.41908660531044006
Final reward: -0.4310627281665802
Final reward: -0.3024331033229828
Final reward: -0.28013354539871216
Final reward: -0.35977721214294434
Final reward: -0.4319155216217041
Final reward: -0.48385152220726013
Final reward: -0.41013580560684204
Final reward: -0.3232768476009369
Final reward: -0.35367506742477417
Final reward: -0.4303243160247803
Final reward: -0.46510130167007446
Final reward: -0.3608671724796295
Final reward: -0.32266750931739807
Final reward: -0.39529862999916077
Final reward: -0.4667071998119354
Final reward: -0.4153662323951721
Final reward: -0.3168242275714874
Final reward: -0.36328721046447754
Final reward: -0.4433717131614685
Final reward: -0.4532806873321533
Final reward: -0.3314604163169861
Final reward: -0.3339768052101135
Final reward: -0.4188382923603058
Final reward: -0.48583459854125977
Final reward: -0.43203774094581604
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.34309759736061096
Final reward: -0.3891911208629608
Final reward: -0.46375393867492676
Final reward: -0.48198288679122925
Final reward: -0.39043891429901123
Final reward: -0.31253015995025635
Final reward: -0.37587693333625793
Final reward: -0.4469676911830902
Final reward: -0.4855637550354004
Final reward: -0.3847719430923462
Final reward: -0.3535500168800354
Final reward: -0.4216786026954651
Final reward: -0.48812243342399597
Final reward: -0.4414099454879761
Final reward: -0.33927884697914124
Final reward: -0.36381128430366516
Final reward: -0.4367448091506958
Final reward: -0.4760759472846985
Final reward: -0.38480088114738464
Final reward: -0.331479549407959
Final reward: -0.403004914522171
Final reward: -0.47777649760246277
Final reward: -0.46115362644195557
Final reward: -0.3522818386554718
Final reward: -0.3735123872756958
Final reward: -0.44365906715393066
Final reward: -0.48610562086105347
Final reward: -0.3874971568584442
Final reward: -0.3493277132511139
Final reward: -0.412062406539917
Final reward: -0.48412564396858215
Final reward: -0.45267799496650696
Final reward: -0.3313245475292206
Final reward: -0.3229208290576935
Final reward: -0.40028151869773865
Final reward: -0.46304553747177124
Final reward: -0.40408143401145935
Final reward: -0.3094126582145691
Final reward: -0.3611401915550232
Final reward: -0.44240060448646545
Final reward: -0.445146769285202
Final reward: -0.31969889998435974
Final reward: -0.2990855872631073
Final reward: -0.3850879669189453
Final reward: -0.45856979489326477
Final reward: -0.4074842035770416
Final reward: -0.2947569787502289
Final reward: -0.3232489824295044
Final reward: -0.4186524748802185
Final reward: -0.48559269309043884
Final reward: -0.431991845369339
Final reward: -0.34270069003105164
Final reward: -0.39145559072494507
Final reward: -0.4643840491771698
Final reward: -0.4871337413787842
Final reward: -0.38090044260025024
Final reward: -0.3632553815841675
Final reward: -0.43648669123649597
Final reward: -0.5024873614311218
Final reward: -0.45789438486099243
Final reward: -0.35122689604759216
Final reward: -0.3772319257259369
Final reward: -0.45592713356018066
Final reward: -0.5144822001457214
Final reward: -0.4523255527019501
Final reward: -0.377900093793869
Final reward: -0.42159217596054077
Final reward: -0.49816372990608215
Final reward: -0.5535615682601929
Final reward: -0.5007051825523376
Final reward: -0.4222089946269989
Final reward: -0.453262597322464
Final reward: -0.5207591652870178
Final reward: -0.5692027807235718
Final reward: -0.5054070353507996
Final reward: -0.452267050743103
Final reward: -0.49819469451904297
Final reward: -0.5602314472198486
Final reward: -0.5427394509315491
Final reward: -0.4555796682834625
Final reward: -0.4748407304286957
Final reward: -0.5314989686012268
Final reward: -0.5707791447639465
Final reward: -0.5016958713531494
Final reward: -0.43089136481285095
Final reward: -0.4704265594482422
Final reward: -0.5354992747306824
Final reward: -0.535738468170166
Final reward: -0.4396136403083801
Final reward: -0.44697868824005127
Final reward: -0.506864070892334
Final reward: -0.5520278811454773
Final reward: -0.4775722026824951
Final reward: -0.4326971769332886
Final reward: -0.493400514125824
Final reward: -0.5517638921737671
Final reward: -0.5760980844497681
Final reward: -0.4955320656299591
Final reward: -0.44424667954444885
Final reward: -0.49558714032173157
Final reward: -0.5536343455314636
Final reward: -0.5781660676002502
Final reward: -0.49260637164115906
Final reward: -0.4773614704608917
Final reward: -0.5330407619476318
Final reward: -0.5824850797653198
Final reward: -0.5797653794288635
Final reward: -0.4932456612586975
Final reward: -0.5017736554145813
Final reward: -0.5557541251182556
Final reward: -0.5979244112968445
Final reward: -0.5314832925796509
Final reward: -0.4790028929710388
Final reward: -0.5115718245506287
Final reward: -0.5671074390411377
Final reward: -0.5941312313079834
Final reward: -0.512835681438446
Final reward: -0.48815909028053284
Final reward: -0.531598687171936
Final reward: -0.584942102432251
Final reward: -0.6121420860290527
Final reward: -0.5341198444366455
Final reward: -0.5112680792808533
Final reward: -0.554880678653717
Final reward: -0.6112710237503052
Final reward: -0.6071785688400269
Final reward: -0.5257042646408081
Final reward: -0.5346513390541077
Final reward: -0.5988901257514954
Final reward: -0.6467396020889282
Final reward: -0.6596815586090088
Final reward: -0.5863907933235168
Final reward: -0.553460955619812
Final reward: -0.599100649356842
Final reward: -0.6516961455345154
Final reward: -0.6388751268386841
Final reward: -0.5656684041023254
Final reward: -0.5799389481544495
Final reward: -0.6272588968276978
Final reward: -0.6626076102256775
Final reward: -0.5994779467582703
Final reward: -0.5681483149528503
Final reward: -0.616012454032898
Final reward: -0.666720986366272
Final reward: -0.6703605651855469
Final reward: -0.5954494476318359
Final reward: -0.5987271070480347
Final reward: -0.6445688009262085
Final reward: -0.6821470856666565
Final reward: -0.6272478699684143
Final reward: -0.5782312154769897
Final reward: -0.6132373213768005
Final reward: -0.6646044254302979
Final reward: -0.7016856670379639
Final reward: -0.6514629125595093
Final reward: -0.5766212940216064
Final reward: -0.5759190917015076
Final reward: -0.6186437010765076
Final reward: -0.6673193573951721
Final reward: -0.6353194713592529
Final reward: -0.5736363530158997
Final reward: -0.5988710522651672
Final reward: -0.6499904990196228
Final reward: -0.6592226028442383
Final reward: -0.603369951248169
Final reward: -0.5581461191177368
Final reward: -0.5898303985595703
Final reward: -0.6430532336235046
Final reward: -0.6421290040016174
Final reward: -0.5654557943344116
Final reward: -0.554332435131073
Final reward: -0.601862370967865
Final reward: -0.6479785442352295
Final reward: -0.6032364368438721
Final reward: -0.5280709862709045
Final reward: -0.5405782461166382
Final reward: -0.5908481478691101
Final reward: -0.6253529787063599
Final reward: -0.5564375519752502
Final reward: -0.5074419379234314
Final reward: -0.5457603335380554
Final reward: -0.603101372718811
Final reward: -0.5955417156219482
Final reward: -0.5159860253334045
Final reward: -0.4433670938014984
Final reward: -0.4734154939651489
Final reward: -0.5335034728050232
Final reward: -0.5707605481147766
Final reward: -0.4905577003955841
Final reward: -0.4612409472465515
Final reward: -0.5142980813980103
Final reward: -0.5714235901832581
Final reward: -0.5311371088027954
Final reward: -0.44561389088630676
Final reward: -0.4145665466785431
Final reward: -0.4731493294239044
Final reward: -0.5344415903091431
Final reward: -0.49230295419692993
Final reward: -0.384382963180542
Final reward: -0.3494407534599304
Final reward: -0.4224281907081604
Final reward: -0.46741414070129395
Final reward: -0.49643591046333313
Final reward: -0.39367273449897766
Final reward: -0.3699394762516022
Final reward: -0.45601218938827515
Final reward: -0.49655845761299133
Final reward: -0.472817063331604
Final reward: -0.3736457824707031
Final reward: -0.3133021295070648
Final reward: -0.4031497538089752
Final reward: -0.4586351215839386
Final reward: -0.42428553104400635
Final reward: -0.3110682964324951
Final reward: -0.3646896183490753
Final reward: -0.42614713311195374
Final reward: -0.4560665786266327
Final reward: -0.34618568420410156
Final reward: -0.2970380187034607
Final reward: -0.39875417947769165
Final reward: -0.445604145526886
Final reward: -0.413506418466568
Final reward: -0.28881123661994934
Final reward: -0.2430446296930313
Final reward: -0.35103461146354675
Final reward: -0.415625661611557
Final reward: -0.36245158314704895
Final reward: -0.22420337796211243
Final reward: -0.2931666374206543
Final reward: -0.36809390783309937
Final reward: -0.41280290484428406
Final reward: -0.2961397171020508
Final reward: -0.2280586063861847
Final reward: -0.3530885577201843
Final reward: -0.4049800932407379
Final reward: -0.39470013976097107
Final reward: -0.2459695190191269
Final reward: -0.2596825361251831
Final reward: -0.3614334762096405
Final reward: -0.4080713391304016
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3245514929294586
Final reward: -0.15901130437850952
Final reward: -0.2697490155696869
Final reward: -0.34601345658302307
Final reward: -0.3670536279678345
Final reward: -0.21101778745651245
Final reward: -0.16264614462852478
Final reward: -0.28936365246772766
Final reward: -0.3468875586986542
Final reward: -0.31092527508735657
Final reward: -0.1127374917268753
Final reward: -0.5495516061782837
Final reward: -0.5495936870574951
Final reward: -0.5499057173728943
Final reward: -0.5504541397094727
Final reward: -0.5516221523284912
Final reward: -0.5528380870819092
Final reward: -0.5534495115280151
Final reward: -0.5543977618217468
Final reward: -0.5549409985542297
Final reward: -0.5556071996688843
Final reward: -0.5558076500892639
Final reward: -0.5536224246025085
Final reward: -0.5526155829429626
Final reward: -0.5485968589782715
Final reward: -0.5450581312179565
Final reward: -0.5396288633346558
Final reward: -0.5319116711616516
Final reward: -0.5217205286026001
Final reward: -0.5092589855194092
Final reward: -0.495061993598938
Final reward: -0.4773670732975006
Final reward: -0.4583490490913391
Final reward: -0.4397238790988922
Final reward: -0.4305652379989624
Final reward: -0.4178687036037445
Final reward: -0.4257608950138092
Final reward: -0.44105663895606995
Final reward: -0.46097519993782043
Final reward: -0.48417019844055176
Final reward: -0.5070710182189941
Final reward: -0.5281525254249573
Final reward: -0.5443242788314819
Final reward: -0.5533868670463562
Final reward: -0.5592553615570068
Final reward: -0.5582920908927917
Final reward: -0.5497314929962158
Final reward: -0.5266239047050476
Final reward: -0.49424949288368225
Final reward: -0.4566703736782074
Final reward: -0.42277225852012634
Final reward: -0.4329048991203308
Final reward: -0.4614565074443817
Final reward: -0.4974709451198578
Final reward: -0.5281411409378052
Final reward: -0.5429286360740662
Final reward: -0.5526096224784851
Final reward: -0.5406892895698547
Final reward: -0.5017236471176147
Final reward: -0.45106878876686096
Final reward: -0.4306526184082031
Final reward: -0.46362701058387756
Final reward: -0.5088472366333008
Final reward: -0.5387482047080994
Final reward: -0.5519495606422424
Final reward: -0.5366257429122925
Final reward: -0.4929078221321106
Final reward: -0.43606242537498474
Final reward: -0.4209388494491577
Final reward: -0.46367552876472473
Final reward: -0.5141391754150391
Final reward: -0.5408851504325867
Final reward: -0.5485784411430359
Final reward: -0.5203083157539368
Final reward: -0.45853638648986816
Final reward: -0.3982810974121094
Final reward: -0.43874138593673706
Final reward: -0.49788594245910645
Final reward: -0.5244026184082031
Final reward: -0.5179872512817383
Final reward: -0.4494253098964691
Final reward: -0.39538195729255676
Final reward: -0.43533211946487427
Final reward: -0.49854639172554016
Final reward: -0.526542067527771
Final reward: -0.5043824911117554
Final reward: -0.42143091559410095
Final reward: -0.4151524007320404
Final reward: -0.4898603856563568
Final reward: -0.539567232131958
Final reward: -0.5511744618415833
Final reward: -0.485773503780365
Final reward: -0.43359091877937317
Final reward: -0.4940486550331116
Final reward: -0.5408637523651123
Final reward: -0.5447403788566589
Final reward: -0.47287264466285706
Final reward: -0.4271634519100189
Final reward: -0.4948803186416626
Final reward: -0.5384093523025513
Final reward: -0.5265572667121887
Final reward: -0.4333072900772095
Final reward: -0.4559398293495178
Final reward: -0.5398778915405273
Final reward: -0.594994306564331
Final reward: -0.6144134998321533
Final reward: -0.5519524812698364
Final reward: -0.502505898475647
Final reward: -0.545341432094574
Final reward: -0.6108700633049011
Final reward: -0.6542631387710571
Final reward: -0.6647859811782837
Final reward: -0.6006987690925598
Final reward: -0.5687949061393738
Final reward: -0.625967800617218
Final reward: -0.6587192416191101
Final reward: -0.6259005069732666
Final reward: -0.5837788581848145
Final reward: -0.519672155380249
Final reward: -0.5027353763580322
Final reward: -0.559190034866333
Final reward: -0.6027252674102783
Final reward: -0.6023097038269043
Final reward: -0.5271898508071899
Final reward: -0.5140436887741089
Final reward: -0.5835039019584656
Final reward: -0.6200404167175293
Final reward: -0.5904765725135803
Final reward: -0.5125908255577087
Final reward: -0.4934794306755066
Final reward: -0.5658915042877197
Final reward: -0.6076828241348267
Final reward: -0.59900963306427
Final reward: -0.5176729559898376
Final reward: -0.5386767387390137
Final reward: -0.5982906818389893
Final reward: -0.615930438041687
Final reward: -0.5524376034736633
Final reward: -0.5007593035697937
Final reward: -0.5621610283851624
Final reward: -0.6040952801704407
Final reward: -0.5946662425994873
Final reward: -0.5124521255493164
Final reward: -0.5351791977882385
Final reward: -0.594867467880249
Final reward: -0.6115282773971558
Final reward: -0.5457205772399902
Final reward: -0.5125797390937805
Final reward: -0.5753867030143738
Final reward: -0.6114763617515564
Final reward: -0.5802682042121887
Final reward: -0.49708330631256104
Final reward: -0.5354150533676147
Final reward: -0.5914540886878967
Final reward: -0.597751259803772
Final reward: -0.5425072312355042
Final reward: -0.48417678475379944
Final reward: -0.5406591892242432
Final reward: -0.5848292708396912
Final reward: -0.5802720189094543
Final reward: -0.49600929021835327
Final reward: -0.5115150809288025
Final reward: -0.5765213966369629
Final reward: -0.6015146970748901
Final reward: -0.545414388179779
Final reward: -0.48756852746009827
Final reward: -0.4888274669647217
Final reward: -0.5583162307739258
Final reward: -0.5968500971794128
Final reward: -0.5705029964447021
Final reward: -0.4873214066028595
Final reward: -0.531117856502533
Final reward: -0.5870065093040466
Final reward: -0.597326934337616
Final reward: -0.5226737260818481
Final reward: -0.5057538747787476
Final reward: -0.5715584754943848
Final reward: -0.6026197671890259
Final reward: -0.5574038028717041
Final reward: -0.4738352596759796
Final reward: -0.47462138533592224
Final reward: -0.5441843271255493
Final reward: -0.5656629204750061
Final reward: -0.5438277721405029
Final reward: -0.45330196619033813
Final reward: -0.49387693405151367
Final reward: -0.561715841293335
Final reward: -0.5843005180358887
Final reward: -0.5333642959594727
Final reward: -0.4403263330459595
Final reward: -0.4572712481021881
Final reward: -0.5274065732955933
Final reward: -0.5496171712875366
Final reward: -0.4795529842376709
Final reward: -0.43293777108192444
Final reward: -0.5084670186042786
Final reward: -0.5691116452217102
Final reward: -0.5930714011192322
Final reward: -0.5337256193161011
Final reward: -0.48360612988471985
Final reward: -0.5467731952667236
Final reward: -0.5873480439186096
Final reward: -0.567651093006134
Final reward: -0.481302410364151
Final reward: -0.5176089406013489
Final reward: -0.5868096351623535
Final reward: -0.6174513697624207
Final reward: -0.5745688080787659
Final reward: -0.49683666229248047
Final reward: -0.5183864235877991
Final reward: -0.5807518362998962
Final reward: -0.5985167622566223
Final reward: -0.5388948321342468
Final reward: -0.4877059757709503
Final reward: -0.5467325448989868
Final reward: -0.5895386338233948
Final reward: -0.5781679749488831
Final reward: -0.4933541417121887
Final reward: -0.5125681161880493
Final reward: -0.575394332408905
Final reward: -0.5942970514297485
Final reward: -0.5281307697296143
Final reward: -0.49018263816833496
Final reward: -0.5554183721542358
Final reward: -0.5929892063140869
Final reward: -0.5626292824745178
Final reward: -0.48130300641059875
Final reward: -0.5282427668571472
Final reward: -0.5855318903923035
Final reward: -0.5968745350837708
Final reward: -0.525498628616333
Final reward: -0.47262874245643616
Final reward: -0.5367498397827148
Final reward: -0.578724205493927
Final reward: -0.558217465877533
Final reward: -0.4701947867870331
Final reward: -0.5085379481315613
Final reward: -0.571638822555542
Final reward: -0.5902397036552429
Final reward: -0.5242162346839905
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.4300720691680908
Final reward: -0.4774797856807709
Final reward: -0.5385002493858337
Final reward: -0.5482882857322693
Final reward: -0.46467480063438416
Final reward: -0.44924113154411316
Final reward: -0.5242626667022705
Final reward: -0.556370198726654
Final reward: -0.534784734249115
Final reward: -0.4452982246875763
Final reward: -0.46324828267097473
Final reward: -0.5324333310127258
Final reward: -0.549236536026001
Final reward: -0.504170835018158
Final reward: -0.42467552423477173
Final reward: -0.4219045341014862
Final reward: -0.5037071108818054
Final reward: -0.5414711236953735
Final reward: -0.4980645775794983
Final reward: -0.41259458661079407
Final reward: -0.4704104959964752
Final reward: -0.5265852212905884
Final reward: -0.5294053554534912
Final reward: -0.44160133600234985
Final reward: -0.3898847997188568
Final reward: -0.4731323719024658
Final reward: -0.5311925411224365
Final reward: -0.5368273854255676
Final reward: -0.46917426586151123
Final reward: -0.4134705066680908
Final reward: -0.4865182936191559
Final reward: -0.5315556526184082
Final reward: -0.5064014792442322
Final reward: -0.40795397758483887
Final reward: -0.45505407452583313
Final reward: -0.5194849967956543
Final reward: -0.5308606028556824
Final reward: -0.4475327134132385
Final reward: -0.3909558355808258
Final reward: -0.46795204281806946
Final reward: -0.5142298936843872
Final reward: -0.4869314730167389
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                   avg_speed ‚ñÜ‚ñà‚ñÖ‚ñà‚ñà‚ñÑ‚ñà‚ñà‚ñÖ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                        cost ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  is_success ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   max_speed ‚ñÜ‚ñà‚ñÖ‚ñà‚ñà‚ñÑ‚ñà‚ñà‚ñÖ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                      reward ‚ñÉ‚ñÅ‚ñá‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ
wandb:             train/approx_kl ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ
wandb:         train/clip_fraction ‚ñÇ‚ñÇ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÇ
wandb:            train/clip_range ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/cost_returns ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÖ
wandb:       train/cost_value_loss ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ
wandb:           train/cost_values ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train/entropy ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:          train/entropy_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:    train/explained_variance ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÜ
wandb: train/lagrangian_multiplier ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ
wandb:         train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train/loss ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ
wandb:             train/n_updates ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  train/policy_gradient_loss ‚ñá‚ñà‚ñÖ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÅ‚ñá‚ñÜ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ
wandb:                   train/std ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            train/value_loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                   avg_speed 8.00213
wandb:                        cost 0
wandb:                  is_success 0
wandb:                   max_speed 8.00213
wandb:                      reward -0.72043
wandb:             train/approx_kl 0.00276
wandb:         train/clip_fraction 0.01914
wandb:            train/clip_range 0.2
wandb:          train/cost_returns 5.38106
wandb:       train/cost_value_loss 12.78583
wandb:           train/cost_values 2.99948
wandb:               train/entropy -0.22211
wandb:          train/entropy_loss -0.22193
wandb:    train/explained_variance 0.0
wandb: train/lagrangian_multiplier 0.00652
wandb:         train/learning_rate 0.0003
wandb:                  train/loss 6.32173
wandb:             train/n_updates 14690
wandb:  train/policy_gradient_loss -0.00117
wandb:                   train/std 0.27195
wandb:            train/value_loss 16.55656
wandb: 
wandb: üöÄ View run vermilion-dragon-6 at: https://wandb.ai/ecrl/ppol-extra-obs/runs/x99x1ok7
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240222_152550-x99x1ok7/logs
