wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240416_154326-ojl4ujmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-deluge-8
wandb: ⭐️ View project at https://wandb.ai/ecrl/mini-grid
wandb: 🚀 View run at https://wandb.ai/ecrl/mini-grid/runs/ojl4ujmc
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/envs/registration.py:523: DeprecationWarning: [33mWARN: The environment MiniGrid-Empty-16x16-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.deprecation(
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppol/ppol.py:165: UserWarning: You have specified a mini-batch size of 4096, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2048`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 2048
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=1)
  warnings.warn(
Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/tests/PPOL/train_ppol_safety_grid.py", line 138, in <module>
    train()
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/tests/PPOL/train_ppol_safety_grid.py", line 131, in train
    agent.learn(total_timesteps=args.total_timesteps, callback=callback, reset_num_timesteps=False)
  File "/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppol/ppol.py", line 418, in learn
    result = super().learn(
  File "/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/on_policy_algorithm.py", line 646, in learn
    self.train()
  File "/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppol/ppol.py", line 266, in train
    lambdas, integral = self.pid_controller(d=d, K_P=self.K_P, K_I=self.K_I, K_D=self.K_D, j_c=cost_values, j_c_prev=j_c_prev, integral=integral)
  File "/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppol/ppol.py", line 392, in pid_controller
    derivative = th.clamp(j_c-j_c_prev, min=0)
RuntimeError: The size of tensor a (2048) must match the size of tensor b (4096) at non-singleton dimension 1
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: \ 0.027 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: is_success ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: is_success 0
wandb:     reward 0.0
wandb: 
wandb: 🚀 View run dulcet-deluge-8 at: https://wandb.ai/ecrl/mini-grid/runs/ojl4ujmc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240416_154326-ojl4ujmc/logs
srun: error: sac.ist.berkeley.edu: task 0: Exited with exit code 1
