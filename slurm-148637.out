wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240307_162219-6qm056rl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-snowflake-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/6qm056rl
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240307_082221-r3u8gkix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-wildflower-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/r3u8gkix
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
Using cpu device
------------------------------------
| avg_speed          | 1.67        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.67        |
| reward             | -0.47781765 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -810        |
| time/              |             |
|    fps             | 99          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 2048        |
------------------------------------
Using cpu device
------------------------------------
| avg_speed          | 1.67        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.67        |
| reward             | -0.47781765 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -810        |
| time/              |             |
|    fps             | 103         |
|    iterations      | 1           |
|    time_elapsed    | 19          |
|    total_timesteps | 2048        |
------------------------------------
-------------------------------------------
| avg_speed                | 0.825        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.825        |
| reward                   | -0.45933646  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 79           |
|    iterations            | 2            |
|    time_elapsed          | 51           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0030983672 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 9.77         |
|    cost_values           | 0.401        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.000666     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.5         |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 1            |
|    value_loss            | 151          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.824       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.824       |
| reward                   | -0.4589864  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 81          |
|    iterations            | 2           |
|    time_elapsed          | 49          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.003097332 |
|    clip_fraction         | 0.0152      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 9.77        |
|    cost_values           | 0.401       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.000666    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 48.5        |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00196    |
|    std                   | 1           |
|    value_loss            | 151         |
------------------------------------------
--------------------------------------------
| avg_speed                | 2.99          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.99          |
| reward                   | -0.8383264    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -1.23e+03     |
| time/                    |               |
|    fps                   | 74            |
|    iterations            | 3             |
|    time_elapsed          | 82            |
|    total_timesteps       | 6144          |
| train/                   |               |
|    approx_kl             | 0.00044593864 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.72          |
|    cost_value_loss       | 9.28          |
|    cost_values           | 0.978         |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -0.0644       |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 441           |
|    n_updates             | 20            |
|    policy_gradient_loss  | -0.000619     |
|    std                   | 1             |
|    value_loss            | 966           |
--------------------------------------------
--------------------------------------------
| avg_speed                | 6.82          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.82          |
| reward                   | -0.68010265   |
| rollout/                 |               |
|    ep_len_mean           | 880           |
|    ep_rew_mean           | -1.08e+03     |
| time/                    |               |
|    fps                   | 76            |
|    iterations            | 3             |
|    time_elapsed          | 80            |
|    total_timesteps       | 6144          |
| train/                   |               |
|    approx_kl             | 0.00043851463 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.7           |
|    cost_value_loss       | 9.24          |
|    cost_values           | 0.978         |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -0.0732       |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 439           |
|    n_updates             | 20            |
|    policy_gradient_loss  | -0.000608     |
|    std                   | 1             |
|    value_loss            | 962           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -1.2571725   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 4            |
|    time_elapsed          | 114          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0009868172 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 4.77         |
|    cost_values           | 0.966        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.0698      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 130          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.000776    |
|    std                   | 1.01         |
|    value_loss            | 283          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -1.0821882   |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 110          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0021850946 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 0.983        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.0873      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 92.3         |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 1            |
|    value_loss            | 193          |
-------------------------------------------
srun: Job 148637 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 148637 step creation temporarily disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 6.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.92         |
| reward                   | -2.4204667   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 141          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0016065657 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 3.25         |
|    cost_values           | 0.971        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.00151     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 104          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 1            |
|    value_loss            | 223          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.49         |
| reward                   | -1.381624    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 5            |
|    time_elapsed          | 145          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0017113987 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 5.14         |
|    cost_values           | 0.813        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.688       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.2         |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.000879    |
|    std                   | 1.01         |
|    value_loss            | 192          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.96          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.96          |
| reward                   | -1.1790127    |
| rollout/                 |               |
|    ep_len_mean           | 941           |
|    ep_rew_mean           | -1.06e+03     |
| time/                    |               |
|    fps                   | 71            |
|    iterations            | 6             |
|    time_elapsed          | 171           |
|    total_timesteps       | 12288         |
| train/                   |               |
|    approx_kl             | 0.00094940874 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.13          |
|    cost_value_loss       | 8.92          |
|    cost_values           | 0.997         |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -4.72e-05     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 191           |
|    n_updates             | 50            |
|    policy_gradient_loss  | -0.000936     |
|    std                   | 1             |
|    value_loss            | 388           |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.96          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.96          |
| reward                   | -1.8933661    |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -1.12e+03     |
| time/                    |               |
|    fps                   | 69            |
|    iterations            | 6             |
|    time_elapsed          | 176           |
|    total_timesteps       | 12288         |
| train/                   |               |
|    approx_kl             | 0.00052548526 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.7           |
|    cost_value_loss       | 6.24          |
|    cost_values           | 0.982         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -0.000137     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 155           |
|    n_updates             | 50            |
|    policy_gradient_loss  | -0.000555     |
|    std                   | 1.01          |
|    value_loss            | 340           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.96         |
| reward                   | -0.5792131   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 202          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0015740686 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 14.4         |
|    cost_values           | 1            |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -8.12e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.000917    |
|    std                   | 0.998        |
|    value_loss            | 215          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.35        |
| reward                   | -1.8530284  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 7           |
|    time_elapsed          | 206         |
|    total_timesteps       | 14336       |
| train/                   |             |
|    approx_kl             | 0.002261795 |
|    clip_fraction         | 0.000586    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 9.48        |
|    cost_values           | 0.993       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -0.00139    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 120         |
|    n_updates             | 60          |
|    policy_gradient_loss  | -0.0013     |
|    std                   | 1.01        |
|    value_loss            | 252         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.62        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.62        |
| reward                   | -0.32036534 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 16384       |
| train/                   |             |
|    approx_kl             | 0.004977055 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 1           |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -2.56e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 70          |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.998       |
|    value_loss            | 258         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -1.6922837   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 8            |
|    time_elapsed          | 237          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0009583912 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 2.68         |
|    cost_values           | 0.967        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.000106    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 199          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.000791    |
|    std                   | 1.01         |
|    value_loss            | 437          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| avg_speed                | 1.14          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.14          |
| reward                   | -0.48141947   |
| rollout/                 |               |
|    ep_len_mean           | 963           |
|    ep_rew_mean           | -1.01e+03     |
| time/                    |               |
|    fps                   | 70            |
|    iterations            | 9             |
|    time_elapsed          | 263           |
|    total_timesteps       | 18432         |
| train/                   |               |
|    approx_kl             | 0.00064007833 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.27          |
|    cost_value_loss       | 2.51          |
|    cost_values           | 0.985         |
|    entropy               | -2.83         |
|    entropy_loss          | -2.83         |
|    explained_variance    | -0.00187      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 114           |
|    n_updates             | 80            |
|    policy_gradient_loss  | -0.000414     |
|    std                   | 0.997         |
|    value_loss            | 243           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.77242386  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 9            |
|    time_elapsed          | 268          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0014964193 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 6.62         |
|    cost_values           | 0.982        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -9.3e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00092     |
|    std                   | 1.01         |
|    value_loss            | 311          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.49        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.49        |
| reward                   | -0.55188024 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 293         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.00352756  |
|    clip_fraction         | 0.00366     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 16.9        |
|    cost_values           | 1.01        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -0.000583   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41.3        |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 1           |
|    value_loss            | 79.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.3032552   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 10           |
|    time_elapsed          | 299          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0036871298 |
|    clip_fraction         | 0.00386      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 7.73         |
|    cost_values           | 0.985        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -1.06e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 210          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 1.01         |
|    value_loss            | 439          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.49         |
| reward                   | -1.0940964   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 324          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0047808182 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 0.997        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000298    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 1            |
|    value_loss            | 209          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.44         |
| reward                   | -1.3702172   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 11           |
|    time_elapsed          | 330          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0005950902 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 5.65         |
|    cost_values           | 0.979        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -8.46e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 220          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.000564    |
|    std                   | 1.01         |
|    value_loss            | 465          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.49        |
| reward                   | -0.8276895  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -999        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 354         |
|    total_timesteps       | 24576       |
| train/                   |             |
|    approx_kl             | 0.005761032 |
|    clip_fraction         | 0.0215      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 6.36        |
|    cost_values           | 0.997       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -5.01e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 98.6        |
|    n_updates             | 110         |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 1.01        |
|    value_loss            | 204         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.57         |
| reward                   | -1.8739215   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 12           |
|    time_elapsed          | 360          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0012931314 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 1.86         |
|    cost_values           | 0.915        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.822       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 176          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.000913    |
|    std                   | 1.01         |
|    value_loss            | 387          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.34         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.34         |
| reward                   | -0.58957916  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -995         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 385          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0034738125 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 1            |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000183    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66           |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 1            |
|    value_loss            | 132          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -1.3837253  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 13          |
|    time_elapsed          | 391         |
|    total_timesteps       | 26624       |
| train/                   |             |
|    approx_kl             | 0.000631604 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 8.71        |
|    cost_values           | 0.982       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 4.71e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 153         |
|    n_updates             | 120         |
|    policy_gradient_loss  | -0.000521   |
|    std                   | 1.01        |
|    value_loss            | 328         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.8042497   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -966         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 415          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0035769837 |
|    clip_fraction         | 0.00532      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 1.01         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -2.86e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 75           |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 1            |
|    value_loss            | 152          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.05          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.05          |
| reward                   | -2.4711788    |
| rollout/                 |               |
|    ep_len_mean           | 963           |
|    ep_rew_mean           | -1.18e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 14            |
|    time_elapsed          | 423           |
|    total_timesteps       | 28672         |
| train/                   |               |
|    approx_kl             | 0.00040104738 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.912         |
|    cost_value_loss       | 0.507         |
|    cost_values           | 0.934         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -5.96e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 208           |
|    n_updates             | 130           |
|    policy_gradient_loss  | -0.000572     |
|    std                   | 1.01          |
|    value_loss            | 444           |
--------------------------------------------
------------------------------------------
| avg_speed                | 1.5         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.5         |
| reward                   | -0.57746655 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -964        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 446         |
|    total_timesteps       | 30720       |
| train/                   |             |
|    approx_kl             | 0.003838819 |
|    clip_fraction         | 0.004       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 31.8        |
|    cost_values           | 1.29        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -3.05e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.7        |
|    n_updates             | 140         |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 1           |
|    value_loss            | 36.9        |
------------------------------------------
--------------------------------------------
| avg_speed                | 6.2           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.2           |
| reward                   | -3.0506942    |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -1.22e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 15            |
|    time_elapsed          | 454           |
|    total_timesteps       | 30720         |
| train/                   |               |
|    approx_kl             | 0.00022108012 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.08          |
|    cost_value_loss       | 2.71          |
|    cost_values           | 0.941         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -0.000129     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 196           |
|    n_updates             | 140           |
|    policy_gradient_loss  | -0.000222     |
|    std                   | 1.01          |
|    value_loss            | 439           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 2.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.47         |
| reward                   | -0.750671    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -949         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 477          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0053486945 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 7.34         |
|    cost_values           | 1.47         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -6.6e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.2         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 1.01         |
|    value_loss            | 151          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.5655191   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 16           |
|    time_elapsed          | 485          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0011257648 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 3.93         |
|    cost_values           | 0.993        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000113    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 388          |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 1.01         |
|    value_loss            | 834          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.455       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.455       |
| reward                   | -0.4659197  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -941        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 507         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.002145283 |
|    clip_fraction         | 0.00205     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 27.6        |
|    cost_values           | 1.13        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -7.39e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.7        |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 1.01        |
|    value_loss            | 48.8        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.4980967    |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -1.26e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 17            |
|    time_elapsed          | 515           |
|    total_timesteps       | 34816         |
| train/                   |               |
|    approx_kl             | 0.00023603378 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.74          |
|    cost_value_loss       | 8.69          |
|    cost_values           | 0.992         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -8.55e-05     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 245           |
|    n_updates             | 160           |
|    policy_gradient_loss  | -0.000547     |
|    std                   | 1.01          |
|    value_loss            | 488           |
--------------------------------------------
------------------------------------------
| avg_speed                | 1.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.72        |
| reward                   | -0.66731185 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -924        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 538         |
|    total_timesteps       | 36864       |
| train/                   |             |
|    approx_kl             | 0.004640847 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 36          |
|    cost_values           | 1.36        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -3.7e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 60.1        |
|    n_updates             | 170         |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 1.01        |
|    value_loss            | 93.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.8082119  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 18          |
|    time_elapsed          | 546         |
|    total_timesteps       | 36864       |
| train/                   |             |
|    approx_kl             | 0.001885989 |
|    clip_fraction         | 0.00151     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 4.51        |
|    cost_values           | 0.963       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -3.7e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 161         |
|    n_updates             | 170         |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 1.02        |
|    value_loss            | 337         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.89         |
| reward                   | -2.2775717   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 568          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0024663694 |
|    clip_fraction         | 0.00493      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.36         |
|    cost_value_loss       | 17.7         |
|    cost_values           | 1.41         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -2.1e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22           |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 1.01         |
|    value_loss            | 36.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.3          |
| reward                   | -2.4934497   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 19           |
|    time_elapsed          | 577          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0006201443 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 1.65         |
|    cost_values           | 0.938        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.000255    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 214          |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.000443    |
|    std                   | 1.01         |
|    value_loss            | 420          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.61         |
| reward                   | -0.9736638   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -940         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 598          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0017253545 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 3.56         |
|    cost_values           | 1.19         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 5.96e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 92.8         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 1.01         |
|    value_loss            | 198          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.615        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.615        |
| reward                   | -0.53644484  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 20           |
|    time_elapsed          | 608          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0025094664 |
|    clip_fraction         | 0.00137      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.997        |
|    cost_value_loss       | 0.902        |
|    cost_values           | 0.976        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 224          |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 1.01         |
|    value_loss            | 486          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.56         |
| reward                   | -1.34087     |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -929         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 629          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0034607034 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 1            |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 3.52e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 123          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 1.01         |
|    value_loss            | 257          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.22         |
| reward                   | -0.3850343   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 21           |
|    time_elapsed          | 638          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0013212943 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.949        |
|    cost_value_loss       | 0.643        |
|    cost_values           | 0.98         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 5.96e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 191          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.000937    |
|    std                   | 1.01         |
|    value_loss            | 401          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.86536413  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -923         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 659          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0033192267 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 7.7          |
|    cost_values           | 1            |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -2.23e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.8         |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 1.01         |
|    value_loss            | 65.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 1.61          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.61          |
| reward                   | -0.7573934    |
| rollout/                 |               |
|    ep_len_mean           | 977           |
|    ep_rew_mean           | -1.3e+03      |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 22            |
|    time_elapsed          | 670           |
|    total_timesteps       | 45056         |
| train/                   |               |
|    approx_kl             | 0.00047434558 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.13          |
|    cost_value_loss       | 2.35          |
|    cost_values           | 0.966         |
|    entropy               | -2.86         |
|    entropy_loss          | -2.86         |
|    explained_variance    | -1.43e-06     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 156           |
|    n_updates             | 210           |
|    policy_gradient_loss  | -0.000833     |
|    std                   | 1.01          |
|    value_loss            | 326           |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.955       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.955       |
| reward                   | -0.9870066  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -912        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 690         |
|    total_timesteps       | 47104       |
| train/                   |             |
|    approx_kl             | 0.005028944 |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.83        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 1.01        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -1.29e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.1        |
|    n_updates             | 220         |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 1.01        |
|    value_loss            | 48.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.95         |
| reward                   | -1.0684061   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 23           |
|    time_elapsed          | 700          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0017444559 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 2.74         |
|    cost_values           | 0.949        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -6.79e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 140          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00067     |
|    std                   | 1.01         |
|    value_loss            | 285          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.41         |
| reward                   | -0.8715075   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -906         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 720          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0022736618 |
|    clip_fraction         | 0.00225      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 22.2         |
|    cost_values           | 1.11         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -7.99e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23           |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00082     |
|    std                   | 1.01         |
|    value_loss            | 28.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.77         |
| reward                   | -0.92848545  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 24           |
|    time_elapsed          | 731          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0012882638 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 0.972        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -7.47e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 161          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00075     |
|    std                   | 1.01         |
|    value_loss            | 351          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.58         |
| reward                   | -0.9637316   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -892         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 751          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0025007534 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 1.18         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 7.15e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.7         |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.000938    |
|    std                   | 1.01         |
|    value_loss            | 68.9         |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| avg_speed                | 2.97          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.97          |
| reward                   | -0.9207556    |
| rollout/                 |               |
|    ep_len_mean           | 980           |
|    ep_rew_mean           | -1.32e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 25            |
|    time_elapsed          | 762           |
|    total_timesteps       | 51200         |
| train/                   |               |
|    approx_kl             | 0.00022560058 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.993         |
|    cost_value_loss       | 0.774         |
|    cost_values           | 0.974         |
|    entropy               | -2.86         |
|    entropy_loss          | -2.86         |
|    explained_variance    | -8.75e-05     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 247           |
|    n_updates             | 240           |
|    policy_gradient_loss  | -0.000295     |
|    std                   | 1.01          |
|    value_loss            | 527           |
--------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 6.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.24         |
| reward                   | -0.7006976   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -879         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 781          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0046607833 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 1.01         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -4.01e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.3         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 1.01         |
|    value_loss            | 83.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.99        |
| reward                   | -0.68619555 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 793         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.00258988  |
|    clip_fraction         | 0.00132     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 1.31        |
|    cost_values           | 0.989       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -6.68e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 129         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 1.01        |
|    value_loss            | 279         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.84757555  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -880         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 811          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0050545656 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 1.01         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -5.13e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 61.5         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.01         |
|    value_loss            | 110          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.68        |
| reward                   | -1.6833993  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 823         |
|    total_timesteps       | 55296       |
| train/                   |             |
|    approx_kl             | 0.006028096 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 1.63        |
|    cost_values           | 0.983       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -2.48e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 100         |
|    n_updates             | 260         |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 1           |
|    value_loss            | 219         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -2.0362787   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -882         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 842          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0051336326 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 8.67         |
|    cost_values           | 0.999        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -3.33e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.6         |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 1.02         |
|    value_loss            | 75.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.92         |
| reward                   | -1.5781145   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 854          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0022535573 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 4.01         |
|    cost_values           | 0.942        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -2.23e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 145          |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 1.01         |
|    value_loss            | 300          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.23        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.23        |
| reward                   | -0.35923064 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -881        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 872         |
|    total_timesteps       | 59392       |
| train/                   |             |
|    approx_kl             | 0.007825792 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 19.8        |
|    cost_values           | 1.01        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.87       |
|    explained_variance    | -0.00262    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 90.7        |
|    n_updates             | 280         |
|    policy_gradient_loss  | -0.00481    |
|    std                   | 1.02        |
|    value_loss            | 171         |
------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.64        |
| reward                   | -1.653525   |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 29          |
|    time_elapsed          | 885         |
|    total_timesteps       | 59392       |
| train/                   |             |
|    approx_kl             | 0.007331689 |
|    clip_fraction         | 0.0351      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.985       |
|    cost_value_loss       | 1.13        |
|    cost_values           | 0.954       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 154         |
|    n_updates             | 280         |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 1.01        |
|    value_loss            | 313         |
------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 0.239        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.239        |
| reward                   | -0.8306615   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -890         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 902          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0038667787 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 27.2         |
|    cost_values           | 1.03         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -1.59e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 74.8         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 1.02         |
|    value_loss            | 144          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.94         |
| reward                   | -0.77347815  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 30           |
|    time_elapsed          | 916          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0043686433 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 0.998        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -1.1e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 119          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 1.01         |
|    value_loss            | 253          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.63         |
| reward                   | -1.1031909   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -894         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 31           |
|    time_elapsed          | 932          |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0025968244 |
|    clip_fraction         | 0.0022       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 0.997        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -1.34e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 76.3         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 1.03         |
|    value_loss            | 169          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.79108405 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 947         |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.004243468 |
|    clip_fraction         | 0.00566     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 4.05        |
|    cost_values           | 0.964       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -7.51e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 79.6        |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 1.01        |
|    value_loss            | 171         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.807        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.807        |
| reward                   | -0.8465206   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -898         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 963          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0030667563 |
|    clip_fraction         | 0.00586      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 1            |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -5.84e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 86.6         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 1.03         |
|    value_loss            | 170          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.38         |
| reward                   | -1.4911993   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 32           |
|    time_elapsed          | 977          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0059112874 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 3.25         |
|    cost_values           | 0.966        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -8.34e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 107          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 1            |
|    value_loss            | 210          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.34         |
| reward                   | -0.49685723  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -906         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 993          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0031573693 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 4.94         |
|    cost_values           | 0.998        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -2.3e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.3         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 1.02         |
|    value_loss            | 95.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.4169365   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 33           |
|    time_elapsed          | 1008         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0048509636 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.955        |
|    cost_values           | 0.952        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -1.07e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.9         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 1.01         |
|    value_loss            | 124          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 5.21       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.21       |
| reward                   | -1.0636234 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -908       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 34         |
|    time_elapsed          | 1023       |
|    total_timesteps       | 69632      |
| train/                   |            |
|    approx_kl             | 0.00665871 |
|    clip_fraction         | 0.0213     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.41       |
|    cost_value_loss       | 4.15       |
|    cost_values           | 0.998      |
|    entropy               | -2.88      |
|    entropy_loss          | -2.88      |
|    explained_variance    | -9.54e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 58.1       |
|    n_updates             | 330        |
|    policy_gradient_loss  | -0.00266   |
|    std                   | 1.02       |
|    value_loss            | 125        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.70973647 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1039        |
|    total_timesteps       | 69632       |
| train/                   |             |
|    approx_kl             | 0.005207923 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 1.91        |
|    cost_values           | 0.96        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -4.65e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59.3        |
|    n_updates             | 330         |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 1           |
|    value_loss            | 131         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.11         |
| reward                   | -0.78216946  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -913         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 35           |
|    time_elapsed          | 1053         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0029588134 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 0.996        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -1.12        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.9         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 1.02         |
|    value_loss            | 114          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -2.5880895   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 35           |
|    time_elapsed          | 1069         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0035381804 |
|    clip_fraction         | 0.00781      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 2.39         |
|    cost_values           | 0.979        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -3.46e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 61.2         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 1            |
|    value_loss            | 136          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.2551379   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -929         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 36           |
|    time_elapsed          | 1083         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0024080426 |
|    clip_fraction         | 0.00269      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 1            |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.8         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 1.02         |
|    value_loss            | 99.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.82         |
| reward                   | -0.5768166   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 36           |
|    time_elapsed          | 1101         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0054058046 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 2.83         |
|    cost_values           | 0.976        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.6e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.4         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 1            |
|    value_loss            | 147          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -1.2815773   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -953         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 37           |
|    time_elapsed          | 1113         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0026292854 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 2.84         |
|    cost_values           | 0.992        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -7.99e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 162          |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 1.02         |
|    value_loss            | 359          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.39         |
| reward                   | -1.607186    |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 37           |
|    time_elapsed          | 1131         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0026805855 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.96         |
|    cost_values           | 0.97         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -2.36e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 148          |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 1.01         |
|    value_loss            | 316          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.8113643   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -974         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 38           |
|    time_elapsed          | 1143         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0013936348 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.23         |
|    cost_values           | 0.997        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -5.96e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 259          |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 1.02         |
|    value_loss            | 543          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 6.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.57         |
| reward                   | -2.6389623   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 38           |
|    time_elapsed          | 1162         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0050085234 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 1.42         |
|    cost_values           | 0.947        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -3.93e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.4         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 0.997        |
|    value_loss            | 86.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.09        |
| reward                   | -2.9320817  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -992        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1174        |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.004572332 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 3.24        |
|    cost_values           | 1           |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | -4.29e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 331         |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 1.02        |
|    value_loss            | 673         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -1.1587238  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 39          |
|    time_elapsed          | 1192        |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.005633531 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.995       |
|    cost_value_loss       | 1.11        |
|    cost_values           | 0.933       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -6.44e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 145         |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00324    |
|    std                   | 0.995       |
|    value_loss            | 301         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.4          |
| reward                   | -2.3442986   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 40           |
|    time_elapsed          | 1204         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0022104208 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 2.17         |
|    cost_values           | 1            |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -1.08e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 255          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 1.02         |
|    value_loss            | 548          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.7          |
| reward                   | -1.9668168   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 40           |
|    time_elapsed          | 1222         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0039573894 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.965        |
|    cost_value_loss       | 1.24         |
|    cost_values           | 0.935        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -5.6e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 115          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.998        |
|    value_loss            | 239          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -1.4398808  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1235        |
|    total_timesteps       | 83968       |
| train/                   |             |
|    approx_kl             | 0.004170452 |
|    clip_fraction         | 0.00703     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 3.39        |
|    cost_values           | 1           |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | -2.86e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 288         |
|    n_updates             | 400         |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 1.02        |
|    value_loss            | 637         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.7795823   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 41           |
|    time_elapsed          | 1253         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0040367045 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 3.76         |
|    cost_values           | 0.955        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -5.13e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 1            |
|    value_loss            | 237          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.4588299  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1265        |
|    total_timesteps       | 86016       |
| train/                   |             |
|    approx_kl             | 0.003493844 |
|    clip_fraction         | 0.00527     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 1           |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | -4.89e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 274         |
|    n_updates             | 410         |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 1.02        |
|    value_loss            | 591         |
------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -1.3426212  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 42          |
|    time_elapsed          | 1283        |
|    total_timesteps       | 86016       |
| train/                   |             |
|    approx_kl             | 0.007391043 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 1.39        |
|    cost_values           | 0.955       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -3.34e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 94.6        |
|    n_updates             | 410         |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 1.01        |
|    value_loss            | 212         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.7678266   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1295         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0046322756 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 1.59         |
|    cost_values           | 0.997        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -3.58e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 119          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 1.02         |
|    value_loss            | 255          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -2.232579    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 43           |
|    time_elapsed          | 1314         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0038956003 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 6.07         |
|    cost_values           | 0.975        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -4.05e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 73.2         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 1            |
|    value_loss            | 162          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.4484804   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1325         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0051119556 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.04         |
|    cost_values           | 0.993        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -7.84e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.4         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 1.02         |
|    value_loss            | 139          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.22        |
| reward                   | -2.5227191  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 44          |
|    time_elapsed          | 1345        |
|    total_timesteps       | 90112       |
| train/                   |             |
|    approx_kl             | 0.003329443 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.913       |
|    cost_values           | 0.893       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -7.15e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 64.5        |
|    n_updates             | 430         |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 1           |
|    value_loss            | 142         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -1.9527806   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1356         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0043108584 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 1.72         |
|    cost_values           | 0.989        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -8.25e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 68.2         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 1.01         |
|    value_loss            | 151          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.207       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.207       |
| reward                   | -0.28336746 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 45          |
|    time_elapsed          | 1376        |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.005235861 |
|    clip_fraction         | 0.0777      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 0.999       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -4.53e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59.9        |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.00719    |
|    std                   | 0.998       |
|    value_loss            | 121         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -2.42184     |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1386         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0030896263 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 4.55         |
|    cost_values           | 0.999        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -5.48e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.9         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 1.01         |
|    value_loss            | 123          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 1.08         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.08         |
| reward                   | -0.61741436  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 46           |
|    time_elapsed          | 1406         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0033024321 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 5.38         |
|    cost_values           | 0.988        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -5.01e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.8         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 1            |
|    value_loss            | 108          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.97         |
| reward                   | -1.7803475   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1416         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0038701147 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 2.83         |
|    cost_values           | 0.995        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -1.43e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 193          |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 1.01         |
|    value_loss            | 409          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.32        |
| reward                   | -0.44201216 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1438        |
|    total_timesteps       | 96256       |
| train/                   |             |
|    approx_kl             | 0.002900351 |
|    clip_fraction         | 0.00415     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 5.78        |
|    cost_values           | 0.972       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 133         |
|    n_updates             | 460         |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 1           |
|    value_loss            | 267         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -1.9743462   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1446         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0034142719 |
|    clip_fraction         | 0.00728      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 3.68         |
|    cost_values           | 0.997        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -2.03e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.7         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 1.01         |
|    value_loss            | 89           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.25         |
| reward                   | -0.38539362  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 48           |
|    time_elapsed          | 1468         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0054071224 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 2.62         |
|    cost_values           | 0.982        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -5.72e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 105          |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 0.999        |
|    value_loss            | 229          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.18         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.18         |
| reward                   | -0.39677286  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1476         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0035026046 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 5.8          |
|    cost_values           | 0.997        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -1e-05       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.9         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 1.01         |
|    value_loss            | 59.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.27         |
| reward                   | -0.5953437   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 49           |
|    time_elapsed          | 1499         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0052932305 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 3.06         |
|    cost_values           | 0.983        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.5         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 1            |
|    value_loss            | 80           |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/r3u8gkix
-----------------------------------
| avg_speed          | 1.43       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.43       |
| reward             | -0.5505064 |
| rollout/           |            |
|    ep_len_mean     | 973        |
|    ep_rew_mean     | -1.07e+03  |
| time/              |            |
|    fps             | 103        |
|    iterations      | 1          |
|    time_elapsed    | 19         |
|    total_timesteps | 102400     |
-----------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
Directory created: tests/PPOL_New/models/ppol-extra-obs/6qm056rl
-----------------------------------
| avg_speed          | 6.93       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 6.93       |
| reward             | -1.2005733 |
| rollout/           |            |
|    ep_len_mean     | 962        |
|    ep_rew_mean     | -1.28e+03  |
| time/              |            |
|    fps             | 99         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 102400     |
-----------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.24         |
| reward                   | -0.24667493  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0025732568 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 0.991        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -7.63e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.9         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 1            |
|    value_loss            | 146          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.54         |
| reward                   | -1.2122465   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 79           |
|    iterations            | 2            |
|    time_elapsed          | 51           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0049107014 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.99         |
|    cost_values           | 0.974        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -8.82e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 169          |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 1            |
|    value_loss            | 378          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.93        |
| reward                   | -0.56765544 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 76          |
|    iterations            | 3           |
|    time_elapsed          | 80          |
|    total_timesteps       | 106496      |
| train/                   |             |
|    approx_kl             | 0.012021181 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.01        |
|    cost_value_loss       | 8.57        |
|    cost_values           | 1.57        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -4.17e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.4        |
|    n_updates             | 510         |
|    policy_gradient_loss  | -0.00617    |
|    std                   | 1.01        |
|    value_loss            | 27.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -1.2620323  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 3           |
|    time_elapsed          | 82          |
|    total_timesteps       | 106496      |
| train/                   |             |
|    approx_kl             | 0.004313784 |
|    clip_fraction         | 0.0117      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 2.76        |
|    cost_values           | 0.97        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -6.79e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 200         |
|    n_updates             | 510         |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 1           |
|    value_loss            | 413         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.47        |
| reward                   | -0.43251294 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 110         |
|    total_timesteps       | 108544      |
| train/                   |             |
|    approx_kl             | 0.004762621 |
|    clip_fraction         | 0.0943      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 8.78        |
|    cost_values           | 2.3         |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -7.15e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 520         |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 1.01        |
|    value_loss            | 18.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.47982535 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 114         |
|    total_timesteps       | 108544      |
| train/                   |             |
|    approx_kl             | 0.006096594 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 1.97        |
|    cost_values           | 0.984       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -2.86e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 125         |
|    n_updates             | 520         |
|    policy_gradient_loss  | -0.0034     |
|    std                   | 1           |
|    value_loss            | 260         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.28         |
| reward                   | -0.68264806  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 141          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0036545915 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.66         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 2.96         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.67e-06    |
|    lagrangian_multiplier | 0.0153       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.49         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.999        |
|    value_loss            | 23.9         |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.5143462   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 5            |
|    time_elapsed          | 145          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0042025046 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 2.34         |
|    cost_values           | 0.986        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -3.46e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 155          |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.999        |
|    value_loss            | 321          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 0.545        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.545        |
| reward                   | -0.633564    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0023652143 |
|    clip_fraction         | 0.00479      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.53         |
|    cost_value_loss       | 6.69         |
|    cost_values           | 2.65         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 137          |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.999        |
|    value_loss            | 283          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.5153496   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 6            |
|    time_elapsed          | 176          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0047255745 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 3.16         |
|    cost_values           | 0.983        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.4         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.993        |
|    value_loss            | 73.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.3         |
| reward                   | -1.6824155  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 114688      |
| train/                   |             |
|    approx_kl             | 0.005669745 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.7         |
|    cost_value_loss       | 7.93        |
|    cost_values           | 2           |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.3        |
|    n_updates             | 550         |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 1           |
|    value_loss            | 60.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.9148917   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 7            |
|    time_elapsed          | 207          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0055006244 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 4.12         |
|    cost_values           | 0.993        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -3.7e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 91.4         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 0.988        |
|    value_loss            | 195          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.14         |
| reward                   | -0.7025491   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 8            |
|    time_elapsed          | 232          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0007631581 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 10           |
|    cost_values           | 1.51         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.5         |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.000519    |
|    std                   | 1            |
|    value_loss            | 143          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -1.0230305   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 8            |
|    time_elapsed          | 238          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0069256295 |
|    clip_fraction         | 0.042        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 4.51         |
|    cost_values           | 1            |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36           |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 0.993        |
|    value_loss            | 72.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.858        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.858        |
| reward                   | -1.3826221   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 9            |
|    time_elapsed          | 262          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0018343256 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 8.7          |
|    cost_values           | 1.06         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 126          |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 1            |
|    value_loss            | 250          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.57         |
| reward                   | -2.1254928   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 9            |
|    time_elapsed          | 268          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0030421885 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.02         |
|    cost_values           | 0.984        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.91e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 1.01         |
|    value_loss            | 32.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.58         |
| reward                   | -1.404505    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0012871923 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 3.52         |
|    cost_values           | 0.989        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.1         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 1            |
|    value_loss            | 148          |
-------------------------------------------
srun: Job 148637 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.2910709   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 10           |
|    time_elapsed          | 299          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0055668885 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 2.17         |
|    cost_values           | 0.967        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.9         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 1.01         |
|    value_loss            | 83.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -1.9302264   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 323          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0017418104 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 11.5         |
|    cost_values           | 1            |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.2         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 1            |
|    value_loss            | 126          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5209781   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 11           |
|    time_elapsed          | 331          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0061448673 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.86         |
|    cost_values           | 0.98         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 6.56e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.9         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 1.01         |
|    value_loss            | 122          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.99         |
| reward                   | -1.1115968   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 354          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0037778798 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 6.57         |
|    cost_values           | 1            |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.7         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 1            |
|    value_loss            | 95.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.3978548  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 12          |
|    time_elapsed          | 362         |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.005754412 |
|    clip_fraction         | 0.0544      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 2.51        |
|    cost_values           | 0.991       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -1.31e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.6        |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00513    |
|    std                   | 1.02        |
|    value_loss            | 69.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.8          |
| reward                   | -0.7603349   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 384          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0060714623 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 4.37         |
|    cost_values           | 0.998        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 113          |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 1.01         |
|    value_loss            | 214          |
-------------------------------------------
slurmstepd: error: *** STEP 148637.1 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-03-07T08:53:47 ***
slurmstepd: error: *** JOB 148637 ON airl.ist.berkeley.edu CANCELLED AT 2024-03-07T16:53:47 ***
slurmstepd: error: *** STEP 148637.0 ON airl.ist.berkeley.edu CANCELLED AT 2024-03-07T16:53:47 ***
