wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240123_021636-an325vgg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-elevator-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/seed-testing
wandb: üöÄ View run at https://wandb.ai/ecrl/seed-testing/runs/an325vgg
Using cpu device
------------------------------------
| avg_speed          | 0.114       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.114       |
| reward             | -0.40254623 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.59e+03   |
| time/              |             |
|    fps             | 96          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2048        |
------------------------------------
-------------------------------------------
| avg_speed                | 0.803        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.803        |
| reward                   | -0.88885176  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.85e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0034414995 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 240          |
|    cost_values           | 0.0235       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00357      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 367          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 1            |
|    value_loss            | 806          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.68         |
| reward                   | -0.926823    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.82e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 3            |
|    time_elapsed          | 64           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0061845565 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 227          |
|    cost_values           | -0.193       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0676       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 686          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.01         |
|    value_loss            | 1.43e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.57         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.57         |
| reward                   | -1.2337818   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.75e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0037988627 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.42         |
|    cost_value_loss       | 156          |
|    cost_values           | -0.34        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.11         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 508          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 1.01         |
|    value_loss            | 1.05e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.488        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.488        |
| reward                   | -0.8480502   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.74e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 5            |
|    time_elapsed          | 108          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0070569185 |
|    clip_fraction         | 0.053        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 185          |
|    cost_values           | -0.269       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.208        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 374          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 1.01         |
|    value_loss            | 785          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.09        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.09        |
| reward                   | -0.99639636 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.64e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 130         |
|    total_timesteps       | 12288       |
| train/                   |             |
|    approx_kl             | 0.005834993 |
|    clip_fraction         | 0.0238      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 226         |
|    cost_values           | -0.583      |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.235       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 420         |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 1.01        |
|    value_loss            | 864         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.68627906  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.57e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 152          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0042045964 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.69         |
|    cost_value_loss       | 87.5         |
|    cost_values           | -0.0428      |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -1.37        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 201          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00536     |
|    std                   | 1.02         |
|    value_loss            | 422          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.204       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.204       |
| reward                   | -0.8342897  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 174         |
|    total_timesteps       | 16384       |
| train/                   |             |
|    approx_kl             | 0.002639722 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.72        |
|    cost_value_loss       | 40.3        |
|    cost_values           | -0.49       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0668      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 170         |
|    n_updates             | 70          |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 1.02        |
|    value_loss            | 369         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.23        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.23        |
| reward                   | -0.8709277  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.43e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 196         |
|    total_timesteps       | 18432       |
| train/                   |             |
|    approx_kl             | 0.003487117 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 54.8        |
|    cost_values           | -0.5        |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | -0.106      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 54.9        |
|    n_updates             | 80          |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 1.02        |
|    value_loss            | 126         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.006762    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 218          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0040515047 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.49         |
|    cost_value_loss       | 96.2         |
|    cost_values           | -0.69        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.219        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 150          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 1.02         |
|    value_loss            | 321          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.481       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.481       |
| reward                   | -0.9590498  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.34e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 11          |
|    time_elapsed          | 240         |
|    total_timesteps       | 22528       |
| train/                   |             |
|    approx_kl             | 0.003959545 |
|    clip_fraction         | 0.0379      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.96        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.62       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.143       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 92.1        |
|    n_updates             | 100         |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 1.02        |
|    value_loss            | 217         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0667       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0667       |
| reward                   | -1.0608063   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 262          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0040673474 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.17         |
|    cost_value_loss       | 161          |
|    cost_values           | -0.631       |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0247       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 120          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.02         |
|    value_loss            | 272          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -1.7545193   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 284          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0032221545 |
|    clip_fraction         | 0.00757      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 47.1         |
|    cost_values           | -0.631       |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.292        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 90.7         |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 1.02         |
|    value_loss            | 201          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.5999986  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 14          |
|    time_elapsed          | 306         |
|    total_timesteps       | 28672       |
| train/                   |             |
|    approx_kl             | 0.006562709 |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 83.1        |
|    cost_values           | -0.653      |
|    entropy               | -2.88       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.00209     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 101         |
|    n_updates             | 130         |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 1.02        |
|    value_loss            | 236         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.88         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.88         |
| reward                   | -0.78285754  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 328          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0030165706 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 53.3         |
|    cost_values           | -0.799       |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0396       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 137          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00484     |
|    std                   | 1.03         |
|    value_loss            | 276          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.22         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.22         |
| reward                   | -1.1369139   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 350          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0034393542 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.23         |
|    cost_value_loss       | 123          |
|    cost_values           | -0.679       |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.947       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51           |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 1.03         |
|    value_loss            | 133          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -2.3937993  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 17          |
|    time_elapsed          | 372         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.003974962 |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.8        |
|    cost_value_loss       | 223         |
|    cost_values           | -0.623      |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.267       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 237         |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 1.03        |
|    value_loss            | 514         |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.98       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.98       |
| reward                   | -2.3611727 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -1.27e+03  |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 18         |
|    time_elapsed          | 394        |
|    total_timesteps       | 36864      |
| train/                   |            |
|    approx_kl             | 0.00303208 |
|    clip_fraction         | 0.00479    |
|    clip_range            | 0.2        |
|    cost_returns          | 14.5       |
|    cost_value_loss       | 252        |
|    cost_values           | -0.697     |
|    entropy               | -2.9       |
|    entropy_loss          | -2.9       |
|    explained_variance    | -0.0913    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 290        |
|    n_updates             | 170        |
|    policy_gradient_loss  | -0.00131   |
|    std                   | 1.03       |
|    value_loss            | 660        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.2          |
| reward                   | -1.9515822   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 19           |
|    time_elapsed          | 416          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0038772738 |
|    clip_fraction         | 0.00532      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 241          |
|    cost_values           | -0.617       |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -1.43        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 181          |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 1.03         |
|    value_loss            | 545          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.05         |
| reward                   | -2.505617    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 438          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0032428436 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 177          |
|    cost_values           | -0.701       |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.315       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 226          |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 1.03         |
|    value_loss            | 492          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.7622573   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 460          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0052539986 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.98         |
|    cost_value_loss       | 173          |
|    cost_values           | -0.726       |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.395       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 156          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 1.03         |
|    value_loss            | 369          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.47480097  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 482          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0047028987 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 12           |
|    cost_value_loss       | 205          |
|    cost_values           | -0.796       |
|    entropy               | -2.9         |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.0284      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 177          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 1.03         |
|    value_loss            | 366          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.63235617  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 23           |
|    time_elapsed          | 504          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0048040696 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.9         |
|    cost_value_loss       | 241          |
|    cost_values           | -0.793       |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.123       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 407          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.03         |
|    value_loss            | 863          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.14        |
| reward                   | -0.88148993 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 24          |
|    time_elapsed          | 526         |
|    total_timesteps       | 49152       |
| train/                   |             |
|    approx_kl             | 0.005840798 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 200         |
|    cost_values           | -0.796      |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.158      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 191         |
|    n_updates             | 230         |
|    policy_gradient_loss  | -0.00471    |
|    std                   | 1.03        |
|    value_loss            | 418         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.946       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.946       |
| reward                   | -0.5684361  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 25          |
|    time_elapsed          | 548         |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.004649601 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.99        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.825      |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.119      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 71.2        |
|    n_updates             | 240         |
|    policy_gradient_loss  | -0.00304    |
|    std                   | 1.03        |
|    value_loss            | 151         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.94934154 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 570         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.002792178 |
|    clip_fraction         | 0.00459     |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 200         |
|    cost_values           | -0.808      |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.463      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 98.1        |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 1.03        |
|    value_loss            | 224         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.15         |
| reward                   | -1.3163407   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 592          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0058843484 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 206          |
|    cost_values           | -0.83        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.0839      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 153          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.03         |
|    value_loss            | 331          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.01        |
| reward                   | -1.4813567  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 28          |
|    time_elapsed          | 614         |
|    total_timesteps       | 57344       |
| train/                   |             |
|    approx_kl             | 0.003507655 |
|    clip_fraction         | 0.00649     |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 193         |
|    cost_values           | -0.826      |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.118      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 370         |
|    n_updates             | 270         |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 1.03        |
|    value_loss            | 809         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.543        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.543        |
| reward                   | -0.35503888  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 636          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0023523653 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.21         |
|    cost_value_loss       | 122          |
|    cost_values           | -0.837       |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.00666     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 146          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 1.03         |
|    value_loss            | 304          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.38         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.38         |
| reward                   | -0.7371665   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 30           |
|    time_elapsed          | 658          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0039351247 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.65         |
|    cost_value_loss       | 167          |
|    cost_values           | -0.841       |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.0223      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 1.04         |
|    value_loss            | 239          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.86         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.86         |
| reward                   | -1.2317497   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 680          |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0038659058 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.42         |
|    cost_value_loss       | 137          |
|    cost_values           | -0.847       |
|    entropy               | -2.92        |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.0159      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.7         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 1.04         |
|    value_loss            | 107          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.14         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.14         |
| reward                   | -1.6220944   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 702          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0071817795 |
|    clip_fraction         | 0.0616       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.6         |
|    cost_value_loss       | 196          |
|    cost_values           | -0.85        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00924      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 134          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 1.04         |
|    value_loss            | 271          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.97         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.97         |
| reward                   | -0.63949287  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 33           |
|    time_elapsed          | 724          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0061304993 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.3          |
|    cost_value_loss       | 155          |
|    cost_values           | -0.847       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00717      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 112          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00458     |
|    std                   | 1.05         |
|    value_loss            | 235          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -1.2333099   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 746          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0041650287 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 180          |
|    cost_values           | -0.852       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.00679      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 310          |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 1.05         |
|    value_loss            | 658          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.751        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.751        |
| reward                   | -1.5063251   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 768          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0052309465 |
|    clip_fraction         | 0.0375       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.22         |
|    cost_value_loss       | 121          |
|    cost_values           | -0.846       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0341       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 93.7         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00557     |
|    std                   | 1.06         |
|    value_loss            | 194          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.3         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.3         |
| reward                   | -2.6604939  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 36          |
|    time_elapsed          | 790         |
|    total_timesteps       | 73728       |
| train/                   |             |
|    approx_kl             | 0.004058244 |
|    clip_fraction         | 0.0112      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 193         |
|    cost_values           | -0.845      |
|    entropy               | -2.96       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.0173      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 150         |
|    n_updates             | 350         |
|    policy_gradient_loss  | -0.00298    |
|    std                   | 1.06        |
|    value_loss            | 325         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.58        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.58        |
| reward                   | -1.496801   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 37          |
|    time_elapsed          | 812         |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.005181605 |
|    clip_fraction         | 0.0348      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 202         |
|    cost_values           | -0.85       |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.0177      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 207         |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 1.06        |
|    value_loss            | 435         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.2          |
| reward                   | -1.4429297   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 38           |
|    time_elapsed          | 834          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0037138532 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 222          |
|    cost_values           | -0.853       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.00746      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 222          |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 1.06         |
|    value_loss            | 455          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.82       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.82       |
| reward                   | -1.3803412 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -1.26e+03  |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 39         |
|    time_elapsed          | 856        |
|    total_timesteps       | 79872      |
| train/                   |            |
|    approx_kl             | 0.00550555 |
|    clip_fraction         | 0.0432     |
|    clip_range            | 0.2        |
|    cost_returns          | 10.4       |
|    cost_value_loss       | 178        |
|    cost_values           | -0.848     |
|    entropy               | -2.97      |
|    entropy_loss          | -2.97      |
|    explained_variance    | 0.0231     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 109        |
|    n_updates             | 380        |
|    policy_gradient_loss  | -0.00568   |
|    std                   | 1.07       |
|    value_loss            | 226        |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.169       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.169       |
| reward                   | -1.1873573  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 40          |
|    time_elapsed          | 878         |
|    total_timesteps       | 81920       |
| train/                   |             |
|    approx_kl             | 0.003919025 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 225         |
|    cost_values           | -0.849      |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.0337      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 90.5        |
|    n_updates             | 390         |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 1.06        |
|    value_loss            | 185         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.8          |
| reward                   | -1.3401482   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 900          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0046950825 |
|    clip_fraction         | 0.0392       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 199          |
|    cost_values           | -0.849       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0173       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 89           |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 1.07         |
|    value_loss            | 205          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.39         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.39         |
| reward                   | -1.2687534   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 922          |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0048280302 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.62         |
|    cost_value_loss       | 113          |
|    cost_values           | -0.85        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00609      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50.3         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 1.07         |
|    value_loss            | 110          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.92         |
| reward                   | -1.5181657   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 944          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0030467345 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 11           |
|    cost_value_loss       | 182          |
|    cost_values           | -0.853       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0102       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 1.07         |
|    value_loss            | 211          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.18         |
| reward                   | -0.64886963  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 44           |
|    time_elapsed          | 966          |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0042571053 |
|    clip_fraction         | 0.0431       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 182          |
|    cost_values           | -0.852       |
|    entropy               | -2.98        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00826      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 81.6         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00494     |
|    std                   | 1.07         |
|    value_loss            | 187          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.1          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.1          |
| reward                   | -2.1769843   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 45           |
|    time_elapsed          | 988          |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0037858398 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.6         |
|    cost_value_loss       | 197          |
|    cost_values           | -0.853       |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.0143       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 138          |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 1.08         |
|    value_loss            | 293          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.155        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.155        |
| reward                   | -0.72023535  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 46           |
|    time_elapsed          | 1010         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0051546264 |
|    clip_fraction         | 0.0646       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 179          |
|    cost_values           | -0.853       |
|    entropy               | -3           |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.00933      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00638     |
|    std                   | 1.09         |
|    value_loss            | 212          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -1.0288019   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 47           |
|    time_elapsed          | 1032         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0044082077 |
|    clip_fraction         | 0.0577       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 181          |
|    cost_values           | -0.852       |
|    entropy               | -3.02        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.0105       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 67.8         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00564     |
|    std                   | 1.1          |
|    value_loss            | 147          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.85         |
| reward                   | -1.3272346   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 48           |
|    time_elapsed          | 1054         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0033925031 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 201          |
|    cost_values           | -0.852       |
|    entropy               | -3.01        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.0144       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 68.4         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 1.09         |
|    value_loss            | 147          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.55         |
| reward                   | -2.1527889   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 49           |
|    time_elapsed          | 1076         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0043414487 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.26         |
|    cost_value_loss       | 153          |
|    cost_values           | -0.853       |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.014        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 115          |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 1.09         |
|    value_loss            | 245          |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/an325vgg/model_epoch(0)
-----------------------------------
| avg_speed          | 8.03       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 8.03       |
| reward             | -1.1199254 |
| rollout/           |            |
|    ep_len_mean     | 985        |
|    ep_rew_mean     | -1.19e+03  |
| time/              |            |
|    fps             | 94         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 102400     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -1.4724437   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0037900219 |
|    clip_fraction         | 0.0339       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.99         |
|    cost_value_loss       | 138          |
|    cost_values           | -0.85        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.016        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.5         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00497     |
|    std                   | 1.1          |
|    value_loss            | 72.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.58         |
| reward                   | -1.5495856   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0043488787 |
|    clip_fraction         | 0.0278       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 205          |
|    cost_values           | -0.853       |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.0121       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.2         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 1.1          |
|    value_loss            | 90.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.37        |
| reward                   | -0.87911725 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 108544      |
| train/                   |             |
|    approx_kl             | 0.004742326 |
|    clip_fraction         | 0.0287      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.68        |
|    cost_value_loss       | 148         |
|    cost_values           | -0.846      |
|    entropy               | -3.02       |
|    entropy_loss          | -3.03       |
|    explained_variance    | -0.248      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 53.3        |
|    n_updates             | 520         |
|    policy_gradient_loss  | -0.00287    |
|    std                   | 1.1         |
|    value_loss            | 126         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.61        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.61        |
| reward                   | -0.9764744  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 110592      |
| train/                   |             |
|    approx_kl             | 0.004439902 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 201         |
|    cost_values           | -0.853      |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.0041      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 47.1        |
|    n_updates             | 530         |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 1.09        |
|    value_loss            | 106         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.482       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.482       |
| reward                   | -1.3212447  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.006586436 |
|    clip_fraction         | 0.0595      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 216         |
|    cost_values           | -0.854      |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00508     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 98.7        |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.0068     |
|    std                   | 1.1         |
|    value_loss            | 205         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.6356758   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0033003981 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 207          |
|    cost_values           | -0.854       |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.00381      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.1         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 1.1          |
|    value_loss            | 83.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.35        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.35        |
| reward                   | -0.7748515  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.003591094 |
|    clip_fraction         | 0.0285      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 179         |
|    cost_values           | -0.853      |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | -0.00419    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50          |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 1.1         |
|    value_loss            | 113         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.1915553  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 118784      |
| train/                   |             |
|    approx_kl             | 0.005884327 |
|    clip_fraction         | 0.0362      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 215         |
|    cost_values           | -0.854      |
|    entropy               | -3.04       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.00243     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 570         |
|    policy_gradient_loss  | -0.00621    |
|    std                   | 1.11        |
|    value_loss            | 299         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.6          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.6          |
| reward                   | -0.9788537   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0045634797 |
|    clip_fraction         | 0.0451       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 230          |
|    cost_values           | -0.854       |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.00409      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 210          |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00541     |
|    std                   | 1.1          |
|    value_loss            | 433          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -1.0017296   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0042839507 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.853       |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | -0.0145      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 155          |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 1.1          |
|    value_loss            | 321          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.8205143   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 264          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0037955523 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 224          |
|    cost_values           | -0.853       |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | -0.00493     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 82.1         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 1.1          |
|    value_loss            | 174          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.01         |
| reward                   | -2.232612    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0055238316 |
|    clip_fraction         | 0.0671       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 252          |
|    cost_values           | -0.854       |
|    entropy               | -3.02        |
|    entropy_loss          | -3.03        |
|    explained_variance    | -0.00192     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31           |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00665     |
|    std                   | 1.1          |
|    value_loss            | 63           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.8836508  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 14          |
|    time_elapsed          | 308         |
|    total_timesteps       | 129024      |
| train/                   |             |
|    approx_kl             | 0.003298676 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 222         |
|    cost_values           | -0.854      |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00125     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 136         |
|    n_updates             | 620         |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 1.09        |
|    value_loss            | 307         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -2.3043964   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 330          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0042870976 |
|    clip_fraction         | 0.0253       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 261          |
|    cost_values           | -0.854       |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00319      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 393          |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 1.1          |
|    value_loss            | 776          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -2.7391202  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 16          |
|    time_elapsed          | 352         |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.004947438 |
|    clip_fraction         | 0.0432      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 210         |
|    cost_values           | -0.854      |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.00371     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00512    |
|    std                   | 1.1         |
|    value_loss            | 284         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -1.3474734  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 17          |
|    time_elapsed          | 374         |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.003952367 |
|    clip_fraction         | 0.0316      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 212         |
|    cost_values           | -0.854      |
|    entropy               | -3.04       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.00448     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 183         |
|    n_updates             | 650         |
|    policy_gradient_loss  | -0.00529    |
|    std                   | 1.1         |
|    value_loss            | 363         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.89         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.89         |
| reward                   | -1.938399    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 396          |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0025640572 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 11           |
|    cost_value_loss       | 190          |
|    cost_values           | -0.855       |
|    entropy               | -3.03        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.00133      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 193          |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 1.1          |
|    value_loss            | 377          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -1.1818494  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 19          |
|    time_elapsed          | 418         |
|    total_timesteps       | 139264      |
| train/                   |             |
|    approx_kl             | 0.004345144 |
|    clip_fraction         | 0.0372      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 226         |
|    cost_values           | -0.854      |
|    entropy               | -3.04       |
|    entropy_loss          | -3.04       |
|    explained_variance    | 0.00186     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 64.6        |
|    n_updates             | 670         |
|    policy_gradient_loss  | -0.00571    |
|    std                   | 1.11        |
|    value_loss            | 146         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.44        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.44        |
| reward                   | -1.5728619  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 20          |
|    time_elapsed          | 440         |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.002872085 |
|    clip_fraction         | 0.0182      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 207         |
|    cost_values           | -0.854      |
|    entropy               | -3.06       |
|    entropy_loss          | -3.05       |
|    explained_variance    | 0.00285     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38.8        |
|    n_updates             | 680         |
|    policy_gradient_loss  | -0.00555    |
|    std                   | 1.12        |
|    value_loss            | 91.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.6139611   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 462          |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0033425177 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 184          |
|    cost_values           | -0.854       |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.00547      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.9         |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 1.12         |
|    value_loss            | 118          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0831       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0831       |
| reward                   | -0.5821276   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 484          |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0036356011 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.4         |
|    cost_value_loss       | 170          |
|    cost_values           | -0.855       |
|    entropy               | -3.07        |
|    entropy_loss          | -3.06        |
|    explained_variance    | -0.00146     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.4         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 1.12         |
|    value_loss            | 127          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.43        |
| reward                   | -0.24976015 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 23          |
|    time_elapsed          | 506         |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.004032792 |
|    clip_fraction         | 0.0297      |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 245         |
|    cost_values           | -0.855      |
|    entropy               | -3.08       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.00313     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 56.7        |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 1.13        |
|    value_loss            | 119         |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.54       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 2.54       |
| reward                   | -0.5860705 |
| rollout/                 |            |
|    ep_len_mean           | 973        |
|    ep_rew_mean           | -1.13e+03  |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 24         |
|    time_elapsed          | 528        |
|    total_timesteps       | 149504     |
| train/                   |            |
|    approx_kl             | 0.00510581 |
|    clip_fraction         | 0.0407     |
|    clip_range            | 0.2        |
|    cost_returns          | 10.8       |
|    cost_value_loss       | 183        |
|    cost_values           | -0.855     |
|    entropy               | -3.08      |
|    entropy_loss          | -3.08      |
|    explained_variance    | 0.00219    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 25.6       |
|    n_updates             | 720        |
|    policy_gradient_loss  | -0.00423   |
|    std                   | 1.13       |
|    value_loss            | 55.2       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.28        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.28        |
| reward                   | -0.8582091  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 25          |
|    time_elapsed          | 550         |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.008773803 |
|    clip_fraction         | 0.0859      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 224         |
|    cost_values           | -0.855      |
|    entropy               | -3.09       |
|    entropy_loss          | -3.08       |
|    explained_variance    | -0.000481   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00813    |
|    std                   | 1.13        |
|    value_loss            | 26.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.34        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.34        |
| reward                   | -0.5642674  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 572         |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.008433539 |
|    clip_fraction         | 0.0954      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 202         |
|    cost_values           | -0.855      |
|    entropy               | -3.12       |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.00215     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.79        |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00817    |
|    std                   | 1.15        |
|    value_loss            | 19.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.45         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.45         |
| reward                   | -0.9510422   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 594          |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0049301945 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 253          |
|    cost_values           | -0.854       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.0138      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 57.4         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00763     |
|    std                   | 1.16         |
|    value_loss            | 132          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.33         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.33         |
| reward                   | -0.73938483  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 616          |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0054844497 |
|    clip_fraction         | 0.0421       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 267          |
|    cost_values           | -0.854       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.00467     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 70.2         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 1.16         |
|    value_loss            | 148          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.09         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.09         |
| reward                   | -0.897074    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 638          |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0049816384 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 179          |
|    cost_values           | -0.855       |
|    entropy               | -3.12        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.000414     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00582     |
|    std                   | 1.15         |
|    value_loss            | 34.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.458       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.458       |
| reward                   | -1.4998662  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 30          |
|    time_elapsed          | 660         |
|    total_timesteps       | 161792      |
| train/                   |             |
|    approx_kl             | 0.005542562 |
|    clip_fraction         | 0.0401      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 268         |
|    cost_values           | -0.854      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | -0.0218     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 226         |
|    n_updates             | 780         |
|    policy_gradient_loss  | -0.00449    |
|    std                   | 1.15        |
|    value_loss            | 442         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.61        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.61        |
| reward                   | -1.578405   |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 31          |
|    time_elapsed          | 682         |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.004312778 |
|    clip_fraction         | 0.035       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 246         |
|    cost_values           | -0.855      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.00043     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 54.6        |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 1.14        |
|    value_loss            | 115         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.38         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.38         |
| reward                   | -1.3808373   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 704          |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0033113135 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 221          |
|    cost_values           | -0.854       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | -0.000225    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.3         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 1.14         |
|    value_loss            | 181          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.57        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.57        |
| reward                   | -1.3660094  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 33          |
|    time_elapsed          | 726         |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.004352841 |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 265         |
|    cost_values           | -0.855      |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | -0.0048     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 149         |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 1.14        |
|    value_loss            | 316         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.34        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.34        |
| reward                   | -0.92198044 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 34          |
|    time_elapsed          | 748         |
|    total_timesteps       | 169984      |
| train/                   |             |
|    approx_kl             | 0.004249706 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 254         |
|    cost_values           | -0.855      |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | -0.00267    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59.9        |
|    n_updates             | 820         |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 1.14        |
|    value_loss            | 126         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.7          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.7          |
| reward                   | -1.9116554   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 770          |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0048298184 |
|    clip_fraction         | 0.0487       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.5         |
|    cost_value_loss       | 214          |
|    cost_values           | -0.855       |
|    entropy               | -3.08        |
|    entropy_loss          | -3.09        |
|    explained_variance    | -0.00551     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.00623     |
|    std                   | 1.13         |
|    value_loss            | 33.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.02        |
| reward                   | -1.4675448  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 36          |
|    time_elapsed          | 792         |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.004668829 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.855      |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | -0.00123    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 55.4        |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 1.13        |
|    value_loss            | 120         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.258893    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 37           |
|    time_elapsed          | 814          |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0037998315 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 202          |
|    cost_values           | -0.855       |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.00151     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.6         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 1.13         |
|    value_loss            | 103          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.73         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.73         |
| reward                   | -2.5223334   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 38           |
|    time_elapsed          | 836          |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0047590765 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.2         |
|    cost_value_loss       | 206          |
|    cost_values           | -0.855       |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.00108      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.8         |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.13         |
|    value_loss            | 162          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.78         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.78         |
| reward                   | -1.062959    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 39           |
|    time_elapsed          | 858          |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0038132102 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 253          |
|    cost_values           | -0.855       |
|    entropy               | -3.07        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.00253     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.9         |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 1.13         |
|    value_loss            | 125          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.284        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.284        |
| reward                   | -1.2580072   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 880          |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0055747223 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 222          |
|    cost_values           | -0.855       |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | -0.000237    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.8         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00425     |
|    std                   | 1.13         |
|    value_loss            | 122          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.39        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.39        |
| reward                   | -1.9222842  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 41          |
|    time_elapsed          | 902         |
|    total_timesteps       | 184320      |
| train/                   |             |
|    approx_kl             | 0.005627002 |
|    clip_fraction         | 0.0508      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 222         |
|    cost_values           | -0.855      |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 6.72e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 51.6        |
|    n_updates             | 890         |
|    policy_gradient_loss  | -0.00583    |
|    std                   | 1.13        |
|    value_loss            | 103         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -1.9794768   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 924          |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0040794415 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 258          |
|    cost_values           | -0.855       |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.000429    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.4         |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00551     |
|    std                   | 1.13         |
|    value_loss            | 89.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.4109191   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 946          |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0038622145 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 257          |
|    cost_values           | -0.855       |
|    entropy               | -3.07        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.000368    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.5         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 1.13         |
|    value_loss            | 149          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -1.4432511   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 44           |
|    time_elapsed          | 968          |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0046234066 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 251          |
|    cost_values           | -0.855       |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | -0.000791    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.4         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 1.13         |
|    value_loss            | 104          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -1.372518    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 45           |
|    time_elapsed          | 990          |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0052520745 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 14           |
|    cost_value_loss       | 239          |
|    cost_values           | -0.855       |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.00205      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.1         |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 1.12         |
|    value_loss            | 57.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.2831163  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 46          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 194560      |
| train/                   |             |
|    approx_kl             | 0.005560378 |
|    clip_fraction         | 0.0478      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 261         |
|    cost_values           | -0.855      |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | -0.000453   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 42.7        |
|    n_updates             | 940         |
|    policy_gradient_loss  | -0.00552    |
|    std                   | 1.12        |
|    value_loss            | 90.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.79018575  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 47           |
|    time_elapsed          | 1034         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0048375637 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 258          |
|    cost_values           | -0.855       |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.000757     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 81           |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.004       |
|    std                   | 1.13         |
|    value_loss            | 182          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.734        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.734        |
| reward                   | -0.51854646  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 48           |
|    time_elapsed          | 1056         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0021929252 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 263          |
|    cost_values           | -0.855       |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.000636     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58           |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 1.13         |
|    value_loss            | 121          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.54        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.54        |
| reward                   | -0.5686404  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 49          |
|    time_elapsed          | 1078        |
|    total_timesteps       | 200704      |
| train/                   |             |
|    approx_kl             | 0.005450338 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 260         |
|    cost_values           | -0.855      |
|    entropy               | -3.09       |
|    entropy_loss          | -3.09       |
|    explained_variance    | 0.000474    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23          |
|    n_updates             | 970         |
|    policy_gradient_loss  | -0.00554    |
|    std                   | 1.13        |
|    value_loss            | 49.4        |
------------------------------------------
-----------------------------------
| avg_speed          | 3.47       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 3.47       |
| reward             | -0.7907243 |
| rollout/           |            |
|    ep_len_mean     | 972        |
|    ep_rew_mean     | -1.13e+03  |
| time/              |            |
|    fps             | 94         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 5.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.92         |
| reward                   | -0.40824664  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0037722841 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 246          |
|    cost_values           | -0.855       |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 5.84e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.2         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00541     |
|    std                   | 1.13         |
|    value_loss            | 75.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.84         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.84         |
| reward                   | -1.0723872   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0044797547 |
|    clip_fraction         | 0.059        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 258          |
|    cost_values           | -0.855       |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.00011      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.9         |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.0066      |
|    std                   | 1.14         |
|    value_loss            | 78.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.45         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.45         |
| reward                   | -0.729176    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0045483178 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.3         |
|    cost_value_loss       | 227          |
|    cost_values           | -0.855       |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | -8.81e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.6         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 1.13         |
|    value_loss            | 62.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.42452246 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.004281751 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 245         |
|    cost_values           | -0.855      |
|    entropy               | -3.09       |
|    entropy_loss          | -3.09       |
|    explained_variance    | 0.00101     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.7        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 1.14        |
|    value_loss            | 41.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.94        |
| reward                   | -1.1647137  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 212992      |
| train/                   |             |
|    approx_kl             | 0.004234152 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 228         |
|    cost_values           | -0.855      |
|    entropy               | -3.09       |
|    entropy_loss          | -3.09       |
|    explained_variance    | 0.000353    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.4        |
|    n_updates             | 1030        |
|    policy_gradient_loss  | -0.00603    |
|    std                   | 1.13        |
|    value_loss            | 39.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.66        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.66        |
| reward                   | -1.2584993  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 215040      |
| train/                   |             |
|    approx_kl             | 0.009358704 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 256         |
|    cost_values           | -0.855      |
|    entropy               | -3.13       |
|    entropy_loss          | -3.12       |
|    explained_variance    | -0.00154    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 1040        |
|    policy_gradient_loss  | -0.00809    |
|    std                   | 1.16        |
|    value_loss            | 25.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.465       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.465       |
| reward                   | -1.4672195  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 217088      |
| train/                   |             |
|    approx_kl             | 0.005955578 |
|    clip_fraction         | 0.0975      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 210         |
|    cost_values           | -0.855      |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | -0.000834   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 1050        |
|    policy_gradient_loss  | 0.00234     |
|    std                   | 1.16        |
|    value_loss            | 25.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -1.1853077   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 197          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0030113333 |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 197          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.000118    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34           |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 1.16         |
|    value_loss            | 65.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.37         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.37         |
| reward                   | -1.8299204   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0053786794 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 207          |
|    cost_values           | -0.855       |
|    entropy               | -3.12        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -7.88e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.5         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 1.15         |
|    value_loss            | 70.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -1.228583    |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 241          |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0060914624 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 179          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.12        |
|    explained_variance    | -0.00231     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.4         |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 1.16         |
|    value_loss            | 43.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.96         |
| reward                   | -0.6236986   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 263          |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0032967406 |
|    clip_fraction         | 0.00664      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 200          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 5.91e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 68.3         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 1.16         |
|    value_loss            | 162          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.59          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 7.59          |
| reward                   | -1.3479248    |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -1.1e+03      |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 13            |
|    time_elapsed          | 285           |
|    total_timesteps       | 227328        |
| train/                   |               |
|    approx_kl             | 0.00071658345 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 13.4          |
|    cost_value_loss       | 231           |
|    cost_values           | -0.855        |
|    entropy               | -3.13         |
|    entropy_loss          | -3.13         |
|    explained_variance    | -0.000832     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 55.9          |
|    n_updates             | 1100          |
|    policy_gradient_loss  | -0.000638     |
|    std                   | 1.16          |
|    value_loss            | 124           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.1          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.1          |
| reward                   | -1.5225698   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 307          |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0005309074 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.000324    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 72.2         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.000744    |
|    std                   | 1.16         |
|    value_loss            | 143          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -1.7354376   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 329          |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0069674514 |
|    clip_fraction         | 0.0621       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.4         |
|    cost_value_loss       | 229          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.000351    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.3         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.00576     |
|    std                   | 1.16         |
|    value_loss            | 45.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.45         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.45         |
| reward                   | -1.7282137   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 351          |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0024631056 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 13.9         |
|    cost_value_loss       | 240          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.00056     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.3         |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 1.16         |
|    value_loss            | 103          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.3          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.3          |
| reward                   | -1.5346254   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 373          |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0004532413 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 233          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.000202    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.7         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.000723    |
|    std                   | 1.16         |
|    value_loss            | 187          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.9          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.9          |
| reward                   | -1.5271916   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 395          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0017894047 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 13.7         |
|    cost_value_loss       | 236          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.000496     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.7         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 1.16         |
|    value_loss            | 79.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.6785336   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 19           |
|    time_elapsed          | 417          |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0037987237 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.3         |
|    cost_value_loss       | 228          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -3.52e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.4         |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 1.16         |
|    value_loss            | 77.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.92        |
| reward                   | -1.9416913  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 20          |
|    time_elapsed          | 439         |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.002156037 |
|    clip_fraction         | 0.00288     |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 237         |
|    cost_values           | -0.855      |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | -0.000277   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.1        |
|    n_updates             | 1170        |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 1.16        |
|    value_loss            | 83          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.1699024   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 461          |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0038256727 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 242          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -6.01e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.6         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 1.16         |
|    value_loss            | 52           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9540243   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 483          |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0029308666 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 245          |
|    cost_values           | -0.855       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.000246     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.8         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 1.16         |
|    value_loss            | 99.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.72531134 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 23          |
|    time_elapsed          | 505         |
|    total_timesteps       | 247808      |
| train/                   |             |
|    approx_kl             | 0.003128171 |
|    clip_fraction         | 0.00571     |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 245         |
|    cost_values           | -0.855      |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.000314    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 68          |
|    n_updates             | 1200        |
|    policy_gradient_loss  | -0.00327    |
|    std                   | 1.16        |
|    value_loss            | 136         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -1.0416186  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.005184967 |
|    clip_fraction         | 0.0451      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 254         |
|    cost_values           | -0.855      |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.000789    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.00579    |
|    std                   | 1.16        |
|    value_loss            | 28.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -1.9351231  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 25          |
|    time_elapsed          | 550         |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.008519769 |
|    clip_fraction         | 0.0919      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 239         |
|    cost_values           | -0.855      |
|    entropy               | -3.12       |
|    entropy_loss          | -3.12       |
|    explained_variance    | 0.000185    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00548    |
|    std                   | 1.15        |
|    value_loss            | 21.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.32        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.32        |
| reward                   | -1.9295745  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 572         |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.025242003 |
|    clip_fraction         | 0.261       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 258         |
|    cost_values           | -0.855      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.00961     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 78.2        |
|    n_updates             | 1230        |
|    policy_gradient_loss  | 0.0174      |
|    std                   | 1.15        |
|    value_loss            | 166         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.15         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.15         |
| reward                   | -0.42172524  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 593          |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0022098143 |
|    clip_fraction         | 0.0022       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 254          |
|    cost_values           | -0.855       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.00927      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 75.5         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 1.15         |
|    value_loss            | 160          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.85          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 7.85          |
| reward                   | -0.25702754   |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -1.14e+03     |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 28            |
|    time_elapsed          | 615           |
|    total_timesteps       | 258048        |
| train/                   |               |
|    approx_kl             | 0.00065460993 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 14.4          |
|    cost_value_loss       | 250           |
|    cost_values           | -0.855        |
|    entropy               | -3.11         |
|    entropy_loss          | -3.11         |
|    explained_variance    | 0.00433       |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 46.3          |
|    n_updates             | 1250          |
|    policy_gradient_loss  | -0.000768     |
|    std                   | 1.15          |
|    value_loss            | 94.1          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 3.97         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.97         |
| reward                   | -0.74479264  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 637          |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0047965907 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 225          |
|    cost_values           | -0.855       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.000212     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 1260         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 1.15         |
|    value_loss            | 22.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.04         |
| reward                   | -0.54815745  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 30           |
|    time_elapsed          | 660          |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0036779772 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.1         |
|    cost_value_loss       | 227          |
|    cost_values           | -0.855       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.00143      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.9         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 1.15         |
|    value_loss            | 63.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.881566    |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 682          |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0017912725 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 248          |
|    cost_values           | -0.854       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.023        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 1.15         |
|    value_loss            | 30.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -1.0800894   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 704          |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0045304643 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 218          |
|    cost_values           | -0.854       |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.00218      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.67         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 1.15         |
|    value_loss            | 17.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.945397   |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 33          |
|    time_elapsed          | 726         |
|    total_timesteps       | 268288      |
| train/                   |             |
|    approx_kl             | 0.005319791 |
|    clip_fraction         | 0.0158      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 259         |
|    cost_values           | -0.854      |
|    entropy               | -3.12       |
|    entropy_loss          | -3.12       |
|    explained_variance    | 0.0514      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.3        |
|    n_updates             | 1300        |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 1.15        |
|    value_loss            | 42.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.92         |
| reward                   | -0.88195664  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 748          |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0041627837 |
|    clip_fraction         | 0.0414       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.7         |
|    cost_value_loss       | 219          |
|    cost_values           | -0.854       |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.0115       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.4         |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.00472     |
|    std                   | 1.15         |
|    value_loss            | 64.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.729        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.729        |
| reward                   | -0.4832028   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 770          |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0050307736 |
|    clip_fraction         | 0.033        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.854       |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.0386       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 1.15         |
|    value_loss            | 29.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.98        |
| reward                   | -0.5178222  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 36          |
|    time_elapsed          | 792         |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.005082551 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 242         |
|    cost_values           | -0.853      |
|    entropy               | -3.12       |
|    entropy_loss          | -3.12       |
|    explained_variance    | -0.11       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 53.4        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 1.15        |
|    value_loss            | 91.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.5          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.5          |
| reward                   | -0.66173077  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 37           |
|    time_elapsed          | 814          |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0031413913 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 250          |
|    cost_values           | -0.851       |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | -1.22        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.6         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 1.15         |
|    value_loss            | 37.8         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.25       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.25       |
| reward                   | -1.0168432 |
| rollout/                 |            |
|    ep_len_mean           | 967        |
|    ep_rew_mean           | -1.1e+03   |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 38         |
|    time_elapsed          | 836        |
|    total_timesteps       | 278528     |
| train/                   |            |
|    approx_kl             | 0.00477717 |
|    clip_fraction         | 0.0145     |
|    clip_range            | 0.2        |
|    cost_returns          | 14.4       |
|    cost_value_loss       | 248        |
|    cost_values           | -0.859     |
|    entropy               | -3.12      |
|    entropy_loss          | -3.12      |
|    explained_variance    | 0.000783   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.25       |
|    n_updates             | 1350       |
|    policy_gradient_loss  | -0.00274   |
|    std                   | 1.15       |
|    value_loss            | 20.4       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 7.1        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.1        |
| reward                   | -0.8005547 |
| rollout/                 |            |
|    ep_len_mean           | 967        |
|    ep_rew_mean           | -1.1e+03   |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 39         |
|    time_elapsed          | 858        |
|    total_timesteps       | 280576     |
| train/                   |            |
|    approx_kl             | 0.00627761 |
|    clip_fraction         | 0.0384     |
|    clip_range            | 0.2        |
|    cost_returns          | 14.1       |
|    cost_value_loss       | 241        |
|    cost_values           | -0.866     |
|    entropy               | -3.13      |
|    entropy_loss          | -3.12      |
|    explained_variance    | 0.127      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.75       |
|    n_updates             | 1360       |
|    policy_gradient_loss  | -0.00597   |
|    std                   | 1.16       |
|    value_loss            | 20.6       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 3.27         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.27         |
| reward                   | -1.3924121   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 880          |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0048600435 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.8         |
|    cost_value_loss       | 233          |
|    cost_values           | -0.858       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.119       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.31         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 1.16         |
|    value_loss            | 22.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1876479   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 902          |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0044935658 |
|    clip_fraction         | 0.0346       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 255          |
|    cost_values           | -0.861       |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.421        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.68         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.00545     |
|    std                   | 1.16         |
|    value_loss            | 14.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.67        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.67        |
| reward                   | -1.161999   |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 42          |
|    time_elapsed          | 924         |
|    total_timesteps       | 286720      |
| train/                   |             |
|    approx_kl             | 0.004304573 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 235         |
|    cost_values           | -0.854      |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.1         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.43        |
|    n_updates             | 1390        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 1.16        |
|    value_loss            | 19.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.17        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.17        |
| reward                   | -1.1603467  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 43          |
|    time_elapsed          | 946         |
|    total_timesteps       | 288768      |
| train/                   |             |
|    approx_kl             | 0.005996396 |
|    clip_fraction         | 0.0401      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 238         |
|    cost_values           | -0.819      |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.328       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.04        |
|    n_updates             | 1400        |
|    policy_gradient_loss  | -0.00481    |
|    std                   | 1.16        |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.23        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.23        |
| reward                   | -1.0184942  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 44          |
|    time_elapsed          | 968         |
|    total_timesteps       | 290816      |
| train/                   |             |
|    approx_kl             | 0.007090519 |
|    clip_fraction         | 0.0765      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 261         |
|    cost_values           | -0.83       |
|    entropy               | -3.12       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.552       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.83        |
|    n_updates             | 1410        |
|    policy_gradient_loss  | -0.00849    |
|    std                   | 1.15        |
|    value_loss            | 6.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0800701  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 45          |
|    time_elapsed          | 990         |
|    total_timesteps       | 292864      |
| train/                   |             |
|    approx_kl             | 0.006186178 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 239         |
|    cost_values           | -0.779      |
|    entropy               | -3.12       |
|    entropy_loss          | -3.12       |
|    explained_variance    | 0.805       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.97        |
|    n_updates             | 1420        |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 1.15        |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.46517324 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 46          |
|    time_elapsed          | 1011        |
|    total_timesteps       | 294912      |
| train/                   |             |
|    approx_kl             | 0.006586566 |
|    clip_fraction         | 0.0468      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 233         |
|    cost_values           | -0.704      |
|    entropy               | -3.12       |
|    entropy_loss          | -3.12       |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.55        |
|    n_updates             | 1430        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 1.15        |
|    value_loss            | 7.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.7663796  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 47          |
|    time_elapsed          | 1033        |
|    total_timesteps       | 296960      |
| train/                   |             |
|    approx_kl             | 0.004878931 |
|    clip_fraction         | 0.0391      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 242         |
|    cost_values           | -0.722      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.577       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.95        |
|    n_updates             | 1440        |
|    policy_gradient_loss  | -0.00572    |
|    std                   | 1.15        |
|    value_loss            | 14.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.115428    |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 48           |
|    time_elapsed          | 1056         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0067097624 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 254          |
|    cost_values           | -0.679       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | -0.0661      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 1.15         |
|    value_loss            | 44.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.91         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.91         |
| reward                   | -0.91886914  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 49           |
|    time_elapsed          | 1077         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0045615966 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 239          |
|    cost_values           | -0.702       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.254        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.66         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 1.15         |
|    value_loss            | 22.4         |
-------------------------------------------
-----------------------------------
| avg_speed          | 4.08       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 4.08       |
| reward             | -0.9013742 |
| rollout/           |            |
|    ep_len_mean     | 967        |
|    ep_rew_mean     | -1.06e+03  |
| time/              |            |
|    fps             | 94         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 303104     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.0670257   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0054157036 |
|    clip_fraction         | 0.0558       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 241          |
|    cost_values           | -0.702       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.635        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 1480         |
|    policy_gradient_loss  | -0.00703     |
|    std                   | 1.14         |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.04         |
| reward                   | -1.4080218   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0041548563 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 243          |
|    cost_values           | -0.68        |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.636        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.37         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 1.14         |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -1.1129075  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 309248      |
| train/                   |             |
|    approx_kl             | 0.006980042 |
|    clip_fraction         | 0.0219      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 235         |
|    cost_values           | -0.678      |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.494       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.34        |
|    n_updates             | 1500        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 1.14        |
|    value_loss            | 26.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6311329   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0046877447 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 253          |
|    cost_values           | -0.641       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.417        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.2         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 1.14         |
|    value_loss            | 44           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.4663153  |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.008681998 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 267         |
|    cost_values           | -0.621      |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.15        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.7        |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 1.14        |
|    value_loss            | 36.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.668996    |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 153          |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0007349768 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 15.8         |
|    cost_value_loss       | 275          |
|    cost_values           | -0.654       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.332        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.5         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.000344    |
|    std                   | 1.14         |
|    value_loss            | 102          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.3456025   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 175          |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0005155381 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 15           |
|    cost_value_loss       | 257          |
|    cost_values           | -0.719       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | -0.922       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.2         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.000412    |
|    std                   | 1.14         |
|    value_loss            | 233          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -2.0752978   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 197          |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0034078532 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.5         |
|    cost_value_loss       | 213          |
|    cost_values           | -0.729       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.499        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 1.14         |
|    value_loss            | 196          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -1.7899445    |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -1.09e+03     |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 10            |
|    time_elapsed          | 219           |
|    total_timesteps       | 321536        |
| train/                   |               |
|    approx_kl             | 0.00028123707 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 15            |
|    cost_value_loss       | 259           |
|    cost_values           | -0.748        |
|    entropy               | -3.1          |
|    entropy_loss          | -3.1          |
|    explained_variance    | 0.503         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 105           |
|    n_updates             | 1560          |
|    policy_gradient_loss  | -0.000684     |
|    std                   | 1.14          |
|    value_loss            | 228           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.9966688   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 241          |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0031894736 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 246          |
|    cost_values           | -0.756       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.408        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64           |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 1.14         |
|    value_loss            | 139          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.81          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 7.81          |
| reward                   | -0.88186955   |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -1.1e+03      |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 12            |
|    time_elapsed          | 263           |
|    total_timesteps       | 325632        |
| train/                   |               |
|    approx_kl             | 0.00056515983 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 15.7          |
|    cost_value_loss       | 275           |
|    cost_values           | -0.736        |
|    entropy               | -3.1          |
|    entropy_loss          | -3.1          |
|    explained_variance    | 0.51          |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 59.9          |
|    n_updates             | 1580          |
|    policy_gradient_loss  | -0.000869     |
|    std                   | 1.14          |
|    value_loss            | 178           |
--------------------------------------------
------------------------------------------
| avg_speed                | 1.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.79        |
| reward                   | -0.32298875 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 13          |
|    time_elapsed          | 285         |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.006941402 |
|    clip_fraction         | 0.0442      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 264         |
|    cost_values           | -0.746      |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.55        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.00491    |
|    std                   | 1.14        |
|    value_loss            | 47.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.05         |
| reward                   | -0.29756567  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 307          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0073159197 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 250          |
|    cost_values           | -0.672       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.825        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00453     |
|    std                   | 1.14         |
|    value_loss            | 31.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.49         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.49         |
| reward                   | -0.37668055  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 329          |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0019729298 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 15.7         |
|    cost_value_loss       | 271          |
|    cost_values           | -0.633       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.628        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 1.14         |
|    value_loss            | 25.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.11        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.11        |
| reward                   | -0.5588922  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -1.09e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 16          |
|    time_elapsed          | 351         |
|    total_timesteps       | 333824      |
| train/                   |             |
|    approx_kl             | 0.002942916 |
|    clip_fraction         | 0.00645     |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 252         |
|    cost_values           | -0.752      |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.387       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 118         |
|    n_updates             | 1620        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 1.14        |
|    value_loss            | 257         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -1.0270321  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 17          |
|    time_elapsed          | 373         |
|    total_timesteps       | 335872      |
| train/                   |             |
|    approx_kl             | 0.004634504 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 252         |
|    cost_values           | -0.662      |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.689       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 1630        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 1.14        |
|    value_loss            | 41.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9673142   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 395          |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0014267085 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 260          |
|    cost_values           | -0.674       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.804        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.82         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 1.14         |
|    value_loss            | 23.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.659       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.659       |
| reward                   | -1.0795093  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 19          |
|    time_elapsed          | 417         |
|    total_timesteps       | 339968      |
| train/                   |             |
|    approx_kl             | 0.005865906 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 244         |
|    cost_values           | -0.681      |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.585       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.6        |
|    n_updates             | 1650        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 1.14        |
|    value_loss            | 42.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.27         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.27         |
| reward                   | -1.1380115   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 439          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0028006332 |
|    clip_fraction         | 0.00356      |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 221          |
|    cost_values           | -0.625       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.653        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.99         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 1.14         |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.38         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.38         |
| reward                   | -0.81533915  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 461          |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0061613875 |
|    clip_fraction         | 0.0576       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 245          |
|    cost_values           | -0.611       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.611        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.11         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00647     |
|    std                   | 1.14         |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.499        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.499        |
| reward                   | -0.9832199   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 483          |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0047314567 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 244          |
|    cost_values           | -0.638       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 1680         |
|    policy_gradient_loss  | -0.00495     |
|    std                   | 1.14         |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.47         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.47         |
| reward                   | -0.3976017   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 23           |
|    time_elapsed          | 505          |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0055624917 |
|    clip_fraction         | 0.0435       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 215          |
|    cost_values           | -0.676       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.794        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.55         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.00628     |
|    std                   | 1.14         |
|    value_loss            | 17           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.36         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.36         |
| reward                   | -0.6096522   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -990         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 24           |
|    time_elapsed          | 527          |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0048750173 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.3         |
|    cost_value_loss       | 220          |
|    cost_values           | -0.659       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.477        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.7         |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 1.14         |
|    value_loss            | 39.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.63        |
| reward                   | -0.52804637 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -990        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 25          |
|    time_elapsed          | 550         |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.005495219 |
|    clip_fraction         | 0.0488      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 221         |
|    cost_values           | -0.761      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.76        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.00603    |
|    std                   | 1.15        |
|    value_loss            | 7.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.58        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.58        |
| reward                   | -0.622983   |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -972        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 572         |
|    total_timesteps       | 354304      |
| train/                   |             |
|    approx_kl             | 0.003966206 |
|    clip_fraction         | 0.0348      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 249         |
|    cost_values           | -0.867      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.795       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.64        |
|    n_updates             | 1720        |
|    policy_gradient_loss  | -0.00433    |
|    std                   | 1.14        |
|    value_loss            | 17.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.74        |
| reward                   | -0.5522066  |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -961        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 27          |
|    time_elapsed          | 594         |
|    total_timesteps       | 356352      |
| train/                   |             |
|    approx_kl             | 0.004619497 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 210         |
|    cost_values           | -0.881      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 1730        |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 1.15        |
|    value_loss            | 34.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -1.2375414   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -954         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 616          |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0034927905 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 214          |
|    cost_values           | -0.802       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.474        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.86         |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 1.15         |
|    value_loss            | 6.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.04         |
| reward                   | -0.9064556   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -945         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 638          |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0037371865 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 254          |
|    cost_values           | -0.753       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.896        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.45         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 1.15         |
|    value_loss            | 7.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.39        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.39        |
| reward                   | -0.8659364  |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -942        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 30          |
|    time_elapsed          | 660         |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.004279811 |
|    clip_fraction         | 0.0413      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 228         |
|    cost_values           | -0.678      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.19        |
|    n_updates             | 1760        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 1.15        |
|    value_loss            | 4.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.894        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.894        |
| reward                   | -0.7474728   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -940         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 682          |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0057915947 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 14           |
|    cost_value_loss       | 236          |
|    cost_values           | -0.654       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.6          |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00498     |
|    std                   | 1.15         |
|    value_loss            | 5.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.93         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.93         |
| reward                   | -0.38298467  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -938         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 704          |
|    total_timesteps       | 366592       |
| train/                   |              |
|    approx_kl             | 0.0047976626 |
|    clip_fraction         | 0.0395       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 236          |
|    cost_values           | -0.694       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.719        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.96         |
|    n_updates             | 1780         |
|    policy_gradient_loss  | -0.00421     |
|    std                   | 1.15         |
|    value_loss            | 33.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.37        |
| reward                   | -0.62286204 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -933        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 33          |
|    time_elapsed          | 726         |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.006755607 |
|    clip_fraction         | 0.044       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 199         |
|    cost_values           | -0.804      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.59        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.00527    |
|    std                   | 1.15        |
|    value_loss            | 4.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.57         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.57         |
| reward                   | -0.75248665  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -930         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 748          |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0045164805 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 241          |
|    cost_values           | -0.794       |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.838        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.17         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 1.15         |
|    value_loss            | 16.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.191        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.191        |
| reward                   | -0.59731627  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -925         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 770          |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0031212005 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 252          |
|    cost_values           | -0.765       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.69         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.00489     |
|    std                   | 1.14         |
|    value_loss            | 6.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.78765154 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -920        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 36          |
|    time_elapsed          | 792         |
|    total_timesteps       | 374784      |
| train/                   |             |
|    approx_kl             | 0.005163244 |
|    clip_fraction         | 0.0571      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 226         |
|    cost_values           | -0.76       |
|    entropy               | -3.09       |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.86        |
|    n_updates             | 1820        |
|    policy_gradient_loss  | -0.00691    |
|    std                   | 1.14        |
|    value_loss            | 5.99        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.11         |
| reward                   | -0.30978063  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -914         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 37           |
|    time_elapsed          | 814          |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0060214903 |
|    clip_fraction         | 0.0399       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.821       |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.879        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.07         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00551     |
|    std                   | 1.13         |
|    value_loss            | 6            |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5072718  |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -912        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 38          |
|    time_elapsed          | 836         |
|    total_timesteps       | 378880      |
| train/                   |             |
|    approx_kl             | 0.006874594 |
|    clip_fraction         | 0.0558      |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 205         |
|    cost_values           | -0.771      |
|    entropy               | -3.09       |
|    entropy_loss          | -3.09       |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.18        |
|    n_updates             | 1840        |
|    policy_gradient_loss  | -0.00651    |
|    std                   | 1.13        |
|    value_loss            | 5.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.8638658   |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -911         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 39           |
|    time_elapsed          | 858          |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0018416432 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 246          |
|    cost_values           | -0.761       |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.472        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.4         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 1.13         |
|    value_loss            | 98.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.409        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.409        |
| reward                   | -0.69423616  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -907         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 880          |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0056069647 |
|    clip_fraction         | 0.0678       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.6         |
|    cost_value_loss       | 271          |
|    cost_values           | -0.716       |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.87         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.00722     |
|    std                   | 1.13         |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.13         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.13         |
| reward                   | -0.445508    |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -904         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 902          |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0038421827 |
|    clip_fraction         | 0.0402       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.4         |
|    cost_value_loss       | 233          |
|    cost_values           | -0.895       |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.6          |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00559     |
|    std                   | 1.13         |
|    value_loss            | 4.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -0.8695052   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -890         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 924          |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0058029653 |
|    clip_fraction         | 0.069        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 207          |
|    cost_values           | -0.843       |
|    entropy               | -3.07        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.505        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00799     |
|    std                   | 1.13         |
|    value_loss            | 8.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.82986164  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -879         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 946          |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0055066273 |
|    clip_fraction         | 0.0627       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 245          |
|    cost_values           | -0.852       |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.675        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00441     |
|    std                   | 1.12         |
|    value_loss            | 26.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.96         |
| reward                   | -1.3599912   |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 44           |
|    time_elapsed          | 968          |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0074922033 |
|    clip_fraction         | 0.0728       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 210          |
|    cost_values           | -0.8         |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.95         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.0103      |
|    std                   | 1.12         |
|    value_loss            | 5.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.5         |
| reward                   | -0.47576502 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -876        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 45          |
|    time_elapsed          | 990         |
|    total_timesteps       | 393216      |
| train/                   |             |
|    approx_kl             | 0.005737491 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 222         |
|    cost_values           | -0.84       |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.589       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.97        |
|    n_updates             | 1910        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 1.12        |
|    value_loss            | 30.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.8378639  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -864        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 46          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 395264      |
| train/                   |             |
|    approx_kl             | 0.005141087 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 224         |
|    cost_values           | -0.864      |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 1920        |
|    policy_gradient_loss  | -0.00422    |
|    std                   | 1.12        |
|    value_loss            | 18.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.66        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.66        |
| reward                   | -0.4601307  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -862        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 47          |
|    time_elapsed          | 1034        |
|    total_timesteps       | 397312      |
| train/                   |             |
|    approx_kl             | 0.005405803 |
|    clip_fraction         | 0.0459      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 212         |
|    cost_values           | -0.827      |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.811       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.96        |
|    n_updates             | 1930        |
|    policy_gradient_loss  | -0.0051     |
|    std                   | 1.12        |
|    value_loss            | 18.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.21        |
| reward                   | -0.5189958  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -853        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 48          |
|    time_elapsed          | 1056        |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.007032663 |
|    clip_fraction         | 0.0714      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 185         |
|    cost_values           | -0.872      |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00694    |
|    std                   | 1.12        |
|    value_loss            | 9.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.33        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.33        |
| reward                   | -0.8710108  |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -864        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 49          |
|    time_elapsed          | 1078        |
|    total_timesteps       | 401408      |
| train/                   |             |
|    approx_kl             | 0.005072945 |
|    clip_fraction         | 0.0471      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 212         |
|    cost_values           | -0.827      |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.84        |
|    n_updates             | 1950        |
|    policy_gradient_loss  | -0.00585    |
|    std                   | 1.12        |
|    value_loss            | 12          |
------------------------------------------
------------------------------------
| avg_speed          | 7.21        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 7.21        |
| reward             | -0.81287307 |
| rollout/           |             |
|    ep_len_mean     | 934         |
|    ep_rew_mean     | -868        |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 403456      |
------------------------------------
-------------------------------------------
| avg_speed                | 3.51         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.51         |
| reward                   | -0.53842336  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -848         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0037455861 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 242          |
|    cost_values           | -0.806       |
|    entropy               | -3.06        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.29         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.00395     |
|    std                   | 1.12         |
|    value_loss            | 5.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.16         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.16         |
| reward                   | -0.9046712   |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -823         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0068650907 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 166          |
|    cost_values           | -0.807       |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.712        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 1.12         |
|    value_loss            | 42.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.26         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.26         |
| reward                   | -0.7683177   |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -809         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0047611524 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.7         |
|    cost_value_loss       | 217          |
|    cost_values           | -0.874       |
|    entropy               | -3.05        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.603        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.06         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 1.11         |
|    value_loss            | 21.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.11        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.11        |
| reward                   | -0.61508524 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -790        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 411648      |
| train/                   |             |
|    approx_kl             | 0.004705334 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 190         |
|    cost_values           | -0.855      |
|    entropy               | -3.04       |
|    entropy_loss          | -3.05       |
|    explained_variance    | 0.729       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.37        |
|    n_updates             | 2000        |
|    policy_gradient_loss  | -0.00433    |
|    std                   | 1.11        |
|    value_loss            | 4.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.99        |
| reward                   | -0.59059244 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 413696      |
| train/                   |             |
|    approx_kl             | 0.005455585 |
|    clip_fraction         | 0.0766      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.5        |
|    cost_value_loss       | 232         |
|    cost_values           | -0.803      |
|    entropy               | -3.03       |
|    entropy_loss          | -3.04       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.81        |
|    n_updates             | 2010        |
|    policy_gradient_loss  | -0.008      |
|    std                   | 1.1         |
|    value_loss            | 7.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -0.4475583   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 153          |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0055587483 |
|    clip_fraction         | 0.0447       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 245          |
|    cost_values           | -0.834       |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.82         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.71         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.00583     |
|    std                   | 1.1          |
|    value_loss            | 7.73         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.76       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.76       |
| reward                   | -0.8775068 |
| rollout/                 |            |
|    ep_len_mean           | 914        |
|    ep_rew_mean           | -728       |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 8          |
|    time_elapsed          | 175        |
|    total_timesteps       | 417792     |
| train/                   |            |
|    approx_kl             | 0.00397631 |
|    clip_fraction         | 0.0494     |
|    clip_range            | 0.2        |
|    cost_returns          | 13.2       |
|    cost_value_loss       | 230        |
|    cost_values           | -0.842     |
|    entropy               | -3.03      |
|    entropy_loss          | -3.03      |
|    explained_variance    | 0.76       |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.99       |
|    n_updates             | 2030       |
|    policy_gradient_loss  | -0.0031    |
|    std                   | 1.1        |
|    value_loss            | 15.7       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.7925058  |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 197         |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.008112575 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.852      |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.846       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.36        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.0107     |
|    std                   | 1.1         |
|    value_loss            | 6.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.41        |
| reward                   | -0.6682842  |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 10          |
|    time_elapsed          | 219         |
|    total_timesteps       | 421888      |
| train/                   |             |
|    approx_kl             | 0.004828971 |
|    clip_fraction         | 0.0421      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 203         |
|    cost_values           | -0.815      |
|    entropy               | -3.02       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.25        |
|    n_updates             | 2050        |
|    policy_gradient_loss  | -0.0063     |
|    std                   | 1.1         |
|    value_loss            | 3.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.46        |
| reward                   | -0.69811386 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -688        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 11          |
|    time_elapsed          | 241         |
|    total_timesteps       | 423936      |
| train/                   |             |
|    approx_kl             | 0.007178987 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 228         |
|    cost_values           | -0.85       |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 2060        |
|    policy_gradient_loss  | -0.0131     |
|    std                   | 1.09        |
|    value_loss            | 4.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.86977565 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -678        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 263         |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.008598414 |
|    clip_fraction         | 0.0738      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 215         |
|    cost_values           | -0.759      |
|    entropy               | -3.01       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.689       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.00485    |
|    std                   | 1.09        |
|    value_loss            | 13.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.93         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.93         |
| reward                   | -0.29195726  |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -659         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 285          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0075346376 |
|    clip_fraction         | 0.0858       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 232          |
|    cost_values           | -0.848       |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.925        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.84         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.00963     |
|    std                   | 1.09         |
|    value_loss            | 5.16         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 4.48       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.48       |
| reward                   | -0.5226208 |
| rollout/                 |            |
|    ep_len_mean           | 920        |
|    ep_rew_mean           | -661       |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 14         |
|    time_elapsed          | 308        |
|    total_timesteps       | 430080     |
| train/                   |            |
|    approx_kl             | 0.00512636 |
|    clip_fraction         | 0.0401     |
|    clip_range            | 0.2        |
|    cost_returns          | 14.5       |
|    cost_value_loss       | 249        |
|    cost_values           | -0.843     |
|    entropy               | -3         |
|    entropy_loss          | -3.01      |
|    explained_variance    | 0.556      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.19       |
|    n_updates             | 2090       |
|    policy_gradient_loss  | -0.00527   |
|    std                   | 1.09       |
|    value_loss            | 17.2       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.53        |
| reward                   | -0.7389476  |
| rollout/                 |             |
|    ep_len_mean           | 920         |
|    ep_rew_mean           | -654        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 432128      |
| train/                   |             |
|    approx_kl             | 0.008527377 |
|    clip_fraction         | 0.0787      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.59        |
|    cost_value_loss       | 156         |
|    cost_values           | -0.779      |
|    entropy               | -3.01       |
|    entropy_loss          | -3          |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.2         |
|    n_updates             | 2100        |
|    policy_gradient_loss  | -0.00902    |
|    std                   | 1.09        |
|    value_loss            | 3.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.337        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.337        |
| reward                   | -0.4998646   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -647         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0065431674 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 264          |
|    cost_values           | -0.801       |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.754        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.43         |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 1.09         |
|    value_loss            | 4.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0644       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0644       |
| reward                   | -0.46955052  |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -640         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 374          |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0047285594 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.36         |
|    cost_value_loss       | 163          |
|    cost_values           | -0.811       |
|    entropy               | -3.01        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.821        |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.00572     |
|    std                   | 1.09         |
|    value_loss            | 2.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.76        |
| reward                   | -0.39349478 |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -637        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 396         |
|    total_timesteps       | 438272      |
| train/                   |             |
|    approx_kl             | 0.007944782 |
|    clip_fraction         | 0.0744      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 256         |
|    cost_values           | -0.873      |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 2130        |
|    policy_gradient_loss  | -0.007      |
|    std                   | 1.09        |
|    value_loss            | 17.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.64187616 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -631        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 418         |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.00463049  |
|    clip_fraction         | 0.064       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 195         |
|    cost_values           | -0.766      |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.43        |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -0.00832    |
|    std                   | 1.09        |
|    value_loss            | 4.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.64        |
| reward                   | -0.37716725 |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -620        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 440         |
|    total_timesteps       | 442368      |
| train/                   |             |
|    approx_kl             | 0.007696865 |
|    clip_fraction         | 0.0517      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 203         |
|    cost_values           | -0.773      |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.729       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 2150        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 1.09        |
|    value_loss            | 22.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.94        |
| reward                   | -0.9631629  |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -609        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 462         |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.009249632 |
|    clip_fraction         | 0.0907      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 185         |
|    cost_values           | -0.743      |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.777       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.76        |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00807    |
|    std                   | 1.09        |
|    value_loss            | 14.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.06         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.06         |
| reward                   | -0.70460856  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -617         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 484          |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0070394604 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.8         |
|    cost_value_loss       | 231          |
|    cost_values           | -0.688       |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.764        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.3         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.00634     |
|    std                   | 1.09         |
|    value_loss            | 37.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.28         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.28         |
| reward                   | -0.72361505  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -620         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 506          |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0069459295 |
|    clip_fraction         | 0.0839       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 210          |
|    cost_values           | -0.636       |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.923        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.84         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.0121      |
|    std                   | 1.09         |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.29        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.29        |
| reward                   | -0.7726129  |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -612        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.003160742 |
|    clip_fraction         | 0.0351      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 260         |
|    cost_values           | -0.741      |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3           |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 1.09        |
|    value_loss            | 9.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.75        |
| reward                   | -0.57864666 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -607        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 550         |
|    total_timesteps       | 452608      |
| train/                   |             |
|    approx_kl             | 0.005228836 |
|    clip_fraction         | 0.0854      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 259         |
|    cost_values           | -0.711      |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.508       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.56        |
|    n_updates             | 2200        |
|    policy_gradient_loss  | -0.00827    |
|    std                   | 1.09        |
|    value_loss            | 9.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.33        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.33        |
| reward                   | -0.6383791  |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -604        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 572         |
|    total_timesteps       | 454656      |
| train/                   |             |
|    approx_kl             | 0.009304653 |
|    clip_fraction         | 0.0623      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 167         |
|    cost_values           | -0.662      |
|    entropy               | -3          |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.41        |
|    n_updates             | 2210        |
|    policy_gradient_loss  | -0.00792    |
|    std                   | 1.09        |
|    value_loss            | 3.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.44765118 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -604        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 594         |
|    total_timesteps       | 456704      |
| train/                   |             |
|    approx_kl             | 0.010810221 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 238         |
|    cost_values           | -0.688      |
|    entropy               | -3          |
|    entropy_loss          | -3          |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.64        |
|    n_updates             | 2220        |
|    policy_gradient_loss  | -0.0131     |
|    std                   | 1.08        |
|    value_loss            | 3.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.02         |
| reward                   | -0.6648793   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -599         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 617          |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0058649112 |
|    clip_fraction         | 0.0557       |
|    clip_range            | 0.2          |
|    cost_returns          | 11           |
|    cost_value_loss       | 173          |
|    cost_values           | -0.688       |
|    entropy               | -2.99        |
|    entropy_loss          | -3           |
|    explained_variance    | 0.813        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.46         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00723     |
|    std                   | 1.08         |
|    value_loss            | 3.69         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.1         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.1         |
| reward                   | -0.6766359  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -596        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 639         |
|    total_timesteps       | 460800      |
| train/                   |             |
|    approx_kl             | 0.004536462 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 192         |
|    cost_values           | -0.7        |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.524       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.17        |
|    n_updates             | 2240        |
|    policy_gradient_loss  | -0.00369    |
|    std                   | 1.07        |
|    value_loss            | 13.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.38         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.38         |
| reward                   | -0.7044965   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -584         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 661          |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0062520253 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 241          |
|    cost_values           | -0.744       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.815        |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.00626     |
|    std                   | 1.07         |
|    value_loss            | 2.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.471       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.471       |
| reward                   | -0.70289    |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -582        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 683         |
|    total_timesteps       | 464896      |
| train/                   |             |
|    approx_kl             | 0.006053251 |
|    clip_fraction         | 0.0595      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 228         |
|    cost_values           | -0.637      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.605       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.02        |
|    n_updates             | 2260        |
|    policy_gradient_loss  | -0.00561    |
|    std                   | 1.07        |
|    value_loss            | 16.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.69         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.69         |
| reward                   | -0.61355597  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -583         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 705          |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0062951394 |
|    clip_fraction         | 0.0761       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 215          |
|    cost_values           | -0.685       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.805        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.41         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.00831     |
|    std                   | 1.07         |
|    value_loss            | 3.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.76        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.76        |
| reward                   | -0.3606682  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -583        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 727         |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.004252902 |
|    clip_fraction         | 0.061       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 235         |
|    cost_values           | -0.722      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.13        |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00675    |
|    std                   | 1.07        |
|    value_loss            | 5.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.07        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.07        |
| reward                   | -0.6178356  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -569        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 749         |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.008992981 |
|    clip_fraction         | 0.0625      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 232         |
|    cost_values           | -0.697      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.29        |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.00572    |
|    std                   | 1.07        |
|    value_loss            | 3.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.84         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.84         |
| reward                   | -0.53847116  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -561         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 771          |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0062382836 |
|    clip_fraction         | 0.0528       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 269          |
|    cost_values           | -0.684       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.712        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.03         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00514     |
|    std                   | 1.07         |
|    value_loss            | 2.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.6893992  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -558        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 793         |
|    total_timesteps       | 475136      |
| train/                   |             |
|    approx_kl             | 0.010026915 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 208         |
|    cost_values           | -0.677      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.768       |
|    n_updates             | 2310        |
|    policy_gradient_loss  | -0.0121     |
|    std                   | 1.07        |
|    value_loss            | 1.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.5          |
| reward                   | -0.7896959   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -558         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 815          |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0063082348 |
|    clip_fraction         | 0.0484       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.5         |
|    cost_value_loss       | 208          |
|    cost_values           | -0.666       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.896        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.78         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.00579     |
|    std                   | 1.06         |
|    value_loss            | 4.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.47        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.47        |
| reward                   | -0.59892625 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -562        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 837         |
|    total_timesteps       | 479232      |
| train/                   |             |
|    approx_kl             | 0.007120554 |
|    clip_fraction         | 0.0641      |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 216         |
|    cost_values           | -0.688      |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.36        |
|    n_updates             | 2330        |
|    policy_gradient_loss  | -0.00773    |
|    std                   | 1.06        |
|    value_loss            | 3.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.75        |
| reward                   | -0.8327268  |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -552        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 860         |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.008135218 |
|    clip_fraction         | 0.085       |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 233         |
|    cost_values           | -0.592      |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.72        |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.0106     |
|    std                   | 1.06        |
|    value_loss            | 4.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.2          |
| reward                   | -0.6743691   |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 882          |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0035049245 |
|    clip_fraction         | 0.00903      |
|    clip_range            | 0.2          |
|    cost_returns          | 13.4         |
|    cost_value_loss       | 220          |
|    cost_values           | -0.61        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.627        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.06         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 1.07         |
|    value_loss            | 26.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.82         |
| reward                   | -0.46523607  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 904          |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0074321227 |
|    clip_fraction         | 0.111        |
|    clip_range            | 0.2          |
|    cost_returns          | 13.1         |
|    cost_value_loss       | 220          |
|    cost_values           | -0.695       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.6          |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.0149      |
|    std                   | 1.06         |
|    value_loss            | 3.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.69         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.69         |
| reward                   | -0.68452585  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -550         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 926          |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0037294547 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 246          |
|    cost_values           | -0.627       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.9          |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 1.06         |
|    value_loss            | 4.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.36         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.36         |
| reward                   | -0.4580637   |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 948          |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0074103894 |
|    clip_fraction         | 0.0759       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 246          |
|    cost_values           | -0.636       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.832        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.7          |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00833     |
|    std                   | 1.06         |
|    value_loss            | 8            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.17         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.17         |
| reward                   | -0.6938861   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 969          |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0058959797 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 211          |
|    cost_values           | -0.628       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.347        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.55         |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 1.06         |
|    value_loss            | 24.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.09         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.09         |
| reward                   | -0.26353955  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -519         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 992          |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0070487065 |
|    clip_fraction         | 0.0797       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 204          |
|    cost_values           | -0.589       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.725        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.08         |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.00807     |
|    std                   | 1.06         |
|    value_loss            | 13.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.84         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.84         |
| reward                   | -0.57759225  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1014         |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0077536195 |
|    clip_fraction         | 0.0604       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 199          |
|    cost_values           | -0.629       |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.49         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.00599     |
|    std                   | 1.06         |
|    value_loss            | 4.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.09        |
| reward                   | -0.39323106 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -525        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1036        |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.00502739  |
|    clip_fraction         | 0.0605      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 250         |
|    cost_values           | -0.647      |
|    entropy               | -2.94       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.31        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00672    |
|    std                   | 1.06        |
|    value_loss            | 3.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.2718159  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -522        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1058        |
|    total_timesteps       | 499712      |
| train/                   |             |
|    approx_kl             | 0.006006587 |
|    clip_fraction         | 0.0448      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 213         |
|    cost_values           | -0.648      |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 2430        |
|    policy_gradient_loss  | -0.00536    |
|    std                   | 1.05        |
|    value_loss            | 5.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.61         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.61         |
| reward                   | -0.39985096  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -511         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1080         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0060993405 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 218          |
|    cost_values           | -0.593       |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.76         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00722     |
|    std                   | 1.05         |
|    value_loss            | 5.96         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.773       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.773       |
| reward             | -0.51799774 |
| rollout/           |             |
|    ep_len_mean     | 908         |
|    ep_rew_mean     | -512        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 503808      |
------------------------------------
------------------------------------------
| avg_speed                | 2.65        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.65        |
| reward                   | -0.58797586 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -507        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 505856      |
| train/                   |             |
|    approx_kl             | 0.005496407 |
|    clip_fraction         | 0.0593      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 249         |
|    cost_values           | -0.733      |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.92        |
|    n_updates             | 2460        |
|    policy_gradient_loss  | -0.0096     |
|    std                   | 1.05        |
|    value_loss            | 7.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.43         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.43         |
| reward                   | -0.7197899   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0060551516 |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.8         |
|    cost_value_loss       | 232          |
|    cost_values           | -0.704       |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.656        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 1.05         |
|    value_loss            | 20.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.677        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.677        |
| reward                   | -0.68848294  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -510         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0069492916 |
|    clip_fraction         | 0.0669       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.7         |
|    cost_value_loss       | 233          |
|    cost_values           | -0.759       |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.5          |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00937     |
|    std                   | 1.04         |
|    value_loss            | 3.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.1          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.1          |
| reward                   | -0.39144683  |
| rollout/                 |              |
|    ep_len_mean           | 901          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0067400765 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 250          |
|    cost_values           | -0.718       |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.3          |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00611     |
|    std                   | 1.04         |
|    value_loss            | 3.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.56        |
| reward                   | -0.2851267  |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -501        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.006092375 |
|    clip_fraction         | 0.045       |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 238         |
|    cost_values           | -0.741      |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.743       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.00424    |
|    std                   | 1.05        |
|    value_loss            | 17.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.09        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.09        |
| reward                   | -0.5453987  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -495        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.008979979 |
|    clip_fraction         | 0.0771      |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 218         |
|    cost_values           | -0.748      |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.782       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.00615    |
|    std                   | 1.04        |
|    value_loss            | 9.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.43        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.43        |
| reward                   | -0.7214713  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -493        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 518144      |
| train/                   |             |
|    approx_kl             | 0.006769152 |
|    clip_fraction         | 0.0606      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 230         |
|    cost_values           | -0.78       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.593       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.81        |
|    n_updates             | 2520        |
|    policy_gradient_loss  | -0.00723    |
|    std                   | 1.04        |
|    value_loss            | 10.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.62         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.62         |
| reward                   | -0.53937536  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 197          |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0040706946 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 245          |
|    cost_values           | -0.762       |
|    entropy               | -2.91        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.18         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 1.04         |
|    value_loss            | 4.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.58         |
| reward                   | -0.7091296   |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0026281918 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.47         |
|    cost_value_loss       | 146          |
|    cost_values           | -0.728       |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.711        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.06         |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -0.00515     |
|    std                   | 1.04         |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.74        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.74        |
| reward                   | -0.63748574 |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 11          |
|    time_elapsed          | 241         |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.007106922 |
|    clip_fraction         | 0.0762      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 237         |
|    cost_values           | -0.665      |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.63        |
|    n_updates             | 2550        |
|    policy_gradient_loss  | -0.00787    |
|    std                   | 1.04        |
|    value_loss            | 19.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.73        |
| reward                   | -0.80941546 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 263         |
|    total_timesteps       | 526336      |
| train/                   |             |
|    approx_kl             | 0.006928259 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 179         |
|    cost_values           | -0.675      |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.35        |
|    n_updates             | 2560        |
|    policy_gradient_loss  | -0.00685    |
|    std                   | 1.04        |
|    value_loss            | 3.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.68628633 |
| rollout/                 |             |
|    ep_len_mean           | 893         |
|    ep_rew_mean           | -488        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 13          |
|    time_elapsed          | 285         |
|    total_timesteps       | 528384      |
| train/                   |             |
|    approx_kl             | 0.008313334 |
|    clip_fraction         | 0.0892      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 239         |
|    cost_values           | -0.768      |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 2570        |
|    policy_gradient_loss  | -0.0132     |
|    std                   | 1.04        |
|    value_loss            | 6.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.69         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.69         |
| reward                   | -0.3979009   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 308          |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0064755175 |
|    clip_fraction         | 0.0653       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.2         |
|    cost_value_loss       | 210          |
|    cost_values           | -0.729       |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.91         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00715     |
|    std                   | 1.03         |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.58456886 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -493        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 532480      |
| train/                   |             |
|    approx_kl             | 0.005144025 |
|    clip_fraction         | 0.0525      |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 167         |
|    cost_values           | -0.753      |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.602       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.75        |
|    n_updates             | 2590        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 1.03        |
|    value_loss            | 7.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.9          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.9          |
| reward                   | -0.20917256  |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -497         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0094902385 |
|    clip_fraction         | 0.118        |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 267          |
|    cost_values           | -0.675       |
|    entropy               | -2.89        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.95         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.0166      |
|    std                   | 1.03         |
|    value_loss            | 6.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.102        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.102        |
| reward                   | -0.51173985  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 374          |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0032442287 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 178          |
|    cost_values           | -0.767       |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.811        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.919        |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 1.03         |
|    value_loss            | 2.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2            |
| reward                   | -0.32028505  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 396          |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0058115176 |
|    clip_fraction         | 0.0339       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.3         |
|    cost_value_loss       | 230          |
|    cost_values           | -0.765       |
|    entropy               | -2.88        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.653        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.66         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00355     |
|    std                   | 1.03         |
|    value_loss            | 13.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.284        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.284        |
| reward                   | -0.23306338  |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 418          |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0069178417 |
|    clip_fraction         | 0.0709       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.7         |
|    cost_value_loss       | 213          |
|    cost_values           | -0.733       |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.52         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00829     |
|    std                   | 1.02         |
|    value_loss            | 4            |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.46        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.46        |
| reward                   | -0.58021086 |
| rollout/                 |             |
|    ep_len_mean           | 884         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 440         |
|    total_timesteps       | 542720      |
| train/                   |             |
|    approx_kl             | 0.004001239 |
|    clip_fraction         | 0.0437      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 249         |
|    cost_values           | -0.786      |
|    entropy               | -2.87       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.663       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.3        |
|    n_updates             | 2640        |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 1.02        |
|    value_loss            | 25.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.82        |
| reward                   | -0.41076493 |
| rollout/                 |             |
|    ep_len_mean           | 870         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 462         |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.007065592 |
|    clip_fraction         | 0.0473      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 242         |
|    cost_values           | -0.757      |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | -0.004      |
|    std                   | 1.02        |
|    value_loss            | 8.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.56        |
| reward                   | -0.5656513  |
| rollout/                 |             |
|    ep_len_mean           | 877         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 484         |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.008196853 |
|    clip_fraction         | 0.084       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 236         |
|    cost_values           | -0.735      |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.651       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.00664    |
|    std                   | 1.02        |
|    value_loss            | 18.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.73        |
| reward                   | -0.62149525 |
| rollout/                 |             |
|    ep_len_mean           | 877         |
|    ep_rew_mean           | -458        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 506         |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.009202751 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 254         |
|    cost_values           | -0.794      |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.92        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | -0.0166     |
|    std                   | 1.02        |
|    value_loss            | 4.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.54        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.54        |
| reward                   | -0.49510393 |
| rollout/                 |             |
|    ep_len_mean           | 884         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.00936547  |
|    clip_fraction         | 0.0858      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 201         |
|    cost_values           | -0.687      |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.48        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.0113     |
|    std                   | 1.02        |
|    value_loss            | 5.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.28        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.28        |
| reward                   | -0.44062328 |
| rollout/                 |             |
|    ep_len_mean           | 884         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 550         |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.007912915 |
|    clip_fraction         | 0.0811      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 243         |
|    cost_values           | -0.772      |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.956       |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.0078     |
|    std                   | 1.02        |
|    value_loss            | 2.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.63        |
| reward                   | -0.3889299  |
| rollout/                 |             |
|    ep_len_mean           | 883         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 572         |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.008756044 |
|    clip_fraction         | 0.0621      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 243         |
|    cost_values           | -0.687      |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00861    |
|    std                   | 1.01        |
|    value_loss            | 5.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.114       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.114       |
| reward                   | -0.547639   |
| rollout/                 |             |
|    ep_len_mean           | 883         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 595         |
|    total_timesteps       | 557056      |
| train/                   |             |
|    approx_kl             | 0.009663817 |
|    clip_fraction         | 0.0563      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 205         |
|    cost_values           | -0.728      |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.427       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.95        |
|    n_updates             | 2710        |
|    policy_gradient_loss  | -0.00677    |
|    std                   | 1.01        |
|    value_loss            | 9.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.64        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.64        |
| reward                   | -0.26176223 |
| rollout/                 |             |
|    ep_len_mean           | 883         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 617         |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.010909183 |
|    clip_fraction         | 0.0891      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 206         |
|    cost_values           | -0.748      |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.819       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.4         |
|    n_updates             | 2720        |
|    policy_gradient_loss  | -0.0122     |
|    std                   | 1           |
|    value_loss            | 2.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.85         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.85         |
| reward                   | -0.40675074  |
| rollout/                 |              |
|    ep_len_mean           | 877          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 639          |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0065061813 |
|    clip_fraction         | 0.0667       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.4         |
|    cost_value_loss       | 227          |
|    cost_values           | -0.797       |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.9          |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.12         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.00891     |
|    std                   | 0.999        |
|    value_loss            | 4.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.23        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.23        |
| reward                   | -0.44362545 |
| rollout/                 |             |
|    ep_len_mean           | 871         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 661         |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.008289826 |
|    clip_fraction         | 0.0776      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 176         |
|    cost_values           | -0.739      |
|    entropy               | -2.81       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.728       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.13        |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.00658    |
|    std                   | 0.991       |
|    value_loss            | 8.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.27        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.27        |
| reward                   | -0.48591578 |
| rollout/                 |             |
|    ep_len_mean           | 871         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 683         |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.00660579  |
|    clip_fraction         | 0.0435      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.52        |
|    cost_value_loss       | 148         |
|    cost_values           | -0.759      |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00536    |
|    std                   | 0.987       |
|    value_loss            | 7           |
------------------------------------------
------------------------------------------
| avg_speed                | 5.61        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.61        |
| reward                   | -0.50446165 |
| rollout/                 |             |
|    ep_len_mean           | 871         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 705         |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.007023461 |
|    clip_fraction         | 0.0596      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 178         |
|    cost_values           | -0.733      |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.701       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.704       |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.00646    |
|    std                   | 0.98        |
|    value_loss            | 1.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.75         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.75         |
| reward                   | -0.5882704   |
| rollout/                 |              |
|    ep_len_mean           | 872          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 727          |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0051973956 |
|    clip_fraction         | 0.0696       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.1         |
|    cost_value_loss       | 157          |
|    cost_values           | -0.746       |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.702        |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 0.98         |
|    value_loss            | 1.88         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.266       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.266       |
| reward                   | -0.36678785 |
| rollout/                 |             |
|    ep_len_mean           | 871         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 749         |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.007351502 |
|    clip_fraction         | 0.0943      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.42        |
|    cost_value_loss       | 156         |
|    cost_values           | -0.747      |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.802       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00687    |
|    std                   | 0.974       |
|    value_loss            | 8.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.73        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.73        |
| reward                   | -0.5343428  |
| rollout/                 |             |
|    ep_len_mean           | 871         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 771         |
|    total_timesteps       | 573440      |
| train/                   |             |
|    approx_kl             | 0.006582761 |
|    clip_fraction         | 0.0779      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 187         |
|    cost_values           | -0.73       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.779       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 2790        |
|    policy_gradient_loss  | -0.00758    |
|    std                   | 0.971       |
|    value_loss            | 9.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.28        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.28        |
| reward                   | -0.49263442 |
| rollout/                 |             |
|    ep_len_mean           | 871         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 793         |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.008681379 |
|    clip_fraction         | 0.0724      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 205         |
|    cost_values           | -0.755      |
|    entropy               | -2.78       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.803       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.264       |
|    n_updates             | 2800        |
|    policy_gradient_loss  | -0.00731    |
|    std                   | 0.977       |
|    value_loss            | 0.647       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.21        |
| reward                   | -0.47859704 |
| rollout/                 |             |
|    ep_len_mean           | 870         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 815         |
|    total_timesteps       | 577536      |
| train/                   |             |
|    approx_kl             | 0.010010813 |
|    clip_fraction         | 0.0982      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 200         |
|    cost_values           | -0.726      |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.892       |
|    n_updates             | 2810        |
|    policy_gradient_loss  | -0.00888    |
|    std                   | 0.978       |
|    value_loss            | 2.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.13         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.13         |
| reward                   | -0.41278034  |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 837          |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0029211123 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 190          |
|    cost_values           | -0.764       |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.737        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.58         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 0.974        |
|    value_loss            | 6.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.36576515 |
| rollout/                 |             |
|    ep_len_mean           | 878         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 859         |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.006709421 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 253         |
|    cost_values           | -0.697      |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.856       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.0159     |
|    std                   | 0.975       |
|    value_loss            | 5.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.26224142  |
| rollout/                 |              |
|    ep_len_mean           | 864          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 881          |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0067600724 |
|    clip_fraction         | 0.0966       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 257          |
|    cost_values           | -0.813       |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.29         |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.00949     |
|    std                   | 0.977        |
|    value_loss            | 2.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.65531373  |
| rollout/                 |              |
|    ep_len_mean           | 863          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 903          |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0051504266 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 209          |
|    cost_values           | -0.769       |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.804        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00542     |
|    std                   | 0.977        |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.54523295 |
| rollout/                 |             |
|    ep_len_mean           | 863         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 925         |
|    total_timesteps       | 587776      |
| train/                   |             |
|    approx_kl             | 0.009500573 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 261         |
|    cost_values           | -0.691      |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.93        |
|    n_updates             | 2860        |
|    policy_gradient_loss  | -0.0121     |
|    std                   | 0.976       |
|    value_loss            | 15.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.40850082  |
| rollout/                 |              |
|    ep_len_mean           | 872          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 947          |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0042289975 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.773       |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.7          |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00557     |
|    std                   | 0.972        |
|    value_loss            | 5.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.89         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.89         |
| reward                   | -0.6390102   |
| rollout/                 |              |
|    ep_len_mean           | 872          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 969          |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0060030594 |
|    clip_fraction         | 0.0789       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 250          |
|    cost_values           | -0.741       |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.47         |
|    n_updates             | 2880         |
|    policy_gradient_loss  | -0.00922     |
|    std                   | 0.971        |
|    value_loss            | 4.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.93         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.93         |
| reward                   | -0.42360938  |
| rollout/                 |              |
|    ep_len_mean           | 870          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 992          |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0056467066 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 234          |
|    cost_values           | -0.748       |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.15         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00535     |
|    std                   | 0.971        |
|    value_loss            | 3.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.35         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.35         |
| reward                   | -0.5511344   |
| rollout/                 |              |
|    ep_len_mean           | 870          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1013         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0033530495 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.07         |
|    cost_value_loss       | 156          |
|    cost_values           | -0.742       |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.655        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.01         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.971        |
|    value_loss            | 8.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.65         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.65         |
| reward                   | -0.4892322   |
| rollout/                 |              |
|    ep_len_mean           | 870          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1036         |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0046446184 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 187          |
|    cost_values           | -0.763       |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.813        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.619        |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00644     |
|    std                   | 0.967        |
|    value_loss            | 1.48         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.85       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.85       |
| reward                   | -0.6103826 |
| rollout/                 |            |
|    ep_len_mean           | 883        |
|    ep_rew_mean           | -427       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 48         |
|    time_elapsed          | 1058       |
|    total_timesteps       | 600064     |
| train/                   |            |
|    approx_kl             | 0.00848121 |
|    clip_fraction         | 0.0574     |
|    clip_range            | 0.2        |
|    cost_returns          | 11.5       |
|    cost_value_loss       | 201        |
|    cost_values           | -0.78      |
|    entropy               | -2.76      |
|    entropy_loss          | -2.76      |
|    explained_variance    | 0.817      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.01       |
|    n_updates             | 2920       |
|    policy_gradient_loss  | -0.00663   |
|    std                   | 0.97       |
|    value_loss            | 2.2        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.11        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.11        |
| reward                   | -0.4060921  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1080        |
|    total_timesteps       | 602112      |
| train/                   |             |
|    approx_kl             | 0.005369873 |
|    clip_fraction         | 0.0524      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 233         |
|    cost_values           | -0.805      |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.11        |
|    n_updates             | 2930        |
|    policy_gradient_loss  | -0.00711    |
|    std                   | 0.967       |
|    value_loss            | 2.29        |
------------------------------------------
Directory created: PPOL_New/models/seed-testing/an325vgg/model_epoch(5)
------------------------------------
| avg_speed          | 7.86        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 7.86        |
| reward             | -0.34972885 |
| rollout/           |             |
|    ep_len_mean     | 888         |
|    ep_rew_mean     | -431        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 604160      |
------------------------------------
-------------------------------------------
| avg_speed                | 5.73         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.73         |
| reward                   | -0.47986647  |
| rollout/                 |              |
|    ep_len_mean           | 881          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0048055933 |
|    clip_fraction         | 0.0872       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 221          |
|    cost_values           | -0.823       |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.731        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.02         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | -0.00755     |
|    std                   | 0.958        |
|    value_loss            | 5.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.1          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.1          |
| reward                   | -0.4177024   |
| rollout/                 |              |
|    ep_len_mean           | 882          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 608256       |
| train/                   |              |
|    approx_kl             | 0.0068264822 |
|    clip_fraction         | 0.0455       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 246          |
|    cost_values           | -0.753       |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.573        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.76         |
|    n_updates             | 2960         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 0.956        |
|    value_loss            | 13.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.3          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.3          |
| reward                   | -0.52302724  |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0065632258 |
|    clip_fraction         | 0.0802       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 253          |
|    cost_values           | -0.751       |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.645        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.676        |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.00889     |
|    std                   | 0.952        |
|    value_loss            | 1.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.03        |
| reward                   | -0.44803098 |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 612352      |
| train/                   |             |
|    approx_kl             | 0.005823508 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 185         |
|    cost_values           | -0.768      |
|    entropy               | -2.71       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.656       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 2980        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.947       |
|    value_loss            | 5.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.71        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.71        |
| reward                   | -0.4922272  |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.007763728 |
|    clip_fraction         | 0.0476      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.15        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.82       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.51        |
|    n_updates             | 2990        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.948       |
|    value_loss            | 7.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.466        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.466        |
| reward                   | -0.4946785   |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 153          |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0066700974 |
|    clip_fraction         | 0.0773       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 235          |
|    cost_values           | -0.784       |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.69         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.9          |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00946     |
|    std                   | 0.948        |
|    value_loss            | 3.9          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.12        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.12        |
| reward                   | -0.2072619  |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.004448759 |
|    clip_fraction         | 0.0424      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 209         |
|    cost_values           | -0.755      |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.805       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.00583    |
|    std                   | 0.947       |
|    value_loss            | 4.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.33         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.33         |
| reward                   | -0.4779371   |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 197          |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0075492132 |
|    clip_fraction         | 0.0667       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 230          |
|    cost_values           | -0.818       |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.65         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.18         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.00451     |
|    std                   | 0.946        |
|    value_loss            | 7.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.49         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.49         |
| reward                   | -0.6566897   |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0029803792 |
|    clip_fraction         | 0.0538       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.4         |
|    cost_value_loss       | 233          |
|    cost_values           | -0.758       |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.792        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.04         |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.00553     |
|    std                   | 0.945        |
|    value_loss            | 4.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.24        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.24        |
| reward                   | -0.5282917  |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 11          |
|    time_elapsed          | 241         |
|    total_timesteps       | 624640      |
| train/                   |             |
|    approx_kl             | 0.004827049 |
|    clip_fraction         | 0.0219      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 210         |
|    cost_values           | -0.684      |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.619       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.05        |
|    n_updates             | 3040        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.942       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.34817696 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 626688      |
| train/                   |             |
|    approx_kl             | 0.007208957 |
|    clip_fraction         | 0.0942      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 259         |
|    cost_values           | -0.678      |
|    entropy               | -2.69       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.64        |
|    n_updates             | 3050        |
|    policy_gradient_loss  | -0.0108     |
|    std                   | 0.939       |
|    value_loss            | 3.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.41049337 |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 13          |
|    time_elapsed          | 286         |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.005693158 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 247         |
|    cost_values           | -0.712      |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.00733    |
|    std                   | 0.938       |
|    value_loss            | 9.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.87        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.87        |
| reward                   | -0.3271971  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 14          |
|    time_elapsed          | 308         |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.005031809 |
|    clip_fraction         | 0.0708      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 204         |
|    cost_values           | -0.733      |
|    entropy               | -2.68       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.563       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00724    |
|    std                   | 0.933       |
|    value_loss            | 5.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.6069778  |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 632832      |
| train/                   |             |
|    approx_kl             | 0.011051469 |
|    clip_fraction         | 0.0685      |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 220         |
|    cost_values           | -0.755      |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.732       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.86        |
|    n_updates             | 3080        |
|    policy_gradient_loss  | -0.00686    |
|    std                   | 0.932       |
|    value_loss            | 6.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.61        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.61        |
| reward                   | -0.5207917  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 16          |
|    time_elapsed          | 352         |
|    total_timesteps       | 634880      |
| train/                   |             |
|    approx_kl             | 0.006617843 |
|    clip_fraction         | 0.0804      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 210         |
|    cost_values           | -0.8        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.04        |
|    n_updates             | 3090        |
|    policy_gradient_loss  | -0.00856    |
|    std                   | 0.935       |
|    value_loss            | 2.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.65        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.65        |
| reward                   | -0.574413   |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 374         |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.008645156 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 244         |
|    cost_values           | -0.86       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.24        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.014      |
|    std                   | 0.934       |
|    value_loss            | 2.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.61        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.61        |
| reward                   | -0.41155612 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 396         |
|    total_timesteps       | 638976      |
| train/                   |             |
|    approx_kl             | 0.007888396 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 243         |
|    cost_values           | -0.747      |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.783       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.71        |
|    n_updates             | 3110        |
|    policy_gradient_loss  | -0.00768    |
|    std                   | 0.93        |
|    value_loss            | 11.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -0.67702127  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 418          |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0050798478 |
|    clip_fraction         | 0.0742       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.9         |
|    cost_value_loss       | 241          |
|    cost_values           | -0.818       |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.844        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.73         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00582     |
|    std                   | 0.927        |
|    value_loss            | 11.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.44661543 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 440         |
|    total_timesteps       | 643072      |
| train/                   |             |
|    approx_kl             | 0.00874021  |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 249         |
|    cost_values           | -0.733      |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.67        |
|    n_updates             | 3130        |
|    policy_gradient_loss  | -0.0112     |
|    std                   | 0.923       |
|    value_loss            | 6.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.18         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.18         |
| reward                   | -0.45123747  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 462          |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0047282674 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.9         |
|    cost_value_loss       | 241          |
|    cost_values           | -0.765       |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.814        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.17         |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.00538     |
|    std                   | 0.92         |
|    value_loss            | 2.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.40924856  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 484          |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0028604744 |
|    clip_fraction         | 0.0541       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 208          |
|    cost_values           | -0.789       |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.436        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00458     |
|    std                   | 0.918        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.31         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.31         |
| reward                   | -0.3002564   |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 506          |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0057672947 |
|    clip_fraction         | 0.0805       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.763       |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.864        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.0081      |
|    std                   | 0.912        |
|    value_loss            | 8.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.47        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.47        |
| reward                   | -0.5631347  |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 651264      |
| train/                   |             |
|    approx_kl             | 0.006472844 |
|    clip_fraction         | 0.0804      |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 238         |
|    cost_values           | -0.733      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.664       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 3170        |
|    policy_gradient_loss  | -0.00606    |
|    std                   | 0.907       |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.52         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.52         |
| reward                   | -0.6489094   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 550          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0045640143 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 220          |
|    cost_values           | -0.726       |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.537        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.81         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.908        |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.43        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.43        |
| reward                   | -0.35805637 |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 572         |
|    total_timesteps       | 655360      |
| train/                   |             |
|    approx_kl             | 0.012011573 |
|    clip_fraction         | 0.0972      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 215         |
|    cost_values           | -0.791      |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.06        |
|    n_updates             | 3190        |
|    policy_gradient_loss  | -0.00994    |
|    std                   | 0.909       |
|    value_loss            | 2.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.15        |
| reward                   | -0.46223262 |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 594         |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.005098843 |
|    clip_fraction         | 0.0404      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 194         |
|    cost_values           | -0.777      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.785       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.35        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.908       |
|    value_loss            | 12.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.48942554 |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 616         |
|    total_timesteps       | 659456      |
| train/                   |             |
|    approx_kl             | 0.008454696 |
|    clip_fraction         | 0.0882      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 247         |
|    cost_values           | -0.75       |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.798       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.8         |
|    n_updates             | 3210        |
|    policy_gradient_loss  | -0.0104     |
|    std                   | 0.906       |
|    value_loss            | 4.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.47174314 |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 638         |
|    total_timesteps       | 661504      |
| train/                   |             |
|    approx_kl             | 0.00876223  |
|    clip_fraction         | 0.0927      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 243         |
|    cost_values           | -0.82       |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.13        |
|    n_updates             | 3220        |
|    policy_gradient_loss  | -0.00634    |
|    std                   | 0.905       |
|    value_loss            | 7.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00351      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00351      |
| reward                   | -0.39299643  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 660          |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0056890897 |
|    clip_fraction         | 0.0571       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.1         |
|    cost_value_loss       | 226          |
|    cost_values           | -0.698       |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.807        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.15         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00784     |
|    std                   | 0.907        |
|    value_loss            | 4.41         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.57197005 |
| rollout/                 |             |
|    ep_len_mean           | 905         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 682         |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.010063817 |
|    clip_fraction         | 0.0938      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 241         |
|    cost_values           | -0.755      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.765       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.85        |
|    n_updates             | 3240        |
|    policy_gradient_loss  | -0.0067     |
|    std                   | 0.907       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.82        |
| reward                   | -0.48405442 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 704         |
|    total_timesteps       | 667648      |
| train/                   |             |
|    approx_kl             | 0.008526107 |
|    clip_fraction         | 0.0714      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 185         |
|    cost_values           | -0.773      |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.844       |
|    n_updates             | 3250        |
|    policy_gradient_loss  | -0.00812    |
|    std                   | 0.907       |
|    value_loss            | 2.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.24        |
| reward                   | -0.41052806 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 727         |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.007362523 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 253         |
|    cost_values           | -0.705      |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.696       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.31        |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.0061     |
|    std                   | 0.905       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.48639113 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 749         |
|    total_timesteps       | 671744      |
| train/                   |             |
|    approx_kl             | 0.009868109 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 246         |
|    cost_values           | -0.642      |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 3270        |
|    policy_gradient_loss  | -0.0141     |
|    std                   | 0.898       |
|    value_loss            | 5.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.53        |
| reward                   | -0.33440962 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 771         |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.004975323 |
|    clip_fraction         | 0.0502      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 251         |
|    cost_values           | -0.733      |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.724       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.12        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00525    |
|    std                   | 0.893       |
|    value_loss            | 2.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.57        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.57        |
| reward                   | -0.52395236 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 793         |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.008388905 |
|    clip_fraction         | 0.0709      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 239         |
|    cost_values           | -0.71       |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.957       |
|    n_updates             | 3290        |
|    policy_gradient_loss  | -0.00991    |
|    std                   | 0.895       |
|    value_loss            | 2.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.54        |
| reward                   | -0.2441616  |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 815         |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.010239771 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 243         |
|    cost_values           | -0.739      |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.28        |
|    n_updates             | 3300        |
|    policy_gradient_loss  | -0.00894    |
|    std                   | 0.896       |
|    value_loss            | 2.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.3554297   |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 837          |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0062143872 |
|    clip_fraction         | 0.073        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 249          |
|    cost_values           | -0.709       |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.797        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.61         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00505     |
|    std                   | 0.892        |
|    value_loss            | 6.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.15        |
| reward                   | -0.425195   |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 859         |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.012719799 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 259         |
|    cost_values           | -0.648      |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.751       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.81        |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.0156     |
|    std                   | 0.888       |
|    value_loss            | 4.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5300776  |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 881         |
|    total_timesteps       | 684032      |
| train/                   |             |
|    approx_kl             | 0.006989644 |
|    clip_fraction         | 0.0995      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 264         |
|    cost_values           | -0.754      |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.21        |
|    n_updates             | 3330        |
|    policy_gradient_loss  | -0.0113     |
|    std                   | 0.887       |
|    value_loss            | 2.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.8          |
| reward                   | -0.44782797  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 902          |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0066835457 |
|    clip_fraction         | 0.057        |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 263          |
|    cost_values           | -0.701       |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.7          |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00701     |
|    std                   | 0.885        |
|    value_loss            | 3.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.63414234 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 42          |
|    time_elapsed          | 924         |
|    total_timesteps       | 688128      |
| train/                   |             |
|    approx_kl             | 0.01767994  |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 190         |
|    cost_values           | -0.642      |
|    entropy               | -2.55       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.816       |
|    n_updates             | 3350        |
|    policy_gradient_loss  | -0.0129     |
|    std                   | 0.877       |
|    value_loss            | 1.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.23         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.23         |
| reward                   | -0.3396154   |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 947          |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0074714096 |
|    clip_fraction         | 0.0801       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.4         |
|    cost_value_loss       | 267          |
|    cost_values           | -0.71        |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.649        |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.00673     |
|    std                   | 0.874        |
|    value_loss            | 1.57         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.3252342  |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 969         |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.003754864 |
|    clip_fraction         | 0.0619      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 232         |
|    cost_values           | -0.759      |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 3370        |
|    policy_gradient_loss  | -0.00539    |
|    std                   | 0.87        |
|    value_loss            | 19.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.57548213 |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 990         |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.007329368 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 241         |
|    cost_values           | -0.764      |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.837       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.38        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.0125     |
|    std                   | 0.868       |
|    value_loss            | 3.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.521779   |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1013        |
|    total_timesteps       | 696320      |
| train/                   |             |
|    approx_kl             | 0.004283328 |
|    clip_fraction         | 0.0505      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 259         |
|    cost_values           | -0.726      |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.89        |
|    n_updates             | 3390        |
|    policy_gradient_loss  | -0.00482    |
|    std                   | 0.868       |
|    value_loss            | 8.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53144056  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1035         |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0058896095 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | 15           |
|    cost_value_loss       | 259          |
|    cost_values           | -0.633       |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.737        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.76         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.00798     |
|    std                   | 0.868        |
|    value_loss            | 3.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.422       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.422       |
| reward                   | -0.47157425 |
| rollout/                 |             |
|    ep_len_mean           | 881         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 700416      |
| train/                   |             |
|    approx_kl             | 0.006192539 |
|    clip_fraction         | 0.0441      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 245         |
|    cost_values           | -0.724      |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.381       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.96        |
|    n_updates             | 3410        |
|    policy_gradient_loss  | -0.00521    |
|    std                   | 0.865       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.45        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.45        |
| reward                   | -0.37488842 |
| rollout/                 |             |
|    ep_len_mean           | 875         |
|    ep_rew_mean           | -386        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1079        |
|    total_timesteps       | 702464      |
| train/                   |             |
|    approx_kl             | 0.007916524 |
|    clip_fraction         | 0.0545      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.5        |
|    cost_value_loss       | 233         |
|    cost_values           | -0.692      |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.426       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.79        |
|    n_updates             | 3420        |
|    policy_gradient_loss  | -0.00412    |
|    std                   | 0.865       |
|    value_loss            | 16.7        |
------------------------------------------
------------------------------------
| avg_speed          | 8.02        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.49087048 |
| rollout/           |             |
|    ep_len_mean     | 869         |
|    ep_rew_mean     | -381        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 704512      |
------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.35479233 |
| rollout/                 |             |
|    ep_len_mean           | 855         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.005691778 |
|    clip_fraction         | 0.0547      |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 207         |
|    cost_values           | -0.665      |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.672       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.00709    |
|    std                   | 0.859       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.5220217  |
| rollout/                 |             |
|    ep_len_mean           | 835         |
|    ep_rew_mean           | -361        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 708608      |
| train/                   |             |
|    approx_kl             | 0.006886639 |
|    clip_fraction         | 0.0768      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 258         |
|    cost_values           | -0.735      |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.07        |
|    n_updates             | 3450        |
|    policy_gradient_loss  | -0.0078     |
|    std                   | 0.858       |
|    value_loss            | 9.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.611        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.611        |
| reward                   | -0.3967322   |
| rollout/                 |              |
|    ep_len_mean           | 827          |
|    ep_rew_mean           | -358         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0046934835 |
|    clip_fraction         | 0.0533       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 203          |
|    cost_values           | -0.704       |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.509        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00669     |
|    std                   | 0.856        |
|    value_loss            | 18.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.35604152 |
| rollout/                 |             |
|    ep_len_mean           | 829         |
|    ep_rew_mean           | -359        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.008377424 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 235         |
|    cost_values           | -0.669      |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.749       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.47        |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.00848    |
|    std                   | 0.856       |
|    value_loss            | 9.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.2602829  |
| rollout/                 |             |
|    ep_len_mean           | 813         |
|    ep_rew_mean           | -352        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 714752      |
| train/                   |             |
|    approx_kl             | 0.007209568 |
|    clip_fraction         | 0.0767      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 264         |
|    cost_values           | -0.72       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.655       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 3480        |
|    policy_gradient_loss  | -0.00582    |
|    std                   | 0.853       |
|    value_loss            | 6.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.45006138  |
| rollout/                 |              |
|    ep_len_mean           | 805          |
|    ep_rew_mean           | -346         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 153          |
|    total_timesteps       | 716800       |
| train/                   |              |
|    approx_kl             | 0.0052031805 |
|    clip_fraction         | 0.0455       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.9         |
|    cost_value_loss       | 239          |
|    cost_values           | -0.736       |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.871        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.83         |
|    n_updates             | 3490         |
|    policy_gradient_loss  | -0.00484     |
|    std                   | 0.853        |
|    value_loss            | 7.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.41976342 |
| rollout/                 |             |
|    ep_len_mean           | 797         |
|    ep_rew_mean           | -339        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.0091332   |
|    clip_fraction         | 0.0791      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 254         |
|    cost_values           | -0.654      |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.573       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.52        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00741    |
|    std                   | 0.852       |
|    value_loss            | 8.67        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.4176675   |
| rollout/                 |              |
|    ep_len_mean           | 790          |
|    ep_rew_mean           | -334         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0044770027 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 267          |
|    cost_values           | -0.669       |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.492        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.71         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.85         |
|    value_loss            | 8.65         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.82        |
| reward                   | -0.28241733 |
| rollout/                 |             |
|    ep_len_mean           | 775         |
|    ep_rew_mean           | -327        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 10          |
|    time_elapsed          | 220         |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.008401204 |
|    clip_fraction         | 0.098       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 226         |
|    cost_values           | -0.707      |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.646       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 3520        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 0.85        |
|    value_loss            | 8.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5734009   |
| rollout/                 |              |
|    ep_len_mean           | 766          |
|    ep_rew_mean           | -320         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0060531367 |
|    clip_fraction         | 0.0803       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.695       |
|    entropy               | -2.47        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.573        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.31         |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00562     |
|    std                   | 0.848        |
|    value_loss            | 14.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.6722119  |
| rollout/                 |             |
|    ep_len_mean           | 758         |
|    ep_rew_mean           | -318        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 727040      |
| train/                   |             |
|    approx_kl             | 0.007885168 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 255         |
|    cost_values           | -0.773      |
|    entropy               | -2.46       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.632       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.12        |
|    n_updates             | 3540        |
|    policy_gradient_loss  | -0.00814    |
|    std                   | 0.843       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5014104   |
| rollout/                 |              |
|    ep_len_mean           | 745          |
|    ep_rew_mean           | -309         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0057686395 |
|    clip_fraction         | 0.0603       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.74        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.67         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.64         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.00539     |
|    std                   | 0.839        |
|    value_loss            | 11.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.37         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.37         |
| reward                   | -0.4671529   |
| rollout/                 |              |
|    ep_len_mean           | 728          |
|    ep_rew_mean           | -301         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 308          |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0034364094 |
|    clip_fraction         | 0.0791       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 268          |
|    cost_values           | -0.695       |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.702        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.32         |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 0.839        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.75        |
| reward                   | -0.3346367  |
| rollout/                 |             |
|    ep_len_mean           | 712         |
|    ep_rew_mean           | -292        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 733184      |
| train/                   |             |
|    approx_kl             | 0.005197187 |
|    clip_fraction         | 0.0405      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 256         |
|    cost_values           | -0.691      |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.641       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.76        |
|    n_updates             | 3570        |
|    policy_gradient_loss  | -0.00462    |
|    std                   | 0.841       |
|    value_loss            | 15.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.31         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.31         |
| reward                   | -0.32147884  |
| rollout/                 |              |
|    ep_len_mean           | 697          |
|    ep_rew_mean           | -285         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0042418903 |
|    clip_fraction         | 0.0481       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 246          |
|    cost_values           | -0.723       |
|    entropy               | -2.45        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.524        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.36         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.00583     |
|    std                   | 0.839        |
|    value_loss            | 17.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.33200735  |
| rollout/                 |              |
|    ep_len_mean           | 703          |
|    ep_rew_mean           | -287         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 374          |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0065005934 |
|    clip_fraction         | 0.0379       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 241          |
|    cost_values           | -0.736       |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.687        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.71         |
|    n_updates             | 3590         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 0.838        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.484112   |
| rollout/                 |             |
|    ep_len_mean           | 691         |
|    ep_rew_mean           | -281        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 396         |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.005961636 |
|    clip_fraction         | 0.062       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.6        |
|    cost_value_loss       | 271         |
|    cost_values           | -0.709      |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.709       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.00635    |
|    std                   | 0.839       |
|    value_loss            | 8.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3300439  |
| rollout/                 |             |
|    ep_len_mean           | 655         |
|    ep_rew_mean           | -265        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 418         |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.008158377 |
|    clip_fraction         | 0.0648      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 241         |
|    cost_values           | -0.75       |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.779       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.41        |
|    n_updates             | 3610        |
|    policy_gradient_loss  | -0.00456    |
|    std                   | 0.839       |
|    value_loss            | 9.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.28        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.28        |
| reward                   | -0.37948206 |
| rollout/                 |             |
|    ep_len_mean           | 645         |
|    ep_rew_mean           | -260        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 440         |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.005140895 |
|    clip_fraction         | 0.0531      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 246         |
|    cost_values           | -0.685      |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.668       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.72        |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.00558    |
|    std                   | 0.839       |
|    value_loss            | 17.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33796337 |
| rollout/                 |             |
|    ep_len_mean           | 625         |
|    ep_rew_mean           | -248        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 463         |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.006330916 |
|    clip_fraction         | 0.0677      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 255         |
|    cost_values           | -0.695      |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.629       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.88        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.838       |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.35552338  |
| rollout/                 |              |
|    ep_len_mean           | 625          |
|    ep_rew_mean           | -247         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 485          |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0036712505 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 243          |
|    cost_values           | -0.749       |
|    entropy               | -2.44        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.54         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.74         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.835        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -0.37670568  |
| rollout/                 |              |
|    ep_len_mean           | 610          |
|    ep_rew_mean           | -241         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 507          |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0066909543 |
|    clip_fraction         | 0.088        |
|    clip_range            | 0.2          |
|    cost_returns          | 15.7         |
|    cost_value_loss       | 273          |
|    cost_values           | -0.726       |
|    entropy               | -2.42        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.721        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.997        |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.0086      |
|    std                   | 0.827        |
|    value_loss            | 2.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5565738   |
| rollout/                 |              |
|    ep_len_mean           | 614          |
|    ep_rew_mean           | -241         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 529          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0132421255 |
|    clip_fraction         | 0.186        |
|    clip_range            | 0.2          |
|    cost_returns          | 15.3         |
|    cost_value_loss       | 265          |
|    cost_values           | -0.706       |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.584        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.58         |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.00774     |
|    std                   | 0.825        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.33423573  |
| rollout/                 |              |
|    ep_len_mean           | 613          |
|    ep_rew_mean           | -240         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 551          |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0058246464 |
|    clip_fraction         | 0.0507       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 255          |
|    cost_values           | -0.771       |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.642        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.19         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00551     |
|    std                   | 0.826        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.41389054 |
| rollout/                 |             |
|    ep_len_mean           | 617         |
|    ep_rew_mean           | -242        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 573         |
|    total_timesteps       | 755712      |
| train/                   |             |
|    approx_kl             | 0.008434641 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.7        |
|    cost_value_loss       | 274         |
|    cost_values           | -0.716      |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.93        |
|    n_updates             | 3680        |
|    policy_gradient_loss  | -0.00967    |
|    std                   | 0.828       |
|    value_loss            | 5.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.30472574 |
| rollout/                 |             |
|    ep_len_mean           | 596         |
|    ep_rew_mean           | -232        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 595         |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.009808832 |
|    clip_fraction         | 0.0667      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.7        |
|    cost_value_loss       | 273         |
|    cost_values           | -0.679      |
|    entropy               | -2.41       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.754       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.811       |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.00662    |
|    std                   | 0.825       |
|    value_loss            | 2.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.26        |
| reward                   | -0.4619587  |
| rollout/                 |             |
|    ep_len_mean           | 596         |
|    ep_rew_mean           | -232        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 617         |
|    total_timesteps       | 759808      |
| train/                   |             |
|    approx_kl             | 0.007830858 |
|    clip_fraction         | 0.0699      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 259         |
|    cost_values           | -0.693      |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.664       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.05        |
|    n_updates             | 3700        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.822       |
|    value_loss            | 15.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.49008742  |
| rollout/                 |              |
|    ep_len_mean           | 579          |
|    ep_rew_mean           | -224         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 639          |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0072119674 |
|    clip_fraction         | 0.0607       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.4         |
|    cost_value_loss       | 266          |
|    cost_values           | -0.665       |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.67         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.69         |
|    n_updates             | 3710         |
|    policy_gradient_loss  | -0.00594     |
|    std                   | 0.82         |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.15        |
| reward                   | -0.33835438 |
| rollout/                 |             |
|    ep_len_mean           | 586         |
|    ep_rew_mean           | -227        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 661         |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.008343145 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 252         |
|    cost_values           | -0.72       |
|    entropy               | -2.39       |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.594       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.6        |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.00798    |
|    std                   | 0.817       |
|    value_loss            | 17.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.37        |
| reward                   | -0.21886511 |
| rollout/                 |             |
|    ep_len_mean           | 575         |
|    ep_rew_mean           | -222        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 683         |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.00426358  |
|    clip_fraction         | 0.0426      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.6        |
|    cost_value_loss       | 270         |
|    cost_values           | -0.666      |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.09        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00373    |
|    std                   | 0.814       |
|    value_loss            | 5.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 1            |
| max_speed                | 8.03         |
| reward                   | -0.109082654 |
| rollout/                 |              |
|    ep_len_mean           | 552          |
|    ep_rew_mean           | -212         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 705          |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.006042494  |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 248          |
|    cost_values           | -0.672       |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.653        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.68         |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.00451     |
|    std                   | 0.811        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4636774   |
| rollout/                 |              |
|    ep_len_mean           | 553          |
|    ep_rew_mean           | -212         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 728          |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0054254197 |
|    clip_fraction         | 0.0507       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 260          |
|    cost_values           | -0.692       |
|    entropy               | -2.37        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.683        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.19         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 0.81         |
|    value_loss            | 18.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.75        |
| reward                   | -0.3649208  |
| rollout/                 |             |
|    ep_len_mean           | 558         |
|    ep_rew_mean           | -215        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 750         |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.006048411 |
|    clip_fraction         | 0.0626      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 267         |
|    cost_values           | -0.707      |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.451       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.85        |
|    n_updates             | 3760        |
|    policy_gradient_loss  | -0.00397    |
|    std                   | 0.809       |
|    value_loss            | 12.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.3063536  |
| rollout/                 |             |
|    ep_len_mean           | 537         |
|    ep_rew_mean           | -207        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 772         |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.012568721 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.6        |
|    cost_value_loss       | 271         |
|    cost_values           | -0.708      |
|    entropy               | -2.36       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.793       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.85        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00944    |
|    std                   | 0.804       |
|    value_loss            | 8.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.49591854 |
| rollout/                 |             |
|    ep_len_mean           | 533         |
|    ep_rew_mean           | -205        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 794         |
|    total_timesteps       | 776192      |
| train/                   |             |
|    approx_kl             | 0.010438802 |
|    clip_fraction         | 0.0922      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 254         |
|    cost_values           | -0.718      |
|    entropy               | -2.35       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.699       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.37        |
|    n_updates             | 3780        |
|    policy_gradient_loss  | -0.00805    |
|    std                   | 0.8         |
|    value_loss            | 16.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.29764953 |
| rollout/                 |             |
|    ep_len_mean           | 544         |
|    ep_rew_mean           | -209        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 816         |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.008280776 |
|    clip_fraction         | 0.0918      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 264         |
|    cost_values           | -0.721      |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.543       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.00571    |
|    std                   | 0.795       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.34432548 |
| rollout/                 |             |
|    ep_len_mean           | 534         |
|    ep_rew_mean           | -205        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 838         |
|    total_timesteps       | 780288      |
| train/                   |             |
|    approx_kl             | 0.009103683 |
|    clip_fraction         | 0.0775      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.7        |
|    cost_value_loss       | 273         |
|    cost_values           | -0.69       |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.598       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.32        |
|    n_updates             | 3800        |
|    policy_gradient_loss  | -0.00905    |
|    std                   | 0.794       |
|    value_loss            | 11          |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.38         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.38         |
| reward                   | -0.33019277  |
| rollout/                 |              |
|    ep_len_mean           | 529          |
|    ep_rew_mean           | -202         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 860          |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0076079257 |
|    clip_fraction         | 0.0675       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 249          |
|    cost_values           | -0.68        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.663        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8            |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.00621     |
|    std                   | 0.792        |
|    value_loss            | 14.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.27267593  |
| rollout/                 |              |
|    ep_len_mean           | 527          |
|    ep_rew_mean           | -202         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 882          |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0098715555 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 259          |
|    cost_values           | -0.707       |
|    entropy               | -2.32        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.674        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.00775     |
|    std                   | 0.79         |
|    value_loss            | 13.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.36817318  |
| rollout/                 |              |
|    ep_len_mean           | 537          |
|    ep_rew_mean           | -205         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 904          |
|    total_timesteps       | 786432       |
| train/                   |              |
|    approx_kl             | 0.0045882827 |
|    clip_fraction         | 0.0644       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.8         |
|    cost_value_loss       | 274          |
|    cost_values           | -0.703       |
|    entropy               | -2.33        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.786        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.72         |
|    n_updates             | 3830         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.792        |
|    value_loss            | 3.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38235798 |
| rollout/                 |             |
|    ep_len_mean           | 543         |
|    ep_rew_mean           | -206        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 927         |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.010179208 |
|    clip_fraction         | 0.0839      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 264         |
|    cost_values           | -0.711      |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.706       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.96        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 0.792       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.5724697  |
| rollout/                 |             |
|    ep_len_mean           | 546         |
|    ep_rew_mean           | -205        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 949         |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.010874157 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.8        |
|    cost_value_loss       | 275         |
|    cost_values           | -0.678      |
|    entropy               | -2.32       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.716       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.27        |
|    n_updates             | 3850        |
|    policy_gradient_loss  | -0.00724    |
|    std                   | 0.791       |
|    value_loss            | 4.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.61        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.61        |
| reward                   | -0.40399572 |
| rollout/                 |             |
|    ep_len_mean           | 539         |
|    ep_rew_mean           | -201        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 971         |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.008533222 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 262         |
|    cost_values           | -0.732      |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.677       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.9         |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.0086     |
|    std                   | 0.788       |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3991784  |
| rollout/                 |             |
|    ep_len_mean           | 537         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 993         |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.006645159 |
|    clip_fraction         | 0.0603      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 268         |
|    cost_values           | -0.733      |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.371       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.94        |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.00479    |
|    std                   | 0.785       |
|    value_loss            | 9.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.30771896 |
| rollout/                 |             |
|    ep_len_mean           | 544         |
|    ep_rew_mean           | -201        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1015        |
|    total_timesteps       | 796672      |
| train/                   |             |
|    approx_kl             | 0.011751463 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 257         |
|    cost_values           | -0.707      |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.356       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.92        |
|    n_updates             | 3880        |
|    policy_gradient_loss  | -0.0069     |
|    std                   | 0.785       |
|    value_loss            | 15.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.1         |
| reward                   | -0.43085817 |
| rollout/                 |             |
|    ep_len_mean           | 524         |
|    ep_rew_mean           | -193        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1037        |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.006446819 |
|    clip_fraction         | 0.0521      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.6        |
|    cost_value_loss       | 271         |
|    cost_values           | -0.714      |
|    entropy               | -2.3        |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.725       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.785       |
|    value_loss            | 9.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.36302784  |
| rollout/                 |              |
|    ep_len_mean           | 517          |
|    ep_rew_mean           | -190         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1059         |
|    total_timesteps       | 800768       |
| train/                   |              |
|    approx_kl             | 0.0045894803 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 240          |
|    cost_values           | -0.696       |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.587        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.82         |
|    n_updates             | 3900         |
|    policy_gradient_loss  | -0.00402     |
|    std                   | 0.785        |
|    value_loss            | 18.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.4426919   |
| rollout/                 |              |
|    ep_len_mean           | 499          |
|    ep_rew_mean           | -182         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1082         |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0107676145 |
|    clip_fraction         | 0.094        |
|    clip_range            | 0.2          |
|    cost_returns          | 15.3         |
|    cost_value_loss       | 263          |
|    cost_values           | -0.681       |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.639        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.59         |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.0069      |
|    std                   | 0.781        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------
| avg_speed          | 7.84        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 7.84        |
| reward             | -0.35792944 |
| rollout/           |             |
|    ep_len_mean     | 500         |
|    ep_rew_mean     | -183        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 804864      |
------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.4913485  |
| rollout/                 |             |
|    ep_len_mean           | 500         |
|    ep_rew_mean           | -182        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.006507938 |
|    clip_fraction         | 0.0753      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.8        |
|    cost_value_loss       | 274         |
|    cost_values           | -0.686      |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.652       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 3930        |
|    policy_gradient_loss  | -0.00818    |
|    std                   | 0.778       |
|    value_loss            | 4.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.25566357  |
| rollout/                 |              |
|    ep_len_mean           | 496          |
|    ep_rew_mean           | -179         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0047437707 |
|    clip_fraction         | 0.0634       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.3         |
|    cost_value_loss       | 260          |
|    cost_values           | -0.659       |
|    entropy               | -2.27        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.648        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.771        |
|    value_loss            | 13           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.2026829  |
| rollout/                 |             |
|    ep_len_mean           | 490         |
|    ep_rew_mean           | -176        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.006058056 |
|    clip_fraction         | 0.0813      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 266         |
|    cost_values           | -0.667      |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.732       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.88        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.766       |
|    value_loss            | 9.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.04        |
| reward                   | -0.24114485 |
| rollout/                 |             |
|    ep_len_mean           | 492         |
|    ep_rew_mean           | -176        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.006750988 |
|    clip_fraction         | 0.0924      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 266         |
|    cost_values           | -0.678      |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.662       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.77        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00797    |
|    std                   | 0.765       |
|    value_loss            | 9.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.19335613 |
| rollout/                 |             |
|    ep_len_mean           | 491         |
|    ep_rew_mean           | -174        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.008998306 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 261         |
|    cost_values           | -0.699      |
|    entropy               | -2.24       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.576       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.00652    |
|    std                   | 0.761       |
|    value_loss            | 12.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.48        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.48        |
| reward                   | -0.42817095 |
| rollout/                 |             |
|    ep_len_mean           | 493         |
|    ep_rew_mean           | -174        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 817152      |
| train/                   |             |
|    approx_kl             | 0.009000521 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 262         |
|    cost_values           | -0.668      |
|    entropy               | -2.25       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.594       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.93        |
|    n_updates             | 3980        |
|    policy_gradient_loss  | -0.00722    |
|    std                   | 0.764       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.36608383 |
| rollout/                 |             |
|    ep_len_mean           | 494         |
|    ep_rew_mean           | -173        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.005524011 |
|    clip_fraction         | 0.0715      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 262         |
|    cost_values           | -0.709      |
|    entropy               | -2.24       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.572       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.64        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.762       |
|    value_loss            | 9.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.23155268 |
| rollout/                 |             |
|    ep_len_mean           | 482         |
|    ep_rew_mean           | -167        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 197         |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.013962943 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 267         |
|    cost_values           | -0.691      |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.28        |
|    n_updates             | 4000        |
|    policy_gradient_loss  | -0.00577    |
|    std                   | 0.76        |
|    value_loss            | 8.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.39747915  |
| rollout/                 |              |
|    ep_len_mean           | 476          |
|    ep_rew_mean           | -165         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0051923823 |
|    clip_fraction         | 0.0431       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 257          |
|    cost_values           | -0.653       |
|    entropy               | -2.23        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.588        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.758        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.17696272  |
| rollout/                 |              |
|    ep_len_mean           | 487          |
|    ep_rew_mean           | -169         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0074051525 |
|    clip_fraction         | 0.0578       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 261          |
|    cost_values           | -0.706       |
|    entropy               | -2.24        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.421        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.43         |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00449     |
|    std                   | 0.761        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.20063241 |
| rollout/                 |             |
|    ep_len_mean           | 470         |
|    ep_rew_mean           | -162        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.009424988 |
|    clip_fraction         | 0.0727      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.7        |
|    cost_value_loss       | 274         |
|    cost_values           | -0.682      |
|    entropy               | -2.23       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.482       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.76        |
|    value_loss            | 7.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.40631253  |
| rollout/                 |              |
|    ep_len_mean           | 466          |
|    ep_rew_mean           | -160         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 829440       |
| train/                   |              |
|    approx_kl             | 0.0066467733 |
|    clip_fraction         | 0.0878       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 249          |
|    cost_values           | -0.695       |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.741        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.02         |
|    n_updates             | 4040         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.76         |
|    value_loss            | 15.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.04        |
| reward                   | -0.38787356 |
| rollout/                 |             |
|    ep_len_mean           | 437         |
|    ep_rew_mean           | -150        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 308         |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.008050912 |
|    clip_fraction         | 0.0953      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 261         |
|    cost_values           | -0.686      |
|    entropy               | -2.22       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.649       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.76        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.00432    |
|    std                   | 0.758       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.3390215  |
| rollout/                 |             |
|    ep_len_mean           | 423         |
|    ep_rew_mean           | -145        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.006174066 |
|    clip_fraction         | 0.0615      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 250         |
|    cost_values           | -0.687      |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.517       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.16        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.756       |
|    value_loss            | 14.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.20621787 |
| rollout/                 |             |
|    ep_len_mean           | 414         |
|    ep_rew_mean           | -142        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 352         |
|    total_timesteps       | 835584      |
| train/                   |             |
|    approx_kl             | 0.008301346 |
|    clip_fraction         | 0.0648      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.649      |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.606       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 4070        |
|    policy_gradient_loss  | -0.00424    |
|    std                   | 0.752       |
|    value_loss            | 9.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.38483799 |
| rollout/                 |             |
|    ep_len_mean           | 406         |
|    ep_rew_mean           | -140        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 375         |
|    total_timesteps       | 837632      |
| train/                   |             |
|    approx_kl             | 0.014574055 |
|    clip_fraction         | 0.0968      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 257         |
|    cost_values           | -0.681      |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.36        |
|    n_updates             | 4080        |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.752       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.34923336 |
| rollout/                 |             |
|    ep_len_mean           | 410         |
|    ep_rew_mean           | -141        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 397         |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.008219903 |
|    clip_fraction         | 0.096       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.671      |
|    entropy               | -2.19       |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.709       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.00506    |
|    std                   | 0.747       |
|    value_loss            | 8.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.52        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.52        |
| reward                   | -0.527505   |
| rollout/                 |             |
|    ep_len_mean           | 412         |
|    ep_rew_mean           | -142        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 419         |
|    total_timesteps       | 841728      |
| train/                   |             |
|    approx_kl             | 0.005475309 |
|    clip_fraction         | 0.0714      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 262         |
|    cost_values           | -0.667      |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.619       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.24        |
|    n_updates             | 4100        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.745       |
|    value_loss            | 11.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.24664797 |
| rollout/                 |             |
|    ep_len_mean           | 412         |
|    ep_rew_mean           | -142        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 441         |
|    total_timesteps       | 843776      |
| train/                   |             |
|    approx_kl             | 0.009462075 |
|    clip_fraction         | 0.0917      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 258         |
|    cost_values           | -0.702      |
|    entropy               | -2.19       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.669       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.23        |
|    n_updates             | 4110        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 0.748       |
|    value_loss            | 12.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.30700606 |
| rollout/                 |             |
|    ep_len_mean           | 382         |
|    ep_rew_mean           | -130        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 463         |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.007386324 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.7        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.559       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.00609    |
|    std                   | 0.751       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.29744977 |
| rollout/                 |             |
|    ep_len_mean           | 377         |
|    ep_rew_mean           | -128        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 485         |
|    total_timesteps       | 847872      |
| train/                   |             |
|    approx_kl             | 0.006881422 |
|    clip_fraction         | 0.0452      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 250         |
|    cost_values           | -0.686      |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 4130        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.751       |
|    value_loss            | 14.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4894247  |
| rollout/                 |             |
|    ep_len_mean           | 367         |
|    ep_rew_mean           | -124        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 507         |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.005406025 |
|    clip_fraction         | 0.0583      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.655      |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.7         |
|    n_updates             | 4140        |
|    policy_gradient_loss  | -0.00357    |
|    std                   | 0.75        |
|    value_loss            | 7.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.26693463  |
| rollout/                 |              |
|    ep_len_mean           | 370          |
|    ep_rew_mean           | -124         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 529          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0071477173 |
|    clip_fraction         | 0.0754       |
|    clip_range            | 0.2          |
|    cost_returns          | 15           |
|    cost_value_loss       | 254          |
|    cost_values           | -0.681       |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.411        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.15         |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.00519     |
|    std                   | 0.744        |
|    value_loss            | 10.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.26        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.26        |
| reward                   | -0.42277354 |
| rollout/                 |             |
|    ep_len_mean           | 359         |
|    ep_rew_mean           | -120        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 551         |
|    total_timesteps       | 854016      |
| train/                   |             |
|    approx_kl             | 0.007034975 |
|    clip_fraction         | 0.0958      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.671      |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.596       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 4160        |
|    policy_gradient_loss  | -0.00465    |
|    std                   | 0.744       |
|    value_loss            | 8.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.35307315 |
| rollout/                 |             |
|    ep_len_mean           | 370         |
|    ep_rew_mean           | -123        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 574         |
|    total_timesteps       | 856064      |
| train/                   |             |
|    approx_kl             | 0.006988433 |
|    clip_fraction         | 0.0837      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 260         |
|    cost_values           | -0.674      |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.335       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.4         |
|    n_updates             | 4170        |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.741       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.56        |
| reward                   | -0.25953102 |
| rollout/                 |             |
|    ep_len_mean           | 380         |
|    ep_rew_mean           | -126        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 596         |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.015923928 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.6        |
|    cost_value_loss       | 271         |
|    cost_values           | -0.714      |
|    entropy               | -2.16       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.698       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.82        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.000958   |
|    std                   | 0.739       |
|    value_loss            | 5.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.13        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.13        |
| reward                   | -0.34172544 |
| rollout/                 |             |
|    ep_len_mean           | 355         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 618         |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.011396989 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.7        |
|    cost_value_loss       | 274         |
|    cost_values           | -0.695      |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.284       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 4190        |
|    policy_gradient_loss  | -0.00497    |
|    std                   | 0.735       |
|    value_loss            | 6.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.20657131  |
| rollout/                 |              |
|    ep_len_mean           | 355          |
|    ep_rew_mean           | -118         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 640          |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0057536038 |
|    clip_fraction         | 0.0991       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 244          |
|    cost_values           | -0.687       |
|    entropy               | -2.14        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.511        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 4200         |
|    policy_gradient_loss  | -0.000798    |
|    std                   | 0.732        |
|    value_loss            | 19.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.69        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.69        |
| reward                   | -0.38177356 |
| rollout/                 |             |
|    ep_len_mean           | 353         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 662         |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.006511035 |
|    clip_fraction         | 0.0575      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 259         |
|    cost_values           | -0.689      |
|    entropy               | -2.13       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0.54        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 4210        |
|    policy_gradient_loss  | -0.00488    |
|    std                   | 0.728       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.24706186 |
| rollout/                 |             |
|    ep_len_mean           | 360         |
|    ep_rew_mean           | -119        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 684         |
|    total_timesteps       | 866304      |
| train/                   |             |
|    approx_kl             | 0.005464632 |
|    clip_fraction         | 0.0643      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.701      |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.7         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.2         |
|    n_updates             | 4220        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.729       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19222191 |
| rollout/                 |             |
|    ep_len_mean           | 370         |
|    ep_rew_mean           | -122        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 706         |
|    total_timesteps       | 868352      |
| train/                   |             |
|    approx_kl             | 0.005655025 |
|    clip_fraction         | 0.0766      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 267         |
|    cost_values           | -0.703      |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.45        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.81        |
|    n_updates             | 4230        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.73        |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.45334408 |
| rollout/                 |             |
|    ep_len_mean           | 370         |
|    ep_rew_mean           | -122        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 728         |
|    total_timesteps       | 870400      |
| train/                   |             |
|    approx_kl             | 0.007133048 |
|    clip_fraction         | 0.0762      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.7        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.487       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.78        |
|    n_updates             | 4240        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.73        |
|    value_loss            | 11          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.21        |
| reward                   | -0.25469792 |
| rollout/                 |             |
|    ep_len_mean           | 359         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 750         |
|    total_timesteps       | 872448      |
| train/                   |             |
|    approx_kl             | 0.00801971  |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 259         |
|    cost_values           | -0.685      |
|    entropy               | -2.11       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.481       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.29        |
|    n_updates             | 4250        |
|    policy_gradient_loss  | -0.00646    |
|    std                   | 0.725       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.21621895 |
| rollout/                 |             |
|    ep_len_mean           | 358         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 772         |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.005105539 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 251         |
|    cost_values           | -0.702      |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.669       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.94        |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 0.721       |
|    value_loss            | 14.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.1          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.1          |
| reward                   | -0.5115292   |
| rollout/                 |              |
|    ep_len_mean           | 356          |
|    ep_rew_mean           | -117         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 794          |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0036102878 |
|    clip_fraction         | 0.0737       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.3         |
|    cost_value_loss       | 263          |
|    cost_values           | -0.701       |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0.701        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.56         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.723        |
|    value_loss            | 9.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.55        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.55        |
| reward                   | -0.3379755  |
| rollout/                 |             |
|    ep_len_mean           | 353         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 816         |
|    total_timesteps       | 878592      |
| train/                   |             |
|    approx_kl             | 0.008142786 |
|    clip_fraction         | 0.0451      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 260         |
|    cost_values           | -0.696      |
|    entropy               | -2.08       |
|    entropy_loss          | -2.09       |
|    explained_variance    | 0.699       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 4280        |
|    policy_gradient_loss  | -0.00382    |
|    std                   | 0.718       |
|    value_loss            | 8.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.42566913 |
| rollout/                 |             |
|    ep_len_mean           | 360         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 838         |
|    total_timesteps       | 880640      |
| train/                   |             |
|    approx_kl             | 0.00918452  |
|    clip_fraction         | 0.067       |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 255         |
|    cost_values           | -0.671      |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.603       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.01        |
|    n_updates             | 4290        |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.718       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.64        |
| reward                   | -0.31185785 |
| rollout/                 |             |
|    ep_len_mean           | 353         |
|    ep_rew_mean           | -116        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 860         |
|    total_timesteps       | 882688      |
| train/                   |             |
|    approx_kl             | 0.011372769 |
|    clip_fraction         | 0.0854      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 267         |
|    cost_values           | -0.668      |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.766       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 4300        |
|    policy_gradient_loss  | -0.00566    |
|    std                   | 0.718       |
|    value_loss            | 6.02        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.25495857  |
| rollout/                 |              |
|    ep_len_mean           | 349          |
|    ep_rew_mean           | -115         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 882          |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0070944317 |
|    clip_fraction         | 0.114        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 250          |
|    cost_values           | -0.67        |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.712        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.57         |
|    n_updates             | 4310         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.718        |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -0.2523537  |
| rollout/                 |             |
|    ep_len_mean           | 335         |
|    ep_rew_mean           | -111        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 904         |
|    total_timesteps       | 886784      |
| train/                   |             |
|    approx_kl             | 0.003299577 |
|    clip_fraction         | 0.0608      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 255         |
|    cost_values           | -0.658      |
|    entropy               | -2.07       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0.653       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 4320        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.716       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.35298422 |
| rollout/                 |             |
|    ep_len_mean           | 306         |
|    ep_rew_mean           | -102        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 927         |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.007510989 |
|    clip_fraction         | 0.0829      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 245         |
|    cost_values           | -0.679      |
|    entropy               | -2.06       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.716       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.02        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.00635    |
|    std                   | 0.713       |
|    value_loss            | 12.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.3241414   |
| rollout/                 |              |
|    ep_len_mean           | 313          |
|    ep_rew_mean           | -104         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 949          |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0062573208 |
|    clip_fraction         | 0.0811       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 251          |
|    cost_values           | -0.651       |
|    entropy               | -2.05        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0.646        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.00804     |
|    std                   | 0.709        |
|    value_loss            | 10.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1553693  |
| rollout/                 |             |
|    ep_len_mean           | 319         |
|    ep_rew_mean           | -106        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 971         |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.016060721 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.669      |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.655       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.00837    |
|    std                   | 0.708       |
|    value_loss            | 8.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.26174325 |
| rollout/                 |             |
|    ep_len_mean           | 322         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 993         |
|    total_timesteps       | 894976      |
| train/                   |             |
|    approx_kl             | 0.012760328 |
|    clip_fraction         | 0.0848      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 251         |
|    cost_values           | -0.67       |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.509       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 4360        |
|    policy_gradient_loss  | -0.00432    |
|    std                   | 0.707       |
|    value_loss            | 13          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.35173807 |
| rollout/                 |             |
|    ep_len_mean           | 309         |
|    ep_rew_mean           | -102        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1015        |
|    total_timesteps       | 897024      |
| train/                   |             |
|    approx_kl             | 0.009591991 |
|    clip_fraction         | 0.0968      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 267         |
|    cost_values           | -0.669      |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.621       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.43        |
|    n_updates             | 4370        |
|    policy_gradient_loss  | -0.00598    |
|    std                   | 0.708       |
|    value_loss            | 7.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.22939965 |
| rollout/                 |             |
|    ep_len_mean           | 295         |
|    ep_rew_mean           | -97.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1037        |
|    total_timesteps       | 899072      |
| train/                   |             |
|    approx_kl             | 0.012027886 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 256         |
|    cost_values           | -0.659      |
|    entropy               | -2.03       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.486       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.65        |
|    n_updates             | 4380        |
|    policy_gradient_loss  | -0.00666    |
|    std                   | 0.705       |
|    value_loss            | 10.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.32498074  |
| rollout/                 |              |
|    ep_len_mean           | 302          |
|    ep_rew_mean           | -99.7        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1059         |
|    total_timesteps       | 901120       |
| train/                   |              |
|    approx_kl             | 0.0061667715 |
|    clip_fraction         | 0.0721       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 244          |
|    cost_values           | -0.676       |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.686        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 4390         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.702        |
|    value_loss            | 13.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.32151517 |
| rollout/                 |             |
|    ep_len_mean           | 305         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1081        |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.006028454 |
|    clip_fraction         | 0.0541      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 267         |
|    cost_values           | -0.676      |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.612       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.7         |
|    n_updates             | 4400        |
|    policy_gradient_loss  | -0.00369    |
|    std                   | 0.7         |
|    value_loss            | 6.98        |
------------------------------------------
-----------------------------------
| avg_speed          | 8.01       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 8.01       |
| reward             | -0.3742362 |
| rollout/           |            |
|    ep_len_mean     | 301        |
|    ep_rew_mean     | -99.4      |
| time/              |            |
|    fps             | 94         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 905216     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.23772222  |
| rollout/                 |              |
|    ep_len_mean           | 307          |
|    ep_rew_mean           | -101         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0077703586 |
|    clip_fraction         | 0.0909       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 256          |
|    cost_values           | -0.695       |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.373        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.79         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.00492     |
|    std                   | 0.702        |
|    value_loss            | 12.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21994506 |
| rollout/                 |             |
|    ep_len_mean           | 285         |
|    ep_rew_mean           | -93.9       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 909312      |
| train/                   |             |
|    approx_kl             | 0.011261774 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 267         |
|    cost_values           | -0.682      |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.673       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 4430        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.7         |
|    value_loss            | 6.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.3368113  |
| rollout/                 |             |
|    ep_len_mean           | 294         |
|    ep_rew_mean           | -96.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.007311907 |
|    clip_fraction         | 0.0931      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 233         |
|    cost_values           | -0.692      |
|    entropy               | -2          |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.556       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.52        |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.00276    |
|    std                   | 0.696       |
|    value_loss            | 18.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -0.33530232  |
| rollout/                 |              |
|    ep_len_mean           | 296          |
|    ep_rew_mean           | -96.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 913408       |
| train/                   |              |
|    approx_kl             | 0.0077618225 |
|    clip_fraction         | 0.0718       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 267          |
|    cost_values           | -0.668       |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.258        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.46         |
|    n_updates             | 4450         |
|    policy_gradient_loss  | -0.00476     |
|    std                   | 0.694        |
|    value_loss            | 7.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.54         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.54         |
| reward                   | -0.34076783  |
| rollout/                 |              |
|    ep_len_mean           | 300          |
|    ep_rew_mean           | -97.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0060675023 |
|    clip_fraction         | 0.092        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 251          |
|    cost_values           | -0.694       |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.503        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.73         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 0.689        |
|    value_loss            | 13.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.18        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.18        |
| reward                   | -0.33871755 |
| rollout/                 |             |
|    ep_len_mean           | 312         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.007945432 |
|    clip_fraction         | 0.093       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 261         |
|    cost_values           | -0.674      |
|    entropy               | -1.96       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.687       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.84        |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.684       |
|    value_loss            | 9.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.18589723 |
| rollout/                 |             |
|    ep_len_mean           | 306         |
|    ep_rew_mean           | -98.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.007512956 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 266         |
|    cost_values           | -0.694      |
|    entropy               | -1.95       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.573       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.13        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.007      |
|    std                   | 0.679       |
|    value_loss            | 6.69        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.81       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.81       |
| reward                   | -0.3401609 |
| rollout/                 |            |
|    ep_len_mean           | 312        |
|    ep_rew_mean           | -100       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 9          |
|    time_elapsed          | 198        |
|    total_timesteps       | 921600     |
| train/                   |            |
|    approx_kl             | 0.0077133  |
|    clip_fraction         | 0.101      |
|    clip_range            | 0.2        |
|    cost_returns          | 14.8       |
|    cost_value_loss       | 248        |
|    cost_values           | -0.658     |
|    entropy               | -1.94      |
|    entropy_loss          | -1.94      |
|    explained_variance    | 0.544      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.08       |
|    n_updates             | 4490       |
|    policy_gradient_loss  | -0.00641   |
|    std                   | 0.674      |
|    value_loss            | 13         |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.7         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.7         |
| reward                   | -0.31924555 |
| rollout/                 |             |
|    ep_len_mean           | 311         |
|    ep_rew_mean           | -99.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 220         |
|    total_timesteps       | 923648      |
| train/                   |             |
|    approx_kl             | 0.005506264 |
|    clip_fraction         | 0.0401      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.652      |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0.417       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.53        |
|    n_updates             | 4500        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.674       |
|    value_loss            | 6.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.24502333  |
| rollout/                 |              |
|    ep_len_mean           | 306          |
|    ep_rew_mean           | -98.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 243          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0055300277 |
|    clip_fraction         | 0.0742       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 255          |
|    cost_values           | -0.665       |
|    entropy               | -1.92        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0.5          |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.86         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.671        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2927659   |
| rollout/                 |              |
|    ep_len_mean           | 306          |
|    ep_rew_mean           | -98.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 265          |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0071329013 |
|    clip_fraction         | 0.0961       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 255          |
|    cost_values           | -0.67        |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0.579        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.21         |
|    n_updates             | 4520         |
|    policy_gradient_loss  | -0.00598     |
|    std                   | 0.671        |
|    value_loss            | 10.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.73        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.73        |
| reward                   | -0.5182462  |
| rollout/                 |             |
|    ep_len_mean           | 305         |
|    ep_rew_mean           | -97.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 287         |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.006974223 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 255         |
|    cost_values           | -0.667      |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0.638       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00471    |
|    std                   | 0.67        |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21788031 |
| rollout/                 |             |
|    ep_len_mean           | 291         |
|    ep_rew_mean           | -93.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 309         |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.006730173 |
|    clip_fraction         | 0.0893      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 245         |
|    cost_values           | -0.66       |
|    entropy               | -1.91       |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.572       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 0.668       |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.22403236 |
| rollout/                 |             |
|    ep_len_mean           | 289         |
|    ep_rew_mean           | -92.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 331         |
|    total_timesteps       | 933888      |
| train/                   |             |
|    approx_kl             | 0.006966212 |
|    clip_fraction         | 0.0833      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 255         |
|    cost_values           | -0.647      |
|    entropy               | -1.89       |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.607       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 4550        |
|    policy_gradient_loss  | -0.00674    |
|    std                   | 0.662       |
|    value_loss            | 9.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4337495  |
| rollout/                 |             |
|    ep_len_mean           | 287         |
|    ep_rew_mean           | -91.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 353         |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.009370774 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 255         |
|    cost_values           | -0.655      |
|    entropy               | -1.87       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.578       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.34        |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.00705    |
|    std                   | 0.655       |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.86         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.86         |
| reward                   | -0.5705475   |
| rollout/                 |              |
|    ep_len_mean           | 291          |
|    ep_rew_mean           | -93.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 375          |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0065486445 |
|    clip_fraction         | 0.0514       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.4         |
|    cost_value_loss       | 264          |
|    cost_values           | -0.658       |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0.536        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.72         |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 0.651        |
|    value_loss            | 6.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34826276 |
| rollout/                 |             |
|    ep_len_mean           | 273         |
|    ep_rew_mean           | -88         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 397         |
|    total_timesteps       | 940032      |
| train/                   |             |
|    approx_kl             | 0.006729626 |
|    clip_fraction         | 0.0652      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 246         |
|    cost_values           | -0.654      |
|    entropy               | -1.85       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.728       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.12        |
|    n_updates             | 4580        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.649       |
|    value_loss            | 13.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.37868923 |
| rollout/                 |             |
|    ep_len_mean           | 265         |
|    ep_rew_mean           | -85.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 420         |
|    total_timesteps       | 942080      |
| train/                   |             |
|    approx_kl             | 0.009882189 |
|    clip_fraction         | 0.0801      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 244         |
|    cost_values           | -0.665      |
|    entropy               | -1.84       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.498       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.77        |
|    n_updates             | 4590        |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.645       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.25807852 |
| rollout/                 |             |
|    ep_len_mean           | 266         |
|    ep_rew_mean           | -86.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 442         |
|    total_timesteps       | 944128      |
| train/                   |             |
|    approx_kl             | 0.008150477 |
|    clip_fraction         | 0.0995      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 244         |
|    cost_values           | -0.658      |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.704       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.01        |
|    n_updates             | 4600        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.646       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.25694513 |
| rollout/                 |             |
|    ep_len_mean           | 274         |
|    ep_rew_mean           | -88.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 464         |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.016502075 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.64       |
|    entropy               | -1.83       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.677       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.94        |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00576    |
|    std                   | 0.645       |
|    value_loss            | 7.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.14754413 |
| rollout/                 |             |
|    ep_len_mean           | 271         |
|    ep_rew_mean           | -88         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 486         |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.006990156 |
|    clip_fraction         | 0.081       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 263         |
|    cost_values           | -0.651      |
|    entropy               | -1.82       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.502       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.96        |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.641       |
|    value_loss            | 7.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27961275 |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -87.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 508         |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.008711394 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 251         |
|    cost_values           | -0.658      |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.551       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.00549    |
|    std                   | 0.64        |
|    value_loss            | 11.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.30639994  |
| rollout/                 |              |
|    ep_len_mean           | 260          |
|    ep_rew_mean           | -85.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 530          |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0056483424 |
|    clip_fraction         | 0.0867       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 247          |
|    cost_values           | -0.653       |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0.641        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.65         |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.00516     |
|    std                   | 0.639        |
|    value_loss            | 11.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.27751175 |
| rollout/                 |             |
|    ep_len_mean           | 267         |
|    ep_rew_mean           | -87.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 552         |
|    total_timesteps       | 954368      |
| train/                   |             |
|    approx_kl             | 0.013028163 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 252         |
|    cost_values           | -0.633      |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.71        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 4650        |
|    policy_gradient_loss  | -0.00456    |
|    std                   | 0.641       |
|    value_loss            | 9.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.61        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.61        |
| reward                   | -0.4794509  |
| rollout/                 |             |
|    ep_len_mean           | 271         |
|    ep_rew_mean           | -88.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 574         |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.008350712 |
|    clip_fraction         | 0.0837      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 264         |
|    cost_values           | -0.64       |
|    entropy               | -1.8        |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.559       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.29        |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.638       |
|    value_loss            | 7.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.34482712 |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -87.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 596         |
|    total_timesteps       | 958464      |
| train/                   |             |
|    approx_kl             | 0.009975411 |
|    clip_fraction         | 0.0988      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 253         |
|    cost_values           | -0.643      |
|    entropy               | -1.79       |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.59        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 4670        |
|    policy_gradient_loss  | -0.00662    |
|    std                   | 0.636       |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24191725 |
| rollout/                 |             |
|    ep_len_mean           | 265         |
|    ep_rew_mean           | -86.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 618         |
|    total_timesteps       | 960512      |
| train/                   |             |
|    approx_kl             | 0.012977242 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 247         |
|    cost_values           | -0.642      |
|    entropy               | -1.78       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0.644       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 4680        |
|    policy_gradient_loss  | -0.00744    |
|    std                   | 0.635       |
|    value_loss            | 11          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.28684613  |
| rollout/                 |              |
|    ep_len_mean           | 249          |
|    ep_rew_mean           | -81.9        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 641          |
|    total_timesteps       | 962560       |
| train/                   |              |
|    approx_kl             | 0.0067038103 |
|    clip_fraction         | 0.0731       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 248          |
|    cost_values           | -0.636       |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.662        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.83         |
|    n_updates             | 4690         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.635        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.21080352 |
| rollout/                 |             |
|    ep_len_mean           | 251         |
|    ep_rew_mean           | -82.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 663         |
|    total_timesteps       | 964608      |
| train/                   |             |
|    approx_kl             | 0.009115653 |
|    clip_fraction         | 0.0793      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 236         |
|    cost_values           | -0.641      |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.665       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.02        |
|    n_updates             | 4700        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 0.633       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.06        |
| reward                   | -0.5044449  |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -79.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 685         |
|    total_timesteps       | 966656      |
| train/                   |             |
|    approx_kl             | 0.006190365 |
|    clip_fraction         | 0.0923      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.634      |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.627       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 4710        |
|    policy_gradient_loss  | -0.00393    |
|    std                   | 0.635       |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -0.33945465 |
| rollout/                 |             |
|    ep_len_mean           | 214         |
|    ep_rew_mean           | -71         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 707         |
|    total_timesteps       | 968704      |
| train/                   |             |
|    approx_kl             | 0.010535266 |
|    clip_fraction         | 0.0741      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 239         |
|    cost_values           | -0.636      |
|    entropy               | -1.76       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.696       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 4720        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.632       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2776146   |
| rollout/                 |              |
|    ep_len_mean           | 210          |
|    ep_rew_mean           | -69.8        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 729          |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0072259577 |
|    clip_fraction         | 0.0517       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 236          |
|    cost_values           | -0.638       |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.686        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.5          |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.63         |
|    value_loss            | 11.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.63        |
| reward                   | -0.5029341  |
| rollout/                 |             |
|    ep_len_mean           | 207         |
|    ep_rew_mean           | -68.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 751         |
|    total_timesteps       | 972800      |
| train/                   |             |
|    approx_kl             | 0.009251132 |
|    clip_fraction         | 0.0991      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.633      |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 4740        |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.631       |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.99        |
| reward                   | -0.49500325 |
| rollout/                 |             |
|    ep_len_mean           | 196         |
|    ep_rew_mean           | -65.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 774         |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.010863906 |
|    clip_fraction         | 0.0926      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 244         |
|    cost_values           | -0.635      |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.544       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 4750        |
|    policy_gradient_loss  | -0.00316    |
|    std                   | 0.627       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.3190125   |
| rollout/                 |              |
|    ep_len_mean           | 192          |
|    ep_rew_mean           | -64.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 796          |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0060065007 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 244          |
|    cost_values           | -0.631       |
|    entropy               | -1.73        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.23         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 0.624        |
|    value_loss            | 12.9         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.4170202 |
| rollout/                 |            |
|    ep_len_mean           | 187        |
|    ep_rew_mean           | -62.2      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 37         |
|    time_elapsed          | 818        |
|    total_timesteps       | 978944     |
| train/                   |            |
|    approx_kl             | 0.00896495 |
|    clip_fraction         | 0.107      |
|    clip_range            | 0.2        |
|    cost_returns          | 14.7       |
|    cost_value_loss       | 244        |
|    cost_values           | -0.626     |
|    entropy               | -1.72      |
|    entropy_loss          | -1.73      |
|    explained_variance    | 0.62       |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.86       |
|    n_updates             | 4770       |
|    policy_gradient_loss  | -0.00602   |
|    std                   | 0.621      |
|    value_loss            | 11         |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31757796 |
| rollout/                 |             |
|    ep_len_mean           | 189         |
|    ep_rew_mean           | -62.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 840         |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.00900571  |
|    clip_fraction         | 0.0618      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.628      |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.58        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.72        |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.0046     |
|    std                   | 0.619       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23365176 |
| rollout/                 |             |
|    ep_len_mean           | 194         |
|    ep_rew_mean           | -63.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 862         |
|    total_timesteps       | 983040      |
| train/                   |             |
|    approx_kl             | 0.014279468 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.635      |
|    entropy               | -1.71       |
|    entropy_loss          | -1.71       |
|    explained_variance    | 0.408       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.05        |
|    n_updates             | 4790        |
|    policy_gradient_loss  | -0.00547    |
|    std                   | 0.618       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.33472487 |
| rollout/                 |             |
|    ep_len_mean           | 204         |
|    ep_rew_mean           | -66.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 884         |
|    total_timesteps       | 985088      |
| train/                   |             |
|    approx_kl             | 0.0105942   |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.6        |
|    cost_value_loss       | 268         |
|    cost_values           | -0.622      |
|    entropy               | -1.7        |
|    entropy_loss          | -1.71       |
|    explained_variance    | 0.606       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.56        |
|    n_updates             | 4800        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.616       |
|    value_loss            | 4.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.83        |
| reward                   | -0.23846808 |
| rollout/                 |             |
|    ep_len_mean           | 203         |
|    ep_rew_mean           | -65.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 906         |
|    total_timesteps       | 987136      |
| train/                   |             |
|    approx_kl             | 0.008184536 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 244         |
|    cost_values           | -0.625      |
|    entropy               | -1.69       |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0.652       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 4810        |
|    policy_gradient_loss  | -0.00642    |
|    std                   | 0.614       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.761       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.761       |
| reward                   | -0.5616887  |
| rollout/                 |             |
|    ep_len_mean           | 209         |
|    ep_rew_mean           | -67         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 928         |
|    total_timesteps       | 989184      |
| train/                   |             |
|    approx_kl             | 0.014438335 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 237         |
|    cost_values           | -0.624      |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.582       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.16        |
|    n_updates             | 4820        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.614       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.45268714 |
| rollout/                 |             |
|    ep_len_mean           | 210         |
|    ep_rew_mean           | -66.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 950         |
|    total_timesteps       | 991232      |
| train/                   |             |
|    approx_kl             | 0.012236352 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 247         |
|    cost_values           | -0.618      |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.626       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 4830        |
|    policy_gradient_loss  | -0.00588    |
|    std                   | 0.611       |
|    value_loss            | 9.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5125164  |
| rollout/                 |             |
|    ep_len_mean           | 207         |
|    ep_rew_mean           | -66.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 972         |
|    total_timesteps       | 993280      |
| train/                   |             |
|    approx_kl             | 0.008066123 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 244         |
|    cost_values           | -0.617      |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.69        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 4840        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.61        |
|    value_loss            | 9.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.32155454 |
| rollout/                 |             |
|    ep_len_mean           | 192         |
|    ep_rew_mean           | -61.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 994         |
|    total_timesteps       | 995328      |
| train/                   |             |
|    approx_kl             | 0.016314976 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 245         |
|    cost_values           | -0.623      |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 4850        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 0.609       |
|    value_loss            | 11.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.53797     |
| rollout/                 |              |
|    ep_len_mean           | 200          |
|    ep_rew_mean           | -63.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1017         |
|    total_timesteps       | 997376       |
| train/                   |              |
|    approx_kl             | 0.0043170876 |
|    clip_fraction         | 0.0656       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.9         |
|    cost_value_loss       | 224          |
|    cost_values           | -0.614       |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.624        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.77         |
|    n_updates             | 4860         |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 0.609        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2628378   |
| rollout/                 |              |
|    ep_len_mean           | 200          |
|    ep_rew_mean           | -63.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1039         |
|    total_timesteps       | 999424       |
| train/                   |              |
|    approx_kl             | 0.0070334757 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 251          |
|    cost_values           | -0.62        |
|    entropy               | -1.67        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.66         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 4870         |
|    policy_gradient_loss  | -0.00614     |
|    std                   | 0.61         |
|    value_loss            | 8.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.44425213 |
| rollout/                 |             |
|    ep_len_mean           | 198         |
|    ep_rew_mean           | -63.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1061        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.019763479 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.615      |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.604       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00592    |
|    std                   | 0.611       |
|    value_loss            | 9.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.35344362 |
| rollout/                 |             |
|    ep_len_mean           | 180         |
|    ep_rew_mean           | -58.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1083        |
|    total_timesteps       | 1003520     |
| train/                   |             |
|    approx_kl             | 0.029082766 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 245         |
|    cost_values           | -0.606      |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.63        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.66        |
|    n_updates             | 4890        |
|    policy_gradient_loss  | -0.00086    |
|    std                   | 0.61        |
|    value_loss            | 9.09        |
------------------------------------------
------------------------------------
| avg_speed          | 3.96        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 3.96        |
| reward             | -0.44845378 |
| rollout/           |             |
|    ep_len_mean     | 177         |
|    ep_rew_mean     | -57.8       |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1005568     |
------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31821918  |
| rollout/                 |              |
|    ep_len_mean           | 175          |
|    ep_rew_mean           | -57          |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0054698456 |
|    clip_fraction         | 0.0766       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 234          |
|    cost_values           | -0.612       |
|    entropy               | -1.65        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0.667        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.91         |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.00624     |
|    std                   | 0.606        |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.19464897 |
| rollout/                 |             |
|    ep_len_mean           | 180         |
|    ep_rew_mean           | -58.8       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.008348229 |
|    clip_fraction         | 0.0966      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.608      |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0.661       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.00311    |
|    std                   | 0.604       |
|    value_loss            | 8.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3023355  |
| rollout/                 |             |
|    ep_len_mean           | 178         |
|    ep_rew_mean           | -58.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 1011712     |
| train/                   |             |
|    approx_kl             | 0.005233443 |
|    clip_fraction         | 0.0659      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 244         |
|    cost_values           | -0.614      |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0.563       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.71        |
|    n_updates             | 4930        |
|    policy_gradient_loss  | -0.00543    |
|    std                   | 0.605       |
|    value_loss            | 9.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.31759194  |
| rollout/                 |              |
|    ep_len_mean           | 190          |
|    ep_rew_mean           | -61.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1013760      |
| train/                   |              |
|    approx_kl             | 0.0144957695 |
|    clip_fraction         | 0.11         |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 240          |
|    cost_values           | -0.618       |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0.577        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.09         |
|    n_updates             | 4940         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.602        |
|    value_loss            | 10           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33897343 |
| rollout/                 |             |
|    ep_len_mean           | 186         |
|    ep_rew_mean           | -60.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 1015808     |
| train/                   |             |
|    approx_kl             | 0.008031935 |
|    clip_fraction         | 0.0831      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 251         |
|    cost_values           | -0.611      |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.525       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.94        |
|    n_updates             | 4950        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 0.6         |
|    value_loss            | 8.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.2731061   |
| rollout/                 |              |
|    ep_len_mean           | 185          |
|    ep_rew_mean           | -59.9        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0059915036 |
|    clip_fraction         | 0.0748       |
|    clip_range            | 0.2          |
|    cost_returns          | 15           |
|    cost_value_loss       | 251          |
|    cost_values           | -0.612       |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.628        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.21         |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.00468     |
|    std                   | 0.602        |
|    value_loss            | 8.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.19256455 |
| rollout/                 |             |
|    ep_len_mean           | 186         |
|    ep_rew_mean           | -60.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 1019904     |
| train/                   |             |
|    approx_kl             | 0.009503157 |
|    clip_fraction         | 0.0849      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 231         |
|    cost_values           | -0.614      |
|    entropy               | -1.62       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.626       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.43        |
|    n_updates             | 4970        |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.601       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24542388 |
| rollout/                 |             |
|    ep_len_mean           | 192         |
|    ep_rew_mean           | -62.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 1021952     |
| train/                   |             |
|    approx_kl             | 0.009364363 |
|    clip_fraction         | 0.0818      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 252         |
|    cost_values           | -0.602      |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.651       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 4980        |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.6         |
|    value_loss            | 8.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.43193048 |
| rollout/                 |             |
|    ep_len_mean           | 199         |
|    ep_rew_mean           | -64.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 1024000     |
| train/                   |             |
|    approx_kl             | 0.007289688 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 245         |
|    cost_values           | -0.609      |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 4990        |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 0.6         |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.18        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.18        |
| reward                   | -0.57773685 |
| rollout/                 |             |
|    ep_len_mean           | 193         |
|    ep_rew_mean           | -62.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 1026048     |
| train/                   |             |
|    approx_kl             | 0.012852235 |
|    clip_fraction         | 0.0871      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 247         |
|    cost_values           | -0.608      |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.557       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 5000        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 0.601       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.21        |
| reward                   | -0.44675207 |
| rollout/                 |             |
|    ep_len_mean           | 183         |
|    ep_rew_mean           | -59.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 1028096     |
| train/                   |             |
|    approx_kl             | 0.008952752 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 226         |
|    cost_values           | -0.612      |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.628       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.37        |
|    n_updates             | 5010        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.602       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.51194555 |
| rollout/                 |             |
|    ep_len_mean           | 188         |
|    ep_rew_mean           | -61.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1030144     |
| train/                   |             |
|    approx_kl             | 0.006294832 |
|    clip_fraction         | 0.0799      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 221         |
|    cost_values           | -0.612      |
|    entropy               | -1.62       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.692       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 5020        |
|    policy_gradient_loss  | -0.0066     |
|    std                   | 0.6         |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.4577151  |
| rollout/                 |             |
|    ep_len_mean           | 174         |
|    ep_rew_mean           | -57.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 309         |
|    total_timesteps       | 1032192     |
| train/                   |             |
|    approx_kl             | 0.005551149 |
|    clip_fraction         | 0.074       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.9        |
|    cost_value_loss       | 249         |
|    cost_values           | -0.61       |
|    entropy               | -1.6        |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.717       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 5030        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.594       |
|    value_loss            | 8.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.37        |
| reward                   | -0.341163   |
| rollout/                 |             |
|    ep_len_mean           | 171         |
|    ep_rew_mean           | -56.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 1034240     |
| train/                   |             |
|    approx_kl             | 0.010089043 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 230         |
|    cost_values           | -0.609      |
|    entropy               | -1.6        |
|    entropy_loss          | -1.6        |
|    explained_variance    | 0.663       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.4         |
|    n_updates             | 5040        |
|    policy_gradient_loss  | -0.00858    |
|    std                   | 0.593       |
|    value_loss            | 11.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.29814044 |
| rollout/                 |             |
|    ep_len_mean           | 164         |
|    ep_rew_mean           | -53.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 354         |
|    total_timesteps       | 1036288     |
| train/                   |             |
|    approx_kl             | 0.005333015 |
|    clip_fraction         | 0.0636      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 233         |
|    cost_values           | -0.593      |
|    entropy               | -1.59       |
|    entropy_loss          | -1.6        |
|    explained_variance    | 0.683       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.6         |
|    n_updates             | 5050        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.592       |
|    value_loss            | 8.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25450948 |
| rollout/                 |             |
|    ep_len_mean           | 167         |
|    ep_rew_mean           | -54.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 376         |
|    total_timesteps       | 1038336     |
| train/                   |             |
|    approx_kl             | 0.014421716 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 232         |
|    cost_values           | -0.584      |
|    entropy               | -1.6        |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.644       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 5060        |
|    policy_gradient_loss  | -0.00472    |
|    std                   | 0.594       |
|    value_loss            | 8.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32651153 |
| rollout/                 |             |
|    ep_len_mean           | 161         |
|    ep_rew_mean           | -52.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 398         |
|    total_timesteps       | 1040384     |
| train/                   |             |
|    approx_kl             | 0.011600424 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 255         |
|    cost_values           | -0.582      |
|    entropy               | -1.59       |
|    entropy_loss          | -1.6        |
|    explained_variance    | 0.35        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.941       |
|    n_updates             | 5070        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.593       |
|    value_loss            | 5.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24114266 |
| rollout/                 |             |
|    ep_len_mean           | 163         |
|    ep_rew_mean           | -52.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 420         |
|    total_timesteps       | 1042432     |
| train/                   |             |
|    approx_kl             | 0.007830086 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 232         |
|    cost_values           | -0.584      |
|    entropy               | -1.58       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 5080        |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.588       |
|    value_loss            | 9.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.29575878 |
| rollout/                 |             |
|    ep_len_mean           | 173         |
|    ep_rew_mean           | -55.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 442         |
|    total_timesteps       | 1044480     |
| train/                   |             |
|    approx_kl             | 0.010757528 |
|    clip_fraction         | 0.0986      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 252         |
|    cost_values           | -0.588      |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.5         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.01        |
|    n_updates             | 5090        |
|    policy_gradient_loss  | -0.000812   |
|    std                   | 0.585       |
|    value_loss            | 6.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.17         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.17         |
| reward                   | -0.5270948   |
| rollout/                 |              |
|    ep_len_mean           | 168          |
|    ep_rew_mean           | -54.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 465          |
|    total_timesteps       | 1046528      |
| train/                   |              |
|    approx_kl             | 0.0069885403 |
|    clip_fraction         | 0.109        |
|    clip_range            | 0.2          |
|    cost_returns          | 14           |
|    cost_value_loss       | 224          |
|    cost_values           | -0.579       |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.601        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.4          |
|    n_updates             | 5100         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.585        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.14        |
| reward                   | -0.43548325 |
| rollout/                 |             |
|    ep_len_mean           | 158         |
|    ep_rew_mean           | -50.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 487         |
|    total_timesteps       | 1048576     |
| train/                   |             |
|    approx_kl             | 0.014631163 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 227         |
|    cost_values           | -0.582      |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.597       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.66        |
|    n_updates             | 5110        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.585       |
|    value_loss            | 10.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.36783758  |
| rollout/                 |              |
|    ep_len_mean           | 157          |
|    ep_rew_mean           | -51.3        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 509          |
|    total_timesteps       | 1050624      |
| train/                   |              |
|    approx_kl             | 0.0072379345 |
|    clip_fraction         | 0.0837       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 212          |
|    cost_values           | -0.577       |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.684        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.04         |
|    n_updates             | 5120         |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 0.582        |
|    value_loss            | 11.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.23903021 |
| rollout/                 |             |
|    ep_len_mean           | 151         |
|    ep_rew_mean           | -49.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 531         |
|    total_timesteps       | 1052672     |
| train/                   |             |
|    approx_kl             | 0.015069583 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 228         |
|    cost_values           | -0.595      |
|    entropy               | -1.55       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.708       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.83        |
|    n_updates             | 5130        |
|    policy_gradient_loss  | -0.00578    |
|    std                   | 0.582       |
|    value_loss            | 8.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.3450465   |
| rollout/                 |              |
|    ep_len_mean           | 144          |
|    ep_rew_mean           | -48.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 553          |
|    total_timesteps       | 1054720      |
| train/                   |              |
|    approx_kl             | 0.0054711653 |
|    clip_fraction         | 0.0928       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 232          |
|    cost_values           | -0.594       |
|    entropy               | -1.54        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.641        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 5140         |
|    policy_gradient_loss  | 0.000783     |
|    std                   | 0.579        |
|    value_loss            | 9.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4145575  |
| rollout/                 |             |
|    ep_len_mean           | 139         |
|    ep_rew_mean           | -47         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 576         |
|    total_timesteps       | 1056768     |
| train/                   |             |
|    approx_kl             | 0.029418029 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 232         |
|    cost_values           | -0.595      |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.644       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 5150        |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.578       |
|    value_loss            | 8.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.19525371 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -47.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 598         |
|    total_timesteps       | 1058816     |
| train/                   |             |
|    approx_kl             | 0.009881654 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 236         |
|    cost_values           | -0.6        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.618       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.59        |
|    n_updates             | 5160        |
|    policy_gradient_loss  | 0.00172     |
|    std                   | 0.577       |
|    value_loss            | 9.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.02        |
| reward                   | -0.26536605 |
| rollout/                 |             |
|    ep_len_mean           | 136         |
|    ep_rew_mean           | -46.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 621         |
|    total_timesteps       | 1060864     |
| train/                   |             |
|    approx_kl             | 0.009694132 |
|    clip_fraction         | 0.0895      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 217         |
|    cost_values           | -0.593      |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.705       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.74        |
|    n_updates             | 5170        |
|    policy_gradient_loss  | -0.00533    |
|    std                   | 0.577       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.82         |
| reward                   | -0.352407    |
| rollout/                 |              |
|    ep_len_mean           | 144          |
|    ep_rew_mean           | -48.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 643          |
|    total_timesteps       | 1062912      |
| train/                   |              |
|    approx_kl             | 0.0082348455 |
|    clip_fraction         | 0.0929       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.9         |
|    cost_value_loss       | 222          |
|    cost_values           | -0.587       |
|    entropy               | -1.52        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0.588        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.44         |
|    n_updates             | 5180         |
|    policy_gradient_loss  | -0.00611     |
|    std                   | 0.574        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.22359587 |
| rollout/                 |             |
|    ep_len_mean           | 144         |
|    ep_rew_mean           | -48         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 665         |
|    total_timesteps       | 1064960     |
| train/                   |             |
|    approx_kl             | 0.012078706 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 233         |
|    cost_values           | -0.587      |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.726       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 5190        |
|    policy_gradient_loss  | -0.00667    |
|    std                   | 0.57        |
|    value_loss            | 8.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2647715  |
| rollout/                 |             |
|    ep_len_mean           | 147         |
|    ep_rew_mean           | -48.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 687         |
|    total_timesteps       | 1067008     |
| train/                   |             |
|    approx_kl             | 0.009036491 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 229         |
|    cost_values           | -0.588      |
|    entropy               | -1.49       |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.624       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 5200        |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.569       |
|    value_loss            | 8.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38412014 |
| rollout/                 |             |
|    ep_len_mean           | 150         |
|    ep_rew_mean           | -49.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 709         |
|    total_timesteps       | 1069056     |
| train/                   |             |
|    approx_kl             | 0.014154915 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 233         |
|    cost_values           | -0.585      |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.616       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.77        |
|    n_updates             | 5210        |
|    policy_gradient_loss  | -0.0075     |
|    std                   | 0.568       |
|    value_loss            | 9.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38899878 |
| rollout/                 |             |
|    ep_len_mean           | 147         |
|    ep_rew_mean           | -48.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 731         |
|    total_timesteps       | 1071104     |
| train/                   |             |
|    approx_kl             | 0.007255541 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.579      |
|    entropy               | -1.48       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.471       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.23        |
|    n_updates             | 5220        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.567       |
|    value_loss            | 8.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.43959525 |
| rollout/                 |             |
|    ep_len_mean           | 147         |
|    ep_rew_mean           | -47.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 754         |
|    total_timesteps       | 1073152     |
| train/                   |             |
|    approx_kl             | 0.010735394 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 228         |
|    cost_values           | -0.577      |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.611       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 5230        |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.567       |
|    value_loss            | 9.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.25749218 |
| rollout/                 |             |
|    ep_len_mean           | 145         |
|    ep_rew_mean           | -47.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 776         |
|    total_timesteps       | 1075200     |
| train/                   |             |
|    approx_kl             | 0.011837402 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 218         |
|    cost_values           | -0.573      |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.7         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 5240        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.568       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17745817 |
| rollout/                 |             |
|    ep_len_mean           | 146         |
|    ep_rew_mean           | -47.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 798         |
|    total_timesteps       | 1077248     |
| train/                   |             |
|    approx_kl             | 0.008095177 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 225         |
|    cost_values           | -0.578      |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.792       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.48        |
|    n_updates             | 5250        |
|    policy_gradient_loss  | -0.00462    |
|    std                   | 0.568       |
|    value_loss            | 7.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.39915106 |
| rollout/                 |             |
|    ep_len_mean           | 148         |
|    ep_rew_mean           | -47.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 820         |
|    total_timesteps       | 1079296     |
| train/                   |             |
|    approx_kl             | 0.008730849 |
|    clip_fraction         | 0.0905      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.572      |
|    entropy               | -1.46       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0.675       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 5260        |
|    policy_gradient_loss  | -0.00635    |
|    std                   | 0.565       |
|    value_loss            | 7.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.11        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.11        |
| reward                   | -0.56660336 |
| rollout/                 |             |
|    ep_len_mean           | 152         |
|    ep_rew_mean           | -49.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 843         |
|    total_timesteps       | 1081344     |
| train/                   |             |
|    approx_kl             | 0.006526782 |
|    clip_fraction         | 0.0918      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 221         |
|    cost_values           | -0.573      |
|    entropy               | -1.45       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.623       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.51        |
|    n_updates             | 5270        |
|    policy_gradient_loss  | -0.00299    |
|    std                   | 0.564       |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.22264254 |
| rollout/                 |             |
|    ep_len_mean           | 146         |
|    ep_rew_mean           | -48.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 865         |
|    total_timesteps       | 1083392     |
| train/                   |             |
|    approx_kl             | 0.012791596 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 237         |
|    cost_values           | -0.582      |
|    entropy               | -1.44       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0.486       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.42        |
|    n_updates             | 5280        |
|    policy_gradient_loss  | -0.0101     |
|    std                   | 0.562       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.46893215 |
| rollout/                 |             |
|    ep_len_mean           | 147         |
|    ep_rew_mean           | -49.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 887         |
|    total_timesteps       | 1085440     |
| train/                   |             |
|    approx_kl             | 0.012922173 |
|    clip_fraction         | 0.0998      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 240         |
|    cost_values           | -0.576      |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0.471       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 5290        |
|    policy_gradient_loss  | -0.00761    |
|    std                   | 0.56        |
|    value_loss            | 11          |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.8          |
| reward                   | -0.29360193  |
| rollout/                 |              |
|    ep_len_mean           | 147          |
|    ep_rew_mean           | -49.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 909          |
|    total_timesteps       | 1087488      |
| train/                   |              |
|    approx_kl             | 0.0076447753 |
|    clip_fraction         | 0.0862       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 227          |
|    cost_values           | -0.581       |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0.483        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.73         |
|    n_updates             | 5300         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.56         |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4091751   |
| rollout/                 |              |
|    ep_len_mean           | 149          |
|    ep_rew_mean           | -50          |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 931          |
|    total_timesteps       | 1089536      |
| train/                   |              |
|    approx_kl             | 0.0069916975 |
|    clip_fraction         | 0.0794       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.8         |
|    cost_value_loss       | 219          |
|    cost_values           | -0.571       |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0.705        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.23         |
|    n_updates             | 5310         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.556        |
|    value_loss            | 9.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.16531475 |
| rollout/                 |             |
|    ep_len_mean           | 139         |
|    ep_rew_mean           | -46.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 953         |
|    total_timesteps       | 1091584     |
| train/                   |             |
|    approx_kl             | 0.006244709 |
|    clip_fraction         | 0.0931      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 232         |
|    cost_values           | -0.58       |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.66        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 5320        |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.553       |
|    value_loss            | 8.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3805089  |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -46.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 976         |
|    total_timesteps       | 1093632     |
| train/                   |             |
|    approx_kl             | 0.006056115 |
|    clip_fraction         | 0.0858      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 213         |
|    cost_values           | -0.574      |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.639       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 5330        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.55        |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.48031056 |
| rollout/                 |             |
|    ep_len_mean           | 129         |
|    ep_rew_mean           | -43.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 998         |
|    total_timesteps       | 1095680     |
| train/                   |             |
|    approx_kl             | 0.011835452 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 224         |
|    cost_values           | -0.562      |
|    entropy               | -1.4        |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.724       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.89        |
|    n_updates             | 5340        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.549       |
|    value_loss            | 8.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29827902 |
| rollout/                 |             |
|    ep_len_mean           | 123         |
|    ep_rew_mean           | -40.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 1097728     |
| train/                   |             |
|    approx_kl             | 0.013719509 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.3        |
|    cost_value_loss       | 206         |
|    cost_values           | -0.558      |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.49        |
|    n_updates             | 5350        |
|    policy_gradient_loss  | -0.00629    |
|    std                   | 0.548       |
|    value_loss            | 8.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39479768 |
| rollout/                 |             |
|    ep_len_mean           | 126         |
|    ep_rew_mean           | -41.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1042        |
|    total_timesteps       | 1099776     |
| train/                   |             |
|    approx_kl             | 0.007916931 |
|    clip_fraction         | 0.0804      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 222         |
|    cost_values           | -0.557      |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.638       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 5360        |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.546       |
|    value_loss            | 7.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.30935988  |
| rollout/                 |              |
|    ep_len_mean           | 123          |
|    ep_rew_mean           | -40.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1064         |
|    total_timesteps       | 1101824      |
| train/                   |              |
|    approx_kl             | 0.0073651765 |
|    clip_fraction         | 0.0793       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 229          |
|    cost_values           | -0.549       |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.662        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.06         |
|    n_updates             | 5370         |
|    policy_gradient_loss  | -0.00564     |
|    std                   | 0.544        |
|    value_loss            | 8.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.28538233  |
| rollout/                 |              |
|    ep_len_mean           | 127          |
|    ep_rew_mean           | -42          |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1086         |
|    total_timesteps       | 1103872      |
| train/                   |              |
|    approx_kl             | 0.0089415265 |
|    clip_fraction         | 0.127        |
|    clip_range            | 0.2          |
|    cost_returns          | 13.8         |
|    cost_value_loss       | 218          |
|    cost_values           | -0.547       |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.68         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.34         |
|    n_updates             | 5380         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 0.544        |
|    value_loss            | 8.9          |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/an325vgg/model_epoch(10)
------------------------------------
| avg_speed          | 7.86        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 7.86        |
| reward             | -0.20863377 |
| rollout/           |             |
|    ep_len_mean     | 133         |
|    ep_rew_mean     | -43.9       |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1105920     |
------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.58775574 |
| rollout/                 |             |
|    ep_len_mean           | 133         |
|    ep_rew_mean           | -43.9       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 1107968     |
| train/                   |             |
|    approx_kl             | 0.009419708 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 236         |
|    cost_values           | -0.558      |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.52        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.16        |
|    n_updates             | 5400        |
|    policy_gradient_loss  | -0.00413    |
|    std                   | 0.542       |
|    value_loss            | 8.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18142189 |
| rollout/                 |             |
|    ep_len_mean           | 137         |
|    ep_rew_mean           | -44.9       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 1110016     |
| train/                   |             |
|    approx_kl             | 0.007672908 |
|    clip_fraction         | 0.0727      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.3        |
|    cost_value_loss       | 207         |
|    cost_values           | -0.562      |
|    entropy               | -1.34       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.699       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.49        |
|    n_updates             | 5410        |
|    policy_gradient_loss  | -0.00373    |
|    std                   | 0.54        |
|    value_loss            | 10.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.32850698  |
| rollout/                 |              |
|    ep_len_mean           | 141          |
|    ep_rew_mean           | -46.3        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 1112064      |
| train/                   |              |
|    approx_kl             | 0.0064545465 |
|    clip_fraction         | 0.0646       |
|    clip_range            | 0.2          |
|    cost_returns          | 14           |
|    cost_value_loss       | 225          |
|    cost_values           | -0.562       |
|    entropy               | -1.33        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0.582        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.71         |
|    n_updates             | 5420         |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 0.538        |
|    value_loss            | 8.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32702038 |
| rollout/                 |             |
|    ep_len_mean           | 134         |
|    ep_rew_mean           | -44.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 1114112     |
| train/                   |             |
|    approx_kl             | 0.011888104 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 236         |
|    cost_values           | -0.556      |
|    entropy               | -1.32       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.516       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 5430        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.535       |
|    value_loss            | 8.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.33301157  |
| rollout/                 |              |
|    ep_len_mean           | 142          |
|    ep_rew_mean           | -46.9        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 1116160      |
| train/                   |              |
|    approx_kl             | 0.0075853234 |
|    clip_fraction         | 0.0858       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 213          |
|    cost_values           | -0.561       |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0.683        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 5440         |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 0.532        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.37768552 |
| rollout/                 |             |
|    ep_len_mean           | 137         |
|    ep_rew_mean           | -45.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 1118208     |
| train/                   |             |
|    approx_kl             | 0.008752763 |
|    clip_fraction         | 0.0866      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 236         |
|    cost_values           | -0.569      |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.534       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.26        |
|    n_updates             | 5450        |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 0.53        |
|    value_loss            | 8.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.2552104  |
| rollout/                 |             |
|    ep_len_mean           | 129         |
|    ep_rew_mean           | -42.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 1120256     |
| train/                   |             |
|    approx_kl             | 0.007800971 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 225         |
|    cost_values           | -0.573      |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.574       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 5460        |
|    policy_gradient_loss  | -0.00475    |
|    std                   | 0.527       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24660094 |
| rollout/                 |             |
|    ep_len_mean           | 129         |
|    ep_rew_mean           | -42.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 1122304     |
| train/                   |             |
|    approx_kl             | 0.009597489 |
|    clip_fraction         | 0.0774      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 203         |
|    cost_values           | -0.579      |
|    entropy               | -1.27       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.641       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.75        |
|    n_updates             | 5470        |
|    policy_gradient_loss  | -0.0044     |
|    std                   | 0.523       |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17907104 |
| rollout/                 |             |
|    ep_len_mean           | 127         |
|    ep_rew_mean           | -42.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 1124352     |
| train/                   |             |
|    approx_kl             | 0.009555556 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 214         |
|    cost_values           | -0.585      |
|    entropy               | -1.26       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.614       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.8         |
|    n_updates             | 5480        |
|    policy_gradient_loss  | -0.00801    |
|    std                   | 0.52        |
|    value_loss            | 10          |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3343914 |
| rollout/                 |            |
|    ep_len_mean           | 123        |
|    ep_rew_mean           | -40.8      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 11         |
|    time_elapsed          | 243        |
|    total_timesteps       | 1126400    |
| train/                   |            |
|    approx_kl             | 0.01150758 |
|    clip_fraction         | 0.0935     |
|    clip_range            | 0.2        |
|    cost_returns          | 14         |
|    cost_value_loss       | 225        |
|    cost_values           | -0.589     |
|    entropy               | -1.25      |
|    entropy_loss          | -1.26      |
|    explained_variance    | 0.539      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 4.21       |
|    n_updates             | 5490       |
|    policy_gradient_loss  | -0.00607   |
|    std                   | 0.517      |
|    value_loss            | 8.97       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -0.30701983 |
| rollout/                 |             |
|    ep_len_mean           | 107         |
|    ep_rew_mean           | -36.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 1128448     |
| train/                   |             |
|    approx_kl             | 0.011223499 |
|    clip_fraction         | 0.0767      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 210         |
|    cost_values           | -0.58       |
|    entropy               | -1.24       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.679       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 5500        |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.514       |
|    value_loss            | 8.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.26509848 |
| rollout/                 |             |
|    ep_len_mean           | 113         |
|    ep_rew_mean           | -38.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1130496     |
| train/                   |             |
|    approx_kl             | 0.008862199 |
|    clip_fraction         | 0.0991      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 202         |
|    cost_values           | -0.575      |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0.744       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 5510        |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.513       |
|    value_loss            | 8.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.47754166 |
| rollout/                 |             |
|    ep_len_mean           | 114         |
|    ep_rew_mean           | -38.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 1132544     |
| train/                   |             |
|    approx_kl             | 0.013214272 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 221         |
|    cost_values           | -0.581      |
|    entropy               | -1.21       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0.726       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.3         |
|    n_updates             | 5520        |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 0.51        |
|    value_loss            | 7.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.92        |
| reward                   | -0.2864167  |
| rollout/                 |             |
|    ep_len_mean           | 115         |
|    ep_rew_mean           | -39         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 1134592     |
| train/                   |             |
|    approx_kl             | 0.009355907 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 218         |
|    cost_values           | -0.575      |
|    entropy               | -1.2        |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.657       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.47        |
|    n_updates             | 5530        |
|    policy_gradient_loss  | -0.0066     |
|    std                   | 0.507       |
|    value_loss            | 7.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.30537254 |
| rollout/                 |             |
|    ep_len_mean           | 111         |
|    ep_rew_mean           | -37.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 354         |
|    total_timesteps       | 1136640     |
| train/                   |             |
|    approx_kl             | 0.009841209 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 217         |
|    cost_values           | -0.562      |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0.688       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.52        |
|    n_updates             | 5540        |
|    policy_gradient_loss  | -0.00624    |
|    std                   | 0.504       |
|    value_loss            | 8.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25220767 |
| rollout/                 |             |
|    ep_len_mean           | 115         |
|    ep_rew_mean           | -38.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 376         |
|    total_timesteps       | 1138688     |
| train/                   |             |
|    approx_kl             | 0.010437296 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 210         |
|    cost_values           | -0.563      |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0.691       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 5550        |
|    policy_gradient_loss  | -0.00075    |
|    std                   | 0.503       |
|    value_loss            | 7.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27525383 |
| rollout/                 |             |
|    ep_len_mean           | 118         |
|    ep_rew_mean           | -39         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 398         |
|    total_timesteps       | 1140736     |
| train/                   |             |
|    approx_kl             | 0.011505839 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 221         |
|    cost_values           | -0.567      |
|    entropy               | -1.17       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0.734       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.98        |
|    n_updates             | 5560        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.502       |
|    value_loss            | 6.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32261765 |
| rollout/                 |             |
|    ep_len_mean           | 118         |
|    ep_rew_mean           | -38.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 421         |
|    total_timesteps       | 1142784     |
| train/                   |             |
|    approx_kl             | 0.010824846 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 213         |
|    cost_values           | -0.566      |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0.694       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.15        |
|    n_updates             | 5570        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.502       |
|    value_loss            | 7.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.29254743  |
| rollout/                 |              |
|    ep_len_mean           | 115          |
|    ep_rew_mean           | -37.6        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1144832      |
| train/                   |              |
|    approx_kl             | 0.0071840426 |
|    clip_fraction         | 0.098        |
|    clip_range            | 0.2          |
|    cost_returns          | 13.7         |
|    cost_value_loss       | 217          |
|    cost_values           | -0.565       |
|    entropy               | -1.16        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0.742        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.44         |
|    n_updates             | 5580         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.5          |
|    value_loss            | 6.84         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3014019 |
| rollout/                 |            |
|    ep_len_mean           | 111        |
|    ep_rew_mean           | -36.4      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 21         |
|    time_elapsed          | 465        |
|    total_timesteps       | 1146880    |
| train/                   |            |
|    approx_kl             | 0.01136303 |
|    clip_fraction         | 0.0977     |
|    clip_range            | 0.2        |
|    cost_returns          | 13.4       |
|    cost_value_loss       | 210        |
|    cost_values           | -0.563     |
|    entropy               | -1.15      |
|    entropy_loss          | -1.16      |
|    explained_variance    | 0.668      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 4.25       |
|    n_updates             | 5590       |
|    policy_gradient_loss  | -0.00262   |
|    std                   | 0.498      |
|    value_loss            | 8.88       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.19358052 |
| rollout/                 |             |
|    ep_len_mean           | 117         |
|    ep_rew_mean           | -38.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 487         |
|    total_timesteps       | 1148928     |
| train/                   |             |
|    approx_kl             | 0.010056261 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 208         |
|    cost_values           | -0.564      |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0.712       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.68        |
|    n_updates             | 5600        |
|    policy_gradient_loss  | -0.000535   |
|    std                   | 0.499       |
|    value_loss            | 8.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3889077  |
| rollout/                 |             |
|    ep_len_mean           | 115         |
|    ep_rew_mean           | -37.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 509         |
|    total_timesteps       | 1150976     |
| train/                   |             |
|    approx_kl             | 0.006723703 |
|    clip_fraction         | 0.076       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 222         |
|    cost_values           | -0.561      |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0.689       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 5610        |
|    policy_gradient_loss  | -0.000494   |
|    std                   | 0.499       |
|    value_loss            | 7.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.21172574 |
| rollout/                 |             |
|    ep_len_mean           | 114         |
|    ep_rew_mean           | -37.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 532         |
|    total_timesteps       | 1153024     |
| train/                   |             |
|    approx_kl             | 0.007292485 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 220         |
|    cost_values           | -0.554      |
|    entropy               | -1.14       |
|    entropy_loss          | -1.14       |
|    explained_variance    | 0.718       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.72        |
|    n_updates             | 5620        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.498       |
|    value_loss            | 7.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47828498 |
| rollout/                 |             |
|    ep_len_mean           | 106         |
|    ep_rew_mean           | -34.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 554         |
|    total_timesteps       | 1155072     |
| train/                   |             |
|    approx_kl             | 0.017817684 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 209         |
|    cost_values           | -0.556      |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0.72        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.61        |
|    n_updates             | 5630        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 0.497       |
|    value_loss            | 7.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.57329595 |
| rollout/                 |             |
|    ep_len_mean           | 110         |
|    ep_rew_mean           | -36         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 576         |
|    total_timesteps       | 1157120     |
| train/                   |             |
|    approx_kl             | 0.0105558   |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 188         |
|    cost_values           | -0.557      |
|    entropy               | -1.12       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.65        |
|    n_updates             | 5640        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 0.494       |
|    value_loss            | 8.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.8          |
| reward                   | -0.3311178   |
| rollout/                 |              |
|    ep_len_mean           | 105          |
|    ep_rew_mean           | -34.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 598          |
|    total_timesteps       | 1159168      |
| train/                   |              |
|    approx_kl             | 0.0076619424 |
|    clip_fraction         | 0.086        |
|    clip_range            | 0.2          |
|    cost_returns          | 13.8         |
|    cost_value_loss       | 219          |
|    cost_values           | -0.563       |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0.689        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.85         |
|    n_updates             | 5650         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.493        |
|    value_loss            | 7.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.46482682 |
| rollout/                 |             |
|    ep_len_mean           | 102         |
|    ep_rew_mean           | -33.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 621         |
|    total_timesteps       | 1161216     |
| train/                   |             |
|    approx_kl             | 0.010234505 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 200         |
|    cost_values           | -0.559      |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 0.681       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 5660        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.493       |
|    value_loss            | 7.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2659816   |
| rollout/                 |              |
|    ep_len_mean           | 102          |
|    ep_rew_mean           | -33.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 643          |
|    total_timesteps       | 1163264      |
| train/                   |              |
|    approx_kl             | 0.0050127124 |
|    clip_fraction         | 0.0884       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 215          |
|    cost_values           | -0.556       |
|    entropy               | -1.11        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0.629        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.3          |
|    n_updates             | 5670         |
|    policy_gradient_loss  | -0.00361     |
|    std                   | 0.494        |
|    value_loss            | 6.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2535735  |
| rollout/                 |             |
|    ep_len_mean           | 105         |
|    ep_rew_mean           | -34.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 665         |
|    total_timesteps       | 1165312     |
| train/                   |             |
|    approx_kl             | 0.007469766 |
|    clip_fraction         | 0.071       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 210         |
|    cost_values           | -0.554      |
|    entropy               | -1.1        |
|    entropy_loss          | -1.11       |
|    explained_variance    | 0.701       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.58        |
|    n_updates             | 5680        |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.492       |
|    value_loss            | 7.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.26389205 |
| rollout/                 |             |
|    ep_len_mean           | 108         |
|    ep_rew_mean           | -35.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 687         |
|    total_timesteps       | 1167360     |
| train/                   |             |
|    approx_kl             | 0.01297329  |
|    clip_fraction         | 0.0861      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.3        |
|    cost_value_loss       | 208         |
|    cost_values           | -0.558      |
|    entropy               | -1.08       |
|    entropy_loss          | -1.09       |
|    explained_variance    | 0.683       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.28        |
|    n_updates             | 5690        |
|    policy_gradient_loss  | -0.00437    |
|    std                   | 0.488       |
|    value_loss            | 7.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.13382448 |
| rollout/                 |             |
|    ep_len_mean           | 106         |
|    ep_rew_mean           | -35.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 710         |
|    total_timesteps       | 1169408     |
| train/                   |             |
|    approx_kl             | 0.015564276 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 223         |
|    cost_values           | -0.556      |
|    entropy               | -1.07       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.569       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.06        |
|    n_updates             | 5700        |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.484       |
|    value_loss            | 8.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.40120247 |
| rollout/                 |             |
|    ep_len_mean           | 102         |
|    ep_rew_mean           | -34.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 732         |
|    total_timesteps       | 1171456     |
| train/                   |             |
|    approx_kl             | 0.011735227 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 191         |
|    cost_values           | -0.555      |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.721       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.09        |
|    n_updates             | 5710        |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.483       |
|    value_loss            | 8.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32435882 |
| rollout/                 |             |
|    ep_len_mean           | 99.5        |
|    ep_rew_mean           | -34.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 754         |
|    total_timesteps       | 1173504     |
| train/                   |             |
|    approx_kl             | 0.010514842 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 202         |
|    cost_values           | -0.562      |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.641       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.53        |
|    n_updates             | 5720        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 0.484       |
|    value_loss            | 8.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3971092  |
| rollout/                 |             |
|    ep_len_mean           | 98.7        |
|    ep_rew_mean           | -34.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 776         |
|    total_timesteps       | 1175552     |
| train/                   |             |
|    approx_kl             | 0.008650657 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 202         |
|    cost_values           | -0.56       |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.743       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 5730        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.482       |
|    value_loss            | 7.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.4489924  |
| rollout/                 |             |
|    ep_len_mean           | 93.9        |
|    ep_rew_mean           | -32.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 799         |
|    total_timesteps       | 1177600     |
| train/                   |             |
|    approx_kl             | 0.011140515 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 203         |
|    cost_values           | -0.568      |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.692       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.64        |
|    n_updates             | 5740        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.482       |
|    value_loss            | 7.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.38        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.38        |
| reward                   | -0.3924414  |
| rollout/                 |             |
|    ep_len_mean           | 93.2        |
|    ep_rew_mean           | -32.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 821         |
|    total_timesteps       | 1179648     |
| train/                   |             |
|    approx_kl             | 0.010384955 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 195         |
|    cost_values           | -0.563      |
|    entropy               | -1.04       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.789       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.29        |
|    n_updates             | 5750        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.482       |
|    value_loss            | 6.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36426577 |
| rollout/                 |             |
|    ep_len_mean           | 89.1        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 843         |
|    total_timesteps       | 1181696     |
| train/                   |             |
|    approx_kl             | 0.015696047 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 192         |
|    cost_values           | -0.56       |
|    entropy               | -1.03       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.774       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.36        |
|    n_updates             | 5760        |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.48        |
|    value_loss            | 6.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.44217694 |
| rollout/                 |             |
|    ep_len_mean           | 87.7        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 865         |
|    total_timesteps       | 1183744     |
| train/                   |             |
|    approx_kl             | 0.012554048 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 195         |
|    cost_values           | -0.562      |
|    entropy               | -1.02       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 5770        |
|    policy_gradient_loss  | 3.38e-05    |
|    std                   | 0.48        |
|    value_loss            | 4.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3346708  |
| rollout/                 |             |
|    ep_len_mean           | 84.6        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 888         |
|    total_timesteps       | 1185792     |
| train/                   |             |
|    approx_kl             | 0.006653588 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 192         |
|    cost_values           | -0.569      |
|    entropy               | -1.01       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.75        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.91        |
|    n_updates             | 5780        |
|    policy_gradient_loss  | -0.00534    |
|    std                   | 0.476       |
|    value_loss            | 5.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25980204 |
| rollout/                 |             |
|    ep_len_mean           | 83.6        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 910         |
|    total_timesteps       | 1187840     |
| train/                   |             |
|    approx_kl             | 0.007747267 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 185         |
|    cost_values           | -0.563      |
|    entropy               | -1          |
|    entropy_loss          | -1          |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.55        |
|    n_updates             | 5790        |
|    policy_gradient_loss  | -0.00572    |
|    std                   | 0.476       |
|    value_loss            | 5.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.63        |
| reward                   | -0.3893885  |
| rollout/                 |             |
|    ep_len_mean           | 86.7        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 932         |
|    total_timesteps       | 1189888     |
| train/                   |             |
|    approx_kl             | 0.011284758 |
|    clip_fraction         | 0.094       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 191         |
|    cost_values           | -0.559      |
|    entropy               | -1          |
|    entropy_loss          | -1          |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.05        |
|    n_updates             | 5800        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.477       |
|    value_loss            | 4.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36493134 |
| rollout/                 |             |
|    ep_len_mean           | 84.3        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 954         |
|    total_timesteps       | 1191936     |
| train/                   |             |
|    approx_kl             | 0.010876697 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 200         |
|    cost_values           | -0.55       |
|    entropy               | -0.998      |
|    entropy_loss          | -0.999      |
|    explained_variance    | 0.795       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 5810        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.478       |
|    value_loss            | 5.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.14256993 |
| rollout/                 |             |
|    ep_len_mean           | 88.4        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 977         |
|    total_timesteps       | 1193984     |
| train/                   |             |
|    approx_kl             | 0.010589373 |
|    clip_fraction         | 0.0981      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 192         |
|    cost_values           | -0.555      |
|    entropy               | -0.995      |
|    entropy_loss          | -0.996      |
|    explained_variance    | 0.729       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.87        |
|    n_updates             | 5820        |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.479       |
|    value_loss            | 5.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.219971   |
| rollout/                 |             |
|    ep_len_mean           | 91.2        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 999         |
|    total_timesteps       | 1196032     |
| train/                   |             |
|    approx_kl             | 0.008417991 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.3        |
|    cost_value_loss       | 206         |
|    cost_values           | -0.551      |
|    entropy               | -0.987      |
|    entropy_loss          | -0.992      |
|    explained_variance    | 0.727       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.9         |
|    n_updates             | 5830        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.479       |
|    value_loss            | 5.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27086702 |
| rollout/                 |             |
|    ep_len_mean           | 91.3        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 1198080     |
| train/                   |             |
|    approx_kl             | 0.009903774 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.8        |
|    cost_value_loss       | 193         |
|    cost_values           | -0.546      |
|    entropy               | -0.975      |
|    entropy_loss          | -0.98       |
|    explained_variance    | 0.771       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.79        |
|    n_updates             | 5840        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.477       |
|    value_loss            | 6.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.39506143 |
| rollout/                 |             |
|    ep_len_mean           | 91.3        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1043        |
|    total_timesteps       | 1200128     |
| train/                   |             |
|    approx_kl             | 0.009287354 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 199         |
|    cost_values           | -0.541      |
|    entropy               | -0.968      |
|    entropy_loss          | -0.971      |
|    explained_variance    | 0.809       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 5850        |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 0.475       |
|    value_loss            | 4.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.3964638  |
| rollout/                 |             |
|    ep_len_mean           | 93.6        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1066        |
|    total_timesteps       | 1202176     |
| train/                   |             |
|    approx_kl             | 0.018169098 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 202         |
|    cost_values           | -0.543      |
|    entropy               | -0.962      |
|    entropy_loss          | -0.965      |
|    explained_variance    | 0.771       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.84        |
|    n_updates             | 5860        |
|    policy_gradient_loss  | 0.00296     |
|    std                   | 0.474       |
|    value_loss            | 5.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.37674272 |
| rollout/                 |             |
|    ep_len_mean           | 88.5        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1088        |
|    total_timesteps       | 1204224     |
| train/                   |             |
|    approx_kl             | 0.008636628 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 197         |
|    cost_values           | -0.54       |
|    entropy               | -0.955      |
|    entropy_loss          | -0.96       |
|    explained_variance    | 0.741       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.64        |
|    n_updates             | 5870        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.474       |
|    value_loss            | 6.26        |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.33807424 |
| rollout/           |             |
|    ep_len_mean     | 91.8        |
|    ep_rew_mean     | -30.7       |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1206272     |
------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.44410136  |
| rollout/                 |              |
|    ep_len_mean           | 84.9         |
|    ep_rew_mean           | -28.8        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1208320      |
| train/                   |              |
|    approx_kl             | 0.0125782825 |
|    clip_fraction         | 0.154        |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 199          |
|    cost_values           | -0.537       |
|    entropy               | -0.914       |
|    entropy_loss          | -0.922       |
|    explained_variance    | 0.714        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.91         |
|    n_updates             | 5890         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.464        |
|    value_loss            | 6.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.8          |
| reward                   | -0.26085636  |
| rollout/                 |              |
|    ep_len_mean           | 82           |
|    ep_rew_mean           | -28          |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 1210368      |
| train/                   |              |
|    approx_kl             | 0.0150813665 |
|    clip_fraction         | 0.152        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 179          |
|    cost_values           | -0.535       |
|    entropy               | -0.909       |
|    entropy_loss          | -0.911       |
|    explained_variance    | 0.824        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.23         |
|    n_updates             | 5900         |
|    policy_gradient_loss  | -0.00814     |
|    std                   | 0.464        |
|    value_loss            | 4.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.28843695 |
| rollout/                 |             |
|    ep_len_mean           | 82.5        |
|    ep_rew_mean           | -28.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 1212416     |
| train/                   |             |
|    approx_kl             | 0.011273512 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 190         |
|    cost_values           | -0.527      |
|    entropy               | -0.905      |
|    entropy_loss          | -0.906      |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 5910        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.464       |
|    value_loss            | 4.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.53        |
| reward                   | -0.36630255 |
| rollout/                 |             |
|    ep_len_mean           | 83.6        |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 1214464     |
| train/                   |             |
|    approx_kl             | 0.006225784 |
|    clip_fraction         | 0.0808      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 191         |
|    cost_values           | -0.535      |
|    entropy               | -0.907      |
|    entropy_loss          | -0.905      |
|    explained_variance    | 0.806       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.8         |
|    n_updates             | 5920        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.466       |
|    value_loss            | 4.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.23164931 |
| rollout/                 |             |
|    ep_len_mean           | 83.7        |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 1216512     |
| train/                   |             |
|    approx_kl             | 0.009040894 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 198         |
|    cost_values           | -0.532      |
|    entropy               | -0.906      |
|    entropy_loss          | -0.907      |
|    explained_variance    | 0.797       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 5930        |
|    policy_gradient_loss  | -0.0013     |
|    std                   | 0.468       |
|    value_loss            | 4.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.27151108 |
| rollout/                 |             |
|    ep_len_mean           | 85.7        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 1218560     |
| train/                   |             |
|    approx_kl             | 0.015782462 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 184         |
|    cost_values           | -0.538      |
|    entropy               | -0.901      |
|    entropy_loss          | -0.903      |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 5940        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.467       |
|    value_loss            | 4.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.37192953 |
| rollout/                 |             |
|    ep_len_mean           | 82.7        |
|    ep_rew_mean           | -27.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 177         |
|    total_timesteps       | 1220608     |
| train/                   |             |
|    approx_kl             | 0.00945939  |
|    clip_fraction         | 0.0888      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.8        |
|    cost_value_loss       | 193         |
|    cost_values           | -0.538      |
|    entropy               | -0.9        |
|    entropy_loss          | -0.9        |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.3         |
|    n_updates             | 5950        |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.469       |
|    value_loss            | 4.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3634038  |
| rollout/                 |             |
|    ep_len_mean           | 79.8        |
|    ep_rew_mean           | -27.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 1222656     |
| train/                   |             |
|    approx_kl             | 0.008423045 |
|    clip_fraction         | 0.0908      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 181         |
|    cost_values           | -0.54       |
|    entropy               | -0.899      |
|    entropy_loss          | -0.9        |
|    explained_variance    | 0.753       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.74        |
|    n_updates             | 5960        |
|    policy_gradient_loss  | -0.000959   |
|    std                   | 0.469       |
|    value_loss            | 5.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.24387766 |
| rollout/                 |             |
|    ep_len_mean           | 77.4        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 1224704     |
| train/                   |             |
|    approx_kl             | 0.015053787 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.8        |
|    cost_value_loss       | 193         |
|    cost_values           | -0.537      |
|    entropy               | -0.887      |
|    entropy_loss          | -0.894      |
|    explained_variance    | 0.744       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.53        |
|    n_updates             | 5970        |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 0.466       |
|    value_loss            | 5.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.39534694 |
| rollout/                 |             |
|    ep_len_mean           | 80.8        |
|    ep_rew_mean           | -27         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 1226752     |
| train/                   |             |
|    approx_kl             | 0.019911904 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 175         |
|    cost_values           | -0.542      |
|    entropy               | -0.88       |
|    entropy_loss          | -0.883      |
|    explained_variance    | 0.775       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.3         |
|    n_updates             | 5980        |
|    policy_gradient_loss  | -0.00202    |
|    std                   | 0.465       |
|    value_loss            | 4.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.53437597 |
| rollout/                 |             |
|    ep_len_mean           | 83.4        |
|    ep_rew_mean           | -27.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 266         |
|    total_timesteps       | 1228800     |
| train/                   |             |
|    approx_kl             | 0.010432116 |
|    clip_fraction         | 0.0855      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 202         |
|    cost_values           | -0.537      |
|    entropy               | -0.869      |
|    entropy_loss          | -0.875      |
|    explained_variance    | 0.733       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.62        |
|    n_updates             | 5990        |
|    policy_gradient_loss  | -0.00276    |
|    std                   | 0.464       |
|    value_loss            | 5.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3497635  |
| rollout/                 |             |
|    ep_len_mean           | 84.5        |
|    ep_rew_mean           | -27.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 288         |
|    total_timesteps       | 1230848     |
| train/                   |             |
|    approx_kl             | 0.008675437 |
|    clip_fraction         | 0.0809      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 197         |
|    cost_values           | -0.543      |
|    entropy               | -0.867      |
|    entropy_loss          | -0.867      |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 6000        |
|    policy_gradient_loss  | -0.00432    |
|    std                   | 0.464       |
|    value_loss            | 6.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.1         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.1         |
| reward                   | -0.44099718 |
| rollout/                 |             |
|    ep_len_mean           | 84.7        |
|    ep_rew_mean           | -27.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 1232896     |
| train/                   |             |
|    approx_kl             | 0.013354459 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 192         |
|    cost_values           | -0.534      |
|    entropy               | -0.854      |
|    entropy_loss          | -0.86       |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.78        |
|    n_updates             | 6010        |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.462       |
|    value_loss            | 5.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.5631905  |
| rollout/                 |             |
|    ep_len_mean           | 83.9        |
|    ep_rew_mean           | -27.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 1234944     |
| train/                   |             |
|    approx_kl             | 0.014998502 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 177         |
|    cost_values           | -0.538      |
|    entropy               | -0.857      |
|    entropy_loss          | -0.854      |
|    explained_variance    | 0.803       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 6020        |
|    policy_gradient_loss  | 0.00124     |
|    std                   | 0.463       |
|    value_loss            | 4.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.3729971  |
| rollout/                 |             |
|    ep_len_mean           | 79.7        |
|    ep_rew_mean           | -26.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 355         |
|    total_timesteps       | 1236992     |
| train/                   |             |
|    approx_kl             | 0.015024364 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 198         |
|    cost_values           | -0.535      |
|    entropy               | -0.85       |
|    entropy_loss          | -0.855      |
|    explained_variance    | 0.757       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 6030        |
|    policy_gradient_loss  | -0.000251   |
|    std                   | 0.463       |
|    value_loss            | 4.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.29145923 |
| rollout/                 |             |
|    ep_len_mean           | 78.1        |
|    ep_rew_mean           | -25.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 1239040     |
| train/                   |             |
|    approx_kl             | 0.009378899 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 183         |
|    cost_values           | -0.534      |
|    entropy               | -0.85       |
|    entropy_loss          | -0.85       |
|    explained_variance    | 0.803       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 6040        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.463       |
|    value_loss            | 4.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.3777753  |
| rollout/                 |             |
|    ep_len_mean           | 80.4        |
|    ep_rew_mean           | -26.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 399         |
|    total_timesteps       | 1241088     |
| train/                   |             |
|    approx_kl             | 0.010691361 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 177         |
|    cost_values           | -0.531      |
|    entropy               | -0.847      |
|    entropy_loss          | -0.849      |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 6050        |
|    policy_gradient_loss  | -0.000588   |
|    std                   | 0.463       |
|    value_loss            | 4.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.5419862  |
| rollout/                 |             |
|    ep_len_mean           | 78.9        |
|    ep_rew_mean           | -26.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 422         |
|    total_timesteps       | 1243136     |
| train/                   |             |
|    approx_kl             | 0.017163627 |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 195         |
|    cost_values           | -0.523      |
|    entropy               | -0.835      |
|    entropy_loss          | -0.841      |
|    explained_variance    | 0.808       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.8         |
|    n_updates             | 6060        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.46        |
|    value_loss            | 3.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.39256632 |
| rollout/                 |             |
|    ep_len_mean           | 77.8        |
|    ep_rew_mean           | -25.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 444         |
|    total_timesteps       | 1245184     |
| train/                   |             |
|    approx_kl             | 0.011671891 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 186         |
|    cost_values           | -0.524      |
|    entropy               | -0.817      |
|    entropy_loss          | -0.826      |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.84        |
|    n_updates             | 6070        |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.457       |
|    value_loss            | 4.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.568076   |
| rollout/                 |             |
|    ep_len_mean           | 80.8        |
|    ep_rew_mean           | -27.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 466         |
|    total_timesteps       | 1247232     |
| train/                   |             |
|    approx_kl             | 0.007236682 |
|    clip_fraction         | 0.0933      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 184         |
|    cost_values           | -0.526      |
|    entropy               | -0.804      |
|    entropy_loss          | -0.811      |
|    explained_variance    | 0.773       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.53        |
|    n_updates             | 6080        |
|    policy_gradient_loss  | -0.00341    |
|    std                   | 0.454       |
|    value_loss            | 4.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36645803 |
| rollout/                 |             |
|    ep_len_mean           | 76.7        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 488         |
|    total_timesteps       | 1249280     |
| train/                   |             |
|    approx_kl             | 0.011923391 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 187         |
|    cost_values           | -0.519      |
|    entropy               | -0.793      |
|    entropy_loss          | -0.798      |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.11        |
|    n_updates             | 6090        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.451       |
|    value_loss            | 4.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.32326972 |
| rollout/                 |             |
|    ep_len_mean           | 80.7        |
|    ep_rew_mean           | -27.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 511         |
|    total_timesteps       | 1251328     |
| train/                   |             |
|    approx_kl             | 0.012562975 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 180         |
|    cost_values           | -0.523      |
|    entropy               | -0.779      |
|    entropy_loss          | -0.786      |
|    explained_variance    | 0.805       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.05        |
|    n_updates             | 6100        |
|    policy_gradient_loss  | -0.00831    |
|    std                   | 0.449       |
|    value_loss            | 4.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2881694  |
| rollout/                 |             |
|    ep_len_mean           | 83.6        |
|    ep_rew_mean           | -28         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 533         |
|    total_timesteps       | 1253376     |
| train/                   |             |
|    approx_kl             | 0.009056002 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 198         |
|    cost_values           | -0.528      |
|    entropy               | -0.77       |
|    entropy_loss          | -0.774      |
|    explained_variance    | 0.758       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 6110        |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 0.448       |
|    value_loss            | 4.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.8          |
| reward                   | -0.48610616  |
| rollout/                 |              |
|    ep_len_mean           | 84.3         |
|    ep_rew_mean           | -27.8        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 555          |
|    total_timesteps       | 1255424      |
| train/                   |              |
|    approx_kl             | 0.0074825785 |
|    clip_fraction         | 0.111        |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 199          |
|    cost_values           | -0.532       |
|    entropy               | -0.751       |
|    entropy_loss          | -0.761       |
|    explained_variance    | 0.73         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.61         |
|    n_updates             | 6120         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.444        |
|    value_loss            | 5.26         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.2563345 |
| rollout/                 |            |
|    ep_len_mean           | 83.2       |
|    ep_rew_mean           | -27.3      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 26         |
|    time_elapsed          | 578        |
|    total_timesteps       | 1257472    |
| train/                   |            |
|    approx_kl             | 0.01268211 |
|    clip_fraction         | 0.0889     |
|    clip_range            | 0.2        |
|    cost_returns          | 12.6       |
|    cost_value_loss       | 187        |
|    cost_values           | -0.533     |
|    entropy               | -0.742     |
|    entropy_loss          | -0.745     |
|    explained_variance    | 0.743      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.62       |
|    n_updates             | 6130       |
|    policy_gradient_loss  | -0.000774  |
|    std                   | 0.443      |
|    value_loss            | 5.34       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.3704397 |
| rollout/                 |            |
|    ep_len_mean           | 80.2       |
|    ep_rew_mean           | -26.3      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 27         |
|    time_elapsed          | 600        |
|    total_timesteps       | 1259520    |
| train/                   |            |
|    approx_kl             | 0.00949072 |
|    clip_fraction         | 0.116      |
|    clip_range            | 0.2        |
|    cost_returns          | 12.3       |
|    cost_value_loss       | 180        |
|    cost_values           | -0.542     |
|    entropy               | -0.742     |
|    entropy_loss          | -0.742     |
|    explained_variance    | 0.801      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.32       |
|    n_updates             | 6140       |
|    policy_gradient_loss  | -0.00271   |
|    std                   | 0.444      |
|    value_loss            | 4.76       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.25820583 |
| rollout/                 |             |
|    ep_len_mean           | 75.2        |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 622         |
|    total_timesteps       | 1261568     |
| train/                   |             |
|    approx_kl             | 0.018078597 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 184         |
|    cost_values           | -0.541      |
|    entropy               | -0.739      |
|    entropy_loss          | -0.741      |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.48        |
|    n_updates             | 6150        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.444       |
|    value_loss            | 4.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.22513919 |
| rollout/                 |             |
|    ep_len_mean           | 76.6        |
|    ep_rew_mean           | -25.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 644         |
|    total_timesteps       | 1263616     |
| train/                   |             |
|    approx_kl             | 0.008856113 |
|    clip_fraction         | 0.0994      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 177         |
|    cost_values           | -0.544      |
|    entropy               | -0.727      |
|    entropy_loss          | -0.733      |
|    explained_variance    | 0.792       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 6160        |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 0.442       |
|    value_loss            | 5           |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.33931696 |
| rollout/                 |             |
|    ep_len_mean           | 74.6        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 667         |
|    total_timesteps       | 1265664     |
| train/                   |             |
|    approx_kl             | 0.019389268 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 185         |
|    cost_values           | -0.546      |
|    entropy               | -0.716      |
|    entropy_loss          | -0.721      |
|    explained_variance    | 0.784       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.51        |
|    n_updates             | 6170        |
|    policy_gradient_loss  | -0.00581    |
|    std                   | 0.439       |
|    value_loss            | 4.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27616668 |
| rollout/                 |             |
|    ep_len_mean           | 75.7        |
|    ep_rew_mean           | -25.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 689         |
|    total_timesteps       | 1267712     |
| train/                   |             |
|    approx_kl             | 0.014190998 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 173         |
|    cost_values           | -0.534      |
|    entropy               | -0.704      |
|    entropy_loss          | -0.71       |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.1         |
|    n_updates             | 6180        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.437       |
|    value_loss            | 4.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.44410136 |
| rollout/                 |             |
|    ep_len_mean           | 76.6        |
|    ep_rew_mean           | -26.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 711         |
|    total_timesteps       | 1269760     |
| train/                   |             |
|    approx_kl             | 0.015010543 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 188         |
|    cost_values           | -0.538      |
|    entropy               | -0.695      |
|    entropy_loss          | -0.699      |
|    explained_variance    | 0.736       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.55        |
|    n_updates             | 6190        |
|    policy_gradient_loss  | 0.00174     |
|    std                   | 0.436       |
|    value_loss            | 5.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31940717 |
| rollout/                 |             |
|    ep_len_mean           | 75.7        |
|    ep_rew_mean           | -26         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 734         |
|    total_timesteps       | 1271808     |
| train/                   |             |
|    approx_kl             | 0.014403092 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 187         |
|    cost_values           | -0.532      |
|    entropy               | -0.686      |
|    entropy_loss          | -0.691      |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 6200        |
|    policy_gradient_loss  | -0.00184    |
|    std                   | 0.434       |
|    value_loss            | 4.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.33321896 |
| rollout/                 |             |
|    ep_len_mean           | 77.5        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 756         |
|    total_timesteps       | 1273856     |
| train/                   |             |
|    approx_kl             | 0.014755838 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 180         |
|    cost_values           | -0.53       |
|    entropy               | -0.673      |
|    entropy_loss          | -0.679      |
|    explained_variance    | 0.809       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.09        |
|    n_updates             | 6210        |
|    policy_gradient_loss  | 0.00419     |
|    std                   | 0.431       |
|    value_loss            | 4.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.35980994 |
| rollout/                 |             |
|    ep_len_mean           | 76.4        |
|    ep_rew_mean           | -25.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 778         |
|    total_timesteps       | 1275904     |
| train/                   |             |
|    approx_kl             | 0.013569513 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 186         |
|    cost_values           | -0.53       |
|    entropy               | -0.663      |
|    entropy_loss          | -0.668      |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 6220        |
|    policy_gradient_loss  | -0.00334    |
|    std                   | 0.431       |
|    value_loss            | 4.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.2536305   |
| rollout/                 |              |
|    ep_len_mean           | 76.7         |
|    ep_rew_mean           | -25.7        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 801          |
|    total_timesteps       | 1277952      |
| train/                   |              |
|    approx_kl             | 0.0149520915 |
|    clip_fraction         | 0.148        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 181          |
|    cost_values           | -0.524       |
|    entropy               | -0.647       |
|    entropy_loss          | -0.655       |
|    explained_variance    | 0.779        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.46         |
|    n_updates             | 6230         |
|    policy_gradient_loss  | -0.000672    |
|    std                   | 0.427        |
|    value_loss            | 4.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.31         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.31         |
| reward                   | -0.31551287  |
| rollout/                 |              |
|    ep_len_mean           | 75.7         |
|    ep_rew_mean           | -25.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 823          |
|    total_timesteps       | 1280000      |
| train/                   |              |
|    approx_kl             | 0.0077182227 |
|    clip_fraction         | 0.0913       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 184          |
|    cost_values           | -0.523       |
|    entropy               | -0.635       |
|    entropy_loss          | -0.641       |
|    explained_variance    | 0.802        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.99         |
|    n_updates             | 6240         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.424        |
|    value_loss            | 4.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.33245486 |
| rollout/                 |             |
|    ep_len_mean           | 77.3        |
|    ep_rew_mean           | -25.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 845         |
|    total_timesteps       | 1282048     |
| train/                   |             |
|    approx_kl             | 0.010755286 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 178         |
|    cost_values           | -0.524      |
|    entropy               | -0.627      |
|    entropy_loss          | -0.631      |
|    explained_variance    | 0.797       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 6250        |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.424       |
|    value_loss            | 4.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.24957022 |
| rollout/                 |             |
|    ep_len_mean           | 74.4        |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 868         |
|    total_timesteps       | 1284096     |
| train/                   |             |
|    approx_kl             | 0.009390583 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 12.7        |
|    cost_value_loss       | 191         |
|    cost_values           | -0.516      |
|    entropy               | -0.617      |
|    entropy_loss          | -0.622      |
|    explained_variance    | 0.745       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 6260        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.423       |
|    value_loss            | 4.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.35092685 |
| rollout/                 |             |
|    ep_len_mean           | 75.2        |
|    ep_rew_mean           | -25.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 890         |
|    total_timesteps       | 1286144     |
| train/                   |             |
|    approx_kl             | 0.010761421 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 175         |
|    cost_values           | -0.52       |
|    entropy               | -0.602      |
|    entropy_loss          | -0.609      |
|    explained_variance    | 0.791       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 6270        |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 0.42        |
|    value_loss            | 4.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.27995145 |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 912         |
|    total_timesteps       | 1288192     |
| train/                   |             |
|    approx_kl             | 0.01914178  |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 173         |
|    cost_values           | -0.524      |
|    entropy               | -0.591      |
|    entropy_loss          | -0.595      |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.68        |
|    n_updates             | 6280        |
|    policy_gradient_loss  | 0.000343    |
|    std                   | 0.418       |
|    value_loss            | 3.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37274665 |
| rollout/                 |             |
|    ep_len_mean           | 70.9        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 934         |
|    total_timesteps       | 1290240     |
| train/                   |             |
|    approx_kl             | 0.008327966 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 177         |
|    cost_values           | -0.518      |
|    entropy               | -0.582      |
|    entropy_loss          | -0.587      |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 6290        |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.417       |
|    value_loss            | 3.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.26786253 |
| rollout/                 |             |
|    ep_len_mean           | 73.4        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 957         |
|    total_timesteps       | 1292288     |
| train/                   |             |
|    approx_kl             | 0.009755344 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 181         |
|    cost_values           | -0.517      |
|    entropy               | -0.578      |
|    entropy_loss          | -0.579      |
|    explained_variance    | 0.798       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.89        |
|    n_updates             | 6300        |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.417       |
|    value_loss            | 4.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.25568584 |
| rollout/                 |             |
|    ep_len_mean           | 72.3        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 979         |
|    total_timesteps       | 1294336     |
| train/                   |             |
|    approx_kl             | 0.011778781 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 177         |
|    cost_values           | -0.521      |
|    entropy               | -0.577      |
|    entropy_loss          | -0.578      |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.84        |
|    n_updates             | 6310        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.416       |
|    value_loss            | 3.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.33017585 |
| rollout/                 |             |
|    ep_len_mean           | 78          |
|    ep_rew_mean           | -26.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 1001        |
|    total_timesteps       | 1296384     |
| train/                   |             |
|    approx_kl             | 0.011760143 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 181         |
|    cost_values           | -0.517      |
|    entropy               | -0.575      |
|    entropy_loss          | -0.577      |
|    explained_variance    | 0.764       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.51        |
|    n_updates             | 6320        |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 0.417       |
|    value_loss            | 4.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.20910317 |
| rollout/                 |             |
|    ep_len_mean           | 76.2        |
|    ep_rew_mean           | -25.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1023        |
|    total_timesteps       | 1298432     |
| train/                   |             |
|    approx_kl             | 0.007263204 |
|    clip_fraction         | 0.0851      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 197         |
|    cost_values           | -0.516      |
|    entropy               | -0.571      |
|    entropy_loss          | -0.573      |
|    explained_variance    | 0.743       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 6330        |
|    policy_gradient_loss  | -0.000316   |
|    std                   | 0.416       |
|    value_loss            | 5.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.31648016 |
| rollout/                 |             |
|    ep_len_mean           | 75.3        |
|    ep_rew_mean           | -25.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 47          |
|    time_elapsed          | 1046        |
|    total_timesteps       | 1300480     |
| train/                   |             |
|    approx_kl             | 0.009153068 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 179         |
|    cost_values           | -0.517      |
|    entropy               | -0.566      |
|    entropy_loss          | -0.568      |
|    explained_variance    | 0.69        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.59        |
|    n_updates             | 6340        |
|    policy_gradient_loss  | -0.00523    |
|    std                   | 0.414       |
|    value_loss            | 6.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.37436864 |
| rollout/                 |             |
|    ep_len_mean           | 71.8        |
|    ep_rew_mean           | -24.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1068        |
|    total_timesteps       | 1302528     |
| train/                   |             |
|    approx_kl             | 0.023707176 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 165         |
|    cost_values           | -0.531      |
|    entropy               | -0.559      |
|    entropy_loss          | -0.562      |
|    explained_variance    | 0.788       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.36        |
|    n_updates             | 6350        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.414       |
|    value_loss            | 4.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.4364931  |
| rollout/                 |             |
|    ep_len_mean           | 71.9        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 49          |
|    time_elapsed          | 1090        |
|    total_timesteps       | 1304576     |
| train/                   |             |
|    approx_kl             | 0.011881702 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 175         |
|    cost_values           | -0.528      |
|    entropy               | -0.555      |
|    entropy_loss          | -0.557      |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.73        |
|    n_updates             | 6360        |
|    policy_gradient_loss  | 0.00353     |
|    std                   | 0.413       |
|    value_loss            | 3.86        |
------------------------------------------
------------------------------------
| avg_speed          | 8.03        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8.03        |
| reward             | -0.36607644 |
| rollout/           |             |
|    ep_len_mean     | 68.7        |
|    ep_rew_mean     | -23.5       |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 1306624     |
------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.3241719  |
| rollout/                 |             |
|    ep_len_mean           | 72.6        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 1308672     |
| train/                   |             |
|    approx_kl             | 0.010049153 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 165         |
|    cost_values           | -0.529      |
|    entropy               | -0.546      |
|    entropy_loss          | -0.547      |
|    explained_variance    | 0.8         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 6380        |
|    policy_gradient_loss  | -0.000874   |
|    std                   | 0.412       |
|    value_loss            | 4.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.3154007  |
| rollout/                 |             |
|    ep_len_mean           | 72.3        |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 1310720     |
| train/                   |             |
|    approx_kl             | 0.012922916 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 182         |
|    cost_values           | -0.522      |
|    entropy               | -0.531      |
|    entropy_loss          | -0.538      |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.63        |
|    n_updates             | 6390        |
|    policy_gradient_loss  | -0.000251   |
|    std                   | 0.41        |
|    value_loss            | 3.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.4          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.4          |
| reward                   | -0.2292287   |
| rollout/                 |              |
|    ep_len_mean           | 72.7         |
|    ep_rew_mean           | -24.5        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 4            |
|    time_elapsed          | 89           |
|    total_timesteps       | 1312768      |
| train/                   |              |
|    approx_kl             | 0.0112117315 |
|    clip_fraction         | 0.146        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.2         |
|    cost_value_loss       | 176          |
|    cost_values           | -0.515       |
|    entropy               | -0.524       |
|    entropy_loss          | -0.526       |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.94         |
|    n_updates             | 6400         |
|    policy_gradient_loss  | 0.00266      |
|    std                   | 0.409        |
|    value_loss            | 3.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.22982688 |
| rollout/                 |             |
|    ep_len_mean           | 73.7        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1314816     |
| train/                   |             |
|    approx_kl             | 0.010548878 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 179         |
|    cost_values           | -0.514      |
|    entropy               | -0.515      |
|    entropy_loss          | -0.519      |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 6410        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.407       |
|    value_loss            | 4.25        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.4        |
| reward                   | -0.5135277 |
| rollout/                 |            |
|    ep_len_mean           | 72.4       |
|    ep_rew_mean           | -24.4      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 6          |
|    time_elapsed          | 133        |
|    total_timesteps       | 1316864    |
| train/                   |            |
|    approx_kl             | 0.01826553 |
|    clip_fraction         | 0.136      |
|    clip_range            | 0.2        |
|    cost_returns          | 12.1       |
|    cost_value_loss       | 174        |
|    cost_values           | -0.511     |
|    entropy               | -0.504     |
|    entropy_loss          | -0.509     |
|    explained_variance    | 0.801      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.07       |
|    n_updates             | 6420       |
|    policy_gradient_loss  | 0.00128    |
|    std                   | 0.404      |
|    value_loss            | 4.26       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2389995  |
| rollout/                 |             |
|    ep_len_mean           | 68.6        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 155         |
|    total_timesteps       | 1318912     |
| train/                   |             |
|    approx_kl             | 0.011588118 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 178         |
|    cost_values           | -0.516      |
|    entropy               | -0.496      |
|    entropy_loss          | -0.5        |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 6430        |
|    policy_gradient_loss  | -0.000976   |
|    std                   | 0.403       |
|    value_loss            | 3.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.280703   |
| rollout/                 |             |
|    ep_len_mean           | 68.7        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 178         |
|    total_timesteps       | 1320960     |
| train/                   |             |
|    approx_kl             | 0.010492029 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 166         |
|    cost_values           | -0.514      |
|    entropy               | -0.489      |
|    entropy_loss          | -0.493      |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.54        |
|    n_updates             | 6440        |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.404       |
|    value_loss            | 3.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27324578 |
| rollout/                 |             |
|    ep_len_mean           | 69.4        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 200         |
|    total_timesteps       | 1323008     |
| train/                   |             |
|    approx_kl             | 0.014314333 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 172         |
|    cost_values           | -0.517      |
|    entropy               | -0.484      |
|    entropy_loss          | -0.487      |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.71        |
|    n_updates             | 6450        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.404       |
|    value_loss            | 3.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.49303138 |
| rollout/                 |             |
|    ep_len_mean           | 68.5        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 222         |
|    total_timesteps       | 1325056     |
| train/                   |             |
|    approx_kl             | 0.014631393 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 177         |
|    cost_values           | -0.512      |
|    entropy               | -0.479      |
|    entropy_loss          | -0.481      |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.66        |
|    n_updates             | 6460        |
|    policy_gradient_loss  | -0.0005     |
|    std                   | 0.404       |
|    value_loss            | 3.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3700749  |
| rollout/                 |             |
|    ep_len_mean           | 69.6        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 245         |
|    total_timesteps       | 1327104     |
| train/                   |             |
|    approx_kl             | 0.010353638 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 168         |
|    cost_values           | -0.521      |
|    entropy               | -0.472      |
|    entropy_loss          | -0.476      |
|    explained_variance    | 0.81        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.81        |
|    n_updates             | 6470        |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.402       |
|    value_loss            | 3.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.16255663 |
| rollout/                 |             |
|    ep_len_mean           | 66.4        |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 267         |
|    total_timesteps       | 1329152     |
| train/                   |             |
|    approx_kl             | 0.01998378  |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 179         |
|    cost_values           | -0.506      |
|    entropy               | -0.462      |
|    entropy_loss          | -0.466      |
|    explained_variance    | 0.854       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.33        |
|    n_updates             | 6480        |
|    policy_gradient_loss  | -0.00618    |
|    std                   | 0.4         |
|    value_loss            | 2.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.6          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.6          |
| reward                   | -0.24139069  |
| rollout/                 |              |
|    ep_len_mean           | 65.9         |
|    ep_rew_mean           | -21.8        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 13           |
|    time_elapsed          | 289          |
|    total_timesteps       | 1331200      |
| train/                   |              |
|    approx_kl             | 0.0112656485 |
|    clip_fraction         | 0.168        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 158          |
|    cost_values           | -0.515       |
|    entropy               | -0.465       |
|    entropy_loss          | -0.462       |
|    explained_variance    | 0.831        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.67         |
|    n_updates             | 6490         |
|    policy_gradient_loss  | 0.00332      |
|    std                   | 0.4          |
|    value_loss            | 3.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.24473935 |
| rollout/                 |             |
|    ep_len_mean           | 64.2        |
|    ep_rew_mean           | -21.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 312         |
|    total_timesteps       | 1333248     |
| train/                   |             |
|    approx_kl             | 0.013937033 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.521      |
|    entropy               | -0.463      |
|    entropy_loss          | -0.465      |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.55        |
|    n_updates             | 6500        |
|    policy_gradient_loss  | 0.000102    |
|    std                   | 0.4         |
|    value_loss            | 2.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.5469249  |
| rollout/                 |             |
|    ep_len_mean           | 67.3        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 334         |
|    total_timesteps       | 1335296     |
| train/                   |             |
|    approx_kl             | 0.014105562 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 173         |
|    cost_values           | -0.507      |
|    entropy               | -0.452      |
|    entropy_loss          | -0.457      |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.72        |
|    n_updates             | 6510        |
|    policy_gradient_loss  | 0.0056      |
|    std                   | 0.398       |
|    value_loss            | 3.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.46279988 |
| rollout/                 |             |
|    ep_len_mean           | 67.3        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 356         |
|    total_timesteps       | 1337344     |
| train/                   |             |
|    approx_kl             | 0.010695015 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 176         |
|    cost_values           | -0.506      |
|    entropy               | -0.44       |
|    entropy_loss          | -0.446      |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.8         |
|    n_updates             | 6520        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.397       |
|    value_loss            | 3.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.22672093  |
| rollout/                 |              |
|    ep_len_mean           | 65.8         |
|    ep_rew_mean           | -22.3        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 17           |
|    time_elapsed          | 379          |
|    total_timesteps       | 1339392      |
| train/                   |              |
|    approx_kl             | 0.0080456175 |
|    clip_fraction         | 0.118        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 166          |
|    cost_values           | -0.511       |
|    entropy               | -0.428       |
|    entropy_loss          | -0.433       |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.42         |
|    n_updates             | 6530         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.395        |
|    value_loss            | 2.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.26085636 |
| rollout/                 |             |
|    ep_len_mean           | 64.9        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 401         |
|    total_timesteps       | 1341440     |
| train/                   |             |
|    approx_kl             | 0.013388507 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 167         |
|    cost_values           | -0.511      |
|    entropy               | -0.422      |
|    entropy_loss          | -0.424      |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.51        |
|    n_updates             | 6540        |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.395       |
|    value_loss            | 2.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.27723536 |
| rollout/                 |             |
|    ep_len_mean           | 65.9        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 423         |
|    total_timesteps       | 1343488     |
| train/                   |             |
|    approx_kl             | 0.007979432 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 168         |
|    cost_values           | -0.509      |
|    entropy               | -0.41       |
|    entropy_loss          | -0.417      |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.76        |
|    n_updates             | 6550        |
|    policy_gradient_loss  | -0.00508    |
|    std                   | 0.395       |
|    value_loss            | 3.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.98        |
| reward                   | -0.21889865 |
| rollout/                 |             |
|    ep_len_mean           | 68.8        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 446         |
|    total_timesteps       | 1345536     |
| train/                   |             |
|    approx_kl             | 0.011921384 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 174         |
|    cost_values           | -0.512      |
|    entropy               | -0.395      |
|    entropy_loss          | -0.402      |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.75        |
|    n_updates             | 6560        |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.393       |
|    value_loss            | 4.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.5058496  |
| rollout/                 |             |
|    ep_len_mean           | 67.2        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 468         |
|    total_timesteps       | 1347584     |
| train/                   |             |
|    approx_kl             | 0.016075484 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 176         |
|    cost_values           | -0.5        |
|    entropy               | -0.387      |
|    entropy_loss          | -0.39       |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.62        |
|    n_updates             | 6570        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.392       |
|    value_loss            | 3.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 1            |
| max_speed                | 8            |
| reward                   | -0.117223695 |
| rollout/                 |              |
|    ep_len_mean           | 67.9         |
|    ep_rew_mean           | -22.9        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 22           |
|    time_elapsed          | 490          |
|    total_timesteps       | 1349632      |
| train/                   |              |
|    approx_kl             | 0.0094835805 |
|    clip_fraction         | 0.169        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 166          |
|    cost_values           | -0.503       |
|    entropy               | -0.385       |
|    entropy_loss          | -0.386       |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.53         |
|    n_updates             | 6580         |
|    policy_gradient_loss  | 0.00236      |
|    std                   | 0.392        |
|    value_loss            | 3.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.5684012  |
| rollout/                 |             |
|    ep_len_mean           | 64.5        |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 513         |
|    total_timesteps       | 1351680     |
| train/                   |             |
|    approx_kl             | 0.012818769 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 172         |
|    cost_values           | -0.506      |
|    entropy               | -0.387      |
|    entropy_loss          | -0.385      |
|    explained_variance    | 0.861       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.65        |
|    n_updates             | 6590        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.391       |
|    value_loss            | 3.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.49299508 |
| rollout/                 |             |
|    ep_len_mean           | 63          |
|    ep_rew_mean           | -21.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 535         |
|    total_timesteps       | 1353728     |
| train/                   |             |
|    approx_kl             | 0.015698351 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 163         |
|    cost_values           | -0.508      |
|    entropy               | -0.379      |
|    entropy_loss          | -0.384      |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.56        |
|    n_updates             | 6600        |
|    policy_gradient_loss  | 0.00343     |
|    std                   | 0.39        |
|    value_loss            | 3           |
------------------------------------------
------------------------------------------
| avg_speed                | 7.13        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.13        |
| reward                   | -0.3280212  |
| rollout/                 |             |
|    ep_len_mean           | 63.1        |
|    ep_rew_mean           | -21.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 557         |
|    total_timesteps       | 1355776     |
| train/                   |             |
|    approx_kl             | 0.015338477 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 157         |
|    cost_values           | -0.504      |
|    entropy               | -0.377      |
|    entropy_loss          | -0.377      |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.753       |
|    n_updates             | 6610        |
|    policy_gradient_loss  | 0.0055      |
|    std                   | 0.39        |
|    value_loss            | 1.67        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.2240088 |
| rollout/                 |            |
|    ep_len_mean           | 63.2       |
|    ep_rew_mean           | -21.5      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 26         |
|    time_elapsed          | 580        |
|    total_timesteps       | 1357824    |
| train/                   |            |
|    approx_kl             | 0.01744901 |
|    clip_fraction         | 0.138      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.9       |
|    cost_value_loss       | 170        |
|    cost_values           | -0.506     |
|    entropy               | -0.367     |
|    entropy_loss          | -0.373     |
|    explained_variance    | 0.906      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.984      |
|    n_updates             | 6620       |
|    policy_gradient_loss  | -0.00142   |
|    std                   | 0.388      |
|    value_loss            | 2.06       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.79        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.79        |
| reward                   | -0.24275781 |
| rollout/                 |             |
|    ep_len_mean           | 65.4        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 602         |
|    total_timesteps       | 1359872     |
| train/                   |             |
|    approx_kl             | 0.023157753 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 165         |
|    cost_values           | -0.508      |
|    entropy               | -0.362      |
|    entropy_loss          | -0.363      |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.46        |
|    n_updates             | 6630        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.386       |
|    value_loss            | 2.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.35012704 |
| rollout/                 |             |
|    ep_len_mean           | 69.3        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 624         |
|    total_timesteps       | 1361920     |
| train/                   |             |
|    approx_kl             | 0.018970689 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 169         |
|    cost_values           | -0.496      |
|    entropy               | -0.356      |
|    entropy_loss          | -0.359      |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.25        |
|    n_updates             | 6640        |
|    policy_gradient_loss  | 0.000372    |
|    std                   | 0.385       |
|    value_loss            | 2.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.14765197 |
| rollout/                 |             |
|    ep_len_mean           | 69.7        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 647         |
|    total_timesteps       | 1363968     |
| train/                   |             |
|    approx_kl             | 0.00914189  |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 188         |
|    cost_values           | -0.493      |
|    entropy               | -0.36       |
|    entropy_loss          | -0.357      |
|    explained_variance    | 0.815       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.22        |
|    n_updates             | 6650        |
|    policy_gradient_loss  | 0.000728    |
|    std                   | 0.387       |
|    value_loss            | 2.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28718123 |
| rollout/                 |             |
|    ep_len_mean           | 69.5        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 669         |
|    total_timesteps       | 1366016     |
| train/                   |             |
|    approx_kl             | 0.021707347 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 170         |
|    cost_values           | -0.494      |
|    entropy               | -0.347      |
|    entropy_loss          | -0.356      |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.69        |
|    n_updates             | 6660        |
|    policy_gradient_loss  | -0.0058     |
|    std                   | 0.384       |
|    value_loss            | 3.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.3154498  |
| rollout/                 |             |
|    ep_len_mean           | 68.6        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 691         |
|    total_timesteps       | 1368064     |
| train/                   |             |
|    approx_kl             | 0.014268781 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 164         |
|    cost_values           | -0.506      |
|    entropy               | -0.336      |
|    entropy_loss          | -0.341      |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.3         |
|    n_updates             | 6670        |
|    policy_gradient_loss  | 0.00233     |
|    std                   | 0.383       |
|    value_loss            | 2.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.337157   |
| rollout/                 |             |
|    ep_len_mean           | 68.9        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 714         |
|    total_timesteps       | 1370112     |
| train/                   |             |
|    approx_kl             | 0.014636931 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 175         |
|    cost_values           | -0.507      |
|    entropy               | -0.327      |
|    entropy_loss          | -0.331      |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.24        |
|    n_updates             | 6680        |
|    policy_gradient_loss  | 0.0034      |
|    std                   | 0.383       |
|    value_loss            | 2.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.37263533 |
| rollout/                 |             |
|    ep_len_mean           | 68.4        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 736         |
|    total_timesteps       | 1372160     |
| train/                   |             |
|    approx_kl             | 0.00845331  |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 180         |
|    cost_values           | -0.506      |
|    entropy               | -0.32       |
|    entropy_loss          | -0.324      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.17        |
|    n_updates             | 6690        |
|    policy_gradient_loss  | 0.00463     |
|    std                   | 0.381       |
|    value_loss            | 2.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.58        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.58        |
| reward                   | -0.32627502 |
| rollout/                 |             |
|    ep_len_mean           | 65          |
|    ep_rew_mean           | -21.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 758         |
|    total_timesteps       | 1374208     |
| train/                   |             |
|    approx_kl             | 0.011090051 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.506      |
|    entropy               | -0.311      |
|    entropy_loss          | -0.316      |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.4         |
|    n_updates             | 6700        |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 0.38        |
|    value_loss            | 2.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.38035935 |
| rollout/                 |             |
|    ep_len_mean           | 62.8        |
|    ep_rew_mean           | -21.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 781         |
|    total_timesteps       | 1376256     |
| train/                   |             |
|    approx_kl             | 0.017711531 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 160         |
|    cost_values           | -0.508      |
|    entropy               | -0.304      |
|    entropy_loss          | -0.307      |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.14        |
|    n_updates             | 6710        |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 0.379       |
|    value_loss            | 2.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.58         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.58         |
| reward                   | -0.38860586  |
| rollout/                 |              |
|    ep_len_mean           | 63.6         |
|    ep_rew_mean           | -21.7        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 36           |
|    time_elapsed          | 803          |
|    total_timesteps       | 1378304      |
| train/                   |              |
|    approx_kl             | 0.0104454085 |
|    clip_fraction         | 0.164        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 168          |
|    cost_values           | -0.505       |
|    entropy               | -0.306       |
|    entropy_loss          | -0.305       |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.22         |
|    n_updates             | 6720         |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 0.38         |
|    value_loss            | 2.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3400779  |
| rollout/                 |             |
|    ep_len_mean           | 66.5        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 825         |
|    total_timesteps       | 1380352     |
| train/                   |             |
|    approx_kl             | 0.009168314 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 166         |
|    cost_values           | -0.499      |
|    entropy               | -0.3        |
|    entropy_loss          | -0.303      |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.09        |
|    n_updates             | 6730        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.379       |
|    value_loss            | 2.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.39        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.39        |
| reward                   | -0.27878478 |
| rollout/                 |             |
|    ep_len_mean           | 68.4        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 848         |
|    total_timesteps       | 1382400     |
| train/                   |             |
|    approx_kl             | 0.014275448 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 169         |
|    cost_values           | -0.503      |
|    entropy               | -0.305      |
|    entropy_loss          | -0.301      |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.08        |
|    n_updates             | 6740        |
|    policy_gradient_loss  | -0.00429    |
|    std                   | 0.381       |
|    value_loss            | 2.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2402347   |
| rollout/                 |              |
|    ep_len_mean           | 65.6         |
|    ep_rew_mean           | -22.2        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 39           |
|    time_elapsed          | 870          |
|    total_timesteps       | 1384448      |
| train/                   |              |
|    approx_kl             | 0.0154614765 |
|    clip_fraction         | 0.137        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 173          |
|    cost_values           | -0.499       |
|    entropy               | -0.305       |
|    entropy_loss          | -0.306       |
|    explained_variance    | 0.821        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.42         |
|    n_updates             | 6750         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.382        |
|    value_loss            | 3.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.41154292 |
| rollout/                 |             |
|    ep_len_mean           | 64.1        |
|    ep_rew_mean           | -21.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 893         |
|    total_timesteps       | 1386496     |
| train/                   |             |
|    approx_kl             | 0.010745963 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 158         |
|    cost_values           | -0.505      |
|    entropy               | -0.305      |
|    entropy_loss          | -0.305      |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.53        |
|    n_updates             | 6760        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.383       |
|    value_loss            | 3.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31931075 |
| rollout/                 |             |
|    ep_len_mean           | 60.6        |
|    ep_rew_mean           | -20.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 915         |
|    total_timesteps       | 1388544     |
| train/                   |             |
|    approx_kl             | 0.020804781 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 160         |
|    cost_values           | -0.506      |
|    entropy               | -0.298      |
|    entropy_loss          | -0.302      |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.09        |
|    n_updates             | 6770        |
|    policy_gradient_loss  | 0.00565     |
|    std                   | 0.384       |
|    value_loss            | 2.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.47925895 |
| rollout/                 |             |
|    ep_len_mean           | 62.5        |
|    ep_rew_mean           | -21.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 937         |
|    total_timesteps       | 1390592     |
| train/                   |             |
|    approx_kl             | 0.014059911 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 160         |
|    cost_values           | -0.504      |
|    entropy               | -0.292      |
|    entropy_loss          | -0.295      |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.02        |
|    n_updates             | 6780        |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.383       |
|    value_loss            | 2.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.3629647  |
| rollout/                 |             |
|    ep_len_mean           | 63.3        |
|    ep_rew_mean           | -21.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 960         |
|    total_timesteps       | 1392640     |
| train/                   |             |
|    approx_kl             | 0.013453906 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 166         |
|    cost_values           | -0.499      |
|    entropy               | -0.291      |
|    entropy_loss          | -0.291      |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.08        |
|    n_updates             | 6790        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.384       |
|    value_loss            | 2.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.4          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.4          |
| reward                   | -0.5170439   |
| rollout/                 |              |
|    ep_len_mean           | 63.2         |
|    ep_rew_mean           | -21.5        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 44           |
|    time_elapsed          | 982          |
|    total_timesteps       | 1394688      |
| train/                   |              |
|    approx_kl             | 0.0122055095 |
|    clip_fraction         | 0.165        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 164          |
|    cost_values           | -0.503       |
|    entropy               | -0.282       |
|    entropy_loss          | -0.287       |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.971        |
|    n_updates             | 6800         |
|    policy_gradient_loss  | 0.00137      |
|    std                   | 0.382        |
|    value_loss            | 2.09         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.4        |
| reward                   | -0.3204263 |
| rollout/                 |            |
|    ep_len_mean           | 61.5       |
|    ep_rew_mean           | -21        |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 45         |
|    time_elapsed          | 1004       |
|    total_timesteps       | 1396736    |
| train/                   |            |
|    approx_kl             | 0.01499135 |
|    clip_fraction         | 0.197      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.5       |
|    cost_value_loss       | 159        |
|    cost_values           | -0.507     |
|    entropy               | -0.275     |
|    entropy_loss          | -0.278     |
|    explained_variance    | 0.908      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.885      |
|    n_updates             | 6810       |
|    policy_gradient_loss  | 0.00158    |
|    std                   | 0.38       |
|    value_loss            | 1.92       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20997447 |
| rollout/                 |             |
|    ep_len_mean           | 60.5        |
|    ep_rew_mean           | -20.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 46          |
|    time_elapsed          | 1027        |
|    total_timesteps       | 1398784     |
| train/                   |             |
|    approx_kl             | 0.021163857 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.512      |
|    entropy               | -0.266      |
|    entropy_loss          | -0.27       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.01        |
|    n_updates             | 6820        |
|    policy_gradient_loss  | 0.00487     |
|    std                   | 0.379       |
|    value_loss            | 2.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2971087   |
| rollout/                 |              |
|    ep_len_mean           | 63.7         |
|    ep_rew_mean           | -21.8        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 47           |
|    time_elapsed          | 1049         |
|    total_timesteps       | 1400832      |
| train/                   |              |
|    approx_kl             | 0.0151413325 |
|    clip_fraction         | 0.149        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 159          |
|    cost_values           | -0.507       |
|    entropy               | -0.265       |
|    entropy_loss          | -0.266       |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.689        |
|    n_updates             | 6830         |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 0.379        |
|    value_loss            | 1.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.30618474 |
| rollout/                 |             |
|    ep_len_mean           | 64          |
|    ep_rew_mean           | -21.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1072        |
|    total_timesteps       | 1402880     |
| train/                   |             |
|    approx_kl             | 0.01071161  |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 180         |
|    cost_values           | -0.5        |
|    entropy               | -0.261      |
|    entropy_loss          | -0.264      |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.23        |
|    n_updates             | 6840        |
|    policy_gradient_loss  | 0.000596    |
|    std                   | 0.38        |
|    value_loss            | 2.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.29702553 |
| rollout/                 |             |
|    ep_len_mean           | 64.1        |
|    ep_rew_mean           | -21.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 49          |
|    time_elapsed          | 1094        |
|    total_timesteps       | 1404928     |
| train/                   |             |
|    approx_kl             | 0.01023562  |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.501      |
|    entropy               | -0.253      |
|    entropy_loss          | -0.257      |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.45        |
|    n_updates             | 6850        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 0.38        |
|    value_loss            | 3.05        |
------------------------------------------
------------------------------------
| avg_speed          | 5           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 5           |
| reward             | -0.37897637 |
| rollout/           |             |
|    ep_len_mean     | 61          |
|    ep_rew_mean     | -20.5       |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 1406976     |
------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.15050057 |
| rollout/                 |             |
|    ep_len_mean           | 59.4        |
|    ep_rew_mean           | -20.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 1409024     |
| train/                   |             |
|    approx_kl             | 0.011370047 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 162         |
|    cost_values           | -0.5        |
|    entropy               | -0.248      |
|    entropy_loss          | -0.245      |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.42        |
|    n_updates             | 6870        |
|    policy_gradient_loss  | -0.00486    |
|    std                   | 0.38        |
|    value_loss            | 2.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.31197023 |
| rollout/                 |             |
|    ep_len_mean           | 60.8        |
|    ep_rew_mean           | -20.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 1411072     |
| train/                   |             |
|    approx_kl             | 0.017522898 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 151         |
|    cost_values           | -0.496      |
|    entropy               | -0.244      |
|    entropy_loss          | -0.247      |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.74        |
|    n_updates             | 6880        |
|    policy_gradient_loss  | 0.000264    |
|    std                   | 0.379       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.1760973  |
| rollout/                 |             |
|    ep_len_mean           | 60.9        |
|    ep_rew_mean           | -20.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 1413120     |
| train/                   |             |
|    approx_kl             | 0.013670431 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 165         |
|    cost_values           | -0.5        |
|    entropy               | -0.247      |
|    entropy_loss          | -0.245      |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.28        |
|    n_updates             | 6890        |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.38        |
|    value_loss            | 2.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.2639156  |
| rollout/                 |             |
|    ep_len_mean           | 62.3        |
|    ep_rew_mean           | -20.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1415168     |
| train/                   |             |
|    approx_kl             | 0.013731149 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 165         |
|    cost_values           | -0.503      |
|    entropy               | -0.251      |
|    entropy_loss          | -0.249      |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.11        |
|    n_updates             | 6900        |
|    policy_gradient_loss  | -0.00052    |
|    std                   | 0.381       |
|    value_loss            | 2.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.319979   |
| rollout/                 |             |
|    ep_len_mean           | 63.6        |
|    ep_rew_mean           | -21.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 1417216     |
| train/                   |             |
|    approx_kl             | 0.011377616 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 158         |
|    cost_values           | -0.514      |
|    entropy               | -0.239      |
|    entropy_loss          | -0.246      |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.855       |
|    n_updates             | 6910        |
|    policy_gradient_loss  | 0.000257    |
|    std                   | 0.378       |
|    value_loss            | 1.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.509045   |
| rollout/                 |             |
|    ep_len_mean           | 63.2        |
|    ep_rew_mean           | -21.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 156         |
|    total_timesteps       | 1419264     |
| train/                   |             |
|    approx_kl             | 0.018212974 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 166         |
|    cost_values           | -0.513      |
|    entropy               | -0.233      |
|    entropy_loss          | -0.235      |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.671       |
|    n_updates             | 6920        |
|    policy_gradient_loss  | 0.00222     |
|    std                   | 0.377       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.23611544 |
| rollout/                 |             |
|    ep_len_mean           | 62.5        |
|    ep_rew_mean           | -21.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 179         |
|    total_timesteps       | 1421312     |
| train/                   |             |
|    approx_kl             | 0.014351822 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 163         |
|    cost_values           | -0.505      |
|    entropy               | -0.23       |
|    entropy_loss          | -0.232      |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.925       |
|    n_updates             | 6930        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.376       |
|    value_loss            | 2.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34184238 |
| rollout/                 |             |
|    ep_len_mean           | 62.9        |
|    ep_rew_mean           | -21.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 201         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.013704818 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 158         |
|    cost_values           | -0.502      |
|    entropy               | -0.231      |
|    entropy_loss          | -0.23       |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 6940        |
|    policy_gradient_loss  | -0.0008     |
|    std                   | 0.378       |
|    value_loss            | 2.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.44        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.44        |
| reward                   | -0.40656045 |
| rollout/                 |             |
|    ep_len_mean           | 63          |
|    ep_rew_mean           | -20.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 223         |
|    total_timesteps       | 1425408     |
| train/                   |             |
|    approx_kl             | 0.012758756 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 167         |
|    cost_values           | -0.501      |
|    entropy               | -0.225      |
|    entropy_loss          | -0.228      |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 6950        |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.377       |
|    value_loss            | 2.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36539057 |
| rollout/                 |             |
|    ep_len_mean           | 62.7        |
|    ep_rew_mean           | -20.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 245         |
|    total_timesteps       | 1427456     |
| train/                   |             |
|    approx_kl             | 0.02525199  |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 165         |
|    cost_values           | -0.491      |
|    entropy               | -0.221      |
|    entropy_loss          | -0.222      |
|    explained_variance    | 0.874       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 6960        |
|    policy_gradient_loss  | 0.00979     |
|    std                   | 0.375       |
|    value_loss            | 2.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.1592347  |
| rollout/                 |             |
|    ep_len_mean           | 64.6        |
|    ep_rew_mean           | -21.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 268         |
|    total_timesteps       | 1429504     |
| train/                   |             |
|    approx_kl             | 0.014233774 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 160         |
|    cost_values           | -0.492      |
|    entropy               | -0.208      |
|    entropy_loss          | -0.214      |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.14        |
|    n_updates             | 6970        |
|    policy_gradient_loss  | 0.00462     |
|    std                   | 0.372       |
|    value_loss            | 2.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37497485 |
| rollout/                 |             |
|    ep_len_mean           | 62.5        |
|    ep_rew_mean           | -20.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 290         |
|    total_timesteps       | 1431552     |
| train/                   |             |
|    approx_kl             | 0.009210978 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 168         |
|    cost_values           | -0.491      |
|    entropy               | -0.204      |
|    entropy_loss          | -0.204      |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.09        |
|    n_updates             | 6980        |
|    policy_gradient_loss  | 0.00322     |
|    std                   | 0.37        |
|    value_loss            | 2.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.33912754 |
| rollout/                 |             |
|    ep_len_mean           | 63.3        |
|    ep_rew_mean           | -21.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 312         |
|    total_timesteps       | 1433600     |
| train/                   |             |
|    approx_kl             | 0.025778554 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 159         |
|    cost_values           | -0.502      |
|    entropy               | -0.204      |
|    entropy_loss          | -0.204      |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.06        |
|    n_updates             | 6990        |
|    policy_gradient_loss  | 0.00463     |
|    std                   | 0.37        |
|    value_loss            | 2.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.51654106 |
| rollout/                 |             |
|    ep_len_mean           | 61.9        |
|    ep_rew_mean           | -20.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 335         |
|    total_timesteps       | 1435648     |
| train/                   |             |
|    approx_kl             | 0.013296448 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 163         |
|    cost_values           | -0.496      |
|    entropy               | -0.204      |
|    entropy_loss          | -0.204      |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.13        |
|    n_updates             | 7000        |
|    policy_gradient_loss  | -0.000163   |
|    std                   | 0.37        |
|    value_loss            | 2.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.66        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.66        |
| reward                   | -0.23201236 |
| rollout/                 |             |
|    ep_len_mean           | 61.6        |
|    ep_rew_mean           | -20.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 357         |
|    total_timesteps       | 1437696     |
| train/                   |             |
|    approx_kl             | 0.023303056 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 159         |
|    cost_values           | -0.501      |
|    entropy               | -0.198      |
|    entropy_loss          | -0.202      |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.17        |
|    n_updates             | 7010        |
|    policy_gradient_loss  | -0.000703   |
|    std                   | 0.369       |
|    value_loss            | 2.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.3277538  |
| rollout/                 |             |
|    ep_len_mean           | 63.1        |
|    ep_rew_mean           | -21         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 380         |
|    total_timesteps       | 1439744     |
| train/                   |             |
|    approx_kl             | 0.014835899 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 157         |
|    cost_values           | -0.494      |
|    entropy               | -0.192      |
|    entropy_loss          | -0.195      |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.04        |
|    n_updates             | 7020        |
|    policy_gradient_loss  | 0.00173     |
|    std                   | 0.369       |
|    value_loss            | 1.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.53497857 |
| rollout/                 |             |
|    ep_len_mean           | 65.4        |
|    ep_rew_mean           | -21.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 402         |
|    total_timesteps       | 1441792     |
| train/                   |             |
|    approx_kl             | 0.013012032 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 171         |
|    cost_values           | -0.499      |
|    entropy               | -0.189      |
|    entropy_loss          | -0.191      |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.12        |
|    n_updates             | 7030        |
|    policy_gradient_loss  | 0.0013      |
|    std                   | 0.37        |
|    value_loss            | 2.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.3430572  |
| rollout/                 |             |
|    ep_len_mean           | 64.6        |
|    ep_rew_mean           | -21.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 424         |
|    total_timesteps       | 1443840     |
| train/                   |             |
|    approx_kl             | 0.014619183 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 168         |
|    cost_values           | -0.498      |
|    entropy               | -0.191      |
|    entropy_loss          | -0.19       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 7040        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.371       |
|    value_loss            | 2.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25790069 |
| rollout/                 |             |
|    ep_len_mean           | 62.7        |
|    ep_rew_mean           | -20.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 447         |
|    total_timesteps       | 1445888     |
| train/                   |             |
|    approx_kl             | 0.015887313 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 160         |
|    cost_values           | -0.507      |
|    entropy               | -0.185      |
|    entropy_loss          | -0.188      |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.967       |
|    n_updates             | 7050        |
|    policy_gradient_loss  | 0.000731    |
|    std                   | 0.369       |
|    value_loss            | 1.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.27993324 |
| rollout/                 |             |
|    ep_len_mean           | 62.5        |
|    ep_rew_mean           | -20.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 469         |
|    total_timesteps       | 1447936     |
| train/                   |             |
|    approx_kl             | 0.01057259  |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 158         |
|    cost_values           | -0.509      |
|    entropy               | -0.178      |
|    entropy_loss          | -0.181      |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.809       |
|    n_updates             | 7060        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.368       |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.339813   |
| rollout/                 |             |
|    ep_len_mean           | 61.7        |
|    ep_rew_mean           | -21         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 492         |
|    total_timesteps       | 1449984     |
| train/                   |             |
|    approx_kl             | 0.025651129 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 169         |
|    cost_values           | -0.503      |
|    entropy               | -0.176      |
|    entropy_loss          | -0.177      |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.25        |
|    n_updates             | 7070        |
|    policy_gradient_loss  | 0.00335     |
|    std                   | 0.367       |
|    value_loss            | 2.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.2574978  |
| rollout/                 |             |
|    ep_len_mean           | 61          |
|    ep_rew_mean           | -21.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 514         |
|    total_timesteps       | 1452032     |
| train/                   |             |
|    approx_kl             | 0.018407071 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 157         |
|    cost_values           | -0.512      |
|    entropy               | -0.17       |
|    entropy_loss          | -0.174      |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.95        |
|    n_updates             | 7080        |
|    policy_gradient_loss  | 0.00344     |
|    std                   | 0.365       |
|    value_loss            | 1.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.21689309 |
| rollout/                 |             |
|    ep_len_mean           | 58.8        |
|    ep_rew_mean           | -20.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 536         |
|    total_timesteps       | 1454080     |
| train/                   |             |
|    approx_kl             | 0.016883954 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 154         |
|    cost_values           | -0.509      |
|    entropy               | -0.158      |
|    entropy_loss          | -0.164      |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.901       |
|    n_updates             | 7090        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.362       |
|    value_loss            | 1.84        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.6        |
| reward                   | -0.5022698 |
| rollout/                 |            |
|    ep_len_mean           | 57.4       |
|    ep_rew_mean           | -19.9      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 25         |
|    time_elapsed          | 559        |
|    total_timesteps       | 1456128    |
| train/                   |            |
|    approx_kl             | 0.00803913 |
|    clip_fraction         | 0.165      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.3       |
|    cost_value_loss       | 155        |
|    cost_values           | -0.506     |
|    entropy               | -0.154     |
|    entropy_loss          | -0.155     |
|    explained_variance    | 0.908      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.907      |
|    n_updates             | 7100       |
|    policy_gradient_loss  | 0.00124    |
|    std                   | 0.361      |
|    value_loss            | 1.76       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37580562 |
| rollout/                 |             |
|    ep_len_mean           | 58.3        |
|    ep_rew_mean           | -19.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 581         |
|    total_timesteps       | 1458176     |
| train/                   |             |
|    approx_kl             | 0.010997511 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 151         |
|    cost_values           | -0.495      |
|    entropy               | -0.147      |
|    entropy_loss          | -0.151      |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.86        |
|    n_updates             | 7110        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.359       |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.69        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.69        |
| reward                   | -0.34910116 |
| rollout/                 |             |
|    ep_len_mean           | 59.7        |
|    ep_rew_mean           | -20         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 604         |
|    total_timesteps       | 1460224     |
| train/                   |             |
|    approx_kl             | 0.020914111 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.494      |
|    entropy               | -0.14       |
|    entropy_loss          | -0.143      |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.794       |
|    n_updates             | 7120        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.357       |
|    value_loss            | 1.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24120802 |
| rollout/                 |             |
|    ep_len_mean           | 62.3        |
|    ep_rew_mean           | -20.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 626         |
|    total_timesteps       | 1462272     |
| train/                   |             |
|    approx_kl             | 0.016598366 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 167         |
|    cost_values           | -0.495      |
|    entropy               | -0.137      |
|    entropy_loss          | -0.138      |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 7130        |
|    policy_gradient_loss  | -0.000363   |
|    std                   | 0.356       |
|    value_loss            | 2.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.21125317 |
| rollout/                 |             |
|    ep_len_mean           | 62.9        |
|    ep_rew_mean           | -20.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 648         |
|    total_timesteps       | 1464320     |
| train/                   |             |
|    approx_kl             | 0.012453334 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.494      |
|    entropy               | -0.142      |
|    entropy_loss          | -0.139      |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.02        |
|    n_updates             | 7140        |
|    policy_gradient_loss  | -0.00429    |
|    std                   | 0.358       |
|    value_loss            | 2.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.323513   |
| rollout/                 |             |
|    ep_len_mean           | 59.9        |
|    ep_rew_mean           | -20         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 671         |
|    total_timesteps       | 1466368     |
| train/                   |             |
|    approx_kl             | 0.017215805 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 163         |
|    cost_values           | -0.497      |
|    entropy               | -0.144      |
|    entropy_loss          | -0.144      |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.933       |
|    n_updates             | 7150        |
|    policy_gradient_loss  | 0.00122     |
|    std                   | 0.358       |
|    value_loss            | 1.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1397063  |
| rollout/                 |             |
|    ep_len_mean           | 59.5        |
|    ep_rew_mean           | -20         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 693         |
|    total_timesteps       | 1468416     |
| train/                   |             |
|    approx_kl             | 0.011028054 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 152         |
|    cost_values           | -0.503      |
|    entropy               | -0.143      |
|    entropy_loss          | -0.144      |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.04        |
|    n_updates             | 7160        |
|    policy_gradient_loss  | -0.000626   |
|    std                   | 0.358       |
|    value_loss            | 2.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1323724  |
| rollout/                 |             |
|    ep_len_mean           | 60.7        |
|    ep_rew_mean           | -20.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 715         |
|    total_timesteps       | 1470464     |
| train/                   |             |
|    approx_kl             | 0.014573285 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 159         |
|    cost_values           | -0.503      |
|    entropy               | -0.15       |
|    entropy_loss          | -0.146      |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.541       |
|    n_updates             | 7170        |
|    policy_gradient_loss  | 0.000919    |
|    std                   | 0.361       |
|    value_loss            | 1.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.44405356 |
| rollout/                 |             |
|    ep_len_mean           | 62.1        |
|    ep_rew_mean           | -20.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 738         |
|    total_timesteps       | 1472512     |
| train/                   |             |
|    approx_kl             | 0.02433458  |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 167         |
|    cost_values           | -0.49       |
|    entropy               | -0.147      |
|    entropy_loss          | -0.15       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.619       |
|    n_updates             | 7180        |
|    policy_gradient_loss  | 0.00447     |
|    std                   | 0.359       |
|    value_loss            | 1.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.1939553   |
| rollout/                 |              |
|    ep_len_mean           | 62           |
|    ep_rew_mean           | -20.7        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 34           |
|    time_elapsed          | 760          |
|    total_timesteps       | 1474560      |
| train/                   |              |
|    approx_kl             | 0.0075733843 |
|    clip_fraction         | 0.165        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 159          |
|    cost_values           | -0.494       |
|    entropy               | -0.145       |
|    entropy_loss          | -0.146       |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.21         |
|    n_updates             | 7190         |
|    policy_gradient_loss  | 0.00496      |
|    std                   | 0.359        |
|    value_loss            | 2.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33326194 |
| rollout/                 |             |
|    ep_len_mean           | 57.8        |
|    ep_rew_mean           | -19.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 783         |
|    total_timesteps       | 1476608     |
| train/                   |             |
|    approx_kl             | 0.019271132 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.493      |
|    entropy               | -0.142      |
|    entropy_loss          | -0.144      |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.905       |
|    n_updates             | 7200        |
|    policy_gradient_loss  | -0.000938   |
|    std                   | 0.358       |
|    value_loss            | 1.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.59580153 |
| rollout/                 |             |
|    ep_len_mean           | 58.2        |
|    ep_rew_mean           | -19.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 805         |
|    total_timesteps       | 1478656     |
| train/                   |             |
|    approx_kl             | 0.02048387  |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 148         |
|    cost_values           | -0.495      |
|    entropy               | -0.134      |
|    entropy_loss          | -0.138      |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.817       |
|    n_updates             | 7210        |
|    policy_gradient_loss  | 0.00277     |
|    std                   | 0.356       |
|    value_loss            | 1.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.78        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.78        |
| reward                   | -0.23618232 |
| rollout/                 |             |
|    ep_len_mean           | 58.9        |
|    ep_rew_mean           | -19.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 828         |
|    total_timesteps       | 1480704     |
| train/                   |             |
|    approx_kl             | 0.026325539 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 158         |
|    cost_values           | -0.495      |
|    entropy               | -0.131      |
|    entropy_loss          | -0.132      |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.05        |
|    n_updates             | 7220        |
|    policy_gradient_loss  | 0.00882     |
|    std                   | 0.356       |
|    value_loss            | 2.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.33840713 |
| rollout/                 |             |
|    ep_len_mean           | 61.1        |
|    ep_rew_mean           | -20.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 850         |
|    total_timesteps       | 1482752     |
| train/                   |             |
|    approx_kl             | 0.013546893 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.5        |
|    entropy               | -0.131      |
|    entropy_loss          | -0.131      |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.885       |
|    n_updates             | 7230        |
|    policy_gradient_loss  | 0.000309    |
|    std                   | 0.356       |
|    value_loss            | 1.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.3060609  |
| rollout/                 |             |
|    ep_len_mean           | 62.5        |
|    ep_rew_mean           | -20.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 39          |
|    time_elapsed          | 873         |
|    total_timesteps       | 1484800     |
| train/                   |             |
|    approx_kl             | 0.019418936 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 164         |
|    cost_values           | -0.501      |
|    entropy               | -0.129      |
|    entropy_loss          | -0.13       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.02        |
|    n_updates             | 7240        |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.356       |
|    value_loss            | 1.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2968707  |
| rollout/                 |             |
|    ep_len_mean           | 61.8        |
|    ep_rew_mean           | -20.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 895         |
|    total_timesteps       | 1486848     |
| train/                   |             |
|    approx_kl             | 0.015155443 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 162         |
|    cost_values           | -0.481      |
|    entropy               | -0.129      |
|    entropy_loss          | -0.128      |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.09        |
|    n_updates             | 7250        |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.357       |
|    value_loss            | 2.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.1662548  |
| rollout/                 |             |
|    ep_len_mean           | 60.6        |
|    ep_rew_mean           | -20.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 917         |
|    total_timesteps       | 1488896     |
| train/                   |             |
|    approx_kl             | 0.011227331 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 160         |
|    cost_values           | -0.488      |
|    entropy               | -0.128      |
|    entropy_loss          | -0.129      |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 7260        |
|    policy_gradient_loss  | 0.000849    |
|    std                   | 0.358       |
|    value_loss            | 2.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.28139332 |
| rollout/                 |             |
|    ep_len_mean           | 60.3        |
|    ep_rew_mean           | -20.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 940         |
|    total_timesteps       | 1490944     |
| train/                   |             |
|    approx_kl             | 0.01972241  |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 157         |
|    cost_values           | -0.493      |
|    entropy               | -0.12       |
|    entropy_loss          | -0.125      |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.8         |
|    n_updates             | 7270        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.356       |
|    value_loss            | 1.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4067108  |
| rollout/                 |             |
|    ep_len_mean           | 60.1        |
|    ep_rew_mean           | -20.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 962         |
|    total_timesteps       | 1492992     |
| train/                   |             |
|    approx_kl             | 0.015137238 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 161         |
|    cost_values           | -0.492      |
|    entropy               | -0.126      |
|    entropy_loss          | -0.122      |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.881       |
|    n_updates             | 7280        |
|    policy_gradient_loss  | -0.00546    |
|    std                   | 0.358       |
|    value_loss            | 1.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.58177596 |
| rollout/                 |             |
|    ep_len_mean           | 60.1        |
|    ep_rew_mean           | -20.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 44          |
|    time_elapsed          | 985         |
|    total_timesteps       | 1495040     |
| train/                   |             |
|    approx_kl             | 0.010524627 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 154         |
|    cost_values           | -0.493      |
|    entropy               | -0.129      |
|    entropy_loss          | -0.128      |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.02        |
|    n_updates             | 7290        |
|    policy_gradient_loss  | 0.00605     |
|    std                   | 0.36        |
|    value_loss            | 2.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.79         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.79         |
| reward                   | -0.39112166  |
| rollout/                 |              |
|    ep_len_mean           | 59.6         |
|    ep_rew_mean           | -20.1        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 45           |
|    time_elapsed          | 1007         |
|    total_timesteps       | 1497088      |
| train/                   |              |
|    approx_kl             | 0.0075083924 |
|    clip_fraction         | 0.134        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 157          |
|    cost_values           | -0.489       |
|    entropy               | -0.133       |
|    entropy_loss          | -0.131       |
|    explained_variance    | 0.854        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.06         |
|    n_updates             | 7300         |
|    policy_gradient_loss  | 0.00241      |
|    std                   | 0.361        |
|    value_loss            | 2.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.29880738 |
| rollout/                 |             |
|    ep_len_mean           | 59.7        |
|    ep_rew_mean           | -20.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 46          |
|    time_elapsed          | 1029        |
|    total_timesteps       | 1499136     |
| train/                   |             |
|    approx_kl             | 0.016444651 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 160         |
|    cost_values           | -0.485      |
|    entropy               | -0.124      |
|    entropy_loss          | -0.129      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.937       |
|    n_updates             | 7310        |
|    policy_gradient_loss  | 0.000373    |
|    std                   | 0.36        |
|    value_loss            | 1.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18123828 |
| rollout/                 |             |
|    ep_len_mean           | 58.5        |
|    ep_rew_mean           | -19.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 47          |
|    time_elapsed          | 1052        |
|    total_timesteps       | 1501184     |
| train/                   |             |
|    approx_kl             | 0.018327955 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 159         |
|    cost_values           | -0.489      |
|    entropy               | -0.12       |
|    entropy_loss          | -0.122      |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.27        |
|    n_updates             | 7320        |
|    policy_gradient_loss  | -0.00531    |
|    std                   | 0.359       |
|    value_loss            | 2.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.37730086 |
| rollout/                 |             |
|    ep_len_mean           | 60.6        |
|    ep_rew_mean           | -20.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1074        |
|    total_timesteps       | 1503232     |
| train/                   |             |
|    approx_kl             | 0.013191504 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 151         |
|    cost_values           | -0.476      |
|    entropy               | -0.115      |
|    entropy_loss          | -0.118      |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.17        |
|    n_updates             | 7330        |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.358       |
|    value_loss            | 2.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.40074658 |
| rollout/                 |             |
|    ep_len_mean           | 60.2        |
|    ep_rew_mean           | -20.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 49          |
|    time_elapsed          | 1096        |
|    total_timesteps       | 1505280     |
| train/                   |             |
|    approx_kl             | 0.009489965 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 167         |
|    cost_values           | -0.474      |
|    entropy               | -0.104      |
|    entropy_loss          | -0.11       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.17        |
|    n_updates             | 7340        |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.356       |
|    value_loss            | 2.13        |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.29025578 |
| rollout/           |             |
|    ep_len_mean     | 62.7        |
|    ep_rew_mean     | -21.1       |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1507328     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31505486 |
| rollout/                 |             |
|    ep_len_mean           | 60.3        |
|    ep_rew_mean           | -20.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 1509376     |
| train/                   |             |
|    approx_kl             | 0.013698619 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 167         |
|    cost_values           | -0.49       |
|    entropy               | -0.0789     |
|    entropy_loss          | -0.0825     |
|    explained_variance    | 0.861       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.3         |
|    n_updates             | 7360        |
|    policy_gradient_loss  | 0.00107     |
|    std                   | 0.35        |
|    value_loss            | 2.8         |
------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.339813  |
| rollout/                 |            |
|    ep_len_mean           | 61         |
|    ep_rew_mean           | -21.1      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 3          |
|    time_elapsed          | 66         |
|    total_timesteps       | 1511424    |
| train/                   |            |
|    approx_kl             | 0.01717953 |
|    clip_fraction         | 0.165      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.3       |
|    cost_value_loss       | 156        |
|    cost_values           | -0.49      |
|    entropy               | -0.0722    |
|    entropy_loss          | -0.076     |
|    explained_variance    | 0.844      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.57       |
|    n_updates             | 7370       |
|    policy_gradient_loss  | 0.00301    |
|    std                   | 0.349      |
|    value_loss            | 3.07       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.42528185 |
| rollout/                 |             |
|    ep_len_mean           | 59.4        |
|    ep_rew_mean           | -20.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 1513472     |
| train/                   |             |
|    approx_kl             | 0.013659223 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 159         |
|    cost_values           | -0.495      |
|    entropy               | -0.0734     |
|    entropy_loss          | -0.0724     |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.29        |
|    n_updates             | 7380        |
|    policy_gradient_loss  | -0.000396   |
|    std                   | 0.349       |
|    value_loss            | 2.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.28405133 |
| rollout/                 |             |
|    ep_len_mean           | 58          |
|    ep_rew_mean           | -19.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1515520     |
| train/                   |             |
|    approx_kl             | 0.012045605 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 160         |
|    cost_values           | -0.498      |
|    entropy               | -0.0708     |
|    entropy_loss          | -0.0722     |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.07        |
|    n_updates             | 7390        |
|    policy_gradient_loss  | -0.000336   |
|    std                   | 0.349       |
|    value_loss            | 2.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28134003 |
| rollout/                 |             |
|    ep_len_mean           | 59.1        |
|    ep_rew_mean           | -20.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 133         |
|    total_timesteps       | 1517568     |
| train/                   |             |
|    approx_kl             | 0.012166961 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.494      |
|    entropy               | -0.0604     |
|    entropy_loss          | -0.0658     |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.713       |
|    n_updates             | 7400        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.347       |
|    value_loss            | 1.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.49941137 |
| rollout/                 |             |
|    ep_len_mean           | 60.1        |
|    ep_rew_mean           | -20.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 156         |
|    total_timesteps       | 1519616     |
| train/                   |             |
|    approx_kl             | 0.012442485 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 168         |
|    cost_values           | -0.493      |
|    entropy               | -0.0448     |
|    entropy_loss          | -0.0526     |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.46        |
|    n_updates             | 7410        |
|    policy_gradient_loss  | -0.00428    |
|    std                   | 0.343       |
|    value_loss            | 2.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.3868481  |
| rollout/                 |             |
|    ep_len_mean           | 61.7        |
|    ep_rew_mean           | -20.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 178         |
|    total_timesteps       | 1521664     |
| train/                   |             |
|    approx_kl             | 0.011649739 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 170         |
|    cost_values           | -0.493      |
|    entropy               | -0.0375     |
|    entropy_loss          | -0.0407     |
|    explained_variance    | 0.774       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.61        |
|    n_updates             | 7420        |
|    policy_gradient_loss  | -0.00507    |
|    std                   | 0.341       |
|    value_loss            | 3.55        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6          |
| reward                   | -0.1986139 |
| rollout/                 |            |
|    ep_len_mean           | 60.4       |
|    ep_rew_mean           | -20.2      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 9          |
|    time_elapsed          | 201        |
|    total_timesteps       | 1523712    |
| train/                   |            |
|    approx_kl             | 0.01760758 |
|    clip_fraction         | 0.129      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.1       |
|    cost_value_loss       | 151        |
|    cost_values           | -0.488     |
|    entropy               | -0.0274    |
|    entropy_loss          | -0.0322    |
|    explained_variance    | 0.841      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.29       |
|    n_updates             | 7430       |
|    policy_gradient_loss  | -0.0018    |
|    std                   | 0.339      |
|    value_loss            | 2.65       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2578136  |
| rollout/                 |             |
|    ep_len_mean           | 59          |
|    ep_rew_mean           | -19.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 223         |
|    total_timesteps       | 1525760     |
| train/                   |             |
|    approx_kl             | 0.010228645 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 158         |
|    cost_values           | -0.486      |
|    entropy               | -0.0284     |
|    entropy_loss          | -0.0273     |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 7440        |
|    policy_gradient_loss  | -0.000212   |
|    std                   | 0.339       |
|    value_loss            | 2.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.33195817 |
| rollout/                 |             |
|    ep_len_mean           | 58.8        |
|    ep_rew_mean           | -19.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 245         |
|    total_timesteps       | 1527808     |
| train/                   |             |
|    approx_kl             | 0.015605135 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 159         |
|    cost_values           | -0.489      |
|    entropy               | -0.0178     |
|    entropy_loss          | -0.0239     |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.19        |
|    n_updates             | 7450        |
|    policy_gradient_loss  | 0.00674     |
|    std                   | 0.338       |
|    value_loss            | 2.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.26        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.26        |
| reward                   | -0.38494992 |
| rollout/                 |             |
|    ep_len_mean           | 57.3        |
|    ep_rew_mean           | -19.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 268         |
|    total_timesteps       | 1529856     |
| train/                   |             |
|    approx_kl             | 0.017429361 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 152         |
|    cost_values           | -0.493      |
|    entropy               | -0.00328    |
|    entropy_loss          | -0.00931    |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.18        |
|    n_updates             | 7460        |
|    policy_gradient_loss  | 0.00177     |
|    std                   | 0.336       |
|    value_loss            | 2.25        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1          |
| reward                   | -0.519316  |
| rollout/                 |            |
|    ep_len_mean           | 55.9       |
|    ep_rew_mean           | -19.2      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 13         |
|    time_elapsed          | 290        |
|    total_timesteps       | 1531904    |
| train/                   |            |
|    approx_kl             | 0.01943493 |
|    clip_fraction         | 0.151      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.2       |
|    cost_value_loss       | 151        |
|    cost_values           | -0.482     |
|    entropy               | 0.0152     |
|    entropy_loss          | 0.00611    |
|    explained_variance    | 0.903      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.873      |
|    n_updates             | 7470       |
|    policy_gradient_loss  | -0.000531  |
|    std                   | 0.332      |
|    value_loss            | 1.93       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.5778495  |
| rollout/                 |             |
|    ep_len_mean           | 57.2        |
|    ep_rew_mean           | -19.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 313         |
|    total_timesteps       | 1533952     |
| train/                   |             |
|    approx_kl             | 0.011504617 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 152         |
|    cost_values           | -0.493      |
|    entropy               | 0.0279      |
|    entropy_loss          | 0.0221      |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.945       |
|    n_updates             | 7480        |
|    policy_gradient_loss  | -0.000522   |
|    std                   | 0.331       |
|    value_loss            | 1.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.54566383 |
| rollout/                 |             |
|    ep_len_mean           | 59.9        |
|    ep_rew_mean           | -20.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 335         |
|    total_timesteps       | 1536000     |
| train/                   |             |
|    approx_kl             | 0.012849791 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 158         |
|    cost_values           | -0.481      |
|    entropy               | 0.0428      |
|    entropy_loss          | 0.0351      |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.774       |
|    n_updates             | 7490        |
|    policy_gradient_loss  | 0.00478     |
|    std                   | 0.329       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27199548 |
| rollout/                 |             |
|    ep_len_mean           | 59.4        |
|    ep_rew_mean           | -20.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 358         |
|    total_timesteps       | 1538048     |
| train/                   |             |
|    approx_kl             | 0.019087331 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 166         |
|    cost_values           | -0.478      |
|    entropy               | 0.0496      |
|    entropy_loss          | 0.0481      |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.18        |
|    n_updates             | 7500        |
|    policy_gradient_loss  | 0.00938     |
|    std                   | 0.328       |
|    value_loss            | 2.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.08        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.08        |
| reward                   | -0.33317    |
| rollout/                 |             |
|    ep_len_mean           | 59          |
|    ep_rew_mean           | -20.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 380         |
|    total_timesteps       | 1540096     |
| train/                   |             |
|    approx_kl             | 0.011782581 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 148         |
|    cost_values           | -0.48       |
|    entropy               | 0.0628      |
|    entropy_loss          | 0.0558      |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.781       |
|    n_updates             | 7510        |
|    policy_gradient_loss  | -0.000152   |
|    std                   | 0.326       |
|    value_loss            | 1.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.55644405 |
| rollout/                 |             |
|    ep_len_mean           | 56.3        |
|    ep_rew_mean           | -19.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 402         |
|    total_timesteps       | 1542144     |
| train/                   |             |
|    approx_kl             | 0.015921708 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 155         |
|    cost_values           | -0.474      |
|    entropy               | 0.0619      |
|    entropy_loss          | 0.0635      |
|    explained_variance    | 0.859       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.07        |
|    n_updates             | 7520        |
|    policy_gradient_loss  | 0.00283     |
|    std                   | 0.328       |
|    value_loss            | 2.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.3892     |
| rollout/                 |             |
|    ep_len_mean           | 57.2        |
|    ep_rew_mean           | -19.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 425         |
|    total_timesteps       | 1544192     |
| train/                   |             |
|    approx_kl             | 0.020521661 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 152         |
|    cost_values           | -0.463      |
|    entropy               | 0.0678      |
|    entropy_loss          | 0.0641      |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.36        |
|    n_updates             | 7530        |
|    policy_gradient_loss  | -0.000997   |
|    std                   | 0.328       |
|    value_loss            | 2.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.34663445 |
| rollout/                 |             |
|    ep_len_mean           | 59          |
|    ep_rew_mean           | -19.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 447         |
|    total_timesteps       | 1546240     |
| train/                   |             |
|    approx_kl             | 0.012626927 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 155         |
|    cost_values           | -0.48       |
|    entropy               | 0.0664      |
|    entropy_loss          | 0.0678      |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.837       |
|    n_updates             | 7540        |
|    policy_gradient_loss  | 0.00124     |
|    std                   | 0.329       |
|    value_loss            | 1.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.2783405  |
| rollout/                 |             |
|    ep_len_mean           | 56.9        |
|    ep_rew_mean           | -19.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 470         |
|    total_timesteps       | 1548288     |
| train/                   |             |
|    approx_kl             | 0.030420989 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 157         |
|    cost_values           | -0.488      |
|    entropy               | 0.0692      |
|    entropy_loss          | 0.0675      |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.846       |
|    n_updates             | 7550        |
|    policy_gradient_loss  | 0.0016      |
|    std                   | 0.33        |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.2962836  |
| rollout/                 |             |
|    ep_len_mean           | 54.5        |
|    ep_rew_mean           | -19.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 492         |
|    total_timesteps       | 1550336     |
| train/                   |             |
|    approx_kl             | 0.012530347 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 146         |
|    cost_values           | -0.485      |
|    entropy               | 0.0709      |
|    entropy_loss          | 0.07        |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.729       |
|    n_updates             | 7560        |
|    policy_gradient_loss  | -0.000337   |
|    std                   | 0.33        |
|    value_loss            | 1.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.330603   |
| rollout/                 |             |
|    ep_len_mean           | 56.6        |
|    ep_rew_mean           | -19.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 514         |
|    total_timesteps       | 1552384     |
| train/                   |             |
|    approx_kl             | 0.015812777 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 140         |
|    cost_values           | -0.5        |
|    entropy               | 0.073       |
|    entropy_loss          | 0.0721      |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.796       |
|    n_updates             | 7570        |
|    policy_gradient_loss  | 0.00216     |
|    std                   | 0.329       |
|    value_loss            | 1.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.122247055 |
| rollout/                 |              |
|    ep_len_mean           | 56.1         |
|    ep_rew_mean           | -19.5        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 24           |
|    time_elapsed          | 537          |
|    total_timesteps       | 1554432      |
| train/                   |              |
|    approx_kl             | 0.019974545  |
|    clip_fraction         | 0.151        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.9         |
|    cost_value_loss       | 170          |
|    cost_values           | -0.484       |
|    entropy               | 0.0735       |
|    entropy_loss          | 0.0733       |
|    explained_variance    | 0.871        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.919        |
|    n_updates             | 7580         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.329        |
|    value_loss            | 2.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.15380248 |
| rollout/                 |             |
|    ep_len_mean           | 57          |
|    ep_rew_mean           | -19.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 559         |
|    total_timesteps       | 1556480     |
| train/                   |             |
|    approx_kl             | 0.021390367 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.484      |
|    entropy               | 0.0812      |
|    entropy_loss          | 0.0766      |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.796       |
|    n_updates             | 7590        |
|    policy_gradient_loss  | 0.00106     |
|    std                   | 0.328       |
|    value_loss            | 1.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.3268251  |
| rollout/                 |             |
|    ep_len_mean           | 56.4        |
|    ep_rew_mean           | -19.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 582         |
|    total_timesteps       | 1558528     |
| train/                   |             |
|    approx_kl             | 0.017525177 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 149         |
|    cost_values           | -0.486      |
|    entropy               | 0.0805      |
|    entropy_loss          | 0.0813      |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.2         |
|    n_updates             | 7600        |
|    policy_gradient_loss  | 0.00434     |
|    std                   | 0.328       |
|    value_loss            | 2.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.27596205 |
| rollout/                 |             |
|    ep_len_mean           | 54.9        |
|    ep_rew_mean           | -18.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 604         |
|    total_timesteps       | 1560576     |
| train/                   |             |
|    approx_kl             | 0.015129272 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 154         |
|    cost_values           | -0.483      |
|    entropy               | 0.0888      |
|    entropy_loss          | 0.0837      |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.03        |
|    n_updates             | 7610        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.327       |
|    value_loss            | 2.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.6153398  |
| rollout/                 |             |
|    ep_len_mean           | 53.2        |
|    ep_rew_mean           | -18.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 627         |
|    total_timesteps       | 1562624     |
| train/                   |             |
|    approx_kl             | 0.016231999 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.492      |
|    entropy               | 0.0975      |
|    entropy_loss          | 0.0934      |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.699       |
|    n_updates             | 7620        |
|    policy_gradient_loss  | -0.0048     |
|    std                   | 0.327       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23235622 |
| rollout/                 |             |
|    ep_len_mean           | 53.5        |
|    ep_rew_mean           | -18.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 649         |
|    total_timesteps       | 1564672     |
| train/                   |             |
|    approx_kl             | 0.012371127 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 147         |
|    cost_values           | -0.488      |
|    entropy               | 0.0944      |
|    entropy_loss          | 0.0967      |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.665       |
|    n_updates             | 7630        |
|    policy_gradient_loss  | 0.00126     |
|    std                   | 0.328       |
|    value_loss            | 1.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.63264793 |
| rollout/                 |             |
|    ep_len_mean           | 53.4        |
|    ep_rew_mean           | -18.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 672         |
|    total_timesteps       | 1566720     |
| train/                   |             |
|    approx_kl             | 0.017606862 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 151         |
|    cost_values           | -0.493      |
|    entropy               | 0.0931      |
|    entropy_loss          | 0.0932      |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.742       |
|    n_updates             | 7640        |
|    policy_gradient_loss  | 0.00151     |
|    std                   | 0.329       |
|    value_loss            | 1.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.37502965 |
| rollout/                 |             |
|    ep_len_mean           | 52.2        |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 694         |
|    total_timesteps       | 1568768     |
| train/                   |             |
|    approx_kl             | 0.014292058 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.487      |
|    entropy               | 0.0997      |
|    entropy_loss          | 0.0957      |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.819       |
|    n_updates             | 7650        |
|    policy_gradient_loss  | 0.0034      |
|    std                   | 0.327       |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.58121073 |
| rollout/                 |             |
|    ep_len_mean           | 51.9        |
|    ep_rew_mean           | -18         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 716         |
|    total_timesteps       | 1570816     |
| train/                   |             |
|    approx_kl             | 0.019813564 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.502      |
|    entropy               | 0.102       |
|    entropy_loss          | 0.101       |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.666       |
|    n_updates             | 7660        |
|    policy_gradient_loss  | 0.000884    |
|    std                   | 0.328       |
|    value_loss            | 1.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.3557241  |
| rollout/                 |             |
|    ep_len_mean           | 53.1        |
|    ep_rew_mean           | -18.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 739         |
|    total_timesteps       | 1572864     |
| train/                   |             |
|    approx_kl             | 0.016141526 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 145         |
|    cost_values           | -0.49       |
|    entropy               | 0.107       |
|    entropy_loss          | 0.104       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.859       |
|    n_updates             | 7670        |
|    policy_gradient_loss  | -0.000429   |
|    std                   | 0.327       |
|    value_loss            | 1.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.19183631 |
| rollout/                 |             |
|    ep_len_mean           | 55.6        |
|    ep_rew_mean           | -19.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 761         |
|    total_timesteps       | 1574912     |
| train/                   |             |
|    approx_kl             | 0.013359123 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 152         |
|    cost_values           | -0.49       |
|    entropy               | 0.115       |
|    entropy_loss          | 0.111       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.75        |
|    n_updates             | 7680        |
|    policy_gradient_loss  | 0.00243     |
|    std                   | 0.327       |
|    value_loss            | 1.48        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3          |
| reward                   | -0.6165283 |
| rollout/                 |            |
|    ep_len_mean           | 56.7       |
|    ep_rew_mean           | -19        |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 35         |
|    time_elapsed          | 784        |
|    total_timesteps       | 1576960    |
| train/                   |            |
|    approx_kl             | 0.01207046 |
|    clip_fraction         | 0.201      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.2       |
|    cost_value_loss       | 151        |
|    cost_values           | -0.492     |
|    entropy               | 0.118      |
|    entropy_loss          | 0.117      |
|    explained_variance    | 0.897      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.802      |
|    n_updates             | 7690       |
|    policy_gradient_loss  | 0.000662   |
|    std                   | 0.327      |
|    value_loss            | 1.59       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.2467076  |
| rollout/                 |             |
|    ep_len_mean           | 56          |
|    ep_rew_mean           | -18.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 807         |
|    total_timesteps       | 1579008     |
| train/                   |             |
|    approx_kl             | 0.016633881 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 152         |
|    cost_values           | -0.495      |
|    entropy               | 0.11        |
|    entropy_loss          | 0.114       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.766       |
|    n_updates             | 7700        |
|    policy_gradient_loss  | -0.00114    |
|    std                   | 0.33        |
|    value_loss            | 1.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.75         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.75         |
| reward                   | -0.4732168   |
| rollout/                 |              |
|    ep_len_mean           | 56.7         |
|    ep_rew_mean           | -19.1        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 37           |
|    time_elapsed          | 829          |
|    total_timesteps       | 1581056      |
| train/                   |              |
|    approx_kl             | 0.0129253855 |
|    clip_fraction         | 0.171        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.3         |
|    cost_value_loss       | 154          |
|    cost_values           | -0.492       |
|    entropy               | 0.115        |
|    entropy_loss          | 0.112        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.832        |
|    n_updates             | 7710         |
|    policy_gradient_loss  | 0.00508      |
|    std                   | 0.329        |
|    value_loss            | 1.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.24394383 |
| rollout/                 |             |
|    ep_len_mean           | 56.8        |
|    ep_rew_mean           | -19.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 851         |
|    total_timesteps       | 1583104     |
| train/                   |             |
|    approx_kl             | 0.020353917 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 153         |
|    cost_values           | -0.48       |
|    entropy               | 0.122       |
|    entropy_loss          | 0.119       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.04        |
|    n_updates             | 7720        |
|    policy_gradient_loss  | -0.000287   |
|    std                   | 0.328       |
|    value_loss            | 2.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.33960292 |
| rollout/                 |             |
|    ep_len_mean           | 54.8        |
|    ep_rew_mean           | -18.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 39          |
|    time_elapsed          | 874         |
|    total_timesteps       | 1585152     |
| train/                   |             |
|    approx_kl             | 0.012287494 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 150         |
|    cost_values           | -0.483      |
|    entropy               | 0.131       |
|    entropy_loss          | 0.127       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.724       |
|    n_updates             | 7730        |
|    policy_gradient_loss  | -0.0044     |
|    std                   | 0.327       |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.38391107 |
| rollout/                 |             |
|    ep_len_mean           | 51.7        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 896         |
|    total_timesteps       | 1587200     |
| train/                   |             |
|    approx_kl             | 0.007812253 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 146         |
|    cost_values           | -0.492      |
|    entropy               | 0.147       |
|    entropy_loss          | 0.138       |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.13        |
|    n_updates             | 7740        |
|    policy_gradient_loss  | 0.000567    |
|    std                   | 0.326       |
|    value_loss            | 2.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3392311  |
| rollout/                 |             |
|    ep_len_mean           | 51.7        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 919         |
|    total_timesteps       | 1589248     |
| train/                   |             |
|    approx_kl             | 0.020818349 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 140         |
|    cost_values           | -0.487      |
|    entropy               | 0.152       |
|    entropy_loss          | 0.151       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.76        |
|    n_updates             | 7750        |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.325       |
|    value_loss            | 1.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.4057401  |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -17.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 941         |
|    total_timesteps       | 1591296     |
| train/                   |             |
|    approx_kl             | 0.020613804 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 146         |
|    cost_values           | -0.49       |
|    entropy               | 0.164       |
|    entropy_loss          | 0.157       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.724       |
|    n_updates             | 7760        |
|    policy_gradient_loss  | 0.00214     |
|    std                   | 0.324       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.37909195 |
| rollout/                 |             |
|    ep_len_mean           | 51.4        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 964         |
|    total_timesteps       | 1593344     |
| train/                   |             |
|    approx_kl             | 0.016546769 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.481      |
|    entropy               | 0.168       |
|    entropy_loss          | 0.167       |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.501       |
|    n_updates             | 7770        |
|    policy_gradient_loss  | 0.00732     |
|    std                   | 0.323       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33266243 |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 44          |
|    time_elapsed          | 986         |
|    total_timesteps       | 1595392     |
| train/                   |             |
|    approx_kl             | 0.019296663 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.492      |
|    entropy               | 0.185       |
|    entropy_loss          | 0.175       |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.58        |
|    n_updates             | 7780        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.322       |
|    value_loss            | 1.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.24473935 |
| rollout/                 |             |
|    ep_len_mean           | 52.7        |
|    ep_rew_mean           | -17.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 45          |
|    time_elapsed          | 1009        |
|    total_timesteps       | 1597440     |
| train/                   |             |
|    approx_kl             | 0.014607728 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 146         |
|    cost_values           | -0.483      |
|    entropy               | 0.195       |
|    entropy_loss          | 0.191       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.845       |
|    n_updates             | 7790        |
|    policy_gradient_loss  | 0.0016      |
|    std                   | 0.321       |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.15565124 |
| rollout/                 |             |
|    ep_len_mean           | 53.7        |
|    ep_rew_mean           | -18.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 46          |
|    time_elapsed          | 1031        |
|    total_timesteps       | 1599488     |
| train/                   |             |
|    approx_kl             | 0.021344077 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 146         |
|    cost_values           | -0.484      |
|    entropy               | 0.202       |
|    entropy_loss          | 0.199       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.616       |
|    n_updates             | 7800        |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.32        |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.46482682 |
| rollout/                 |             |
|    ep_len_mean           | 53.7        |
|    ep_rew_mean           | -18.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 47          |
|    time_elapsed          | 1054        |
|    total_timesteps       | 1601536     |
| train/                   |             |
|    approx_kl             | 0.017152041 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 148         |
|    cost_values           | -0.482      |
|    entropy               | 0.204       |
|    entropy_loss          | 0.203       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.639       |
|    n_updates             | 7810        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.319       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.5727357  |
| rollout/                 |             |
|    ep_len_mean           | 53.8        |
|    ep_rew_mean           | -18         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1077        |
|    total_timesteps       | 1603584     |
| train/                   |             |
|    approx_kl             | 0.013620948 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 148         |
|    cost_values           | -0.491      |
|    entropy               | 0.205       |
|    entropy_loss          | 0.204       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.758       |
|    n_updates             | 7820        |
|    policy_gradient_loss  | -0.000835   |
|    std                   | 0.319       |
|    value_loss            | 1.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.20969003 |
| rollout/                 |             |
|    ep_len_mean           | 56          |
|    ep_rew_mean           | -19         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 49          |
|    time_elapsed          | 1099        |
|    total_timesteps       | 1605632     |
| train/                   |             |
|    approx_kl             | 0.023897678 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 145         |
|    cost_values           | -0.488      |
|    entropy               | 0.208       |
|    entropy_loss          | 0.207       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.79        |
|    n_updates             | 7830        |
|    policy_gradient_loss  | 0.00848     |
|    std                   | 0.32        |
|    value_loss            | 1.74        |
------------------------------------------
Directory created: PPOL_New/models/seed-testing/an325vgg/model_epoch(15)
------------------------------------
| avg_speed          | 3.6         |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 3.6         |
| reward             | -0.24964277 |
| rollout/           |             |
|    ep_len_mean     | 54.2        |
|    ep_rew_mean     | -18.5       |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1607680     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2942709  |
| rollout/                 |             |
|    ep_len_mean           | 53.4        |
|    ep_rew_mean           | -18.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 1609728     |
| train/                   |             |
|    approx_kl             | 0.015319295 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 140         |
|    cost_values           | -0.483      |
|    entropy               | 0.217       |
|    entropy_loss          | 0.214       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.2         |
|    n_updates             | 7850        |
|    policy_gradient_loss  | 0.00421     |
|    std                   | 0.32        |
|    value_loss            | 2.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.31900287 |
| rollout/                 |             |
|    ep_len_mean           | 51.2        |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 1611776     |
| train/                   |             |
|    approx_kl             | 0.018180445 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 146         |
|    cost_values           | -0.495      |
|    entropy               | 0.216       |
|    entropy_loss          | 0.216       |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.17        |
|    n_updates             | 7860        |
|    policy_gradient_loss  | 0.000501    |
|    std                   | 0.32        |
|    value_loss            | 2.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.53        |
| reward                   | -0.30070555 |
| rollout/                 |             |
|    ep_len_mean           | 50.9        |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 1613824     |
| train/                   |             |
|    approx_kl             | 0.014835921 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.486      |
|    entropy               | 0.222       |
|    entropy_loss          | 0.219       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.764       |
|    n_updates             | 7870        |
|    policy_gradient_loss  | 0.00381     |
|    std                   | 0.319       |
|    value_loss            | 1.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.30040935 |
| rollout/                 |             |
|    ep_len_mean           | 51.1        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 1615872     |
| train/                   |             |
|    approx_kl             | 0.020331299 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.489      |
|    entropy               | 0.231       |
|    entropy_loss          | 0.226       |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.24        |
|    n_updates             | 7880        |
|    policy_gradient_loss  | 0.000475    |
|    std                   | 0.319       |
|    value_loss            | 2.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.4297216  |
| rollout/                 |             |
|    ep_len_mean           | 52.2        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 1617920     |
| train/                   |             |
|    approx_kl             | 0.029861642 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 145         |
|    cost_values           | -0.495      |
|    entropy               | 0.236       |
|    entropy_loss          | 0.234       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.859       |
|    n_updates             | 7890        |
|    policy_gradient_loss  | 0.0082      |
|    std                   | 0.319       |
|    value_loss            | 1.75        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.39       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.39       |
| reward                   | -0.2983201 |
| rollout/                 |            |
|    ep_len_mean           | 53.6       |
|    ep_rew_mean           | -18.1      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 7          |
|    time_elapsed          | 156        |
|    total_timesteps       | 1619968    |
| train/                   |            |
|    approx_kl             | 0.01605615 |
|    clip_fraction         | 0.203      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.7       |
|    cost_value_loss       | 142        |
|    cost_values           | -0.49      |
|    entropy               | 0.238      |
|    entropy_loss          | 0.237      |
|    explained_variance    | 0.885      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.891      |
|    n_updates             | 7900       |
|    policy_gradient_loss  | -0.00145   |
|    std                   | 0.319      |
|    value_loss            | 1.86       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 2.2        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 2.2        |
| reward                   | -0.323513  |
| rollout/                 |            |
|    ep_len_mean           | 53.2       |
|    ep_rew_mean           | -17.9      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 8          |
|    time_elapsed          | 179        |
|    total_timesteps       | 1622016    |
| train/                   |            |
|    approx_kl             | 0.02771381 |
|    clip_fraction         | 0.209      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.3       |
|    cost_value_loss       | 154        |
|    cost_values           | -0.475     |
|    entropy               | 0.242      |
|    entropy_loss          | 0.24       |
|    explained_variance    | 0.873      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.06       |
|    n_updates             | 7910       |
|    policy_gradient_loss  | 0.00816    |
|    std                   | 0.319      |
|    value_loss            | 2.05       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36962163 |
| rollout/                 |             |
|    ep_len_mean           | 55          |
|    ep_rew_mean           | -18.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 1624064     |
| train/                   |             |
|    approx_kl             | 0.021866243 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.485      |
|    entropy               | 0.248       |
|    entropy_loss          | 0.245       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.802       |
|    n_updates             | 7920        |
|    policy_gradient_loss  | 0.000691    |
|    std                   | 0.317       |
|    value_loss            | 1.81        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.8        |
| reward                   | -0.3933413 |
| rollout/                 |            |
|    ep_len_mean           | 51.7       |
|    ep_rew_mean           | -17.6      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 10         |
|    time_elapsed          | 224        |
|    total_timesteps       | 1626112    |
| train/                   |            |
|    approx_kl             | 0.01022035 |
|    clip_fraction         | 0.155      |
|    clip_range            | 0.2        |
|    cost_returns          | 11.1       |
|    cost_value_loss       | 150        |
|    cost_values           | -0.492     |
|    entropy               | 0.255      |
|    entropy_loss          | 0.251      |
|    explained_variance    | 0.88       |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.01       |
|    n_updates             | 7930       |
|    policy_gradient_loss  | -0.000678  |
|    std                   | 0.317      |
|    value_loss            | 2.03       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.20194758 |
| rollout/                 |             |
|    ep_len_mean           | 51.4        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 1628160     |
| train/                   |             |
|    approx_kl             | 0.022201624 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.497      |
|    entropy               | 0.264       |
|    entropy_loss          | 0.259       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.762       |
|    n_updates             | 7940        |
|    policy_gradient_loss  | 0.000844    |
|    std                   | 0.315       |
|    value_loss            | 1.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.79        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.79        |
| reward                   | -0.37300414 |
| rollout/                 |             |
|    ep_len_mean           | 52          |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 1630208     |
| train/                   |             |
|    approx_kl             | 0.017275019 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 140         |
|    cost_values           | -0.494      |
|    entropy               | 0.279       |
|    entropy_loss          | 0.271       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.837       |
|    n_updates             | 7950        |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.313       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.16776878 |
| rollout/                 |             |
|    ep_len_mean           | 52.4        |
|    ep_rew_mean           | -17.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 1632256     |
| train/                   |             |
|    approx_kl             | 0.012484943 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 148         |
|    cost_values           | -0.486      |
|    entropy               | 0.281       |
|    entropy_loss          | 0.281       |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.15        |
|    n_updates             | 7960        |
|    policy_gradient_loss  | 0.00465     |
|    std                   | 0.313       |
|    value_loss            | 2.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.46197358 |
| rollout/                 |             |
|    ep_len_mean           | 53.1        |
|    ep_rew_mean           | -18.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 314         |
|    total_timesteps       | 1634304     |
| train/                   |             |
|    approx_kl             | 0.018158436 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.486      |
|    entropy               | 0.278       |
|    entropy_loss          | 0.28        |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.46        |
|    n_updates             | 7970        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.314       |
|    value_loss            | 2.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.5609968  |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -17.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 1636352     |
| train/                   |             |
|    approx_kl             | 0.018122569 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 145         |
|    cost_values           | -0.484      |
|    entropy               | 0.281       |
|    entropy_loss          | 0.279       |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.12        |
|    n_updates             | 7980        |
|    policy_gradient_loss  | 0.00124     |
|    std                   | 0.314       |
|    value_loss            | 2.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.24394383 |
| rollout/                 |             |
|    ep_len_mean           | 50.7        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 359         |
|    total_timesteps       | 1638400     |
| train/                   |             |
|    approx_kl             | 0.03151925  |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.499      |
|    entropy               | 0.291       |
|    entropy_loss          | 0.286       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.996       |
|    n_updates             | 7990        |
|    policy_gradient_loss  | 0.00325     |
|    std                   | 0.313       |
|    value_loss            | 2.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26039857 |
| rollout/                 |             |
|    ep_len_mean           | 50.8        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 382         |
|    total_timesteps       | 1640448     |
| train/                   |             |
|    approx_kl             | 0.024508053 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 143         |
|    cost_values           | -0.487      |
|    entropy               | 0.3         |
|    entropy_loss          | 0.296       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.604       |
|    n_updates             | 8000        |
|    policy_gradient_loss  | 0.00211     |
|    std                   | 0.312       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.3467613  |
| rollout/                 |             |
|    ep_len_mean           | 50.6        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 404         |
|    total_timesteps       | 1642496     |
| train/                   |             |
|    approx_kl             | 0.012609886 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.499      |
|    entropy               | 0.308       |
|    entropy_loss          | 0.305       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.566       |
|    n_updates             | 8010        |
|    policy_gradient_loss  | -0.000548   |
|    std                   | 0.311       |
|    value_loss            | 1.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2849885  |
| rollout/                 |             |
|    ep_len_mean           | 49.6        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 427         |
|    total_timesteps       | 1644544     |
| train/                   |             |
|    approx_kl             | 0.019409388 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.496      |
|    entropy               | 0.31        |
|    entropy_loss          | 0.309       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.661       |
|    n_updates             | 8020        |
|    policy_gradient_loss  | 0.00111     |
|    std                   | 0.312       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.39929372 |
| rollout/                 |             |
|    ep_len_mean           | 49.9        |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 449         |
|    total_timesteps       | 1646592     |
| train/                   |             |
|    approx_kl             | 0.014601428 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.498      |
|    entropy               | 0.308       |
|    entropy_loss          | 0.309       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.553       |
|    n_updates             | 8030        |
|    policy_gradient_loss  | -0.000429   |
|    std                   | 0.313       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.10425521 |
| rollout/                 |             |
|    ep_len_mean           | 51.9        |
|    ep_rew_mean           | -17.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 472         |
|    total_timesteps       | 1648640     |
| train/                   |             |
|    approx_kl             | 0.012885617 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.497      |
|    entropy               | 0.311       |
|    entropy_loss          | 0.309       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.405       |
|    n_updates             | 8040        |
|    policy_gradient_loss  | -0.000138   |
|    std                   | 0.312       |
|    value_loss            | 1           |
------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -0.12427937 |
| rollout/                 |             |
|    ep_len_mean           | 52.3        |
|    ep_rew_mean           | -18         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 494         |
|    total_timesteps       | 1650688     |
| train/                   |             |
|    approx_kl             | 0.031406112 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 150         |
|    cost_values           | -0.495      |
|    entropy               | 0.311       |
|    entropy_loss          | 0.312       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.611       |
|    n_updates             | 8050        |
|    policy_gradient_loss  | 0.000824    |
|    std                   | 0.313       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3536436  |
| rollout/                 |             |
|    ep_len_mean           | 53.3        |
|    ep_rew_mean           | -18.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 517         |
|    total_timesteps       | 1652736     |
| train/                   |             |
|    approx_kl             | 0.019445224 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.5        |
|    entropy               | 0.314       |
|    entropy_loss          | 0.312       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.48        |
|    n_updates             | 8060        |
|    policy_gradient_loss  | 0.00566     |
|    std                   | 0.313       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.56568116 |
| rollout/                 |             |
|    ep_len_mean           | 52.7        |
|    ep_rew_mean           | -18         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 539         |
|    total_timesteps       | 1654784     |
| train/                   |             |
|    approx_kl             | 0.028973471 |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 145         |
|    cost_values           | -0.499      |
|    entropy               | 0.315       |
|    entropy_loss          | 0.315       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.653       |
|    n_updates             | 8070        |
|    policy_gradient_loss  | 0.0054      |
|    std                   | 0.314       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.36        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.36        |
| reward                   | -0.33668965 |
| rollout/                 |             |
|    ep_len_mean           | 52.9        |
|    ep_rew_mean           | -18.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 562         |
|    total_timesteps       | 1656832     |
| train/                   |             |
|    approx_kl             | 0.01618505  |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 146         |
|    cost_values           | -0.505      |
|    entropy               | 0.317       |
|    entropy_loss          | 0.315       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.689       |
|    n_updates             | 8080        |
|    policy_gradient_loss  | 0.00304     |
|    std                   | 0.314       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.2731678  |
| rollout/                 |             |
|    ep_len_mean           | 51.7        |
|    ep_rew_mean           | -18         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 584         |
|    total_timesteps       | 1658880     |
| train/                   |             |
|    approx_kl             | 0.017751183 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.51       |
|    entropy               | 0.331       |
|    entropy_loss          | 0.325       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.948       |
|    n_updates             | 8090        |
|    policy_gradient_loss  | -0.000895   |
|    std                   | 0.312       |
|    value_loss            | 2           |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.5727357  |
| rollout/                 |             |
|    ep_len_mean           | 51.6        |
|    ep_rew_mean           | -17.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 607         |
|    total_timesteps       | 1660928     |
| train/                   |             |
|    approx_kl             | 0.018718047 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.507      |
|    entropy               | 0.33        |
|    entropy_loss          | 0.331       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.813       |
|    n_updates             | 8100        |
|    policy_gradient_loss  | 0.00238     |
|    std                   | 0.313       |
|    value_loss            | 1.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.30525935 |
| rollout/                 |             |
|    ep_len_mean           | 51.9        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 629         |
|    total_timesteps       | 1662976     |
| train/                   |             |
|    approx_kl             | 0.01936147  |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 143         |
|    cost_values           | -0.509      |
|    entropy               | 0.337       |
|    entropy_loss          | 0.333       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.869       |
|    n_updates             | 8110        |
|    policy_gradient_loss  | 0.00736     |
|    std                   | 0.312       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.29956886 |
| rollout/                 |             |
|    ep_len_mean           | 50.7        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 652         |
|    total_timesteps       | 1665024     |
| train/                   |             |
|    approx_kl             | 0.014438877 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.502      |
|    entropy               | 0.341       |
|    entropy_loss          | 0.339       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.566       |
|    n_updates             | 8120        |
|    policy_gradient_loss  | 0.00491     |
|    std                   | 0.312       |
|    value_loss            | 1.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4            |
| reward                   | -0.3868481   |
| rollout/                 |              |
|    ep_len_mean           | 49.8         |
|    ep_rew_mean           | -16.8        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 30           |
|    time_elapsed          | 674          |
|    total_timesteps       | 1667072      |
| train/                   |              |
|    approx_kl             | 0.0114168525 |
|    clip_fraction         | 0.166        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 141          |
|    cost_values           | -0.499       |
|    entropy               | 0.353        |
|    entropy_loss          | 0.346        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.663        |
|    n_updates             | 8130         |
|    policy_gradient_loss  | 0.00165      |
|    std                   | 0.31         |
|    value_loss            | 1.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.5162983  |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 697         |
|    total_timesteps       | 1669120     |
| train/                   |             |
|    approx_kl             | 0.020615973 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.51       |
|    entropy               | 0.356       |
|    entropy_loss          | 0.356       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.581       |
|    n_updates             | 8140        |
|    policy_gradient_loss  | 0.00147     |
|    std                   | 0.31        |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.46073303 |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 719         |
|    total_timesteps       | 1671168     |
| train/                   |             |
|    approx_kl             | 0.01836377  |
|    clip_fraction         | 0.264       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.512      |
|    entropy               | 0.366       |
|    entropy_loss          | 0.36        |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.507       |
|    n_updates             | 8150        |
|    policy_gradient_loss  | 0.0161      |
|    std                   | 0.31        |
|    value_loss            | 1.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.27522945  |
| rollout/                 |              |
|    ep_len_mean           | 50.4         |
|    ep_rew_mean           | -17.4        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 33           |
|    time_elapsed          | 742          |
|    total_timesteps       | 1673216      |
| train/                   |              |
|    approx_kl             | 0.0147996135 |
|    clip_fraction         | 0.194        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 141          |
|    cost_values           | -0.495       |
|    entropy               | 0.367        |
|    entropy_loss          | 0.368        |
|    explained_variance    | 0.899        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.731        |
|    n_updates             | 8160         |
|    policy_gradient_loss  | 0.00364      |
|    std                   | 0.311        |
|    value_loss            | 1.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.50941986 |
| rollout/                 |             |
|    ep_len_mean           | 51.3        |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 764         |
|    total_timesteps       | 1675264     |
| train/                   |             |
|    approx_kl             | 0.017705766 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.509      |
|    entropy               | 0.371       |
|    entropy_loss          | 0.369       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.672       |
|    n_updates             | 8170        |
|    policy_gradient_loss  | 0.00194     |
|    std                   | 0.311       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22670275 |
| rollout/                 |             |
|    ep_len_mean           | 50.9        |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 787         |
|    total_timesteps       | 1677312     |
| train/                   |             |
|    approx_kl             | 0.021574741 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.508      |
|    entropy               | 0.377       |
|    entropy_loss          | 0.374       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.67        |
|    n_updates             | 8180        |
|    policy_gradient_loss  | 0.00285     |
|    std                   | 0.31        |
|    value_loss            | 1.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.15881234 |
| rollout/                 |             |
|    ep_len_mean           | 51.1        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 809         |
|    total_timesteps       | 1679360     |
| train/                   |             |
|    approx_kl             | 0.030484337 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.513      |
|    entropy               | 0.378       |
|    entropy_loss          | 0.378       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.69        |
|    n_updates             | 8190        |
|    policy_gradient_loss  | 0.0064      |
|    std                   | 0.311       |
|    value_loss            | 1.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3686705  |
| rollout/                 |             |
|    ep_len_mean           | 52          |
|    ep_rew_mean           | -17.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 832         |
|    total_timesteps       | 1681408     |
| train/                   |             |
|    approx_kl             | 0.013376512 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 140         |
|    cost_values           | -0.5        |
|    entropy               | 0.386       |
|    entropy_loss          | 0.38        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.675       |
|    n_updates             | 8200        |
|    policy_gradient_loss  | 0.00787     |
|    std                   | 0.31        |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.22664338 |
| rollout/                 |             |
|    ep_len_mean           | 52.3        |
|    ep_rew_mean           | -18         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 854         |
|    total_timesteps       | 1683456     |
| train/                   |             |
|    approx_kl             | 0.022123512 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.499      |
|    entropy               | 0.398       |
|    entropy_loss          | 0.393       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.803       |
|    n_updates             | 8210        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.308       |
|    value_loss            | 1.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.1656375  |
| rollout/                 |             |
|    ep_len_mean           | 54.5        |
|    ep_rew_mean           | -18.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 39          |
|    time_elapsed          | 877         |
|    total_timesteps       | 1685504     |
| train/                   |             |
|    approx_kl             | 0.020748166 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 150         |
|    cost_values           | -0.502      |
|    entropy               | 0.401       |
|    entropy_loss          | 0.401       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.764       |
|    n_updates             | 8220        |
|    policy_gradient_loss  | 0.00104     |
|    std                   | 0.308       |
|    value_loss            | 1.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.3370742  |
| rollout/                 |             |
|    ep_len_mean           | 53.6        |
|    ep_rew_mean           | -18.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 900         |
|    total_timesteps       | 1687552     |
| train/                   |             |
|    approx_kl             | 0.016166015 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 153         |
|    cost_values           | -0.513      |
|    entropy               | 0.406       |
|    entropy_loss          | 0.403       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.911       |
|    n_updates             | 8230        |
|    policy_gradient_loss  | 0.00844     |
|    std                   | 0.307       |
|    value_loss            | 1.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.62        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.62        |
| reward                   | -0.24947228 |
| rollout/                 |             |
|    ep_len_mean           | 51.8        |
|    ep_rew_mean           | -17.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 922         |
|    total_timesteps       | 1689600     |
| train/                   |             |
|    approx_kl             | 0.03222232  |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.526      |
|    entropy               | 0.41        |
|    entropy_loss          | 0.408       |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.927       |
|    n_updates             | 8240        |
|    policy_gradient_loss  | 0.00402     |
|    std                   | 0.307       |
|    value_loss            | 1.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.11        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.11        |
| reward                   | -0.27573478 |
| rollout/                 |             |
|    ep_len_mean           | 49.5        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 945         |
|    total_timesteps       | 1691648     |
| train/                   |             |
|    approx_kl             | 0.015408609 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.513      |
|    entropy               | 0.408       |
|    entropy_loss          | 0.409       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.738       |
|    n_updates             | 8250        |
|    policy_gradient_loss  | 0.00169     |
|    std                   | 0.308       |
|    value_loss            | 1.43        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.6        |
| reward                   | -0.5103625 |
| rollout/                 |            |
|    ep_len_mean           | 49.2       |
|    ep_rew_mean           | -16.6      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 43         |
|    time_elapsed          | 967        |
|    total_timesteps       | 1693696    |
| train/                   |            |
|    approx_kl             | 0.02424754 |
|    clip_fraction         | 0.234      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.5       |
|    cost_value_loss       | 137        |
|    cost_values           | -0.497     |
|    entropy               | 0.407      |
|    entropy_loss          | 0.408      |
|    explained_variance    | 0.925      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.594      |
|    n_updates             | 8260       |
|    policy_gradient_loss  | 0.00809    |
|    std                   | 0.309      |
|    value_loss            | 1.12       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.5567756 |
| rollout/                 |            |
|    ep_len_mean           | 48.5       |
|    ep_rew_mean           | -16.7      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 44         |
|    time_elapsed          | 990        |
|    total_timesteps       | 1695744    |
| train/                   |            |
|    approx_kl             | 0.06246452 |
|    clip_fraction         | 0.249      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.4       |
|    cost_value_loss       | 134        |
|    cost_values           | -0.514     |
|    entropy               | 0.406      |
|    entropy_loss          | 0.407      |
|    explained_variance    | 0.937      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.537      |
|    n_updates             | 8270       |
|    policy_gradient_loss  | 0.00639    |
|    std                   | 0.31       |
|    value_loss            | 1.11       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.37937808 |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 1697792     |
| train/                   |             |
|    approx_kl             | 0.01494892  |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.496      |
|    entropy               | 0.418       |
|    entropy_loss          | 0.411       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.507       |
|    n_updates             | 8280        |
|    policy_gradient_loss  | -0.00114    |
|    std                   | 0.309       |
|    value_loss            | 0.985       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.28206512 |
| rollout/                 |             |
|    ep_len_mean           | 50.2        |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1035        |
|    total_timesteps       | 1699840     |
| train/                   |             |
|    approx_kl             | 0.02800442  |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.509      |
|    entropy               | 0.421       |
|    entropy_loss          | 0.421       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.374       |
|    n_updates             | 8290        |
|    policy_gradient_loss  | 0.00114     |
|    std                   | 0.309       |
|    value_loss            | 0.773       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3021297  |
| rollout/                 |             |
|    ep_len_mean           | 48.7        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 1701888     |
| train/                   |             |
|    approx_kl             | 0.020083422 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.501      |
|    entropy               | 0.428       |
|    entropy_loss          | 0.424       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.625       |
|    n_updates             | 8300        |
|    policy_gradient_loss  | 0.00471     |
|    std                   | 0.308       |
|    value_loss            | 1.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.573351   |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -16.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1080        |
|    total_timesteps       | 1703936     |
| train/                   |             |
|    approx_kl             | 0.012652479 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.494      |
|    entropy               | 0.433       |
|    entropy_loss          | 0.431       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.556       |
|    n_updates             | 8310        |
|    policy_gradient_loss  | 0.00434     |
|    std                   | 0.307       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20746021 |
| rollout/                 |             |
|    ep_len_mean           | 49          |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1102        |
|    total_timesteps       | 1705984     |
| train/                   |             |
|    approx_kl             | 0.024038134 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.504      |
|    entropy               | 0.431       |
|    entropy_loss          | 0.432       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.596       |
|    n_updates             | 8320        |
|    policy_gradient_loss  | 0.00695     |
|    std                   | 0.308       |
|    value_loss            | 1.17        |
------------------------------------------
----------------------------------
| avg_speed          | 2         |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 2         |
| reward             | -0.339813 |
| rollout/           |           |
|    ep_len_mean     | 47.9      |
|    ep_rew_mean     | -16.6     |
| time/              |           |
|    fps             | 93        |
|    iterations      | 1         |
|    time_elapsed    | 21        |
|    total_timesteps | 1708032   |
----------------------------------
------------------------------------------
| avg_speed                | 7.16        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.16        |
| reward                   | -0.34001642 |
| rollout/                 |             |
|    ep_len_mean           | 50.5        |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 1710080     |
| train/                   |             |
|    approx_kl             | 0.039214566 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.517      |
|    entropy               | 0.424       |
|    entropy_loss          | 0.425       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.642       |
|    n_updates             | 8340        |
|    policy_gradient_loss  | -0.000659   |
|    std                   | 0.31        |
|    value_loss            | 1.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.5256417  |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 1712128     |
| train/                   |             |
|    approx_kl             | 0.022037141 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.501      |
|    entropy               | 0.434       |
|    entropy_loss          | 0.429       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.472       |
|    n_updates             | 8350        |
|    policy_gradient_loss  | 0.00698     |
|    std                   | 0.309       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.39201197 |
| rollout/                 |             |
|    ep_len_mean           | 50          |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 1714176     |
| train/                   |             |
|    approx_kl             | 0.02212645  |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.502      |
|    entropy               | 0.436       |
|    entropy_loss          | 0.435       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.543       |
|    n_updates             | 8360        |
|    policy_gradient_loss  | 0.00715     |
|    std                   | 0.309       |
|    value_loss            | 1.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.50457966 |
| rollout/                 |             |
|    ep_len_mean           | 49.9        |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1716224     |
| train/                   |             |
|    approx_kl             | 0.026005426 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.495      |
|    entropy               | 0.431       |
|    entropy_loss          | 0.434       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.441       |
|    n_updates             | 8370        |
|    policy_gradient_loss  | 0.00476     |
|    std                   | 0.31        |
|    value_loss            | 0.921       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.26146582 |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 1718272     |
| train/                   |             |
|    approx_kl             | 0.024510063 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.49       |
|    entropy               | 0.432       |
|    entropy_loss          | 0.432       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.439       |
|    n_updates             | 8380        |
|    policy_gradient_loss  | 0.00282     |
|    std                   | 0.311       |
|    value_loss            | 0.956       |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.58117354 |
| rollout/                 |             |
|    ep_len_mean           | 49          |
|    ep_rew_mean           | -17.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 156         |
|    total_timesteps       | 1720320     |
| train/                   |             |
|    approx_kl             | 0.024588201 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.506      |
|    entropy               | 0.437       |
|    entropy_loss          | 0.435       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.584       |
|    n_updates             | 8390        |
|    policy_gradient_loss  | 0.00667     |
|    std                   | 0.31        |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.5241349  |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 179         |
|    total_timesteps       | 1722368     |
| train/                   |             |
|    approx_kl             | 0.022006432 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.501      |
|    entropy               | 0.437       |
|    entropy_loss          | 0.438       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.449       |
|    n_updates             | 8400        |
|    policy_gradient_loss  | 0.00259     |
|    std                   | 0.31        |
|    value_loss            | 0.953       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.57        |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 7.57        |
| reward                   | -0.08427557 |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 201         |
|    total_timesteps       | 1724416     |
| train/                   |             |
|    approx_kl             | 0.026772097 |
|    clip_fraction         | 0.251       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.498      |
|    entropy               | 0.438       |
|    entropy_loss          | 0.438       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.52        |
|    n_updates             | 8410        |
|    policy_gradient_loss  | 0.000986    |
|    std                   | 0.309       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.96        |
| reward                   | -0.16906233 |
| rollout/                 |             |
|    ep_len_mean           | 48.3        |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 1726464     |
| train/                   |             |
|    approx_kl             | 0.02898202  |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.492      |
|    entropy               | 0.436       |
|    entropy_loss          | 0.438       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.618       |
|    n_updates             | 8420        |
|    policy_gradient_loss  | 0.00517     |
|    std                   | 0.31        |
|    value_loss            | 1.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.50416636 |
| rollout/                 |             |
|    ep_len_mean           | 47.7        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 246         |
|    total_timesteps       | 1728512     |
| train/                   |             |
|    approx_kl             | 0.013048457 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.488      |
|    entropy               | 0.443       |
|    entropy_loss          | 0.439       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.531       |
|    n_updates             | 8430        |
|    policy_gradient_loss  | 0.00956     |
|    std                   | 0.309       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.4678632  |
| rollout/                 |             |
|    ep_len_mean           | 46.6        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 1730560     |
| train/                   |             |
|    approx_kl             | 0.022837907 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.498      |
|    entropy               | 0.454       |
|    entropy_loss          | 0.449       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.433       |
|    n_updates             | 8440        |
|    policy_gradient_loss  | 0.00529     |
|    std                   | 0.307       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.39534694 |
| rollout/                 |             |
|    ep_len_mean           | 47.5        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 291         |
|    total_timesteps       | 1732608     |
| train/                   |             |
|    approx_kl             | 0.05467161  |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.506      |
|    entropy               | 0.462       |
|    entropy_loss          | 0.458       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.534       |
|    n_updates             | 8450        |
|    policy_gradient_loss  | 0.00948     |
|    std                   | 0.306       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.16        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.16        |
| reward                   | -0.40015742 |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 314         |
|    total_timesteps       | 1734656     |
| train/                   |             |
|    approx_kl             | 0.042364284 |
|    clip_fraction         | 0.279       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.502      |
|    entropy               | 0.461       |
|    entropy_loss          | 0.462       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.786       |
|    n_updates             | 8460        |
|    policy_gradient_loss  | 0.0195      |
|    std                   | 0.306       |
|    value_loss            | 1.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.6          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.6          |
| reward                   | -0.31473082  |
| rollout/                 |              |
|    ep_len_mean           | 49.4         |
|    ep_rew_mean           | -17.4        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 15           |
|    time_elapsed          | 336          |
|    total_timesteps       | 1736704      |
| train/                   |              |
|    approx_kl             | 0.0140648745 |
|    clip_fraction         | 0.185        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 136          |
|    cost_values           | -0.502       |
|    entropy               | 0.467        |
|    entropy_loss          | 0.464        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.613        |
|    n_updates             | 8470         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.306        |
|    value_loss            | 1.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38804242 |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 359         |
|    total_timesteps       | 1738752     |
| train/                   |             |
|    approx_kl             | 0.021010648 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.498      |
|    entropy               | 0.473       |
|    entropy_loss          | 0.471       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.657       |
|    n_updates             | 8480        |
|    policy_gradient_loss  | 0.00323     |
|    std                   | 0.307       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.33587244 |
| rollout/                 |             |
|    ep_len_mean           | 48.7        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 381         |
|    total_timesteps       | 1740800     |
| train/                   |             |
|    approx_kl             | 0.023642864 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.51       |
|    entropy               | 0.485       |
|    entropy_loss          | 0.478       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.958       |
|    n_updates             | 8490        |
|    policy_gradient_loss  | -0.00202    |
|    std                   | 0.306       |
|    value_loss            | 1.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.29777214 |
| rollout/                 |             |
|    ep_len_mean           | 48.8        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 404         |
|    total_timesteps       | 1742848     |
| train/                   |             |
|    approx_kl             | 0.020105727 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 140         |
|    cost_values           | -0.512      |
|    entropy               | 0.499       |
|    entropy_loss          | 0.491       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.761       |
|    n_updates             | 8500        |
|    policy_gradient_loss  | -0.000226   |
|    std                   | 0.305       |
|    value_loss            | 1.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.38791052 |
| rollout/                 |             |
|    ep_len_mean           | 49.4        |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 427         |
|    total_timesteps       | 1744896     |
| train/                   |             |
|    approx_kl             | 0.016759444 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.504      |
|    entropy               | 0.51        |
|    entropy_loss          | 0.505       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.54        |
|    n_updates             | 8510        |
|    policy_gradient_loss  | 0.00359     |
|    std                   | 0.304       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.27622312 |
| rollout/                 |             |
|    ep_len_mean           | 49          |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 449         |
|    total_timesteps       | 1746944     |
| train/                   |             |
|    approx_kl             | 0.036693513 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.505      |
|    entropy               | 0.511       |
|    entropy_loss          | 0.511       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.611       |
|    n_updates             | 8520        |
|    policy_gradient_loss  | 0.0126      |
|    std                   | 0.303       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.5782849  |
| rollout/                 |             |
|    ep_len_mean           | 49.5        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 472         |
|    total_timesteps       | 1748992     |
| train/                   |             |
|    approx_kl             | 0.022336636 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.492      |
|    entropy               | 0.514       |
|    entropy_loss          | 0.512       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.537       |
|    n_updates             | 8530        |
|    policy_gradient_loss  | 0.00225     |
|    std                   | 0.303       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24621199 |
| rollout/                 |             |
|    ep_len_mean           | 48.1        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 494         |
|    total_timesteps       | 1751040     |
| train/                   |             |
|    approx_kl             | 0.018649144 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.504      |
|    entropy               | 0.512       |
|    entropy_loss          | 0.513       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.452       |
|    n_updates             | 8540        |
|    policy_gradient_loss  | 0.00532     |
|    std                   | 0.304       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.5256417  |
| rollout/                 |             |
|    ep_len_mean           | 47.7        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 517         |
|    total_timesteps       | 1753088     |
| train/                   |             |
|    approx_kl             | 0.017865632 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.519      |
|    entropy               | 0.505       |
|    entropy_loss          | 0.508       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.665       |
|    n_updates             | 8550        |
|    policy_gradient_loss  | 0.00444     |
|    std                   | 0.305       |
|    value_loss            | 1.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.292604   |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 539         |
|    total_timesteps       | 1755136     |
| train/                   |             |
|    approx_kl             | 0.019445881 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.506      |
|    entropy               | 0.512       |
|    entropy_loss          | 0.507       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.409       |
|    n_updates             | 8560        |
|    policy_gradient_loss  | -0.000723   |
|    std                   | 0.303       |
|    value_loss            | 0.943       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.37021983 |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 562         |
|    total_timesteps       | 1757184     |
| train/                   |             |
|    approx_kl             | 0.042033743 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.501      |
|    entropy               | 0.518       |
|    entropy_loss          | 0.517       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.573       |
|    n_updates             | 8570        |
|    policy_gradient_loss  | 0.00592     |
|    std                   | 0.3         |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.47154632 |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 584         |
|    total_timesteps       | 1759232     |
| train/                   |             |
|    approx_kl             | 0.025303729 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.507      |
|    entropy               | 0.524       |
|    entropy_loss          | 0.521       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.476       |
|    n_updates             | 8580        |
|    policy_gradient_loss  | 0.00502     |
|    std                   | 0.299       |
|    value_loss            | 0.997       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31659782 |
| rollout/                 |             |
|    ep_len_mean           | 49.8        |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 607         |
|    total_timesteps       | 1761280     |
| train/                   |             |
|    approx_kl             | 0.022717746 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.492      |
|    entropy               | 0.531       |
|    entropy_loss          | 0.528       |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.518       |
|    n_updates             | 8590        |
|    policy_gradient_loss  | 0.00296     |
|    std                   | 0.298       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.22802937 |
| rollout/                 |             |
|    ep_len_mean           | 50.3        |
|    ep_rew_mean           | -17.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 629         |
|    total_timesteps       | 1763328     |
| train/                   |             |
|    approx_kl             | 0.011193646 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.513      |
|    entropy               | 0.533       |
|    entropy_loss          | 0.533       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.378       |
|    n_updates             | 8600        |
|    policy_gradient_loss  | 0.00461     |
|    std                   | 0.297       |
|    value_loss            | 0.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.3554508  |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 652         |
|    total_timesteps       | 1765376     |
| train/                   |             |
|    approx_kl             | 0.024076827 |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.522      |
|    entropy               | 0.535       |
|    entropy_loss          | 0.534       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.527       |
|    n_updates             | 8610        |
|    policy_gradient_loss  | 0.000915    |
|    std                   | 0.297       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.55273783 |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 674         |
|    total_timesteps       | 1767424     |
| train/                   |             |
|    approx_kl             | 0.014637024 |
|    clip_fraction         | 0.227       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.518      |
|    entropy               | 0.535       |
|    entropy_loss          | 0.534       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.39        |
|    n_updates             | 8620        |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.297       |
|    value_loss            | 0.819       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.29671976 |
| rollout/                 |             |
|    ep_len_mean           | 46.6        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 697         |
|    total_timesteps       | 1769472     |
| train/                   |             |
|    approx_kl             | 0.017361656 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.494      |
|    entropy               | 0.539       |
|    entropy_loss          | 0.537       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.464       |
|    n_updates             | 8630        |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.296       |
|    value_loss            | 0.946       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.45761526 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 719         |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.016329546 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.505      |
|    entropy               | 0.541       |
|    entropy_loss          | 0.541       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.487       |
|    n_updates             | 8640        |
|    policy_gradient_loss  | 0.00548     |
|    std                   | 0.296       |
|    value_loss            | 0.999       |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.3817292  |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 742         |
|    total_timesteps       | 1773568     |
| train/                   |             |
|    approx_kl             | 0.022830496 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.51       |
|    entropy               | 0.546       |
|    entropy_loss          | 0.543       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.443       |
|    n_updates             | 8650        |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.296       |
|    value_loss            | 0.849       |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.1762553 |
| rollout/                 |            |
|    ep_len_mean           | 48         |
|    ep_rew_mean           | -16.8      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 34         |
|    time_elapsed          | 764        |
|    total_timesteps       | 1775616    |
| train/                   |            |
|    approx_kl             | 0.01880926 |
|    clip_fraction         | 0.222      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.5       |
|    cost_value_loss       | 137        |
|    cost_values           | -0.504     |
|    entropy               | 0.551      |
|    entropy_loss          | 0.549      |
|    explained_variance    | 0.958      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.363      |
|    n_updates             | 8660       |
|    policy_gradient_loss  | -1.01e-05  |
|    std                   | 0.295      |
|    value_loss            | 0.711      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.4748885  |
| rollout/                 |             |
|    ep_len_mean           | 50.4        |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 787         |
|    total_timesteps       | 1777664     |
| train/                   |             |
|    approx_kl             | 0.040638387 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.503      |
|    entropy               | 0.554       |
|    entropy_loss          | 0.553       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.545       |
|    n_updates             | 8670        |
|    policy_gradient_loss  | 0.0076      |
|    std                   | 0.294       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.5         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.5         |
| reward                   | -0.26361322 |
| rollout/                 |             |
|    ep_len_mean           | 50.8        |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 809         |
|    total_timesteps       | 1779712     |
| train/                   |             |
|    approx_kl             | 0.018412864 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 148         |
|    cost_values           | -0.497      |
|    entropy               | 0.554       |
|    entropy_loss          | 0.554       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.762       |
|    n_updates             | 8680        |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.295       |
|    value_loss            | 1.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.21914877 |
| rollout/                 |             |
|    ep_len_mean           | 51.6        |
|    ep_rew_mean           | -17.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 832         |
|    total_timesteps       | 1781760     |
| train/                   |             |
|    approx_kl             | 0.013460671 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.51       |
|    entropy               | 0.56        |
|    entropy_loss          | 0.556       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.817       |
|    n_updates             | 8690        |
|    policy_gradient_loss  | 2.64e-05    |
|    std                   | 0.293       |
|    value_loss            | 1.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5125164  |
| rollout/                 |             |
|    ep_len_mean           | 49.3        |
|    ep_rew_mean           | -17.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 855         |
|    total_timesteps       | 1783808     |
| train/                   |             |
|    approx_kl             | 0.011563137 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.502      |
|    entropy               | 0.563       |
|    entropy_loss          | 0.562       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.824       |
|    n_updates             | 8700        |
|    policy_gradient_loss  | 0.00607     |
|    std                   | 0.293       |
|    value_loss            | 1.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.49382657 |
| rollout/                 |             |
|    ep_len_mean           | 49.5        |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 39          |
|    time_elapsed          | 877         |
|    total_timesteps       | 1785856     |
| train/                   |             |
|    approx_kl             | 0.015834652 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.515      |
|    entropy               | 0.565       |
|    entropy_loss          | 0.564       |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.745       |
|    n_updates             | 8710        |
|    policy_gradient_loss  | 0.00811     |
|    std                   | 0.293       |
|    value_loss            | 1.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.37949377 |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 900         |
|    total_timesteps       | 1787904     |
| train/                   |             |
|    approx_kl             | 0.029394377 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.513      |
|    entropy               | 0.566       |
|    entropy_loss          | 0.566       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.457       |
|    n_updates             | 8720        |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.293       |
|    value_loss            | 0.883       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.5481513  |
| rollout/                 |             |
|    ep_len_mean           | 49.5        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 922         |
|    total_timesteps       | 1789952     |
| train/                   |             |
|    approx_kl             | 0.025301166 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.51       |
|    entropy               | 0.573       |
|    entropy_loss          | 0.57        |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.556       |
|    n_updates             | 8730        |
|    policy_gradient_loss  | 0.00401     |
|    std                   | 0.292       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.56123036 |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 945         |
|    total_timesteps       | 1792000     |
| train/                   |             |
|    approx_kl             | 0.027610406 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.504      |
|    entropy               | 0.583       |
|    entropy_loss          | 0.578       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.531       |
|    n_updates             | 8740        |
|    policy_gradient_loss  | 0.00722     |
|    std                   | 0.291       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.3803428  |
| rollout/                 |             |
|    ep_len_mean           | 46.9        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 967         |
|    total_timesteps       | 1794048     |
| train/                   |             |
|    approx_kl             | 0.036870282 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.509      |
|    entropy               | 0.594       |
|    entropy_loss          | 0.589       |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.603       |
|    n_updates             | 8750        |
|    policy_gradient_loss  | 0.00978     |
|    std                   | 0.29        |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.28212765 |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 990         |
|    total_timesteps       | 1796096     |
| train/                   |             |
|    approx_kl             | 0.0399076   |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.514      |
|    entropy               | 0.599       |
|    entropy_loss          | 0.596       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.659       |
|    n_updates             | 8760        |
|    policy_gradient_loss  | 0.0021      |
|    std                   | 0.289       |
|    value_loss            | 1.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.32608065 |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 1798144     |
| train/                   |             |
|    approx_kl             | 0.034829773 |
|    clip_fraction         | 0.254       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.512      |
|    entropy               | 0.596       |
|    entropy_loss          | 0.598       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.515       |
|    n_updates             | 8770        |
|    policy_gradient_loss  | 0.0164      |
|    std                   | 0.29        |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.33673713 |
| rollout/                 |             |
|    ep_len_mean           | 50.2        |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1035        |
|    total_timesteps       | 1800192     |
| train/                   |             |
|    approx_kl             | 0.040366102 |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.512      |
|    entropy               | 0.601       |
|    entropy_loss          | 0.598       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.503       |
|    n_updates             | 8780        |
|    policy_gradient_loss  | 0.0168      |
|    std                   | 0.289       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.2971775  |
| rollout/                 |             |
|    ep_len_mean           | 51.8        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 1802240     |
| train/                   |             |
|    approx_kl             | 0.018966205 |
|    clip_fraction         | 0.268       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.509      |
|    entropy               | 0.598       |
|    entropy_loss          | 0.6         |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.487       |
|    n_updates             | 8790        |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.29        |
|    value_loss            | 0.971       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.17484054 |
| rollout/                 |             |
|    ep_len_mean           | 49.4        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1080        |
|    total_timesteps       | 1804288     |
| train/                   |             |
|    approx_kl             | 0.022023903 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.507      |
|    entropy               | 0.599       |
|    entropy_loss          | 0.599       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.468       |
|    n_updates             | 8800        |
|    policy_gradient_loss  | 0.00986     |
|    std                   | 0.29        |
|    value_loss            | 0.971       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.24175493 |
| rollout/                 |             |
|    ep_len_mean           | 48.7        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1102        |
|    total_timesteps       | 1806336     |
| train/                   |             |
|    approx_kl             | 0.042879917 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.516      |
|    entropy               | 0.601       |
|    entropy_loss          | 0.6         |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.494       |
|    n_updates             | 8810        |
|    policy_gradient_loss  | 0.00735     |
|    std                   | 0.291       |
|    value_loss            | 0.977       |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.18288957 |
| rollout/           |             |
|    ep_len_mean     | 47.2        |
|    ep_rew_mean     | -16.4       |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 1808384     |
------------------------------------
-----------------------------------------
| avg_speed                | 4.2        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.2        |
| reward                   | -0.4744581 |
| rollout/                 |            |
|    ep_len_mean           | 45.9       |
|    ep_rew_mean           | -15.8      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 2          |
|    time_elapsed          | 44         |
|    total_timesteps       | 1810432    |
| train/                   |            |
|    approx_kl             | 0.02642148 |
|    clip_fraction         | 0.205      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.1       |
|    cost_value_loss       | 127        |
|    cost_values           | -0.51      |
|    entropy               | 0.607      |
|    entropy_loss          | 0.601      |
|    explained_variance    | 0.941      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.421      |
|    n_updates             | 8830       |
|    policy_gradient_loss  | 0.00333    |
|    std                   | 0.289      |
|    value_loss            | 0.869      |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.46810985 |
| rollout/                 |             |
|    ep_len_mean           | 48.2        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 1812480     |
| train/                   |             |
|    approx_kl             | 0.0328424   |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.508      |
|    entropy               | 0.61        |
|    entropy_loss          | 0.61        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.374       |
|    n_updates             | 8840        |
|    policy_gradient_loss  | 0.00835     |
|    std                   | 0.29        |
|    value_loss            | 0.893       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5125164  |
| rollout/                 |             |
|    ep_len_mean           | 50.2        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 1814528     |
| train/                   |             |
|    approx_kl             | 0.016855584 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.51       |
|    entropy               | 0.613       |
|    entropy_loss          | 0.611       |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.716       |
|    n_updates             | 8850        |
|    policy_gradient_loss  | 0.00517     |
|    std                   | 0.289       |
|    value_loss            | 1.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.28908584 |
| rollout/                 |             |
|    ep_len_mean           | 50.6        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 1816576     |
| train/                   |             |
|    approx_kl             | 0.02341843  |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 140         |
|    cost_values           | -0.506      |
|    entropy               | 0.612       |
|    entropy_loss          | 0.613       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.564       |
|    n_updates             | 8860        |
|    policy_gradient_loss  | 0.00646     |
|    std                   | 0.29        |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3677239  |
| rollout/                 |             |
|    ep_len_mean           | 51.9        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 1818624     |
| train/                   |             |
|    approx_kl             | 0.017335184 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.511      |
|    entropy               | 0.624       |
|    entropy_loss          | 0.617       |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.702       |
|    n_updates             | 8870        |
|    policy_gradient_loss  | -0.000242   |
|    std                   | 0.288       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.33433604 |
| rollout/                 |             |
|    ep_len_mean           | 51.7        |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 1820672     |
| train/                   |             |
|    approx_kl             | 0.014562122 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 149         |
|    cost_values           | -0.496      |
|    entropy               | 0.634       |
|    entropy_loss          | 0.63        |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.843       |
|    n_updates             | 8880        |
|    policy_gradient_loss  | -0.000201   |
|    std                   | 0.286       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.37122217 |
| rollout/                 |             |
|    ep_len_mean           | 50.3        |
|    ep_rew_mean           | -17.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 179         |
|    total_timesteps       | 1822720     |
| train/                   |             |
|    approx_kl             | 0.014013082 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.502      |
|    entropy               | 0.637       |
|    entropy_loss          | 0.635       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.786       |
|    n_updates             | 8890        |
|    policy_gradient_loss  | 0.00651     |
|    std                   | 0.285       |
|    value_loss            | 1.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.28253663 |
| rollout/                 |             |
|    ep_len_mean           | 49.6        |
|    ep_rew_mean           | -17.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 1824768     |
| train/                   |             |
|    approx_kl             | 0.028574515 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.489      |
|    entropy               | 0.641       |
|    entropy_loss          | 0.639       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.563       |
|    n_updates             | 8900        |
|    policy_gradient_loss  | 0.0087      |
|    std                   | 0.284       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.25042802 |
| rollout/                 |             |
|    ep_len_mean           | 51.1        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 1826816     |
| train/                   |             |
|    approx_kl             | 0.011252186 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 143         |
|    cost_values           | -0.497      |
|    entropy               | 0.64        |
|    entropy_loss          | 0.641       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.546       |
|    n_updates             | 8910        |
|    policy_gradient_loss  | 0.0119      |
|    std                   | 0.285       |
|    value_loss            | 1.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.8          |
| reward                   | -0.33891594  |
| rollout/                 |              |
|    ep_len_mean           | 50           |
|    ep_rew_mean           | -17.1        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 11           |
|    time_elapsed          | 247          |
|    total_timesteps       | 1828864      |
| train/                   |              |
|    approx_kl             | 0.0155002065 |
|    clip_fraction         | 0.189        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 137          |
|    cost_values           | -0.508       |
|    entropy               | 0.652        |
|    entropy_loss          | 0.646        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.734        |
|    n_updates             | 8920         |
|    policy_gradient_loss  | 0.00493      |
|    std                   | 0.283        |
|    value_loss            | 1.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33715782 |
| rollout/                 |             |
|    ep_len_mean           | 48.2        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 1830912     |
| train/                   |             |
|    approx_kl             | 0.01802595  |
|    clip_fraction         | 0.239       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.496      |
|    entropy               | 0.656       |
|    entropy_loss          | 0.655       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.49        |
|    n_updates             | 8930        |
|    policy_gradient_loss  | 0.00926     |
|    std                   | 0.282       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.48701495 |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 1832960     |
| train/                   |             |
|    approx_kl             | 0.02262308  |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.502      |
|    entropy               | 0.665       |
|    entropy_loss          | 0.66        |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.572       |
|    n_updates             | 8940        |
|    policy_gradient_loss  | 0.00961     |
|    std                   | 0.282       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.28505662 |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 314         |
|    total_timesteps       | 1835008     |
| train/                   |             |
|    approx_kl             | 0.023608193 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 127         |
|    cost_values           | -0.509      |
|    entropy               | 0.677       |
|    entropy_loss          | 0.671       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.675       |
|    n_updates             | 8950        |
|    policy_gradient_loss  | 0.00918     |
|    std                   | 0.28        |
|    value_loss            | 1.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.5526418  |
| rollout/                 |             |
|    ep_len_mean           | 46.8        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 1837056     |
| train/                   |             |
|    approx_kl             | 0.020164013 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.506      |
|    entropy               | 0.687       |
|    entropy_loss          | 0.683       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.499       |
|    n_updates             | 8960        |
|    policy_gradient_loss  | 0.00456     |
|    std                   | 0.278       |
|    value_loss            | 0.961       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.5144518  |
| rollout/                 |             |
|    ep_len_mean           | 48.1        |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 360         |
|    total_timesteps       | 1839104     |
| train/                   |             |
|    approx_kl             | 0.053171337 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.498      |
|    entropy               | 0.687       |
|    entropy_loss          | 0.687       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.246       |
|    n_updates             | 8970        |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.277       |
|    value_loss            | 0.595       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.5469249  |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 382         |
|    total_timesteps       | 1841152     |
| train/                   |             |
|    approx_kl             | 0.034687582 |
|    clip_fraction         | 0.264       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.501      |
|    entropy               | 0.681       |
|    entropy_loss          | 0.685       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.432       |
|    n_updates             | 8980        |
|    policy_gradient_loss  | 0.00369     |
|    std                   | 0.279       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.37586114 |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 405         |
|    total_timesteps       | 1843200     |
| train/                   |             |
|    approx_kl             | 0.013263176 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.509      |
|    entropy               | 0.676       |
|    entropy_loss          | 0.678       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.701       |
|    n_updates             | 8990        |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.281       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.42885938 |
| rollout/                 |             |
|    ep_len_mean           | 46.9        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 19          |
|    time_elapsed          | 427         |
|    total_timesteps       | 1845248     |
| train/                   |             |
|    approx_kl             | 0.027299969 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.497      |
|    entropy               | 0.686       |
|    entropy_loss          | 0.681       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.418       |
|    n_updates             | 9000        |
|    policy_gradient_loss  | 0.00134     |
|    std                   | 0.28        |
|    value_loss            | 0.862       |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.2        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.2        |
| reward                   | -0.2828344 |
| rollout/                 |            |
|    ep_len_mean           | 46.1       |
|    ep_rew_mean           | -15.9      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 20         |
|    time_elapsed          | 450        |
|    total_timesteps       | 1847296    |
| train/                   |            |
|    approx_kl             | 0.02726476 |
|    clip_fraction         | 0.236      |
|    clip_range            | 0.2        |
|    cost_returns          | 10         |
|    cost_value_loss       | 126        |
|    cost_values           | -0.493     |
|    entropy               | 0.689      |
|    entropy_loss          | 0.688      |
|    explained_variance    | 0.92       |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.618      |
|    n_updates             | 9010       |
|    policy_gradient_loss  | 0.00961    |
|    std                   | 0.278      |
|    value_loss            | 1.22       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.19121113 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 21          |
|    time_elapsed          | 472         |
|    total_timesteps       | 1849344     |
| train/                   |             |
|    approx_kl             | 0.029315185 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.498      |
|    entropy               | 0.692       |
|    entropy_loss          | 0.69        |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.468       |
|    n_updates             | 9020        |
|    policy_gradient_loss  | 0.00286     |
|    std                   | 0.278       |
|    value_loss            | 0.934       |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.1477392 |
| rollout/                 |            |
|    ep_len_mean           | 46.6       |
|    ep_rew_mean           | -16.3      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 22         |
|    time_elapsed          | 495        |
|    total_timesteps       | 1851392    |
| train/                   |            |
|    approx_kl             | 0.01870624 |
|    clip_fraction         | 0.179      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.1       |
|    cost_value_loss       | 127        |
|    cost_values           | -0.507     |
|    entropy               | 0.702      |
|    entropy_loss          | 0.697      |
|    explained_variance    | 0.958      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.28       |
|    n_updates             | 9030       |
|    policy_gradient_loss  | 0.00293    |
|    std                   | 0.276      |
|    value_loss            | 0.623      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.25024703 |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 518         |
|    total_timesteps       | 1853440     |
| train/                   |             |
|    approx_kl             | 0.0462903   |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.488      |
|    entropy               | 0.704       |
|    entropy_loss          | 0.704       |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.38        |
|    n_updates             | 9040        |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.276       |
|    value_loss            | 0.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.48610616 |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 540         |
|    total_timesteps       | 1855488     |
| train/                   |             |
|    approx_kl             | 0.014554895 |
|    clip_fraction         | 0.247       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.492      |
|    entropy               | 0.698       |
|    entropy_loss          | 0.701       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.452       |
|    n_updates             | 9050        |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.276       |
|    value_loss            | 0.881       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30269402 |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 563         |
|    total_timesteps       | 1857536     |
| train/                   |             |
|    approx_kl             | 0.02125709  |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.502      |
|    entropy               | 0.699       |
|    entropy_loss          | 0.698       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.38        |
|    n_updates             | 9060        |
|    policy_gradient_loss  | 0.00624     |
|    std                   | 0.277       |
|    value_loss            | 0.812       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.25983673 |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 585         |
|    total_timesteps       | 1859584     |
| train/                   |             |
|    approx_kl             | 0.027262108 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.507      |
|    entropy               | 0.703       |
|    entropy_loss          | 0.701       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.592       |
|    n_updates             | 9070        |
|    policy_gradient_loss  | 0.00307     |
|    std                   | 0.276       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.39        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.39        |
| reward                   | -0.34273583 |
| rollout/                 |             |
|    ep_len_mean           | 49          |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 27          |
|    time_elapsed          | 608         |
|    total_timesteps       | 1861632     |
| train/                   |             |
|    approx_kl             | 0.04677685  |
|    clip_fraction         | 0.271       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.487      |
|    entropy               | 0.694       |
|    entropy_loss          | 0.7         |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.469       |
|    n_updates             | 9080        |
|    policy_gradient_loss  | 0.0083      |
|    std                   | 0.277       |
|    value_loss            | 0.816       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -0.15080075 |
| rollout/                 |             |
|    ep_len_mean           | 47.8        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 630         |
|    total_timesteps       | 1863680     |
| train/                   |             |
|    approx_kl             | 0.025199559 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.483      |
|    entropy               | 0.69        |
|    entropy_loss          | 0.691       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.398       |
|    n_updates             | 9090        |
|    policy_gradient_loss  | 0.0092      |
|    std                   | 0.277       |
|    value_loss            | 0.731       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32858592 |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 653         |
|    total_timesteps       | 1865728     |
| train/                   |             |
|    approx_kl             | 0.015480736 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.96        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.495      |
|    entropy               | 0.69        |
|    entropy_loss          | 0.69        |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.596       |
|    n_updates             | 9100        |
|    policy_gradient_loss  | 0.00351     |
|    std                   | 0.277       |
|    value_loss            | 1.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.15311858 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 675         |
|    total_timesteps       | 1867776     |
| train/                   |             |
|    approx_kl             | 0.022147108 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.492      |
|    entropy               | 0.696       |
|    entropy_loss          | 0.693       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.522       |
|    n_updates             | 9110        |
|    policy_gradient_loss  | 0.00863     |
|    std                   | 0.277       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.12368327 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 698         |
|    total_timesteps       | 1869824     |
| train/                   |             |
|    approx_kl             | 0.024321113 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.96        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.501      |
|    entropy               | 0.699       |
|    entropy_loss          | 0.698       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.354       |
|    n_updates             | 9120        |
|    policy_gradient_loss  | 0.0111      |
|    std                   | 0.277       |
|    value_loss            | 0.747       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.42861488 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 720         |
|    total_timesteps       | 1871872     |
| train/                   |             |
|    approx_kl             | 0.033665158 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.5        |
|    entropy               | 0.703       |
|    entropy_loss          | 0.701       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.287       |
|    n_updates             | 9130        |
|    policy_gradient_loss  | 0.00749     |
|    std                   | 0.276       |
|    value_loss            | 0.582       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.16        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.16        |
| reward                   | -0.38971296 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 743         |
|    total_timesteps       | 1873920     |
| train/                   |             |
|    approx_kl             | 0.04654724  |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 126         |
|    cost_values           | -0.494      |
|    entropy               | 0.713       |
|    entropy_loss          | 0.708       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.468       |
|    n_updates             | 9140        |
|    policy_gradient_loss  | 0.00613     |
|    std                   | 0.274       |
|    value_loss            | 0.977       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.3964638  |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 765         |
|    total_timesteps       | 1875968     |
| train/                   |             |
|    approx_kl             | 0.019587582 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.494      |
|    entropy               | 0.721       |
|    entropy_loss          | 0.717       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.42        |
|    n_updates             | 9150        |
|    policy_gradient_loss  | 0.000613    |
|    std                   | 0.274       |
|    value_loss            | 0.779       |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5.6        |
| reward                   | -0.3584114 |
| rollout/                 |            |
|    ep_len_mean           | 47         |
|    ep_rew_mean           | -16.2      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 35         |
|    time_elapsed          | 788        |
|    total_timesteps       | 1878016    |
| train/                   |            |
|    approx_kl             | 0.02445916 |
|    clip_fraction         | 0.215      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.4       |
|    cost_value_loss       | 133        |
|    cost_values           | -0.484     |
|    entropy               | 0.732      |
|    entropy_loss          | 0.727      |
|    explained_variance    | 0.915      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.54       |
|    n_updates             | 9160       |
|    policy_gradient_loss  | 0.00242    |
|    std                   | 0.272      |
|    value_loss            | 1.13       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.49        |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 7.49        |
| reward                   | -0.10790899 |
| rollout/                 |             |
|    ep_len_mean           | 46.8        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 36          |
|    time_elapsed          | 811         |
|    total_timesteps       | 1880064     |
| train/                   |             |
|    approx_kl             | 0.03983046  |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.484      |
|    entropy               | 0.736       |
|    entropy_loss          | 0.735       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.676       |
|    n_updates             | 9170        |
|    policy_gradient_loss  | 0.00391     |
|    std                   | 0.272       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.62254184 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 833         |
|    total_timesteps       | 1882112     |
| train/                   |             |
|    approx_kl             | 0.046568114 |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.484      |
|    entropy               | 0.737       |
|    entropy_loss          | 0.737       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.45        |
|    n_updates             | 9180        |
|    policy_gradient_loss  | 0.00248     |
|    std                   | 0.273       |
|    value_loss            | 0.981       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.323158   |
| rollout/                 |             |
|    ep_len_mean           | 46          |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 856         |
|    total_timesteps       | 1884160     |
| train/                   |             |
|    approx_kl             | 0.033493325 |
|    clip_fraction         | 0.283       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.481      |
|    entropy               | 0.742       |
|    entropy_loss          | 0.74        |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.453       |
|    n_updates             | 9190        |
|    policy_gradient_loss  | 0.0116      |
|    std                   | 0.272       |
|    value_loss            | 0.852       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30835047 |
| rollout/                 |             |
|    ep_len_mean           | 46.6        |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 878         |
|    total_timesteps       | 1886208     |
| train/                   |             |
|    approx_kl             | 0.018152695 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.484      |
|    entropy               | 0.74        |
|    entropy_loss          | 0.742       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.427       |
|    n_updates             | 9200        |
|    policy_gradient_loss  | 0.00768     |
|    std                   | 0.272       |
|    value_loss            | 0.918       |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.16113721 |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 40          |
|    time_elapsed          | 901         |
|    total_timesteps       | 1888256     |
| train/                   |             |
|    approx_kl             | 0.041626144 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.476      |
|    entropy               | 0.736       |
|    entropy_loss          | 0.737       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.424       |
|    n_updates             | 9210        |
|    policy_gradient_loss  | 0.00696     |
|    std                   | 0.273       |
|    value_loss            | 0.915       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.31993115 |
| rollout/                 |             |
|    ep_len_mean           | 47.6        |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 923         |
|    total_timesteps       | 1890304     |
| train/                   |             |
|    approx_kl             | 0.024121523 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.477      |
|    entropy               | 0.74        |
|    entropy_loss          | 0.738       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.372       |
|    n_updates             | 9220        |
|    policy_gradient_loss  | 0.00661     |
|    std                   | 0.273       |
|    value_loss            | 0.818       |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.04       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.04       |
| reward                   | -0.2625142 |
| rollout/                 |            |
|    ep_len_mean           | 48.2       |
|    ep_rew_mean           | -16.8      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 42         |
|    time_elapsed          | 946        |
|    total_timesteps       | 1892352    |
| train/                   |            |
|    approx_kl             | 0.02504493 |
|    clip_fraction         | 0.219      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.7       |
|    cost_value_loss       | 139        |
|    cost_values           | -0.473     |
|    entropy               | 0.735      |
|    entropy_loss          | 0.739      |
|    explained_variance    | 0.933      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.423      |
|    n_updates             | 9230       |
|    policy_gradient_loss  | 0.00434    |
|    std                   | 0.274      |
|    value_loss            | 0.963      |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.38        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.38        |
| reward                   | -0.29675612 |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 43          |
|    time_elapsed          | 969         |
|    total_timesteps       | 1894400     |
| train/                   |             |
|    approx_kl             | 0.028461244 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.483      |
|    entropy               | 0.731       |
|    entropy_loss          | 0.733       |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.62        |
|    n_updates             | 9240        |
|    policy_gradient_loss  | 0.00767     |
|    std                   | 0.275       |
|    value_loss            | 1.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.24586181 |
| rollout/                 |             |
|    ep_len_mean           | 47.6        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 991         |
|    total_timesteps       | 1896448     |
| train/                   |             |
|    approx_kl             | 0.040533654 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.48       |
|    entropy               | 0.74        |
|    entropy_loss          | 0.734       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.552       |
|    n_updates             | 9250        |
|    policy_gradient_loss  | 0.0096      |
|    std                   | 0.275       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.3931622  |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 1898496     |
| train/                   |             |
|    approx_kl             | 0.025471225 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.486      |
|    entropy               | 0.749       |
|    entropy_loss          | 0.745       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.37        |
|    n_updates             | 9260        |
|    policy_gradient_loss  | 0.000478    |
|    std                   | 0.274       |
|    value_loss            | 0.702       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.54        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.54        |
| reward                   | -0.3021555  |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1036        |
|    total_timesteps       | 1900544     |
| train/                   |             |
|    approx_kl             | 0.024068048 |
|    clip_fraction         | 0.255       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.48       |
|    entropy               | 0.743       |
|    entropy_loss          | 0.747       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.424       |
|    n_updates             | 9270        |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.275       |
|    value_loss            | 0.877       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.321551   |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 1902592     |
| train/                   |             |
|    approx_kl             | 0.022434656 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.493      |
|    entropy               | 0.743       |
|    entropy_loss          | 0.742       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.399       |
|    n_updates             | 9280        |
|    policy_gradient_loss  | 0.00399     |
|    std                   | 0.276       |
|    value_loss            | 0.993       |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.22075367 |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1081        |
|    total_timesteps       | 1904640     |
| train/                   |             |
|    approx_kl             | 0.03813167  |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.471      |
|    entropy               | 0.742       |
|    entropy_loss          | 0.743       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.404       |
|    n_updates             | 9290        |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.276       |
|    value_loss            | 0.846       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.07157781 |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1104        |
|    total_timesteps       | 1906688     |
| train/                   |             |
|    approx_kl             | 0.029715227 |
|    clip_fraction         | 0.321       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.484      |
|    entropy               | 0.743       |
|    entropy_loss          | 0.743       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.403       |
|    n_updates             | 9300        |
|    policy_gradient_loss  | 0.026       |
|    std                   | 0.276       |
|    value_loss            | 0.802       |
------------------------------------------
------------------------------------
| avg_speed          | 4           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 4           |
| reward             | -0.19372228 |
| rollout/           |             |
|    ep_len_mean     | 47.4        |
|    ep_rew_mean     | -16.8       |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 1908736     |
------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.51554286 |
| rollout/                 |             |
|    ep_len_mean           | 47.3        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 1910784     |
| train/                   |             |
|    approx_kl             | 0.033521883 |
|    clip_fraction         | 0.257       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.49       |
|    entropy               | 0.731       |
|    entropy_loss          | 0.736       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.413       |
|    n_updates             | 9320        |
|    policy_gradient_loss  | 0.00971     |
|    std                   | 0.28        |
|    value_loss            | 0.824       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.52        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.52        |
| reward                   | -0.18660566 |
| rollout/                 |             |
|    ep_len_mean           | 46.6        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 1912832     |
| train/                   |             |
|    approx_kl             | 0.04878605  |
|    clip_fraction         | 0.282       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.479      |
|    entropy               | 0.724       |
|    entropy_loss          | 0.727       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.432       |
|    n_updates             | 9330        |
|    policy_gradient_loss  | 0.0175      |
|    std                   | 0.281       |
|    value_loss            | 0.886       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.33908626 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 1914880     |
| train/                   |             |
|    approx_kl             | 0.06148702  |
|    clip_fraction         | 0.294       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.488      |
|    entropy               | 0.719       |
|    entropy_loss          | 0.722       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.59        |
|    n_updates             | 9340        |
|    policy_gradient_loss  | 0.0149      |
|    std                   | 0.281       |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.3119309  |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 1916928     |
| train/                   |             |
|    approx_kl             | 0.021684457 |
|    clip_fraction         | 0.283       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.49       |
|    entropy               | 0.714       |
|    entropy_loss          | 0.716       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.422       |
|    n_updates             | 9350        |
|    policy_gradient_loss  | 0.0177      |
|    std                   | 0.281       |
|    value_loss            | 0.886       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.14        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.14        |
| reward                   | -0.44779482 |
| rollout/                 |             |
|    ep_len_mean           | 47.5        |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 1918976     |
| train/                   |             |
|    approx_kl             | 0.024555087 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.48       |
|    entropy               | 0.715       |
|    entropy_loss          | 0.713       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.431       |
|    n_updates             | 9360        |
|    policy_gradient_loss  | 0.00639     |
|    std                   | 0.281       |
|    value_loss            | 0.991       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30204517 |
| rollout/                 |             |
|    ep_len_mean           | 48.1        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 1921024     |
| train/                   |             |
|    approx_kl             | 0.05172029  |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.499      |
|    entropy               | 0.714       |
|    entropy_loss          | 0.715       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.465       |
|    n_updates             | 9370        |
|    policy_gradient_loss  | 0.00591     |
|    std                   | 0.282       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.48447642 |
| rollout/                 |             |
|    ep_len_mean           | 48.5        |
|    ep_rew_mean           | -16.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 8           |
|    time_elapsed          | 180         |
|    total_timesteps       | 1923072     |
| train/                   |             |
|    approx_kl             | 0.02809057  |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.48       |
|    entropy               | 0.717       |
|    entropy_loss          | 0.715       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.498       |
|    n_updates             | 9380        |
|    policy_gradient_loss  | 0.0021      |
|    std                   | 0.282       |
|    value_loss            | 0.999       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.362479   |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 1925120     |
| train/                   |             |
|    approx_kl             | 0.017287366 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.497      |
|    entropy               | 0.724       |
|    entropy_loss          | 0.721       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.422       |
|    n_updates             | 9390        |
|    policy_gradient_loss  | 0.0039      |
|    std                   | 0.282       |
|    value_loss            | 0.878       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.37060994 |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 1927168     |
| train/                   |             |
|    approx_kl             | 0.026051156 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.492      |
|    entropy               | 0.731       |
|    entropy_loss          | 0.728       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.503       |
|    n_updates             | 9400        |
|    policy_gradient_loss  | 0.00285     |
|    std                   | 0.282       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19686407 |
| rollout/                 |             |
|    ep_len_mean           | 49          |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 1929216     |
| train/                   |             |
|    approx_kl             | 0.04999865  |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.484      |
|    entropy               | 0.727       |
|    entropy_loss          | 0.73        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.531       |
|    n_updates             | 9410        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.282       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.37909195 |
| rollout/                 |             |
|    ep_len_mean           | 48.6        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 1931264     |
| train/                   |             |
|    approx_kl             | 0.033258278 |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.499      |
|    entropy               | 0.728       |
|    entropy_loss          | 0.726       |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.471       |
|    n_updates             | 9420        |
|    policy_gradient_loss  | 0.00485     |
|    std                   | 0.282       |
|    value_loss            | 0.983       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.494822  |
| rollout/                 |            |
|    ep_len_mean           | 50.4       |
|    ep_rew_mean           | -17.5      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 13         |
|    time_elapsed          | 292        |
|    total_timesteps       | 1933312    |
| train/                   |            |
|    approx_kl             | 0.02140698 |
|    clip_fraction         | 0.259      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.4       |
|    cost_value_loss       | 134        |
|    cost_values           | -0.487     |
|    entropy               | 0.733      |
|    entropy_loss          | 0.73       |
|    explained_variance    | 0.938      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.555      |
|    n_updates             | 9430       |
|    policy_gradient_loss  | 0.00471    |
|    std                   | 0.281      |
|    value_loss            | 0.997      |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.14802332 |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 314         |
|    total_timesteps       | 1935360     |
| train/                   |             |
|    approx_kl             | 0.018979874 |
|    clip_fraction         | 0.269       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 146         |
|    cost_values           | -0.486      |
|    entropy               | 0.737       |
|    entropy_loss          | 0.735       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.6         |
|    n_updates             | 9440        |
|    policy_gradient_loss  | 0.00723     |
|    std                   | 0.279       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.41959977 |
| rollout/                 |             |
|    ep_len_mean           | 52.6        |
|    ep_rew_mean           | -18.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 1937408     |
| train/                   |             |
|    approx_kl             | 0.032701846 |
|    clip_fraction         | 0.246       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.492      |
|    entropy               | 0.738       |
|    entropy_loss          | 0.738       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.481       |
|    n_updates             | 9450        |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.278       |
|    value_loss            | 1.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36995292 |
| rollout/                 |             |
|    ep_len_mean           | 52.1        |
|    ep_rew_mean           | -17.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 359         |
|    total_timesteps       | 1939456     |
| train/                   |             |
|    approx_kl             | 0.0245382   |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 145         |
|    cost_values           | -0.497      |
|    entropy               | 0.734       |
|    entropy_loss          | 0.736       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.659       |
|    n_updates             | 9460        |
|    policy_gradient_loss  | 0.000722    |
|    std                   | 0.28        |
|    value_loss            | 1.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.2          |
| reward                   | -0.33849153  |
| rollout/                 |              |
|    ep_len_mean           | 50.1         |
|    ep_rew_mean           | -17.2        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 17           |
|    time_elapsed          | 382          |
|    total_timesteps       | 1941504      |
| train/                   |              |
|    approx_kl             | 0.0139567405 |
|    clip_fraction         | 0.175        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 139          |
|    cost_values           | -0.495       |
|    entropy               | 0.726        |
|    entropy_loss          | 0.73         |
|    explained_variance    | 0.921        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.563        |
|    n_updates             | 9470         |
|    policy_gradient_loss  | 0.00123      |
|    std                   | 0.281        |
|    value_loss            | 1.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.28528273 |
| rollout/                 |             |
|    ep_len_mean           | 49.9        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 404         |
|    total_timesteps       | 1943552     |
| train/                   |             |
|    approx_kl             | 0.062297743 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.499      |
|    entropy               | 0.728       |
|    entropy_loss          | 0.726       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.376       |
|    n_updates             | 9480        |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.281       |
|    value_loss            | 0.835       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.383164   |
| rollout/                 |             |
|    ep_len_mean           | 49.1        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 427         |
|    total_timesteps       | 1945600     |
| train/                   |             |
|    approx_kl             | 0.021058867 |
|    clip_fraction         | 0.253       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 143         |
|    cost_values           | -0.489      |
|    entropy               | 0.728       |
|    entropy_loss          | 0.729       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.838       |
|    n_updates             | 9490        |
|    policy_gradient_loss  | 0.00525     |
|    std                   | 0.281       |
|    value_loss            | 1.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.14        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.14        |
| reward                   | -0.26018837 |
| rollout/                 |             |
|    ep_len_mean           | 48.5        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 449         |
|    total_timesteps       | 1947648     |
| train/                   |             |
|    approx_kl             | 0.026959216 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.514      |
|    entropy               | 0.725       |
|    entropy_loss          | 0.726       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.566       |
|    n_updates             | 9500        |
|    policy_gradient_loss  | 0.00754     |
|    std                   | 0.281       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.56938815 |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 472         |
|    total_timesteps       | 1949696     |
| train/                   |             |
|    approx_kl             | 0.022263955 |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.501      |
|    entropy               | 0.724       |
|    entropy_loss          | 0.725       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.548       |
|    n_updates             | 9510        |
|    policy_gradient_loss  | 0.00464     |
|    std                   | 0.281       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2616629  |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 494         |
|    total_timesteps       | 1951744     |
| train/                   |             |
|    approx_kl             | 0.040833086 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.523      |
|    entropy               | 0.73        |
|    entropy_loss          | 0.727       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.807       |
|    n_updates             | 9520        |
|    policy_gradient_loss  | 0.00225     |
|    std                   | 0.282       |
|    value_loss            | 1.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.30186525 |
| rollout/                 |             |
|    ep_len_mean           | 47.3        |
|    ep_rew_mean           | -16.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 517         |
|    total_timesteps       | 1953792     |
| train/                   |             |
|    approx_kl             | 0.019575655 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.489      |
|    entropy               | 0.734       |
|    entropy_loss          | 0.732       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.342       |
|    n_updates             | 9530        |
|    policy_gradient_loss  | 0.000168    |
|    std                   | 0.281       |
|    value_loss            | 0.816       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.43193048 |
| rollout/                 |             |
|    ep_len_mean           | 47.5        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 539         |
|    total_timesteps       | 1955840     |
| train/                   |             |
|    approx_kl             | 0.025091637 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.484      |
|    entropy               | 0.732       |
|    entropy_loss          | 0.732       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.57        |
|    n_updates             | 9540        |
|    policy_gradient_loss  | 0.00916     |
|    std                   | 0.281       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.32157034 |
| rollout/                 |             |
|    ep_len_mean           | 49.1        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 562         |
|    total_timesteps       | 1957888     |
| train/                   |             |
|    approx_kl             | 0.025908789 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.496      |
|    entropy               | 0.735       |
|    entropy_loss          | 0.733       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.579       |
|    n_updates             | 9550        |
|    policy_gradient_loss  | 0.0155      |
|    std                   | 0.282       |
|    value_loss            | 1.35        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3          |
| reward                   | -0.5457159 |
| rollout/                 |            |
|    ep_len_mean           | 49.3       |
|    ep_rew_mean           | -17        |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 26         |
|    time_elapsed          | 584        |
|    total_timesteps       | 1959936    |
| train/                   |            |
|    approx_kl             | 0.02000844 |
|    clip_fraction         | 0.195      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.5       |
|    cost_value_loss       | 135        |
|    cost_values           | -0.488     |
|    entropy               | 0.737      |
|    entropy_loss          | 0.735      |
|    explained_variance    | 0.942      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.353      |
|    n_updates             | 9560       |
|    policy_gradient_loss  | 0.00051    |
|    std                   | 0.282      |
|    value_loss            | 0.814      |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.59694254 |
| rollout/                 |             |
|    ep_len_mean           | 48.7        |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 607         |
|    total_timesteps       | 1961984     |
| train/                   |             |
|    approx_kl             | 0.023217881 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.479      |
|    entropy               | 0.736       |
|    entropy_loss          | 0.737       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.337       |
|    n_updates             | 9570        |
|    policy_gradient_loss  | 0.00144     |
|    std                   | 0.282       |
|    value_loss            | 0.731       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.3028242  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 629         |
|    total_timesteps       | 1964032     |
| train/                   |             |
|    approx_kl             | 0.031648923 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.508      |
|    entropy               | 0.74        |
|    entropy_loss          | 0.737       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.551       |
|    n_updates             | 9580        |
|    policy_gradient_loss  | 0.000879    |
|    std                   | 0.282       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.46893215 |
| rollout/                 |             |
|    ep_len_mean           | 47.7        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 652         |
|    total_timesteps       | 1966080     |
| train/                   |             |
|    approx_kl             | 0.027545787 |
|    clip_fraction         | 0.261       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.95        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.501      |
|    entropy               | 0.74        |
|    entropy_loss          | 0.74        |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.579       |
|    n_updates             | 9590        |
|    policy_gradient_loss  | 0.0159      |
|    std                   | 0.283       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.59        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.59        |
| reward                   | -0.15770428 |
| rollout/                 |             |
|    ep_len_mean           | 49.1        |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 674         |
|    total_timesteps       | 1968128     |
| train/                   |             |
|    approx_kl             | 0.016386852 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 147         |
|    cost_values           | -0.492      |
|    entropy               | 0.737       |
|    entropy_loss          | 0.739       |
|    explained_variance    | 0.806       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.869       |
|    n_updates             | 9600        |
|    policy_gradient_loss  | 0.00961     |
|    std                   | 0.282       |
|    value_loss            | 1.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40078625 |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -17.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 697         |
|    total_timesteps       | 1970176     |
| train/                   |             |
|    approx_kl             | 0.026002787 |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.497      |
|    entropy               | 0.736       |
|    entropy_loss          | 0.736       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.726       |
|    n_updates             | 9610        |
|    policy_gradient_loss  | 0.0111      |
|    std                   | 0.282       |
|    value_loss            | 1.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.42124727 |
| rollout/                 |             |
|    ep_len_mean           | 48.5        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 719         |
|    total_timesteps       | 1972224     |
| train/                   |             |
|    approx_kl             | 0.022518922 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.473      |
|    entropy               | 0.739       |
|    entropy_loss          | 0.738       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.655       |
|    n_updates             | 9620        |
|    policy_gradient_loss  | 0.00276     |
|    std                   | 0.281       |
|    value_loss            | 1.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.21952291 |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 742         |
|    total_timesteps       | 1974272     |
| train/                   |             |
|    approx_kl             | 0.028637856 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.494      |
|    entropy               | 0.749       |
|    entropy_loss          | 0.744       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.473       |
|    n_updates             | 9630        |
|    policy_gradient_loss  | 0.00624     |
|    std                   | 0.28        |
|    value_loss            | 0.987       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.2938558  |
| rollout/                 |             |
|    ep_len_mean           | 48.3        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 764         |
|    total_timesteps       | 1976320     |
| train/                   |             |
|    approx_kl             | 0.021578018 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.515      |
|    entropy               | 0.749       |
|    entropy_loss          | 0.751       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.573       |
|    n_updates             | 9640        |
|    policy_gradient_loss  | 0.00666     |
|    std                   | 0.281       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.6405845  |
| rollout/                 |             |
|    ep_len_mean           | 47.9        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 787         |
|    total_timesteps       | 1978368     |
| train/                   |             |
|    approx_kl             | 0.024350157 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.483      |
|    entropy               | 0.752       |
|    entropy_loss          | 0.75        |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.5         |
|    n_updates             | 9650        |
|    policy_gradient_loss  | 0.00448     |
|    std                   | 0.281       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.35780746 |
| rollout/                 |             |
|    ep_len_mean           | 49.8        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 809         |
|    total_timesteps       | 1980416     |
| train/                   |             |
|    approx_kl             | 0.026467161 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.511      |
|    entropy               | 0.766       |
|    entropy_loss          | 0.759       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.675       |
|    n_updates             | 9660        |
|    policy_gradient_loss  | -0.000364   |
|    std                   | 0.278       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.13750455 |
| rollout/                 |             |
|    ep_len_mean           | 50.6        |
|    ep_rew_mean           | -17.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 832         |
|    total_timesteps       | 1982464     |
| train/                   |             |
|    approx_kl             | 0.026749326 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.485      |
|    entropy               | 0.767       |
|    entropy_loss          | 0.767       |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.745       |
|    n_updates             | 9670        |
|    policy_gradient_loss  | 0.00941     |
|    std                   | 0.279       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3537402  |
| rollout/                 |             |
|    ep_len_mean           | 49.5        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 854         |
|    total_timesteps       | 1984512     |
| train/                   |             |
|    approx_kl             | 0.031879187 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.48       |
|    entropy               | 0.775       |
|    entropy_loss          | 0.77        |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.07        |
|    n_updates             | 9680        |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 0.277       |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25254014 |
| rollout/                 |             |
|    ep_len_mean           | 46.9        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 39          |
|    time_elapsed          | 877         |
|    total_timesteps       | 1986560     |
| train/                   |             |
|    approx_kl             | 0.02513665  |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.486      |
|    entropy               | 0.769       |
|    entropy_loss          | 0.773       |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.988       |
|    n_updates             | 9690        |
|    policy_gradient_loss  | 0.0052      |
|    std                   | 0.277       |
|    value_loss            | 1.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.31982365 |
| rollout/                 |             |
|    ep_len_mean           | 48.6        |
|    ep_rew_mean           | -16.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 900         |
|    total_timesteps       | 1988608     |
| train/                   |             |
|    approx_kl             | 0.028215766 |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.483      |
|    entropy               | 0.775       |
|    entropy_loss          | 0.77        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.491       |
|    n_updates             | 9700        |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.276       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.47477674 |
| rollout/                 |             |
|    ep_len_mean           | 50.2        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 922         |
|    total_timesteps       | 1990656     |
| train/                   |             |
|    approx_kl             | 0.043048445 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 140         |
|    cost_values           | -0.497      |
|    entropy               | 0.782       |
|    entropy_loss          | 0.779       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.652       |
|    n_updates             | 9710        |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.275       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.43288302 |
| rollout/                 |             |
|    ep_len_mean           | 50.7        |
|    ep_rew_mean           | -17.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 945         |
|    total_timesteps       | 1992704     |
| train/                   |             |
|    approx_kl             | 0.038293164 |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.48       |
|    entropy               | 0.795       |
|    entropy_loss          | 0.789       |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.886       |
|    n_updates             | 9720        |
|    policy_gradient_loss  | 0.00466     |
|    std                   | 0.275       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.32204148 |
| rollout/                 |             |
|    ep_len_mean           | 48.1        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 967         |
|    total_timesteps       | 1994752     |
| train/                   |             |
|    approx_kl             | 0.027314778 |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.499      |
|    entropy               | 0.793       |
|    entropy_loss          | 0.795       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.589       |
|    n_updates             | 9730        |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.275       |
|    value_loss            | 1.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.38        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.38        |
| reward                   | -0.3157253  |
| rollout/                 |             |
|    ep_len_mean           | 47.8        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 44          |
|    time_elapsed          | 989         |
|    total_timesteps       | 1996800     |
| train/                   |             |
|    approx_kl             | 0.015316791 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.486      |
|    entropy               | 0.799       |
|    entropy_loss          | 0.795       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.575       |
|    n_updates             | 9740        |
|    policy_gradient_loss  | 0.0123      |
|    std                   | 0.274       |
|    value_loss            | 1.17        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.3154498 |
| rollout/                 |            |
|    ep_len_mean           | 49.5       |
|    ep_rew_mean           | -17.1      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 45         |
|    time_elapsed          | 1012       |
|    total_timesteps       | 1998848    |
| train/                   |            |
|    approx_kl             | 0.050637   |
|    clip_fraction         | 0.243      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.4       |
|    cost_value_loss       | 134        |
|    cost_values           | -0.48      |
|    entropy               | 0.809      |
|    entropy_loss          | 0.804      |
|    explained_variance    | 0.913      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.639      |
|    n_updates             | 9750       |
|    policy_gradient_loss  | 0.0106     |
|    std                   | 0.272      |
|    value_loss            | 1.3        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.20933901 |
| rollout/                 |             |
|    ep_len_mean           | 49.1        |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 46          |
|    time_elapsed          | 1034        |
|    total_timesteps       | 2000896     |
| train/                   |             |
|    approx_kl             | 0.030413555 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.485      |
|    entropy               | 0.821       |
|    entropy_loss          | 0.816       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.4         |
|    n_updates             | 9760        |
|    policy_gradient_loss  | 0.00998     |
|    std                   | 0.271       |
|    value_loss            | 0.808       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.2882359  |
| rollout/                 |             |
|    ep_len_mean           | 48.7        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 47          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 2002944     |
| train/                   |             |
|    approx_kl             | 0.036889642 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.489      |
|    entropy               | 0.826       |
|    entropy_loss          | 0.824       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.592       |
|    n_updates             | 9770        |
|    policy_gradient_loss  | 0.0062      |
|    std                   | 0.27        |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.31355315 |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -16.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 48          |
|    time_elapsed          | 1079        |
|    total_timesteps       | 2004992     |
| train/                   |             |
|    approx_kl             | 0.04457489  |
|    clip_fraction         | 0.278       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.501      |
|    entropy               | 0.825       |
|    entropy_loss          | 0.826       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.567       |
|    n_updates             | 9780        |
|    policy_gradient_loss  | 0.0165      |
|    std                   | 0.27        |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.56123036 |
| rollout/                 |             |
|    ep_len_mean           | 47.6        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 49          |
|    time_elapsed          | 1102        |
|    total_timesteps       | 2007040     |
| train/                   |             |
|    approx_kl             | 0.04841475  |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.489      |
|    entropy               | 0.833       |
|    entropy_loss          | 0.829       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.432       |
|    n_updates             | 9790        |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.269       |
|    value_loss            | 0.899       |
------------------------------------------
-----------------------------------
| avg_speed          | 0.8        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.8        |
| reward             | -0.5459628 |
| rollout/           |            |
|    ep_len_mean     | 48.2       |
|    ep_rew_mean     | -16.5      |
| time/              |            |
|    fps             | 92         |
|    iterations      | 1          |
|    time_elapsed    | 22         |
|    total_timesteps | 2009088    |
-----------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.4751678 |
| rollout/                 |            |
|    ep_len_mean           | 47         |
|    ep_rew_mean           | -16        |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 2          |
|    time_elapsed          | 44         |
|    total_timesteps       | 2011136    |
| train/                   |            |
|    approx_kl             | 0.04368238 |
|    clip_fraction         | 0.234      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.3       |
|    cost_value_loss       | 133        |
|    cost_values           | -0.511     |
|    entropy               | 0.825      |
|    entropy_loss          | 0.829      |
|    explained_variance    | 0.943      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.46       |
|    n_updates             | 9810       |
|    policy_gradient_loss  | 0.00884    |
|    std                   | 0.27       |
|    value_loss            | 0.831      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.3793684  |
| rollout/                 |             |
|    ep_len_mean           | 48.3        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2013184     |
| train/                   |             |
|    approx_kl             | 0.022348437 |
|    clip_fraction         | 0.302       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.496      |
|    entropy               | 0.822       |
|    entropy_loss          | 0.823       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.376       |
|    n_updates             | 9820        |
|    policy_gradient_loss  | 0.0179      |
|    std                   | 0.271       |
|    value_loss            | 0.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.49        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.49        |
| reward                   | -0.24943945 |
| rollout/                 |             |
|    ep_len_mean           | 48.3        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2015232     |
| train/                   |             |
|    approx_kl             | 0.017025039 |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.49       |
|    entropy               | 0.818       |
|    entropy_loss          | 0.82        |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.62        |
|    n_updates             | 9830        |
|    policy_gradient_loss  | 0.00685     |
|    std                   | 0.271       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.56123036 |
| rollout/                 |             |
|    ep_len_mean           | 48.2        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2017280     |
| train/                   |             |
|    approx_kl             | 0.016750367 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.488      |
|    entropy               | 0.814       |
|    entropy_loss          | 0.816       |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.509       |
|    n_updates             | 9840        |
|    policy_gradient_loss  | 0.00796     |
|    std                   | 0.271       |
|    value_loss            | 0.997       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.5451013  |
| rollout/                 |             |
|    ep_len_mean           | 48.2        |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2019328     |
| train/                   |             |
|    approx_kl             | 0.019648863 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.493      |
|    entropy               | 0.818       |
|    entropy_loss          | 0.814       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.404       |
|    n_updates             | 9850        |
|    policy_gradient_loss  | 9.26e-05    |
|    std                   | 0.271       |
|    value_loss            | 0.905       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.41159654 |
| rollout/                 |             |
|    ep_len_mean           | 48.2        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2021376     |
| train/                   |             |
|    approx_kl             | 0.02857615  |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.505      |
|    entropy               | 0.827       |
|    entropy_loss          | 0.823       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.469       |
|    n_updates             | 9860        |
|    policy_gradient_loss  | 0.00787     |
|    std                   | 0.27        |
|    value_loss            | 0.848       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.3016923  |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 179         |
|    total_timesteps       | 2023424     |
| train/                   |             |
|    approx_kl             | 0.035277862 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.497      |
|    entropy               | 0.835       |
|    entropy_loss          | 0.831       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.44        |
|    n_updates             | 9870        |
|    policy_gradient_loss  | 0.00995     |
|    std                   | 0.268       |
|    value_loss            | 0.793       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.35030037 |
| rollout/                 |             |
|    ep_len_mean           | 46.9        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2025472     |
| train/                   |             |
|    approx_kl             | 0.04293125  |
|    clip_fraction         | 0.266       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.49       |
|    entropy               | 0.84        |
|    entropy_loss          | 0.837       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.438       |
|    n_updates             | 9880        |
|    policy_gradient_loss  | 0.00508     |
|    std                   | 0.268       |
|    value_loss            | 0.938       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3487182  |
| rollout/                 |             |
|    ep_len_mean           | 47.3        |
|    ep_rew_mean           | -16.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 2027520     |
| train/                   |             |
|    approx_kl             | 0.019099431 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.493      |
|    entropy               | 0.844       |
|    entropy_loss          | 0.842       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.325       |
|    n_updates             | 9890        |
|    policy_gradient_loss  | 0.0061      |
|    std                   | 0.267       |
|    value_loss            | 0.716       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.49        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.49        |
| reward                   | -0.2696976  |
| rollout/                 |             |
|    ep_len_mean           | 47.5        |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2029568     |
| train/                   |             |
|    approx_kl             | 0.047476783 |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.494      |
|    entropy               | 0.839       |
|    entropy_loss          | 0.842       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.428       |
|    n_updates             | 9900        |
|    policy_gradient_loss  | 0.00868     |
|    std                   | 0.267       |
|    value_loss            | 0.878       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.99        |
| reward                   | -0.29240927 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 2031616     |
| train/                   |             |
|    approx_kl             | 0.04034203  |
|    clip_fraction         | 0.257       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.508      |
|    entropy               | 0.841       |
|    entropy_loss          | 0.84        |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.461       |
|    n_updates             | 9910        |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.267       |
|    value_loss            | 0.998       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.25939462 |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 2033664     |
| train/                   |             |
|    approx_kl             | 0.039676465 |
|    clip_fraction         | 0.296       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.495      |
|    entropy               | 0.846       |
|    entropy_loss          | 0.844       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.677       |
|    n_updates             | 9920        |
|    policy_gradient_loss  | 0.0142      |
|    std                   | 0.265       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.42740265 |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 314         |
|    total_timesteps       | 2035712     |
| train/                   |             |
|    approx_kl             | 0.028378878 |
|    clip_fraction         | 0.257       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.474      |
|    entropy               | 0.854       |
|    entropy_loss          | 0.85        |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.448       |
|    n_updates             | 9930        |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.263       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38133734 |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2037760     |
| train/                   |             |
|    approx_kl             | 0.020808848 |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.95        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.502      |
|    entropy               | 0.859       |
|    entropy_loss          | 0.857       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.578       |
|    n_updates             | 9940        |
|    policy_gradient_loss  | 0.00714     |
|    std                   | 0.262       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.32107747 |
| rollout/                 |             |
|    ep_len_mean           | 46.9        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 359         |
|    total_timesteps       | 2039808     |
| train/                   |             |
|    approx_kl             | 0.018506663 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.5        |
|    entropy               | 0.863       |
|    entropy_loss          | 0.861       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.441       |
|    n_updates             | 9950        |
|    policy_gradient_loss  | 0.00689     |
|    std                   | 0.262       |
|    value_loss            | 0.848       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.42087463 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 382         |
|    total_timesteps       | 2041856     |
| train/                   |             |
|    approx_kl             | 0.028906273 |
|    clip_fraction         | 0.256       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.488      |
|    entropy               | 0.869       |
|    entropy_loss          | 0.866       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.256       |
|    n_updates             | 9960        |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.261       |
|    value_loss            | 0.584       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.535287  |
| rollout/                 |            |
|    ep_len_mean           | 46.3       |
|    ep_rew_mean           | -16        |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 18         |
|    time_elapsed          | 404        |
|    total_timesteps       | 2043904    |
| train/                   |            |
|    approx_kl             | 0.05050298 |
|    clip_fraction         | 0.287      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.2       |
|    cost_value_loss       | 130        |
|    cost_values           | -0.492     |
|    entropy               | 0.873      |
|    entropy_loss          | 0.871      |
|    explained_variance    | 0.938      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.457      |
|    n_updates             | 9970       |
|    policy_gradient_loss  | 0.0121     |
|    std                   | 0.26       |
|    value_loss            | 0.887      |
-----------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.17397106 |
| rollout/                 |             |
|    ep_len_mean           | 46          |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 427         |
|    total_timesteps       | 2045952     |
| train/                   |             |
|    approx_kl             | 0.06357644  |
|    clip_fraction         | 0.29        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.483      |
|    entropy               | 0.873       |
|    entropy_loss          | 0.874       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.571       |
|    n_updates             | 9980        |
|    policy_gradient_loss  | 0.0142      |
|    std                   | 0.26        |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.44305667 |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 449         |
|    total_timesteps       | 2048000     |
| train/                   |             |
|    approx_kl             | 0.031542286 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.484      |
|    entropy               | 0.875       |
|    entropy_loss          | 0.873       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.497       |
|    n_updates             | 9990        |
|    policy_gradient_loss  | 0.00955     |
|    std                   | 0.26        |
|    value_loss            | 0.997       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.29572546 |
| rollout/                 |             |
|    ep_len_mean           | 49.1        |
|    ep_rew_mean           | -16.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 472         |
|    total_timesteps       | 2050048     |
| train/                   |             |
|    approx_kl             | 0.03954602  |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.483      |
|    entropy               | 0.871       |
|    entropy_loss          | 0.873       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.221       |
|    n_updates             | 10000       |
|    policy_gradient_loss  | 0.00866     |
|    std                   | 0.261       |
|    value_loss            | 0.468       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.2683972  |
| rollout/                 |             |
|    ep_len_mean           | 48.7        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 494         |
|    total_timesteps       | 2052096     |
| train/                   |             |
|    approx_kl             | 0.026728898 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.48       |
|    entropy               | 0.884       |
|    entropy_loss          | 0.876       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.312       |
|    n_updates             | 10010       |
|    policy_gradient_loss  | 0.00314     |
|    std                   | 0.26        |
|    value_loss            | 0.623       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.37690088 |
| rollout/                 |             |
|    ep_len_mean           | 48.8        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 517         |
|    total_timesteps       | 2054144     |
| train/                   |             |
|    approx_kl             | 0.03663306  |
|    clip_fraction         | 0.309       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.484      |
|    entropy               | 0.884       |
|    entropy_loss          | 0.885       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.349       |
|    n_updates             | 10020       |
|    policy_gradient_loss  | 0.0171      |
|    std                   | 0.261       |
|    value_loss            | 0.708       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.35        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.35        |
| reward                   | -0.2486316  |
| rollout/                 |             |
|    ep_len_mean           | 49.6        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 539         |
|    total_timesteps       | 2056192     |
| train/                   |             |
|    approx_kl             | 0.022659026 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.485      |
|    entropy               | 0.882       |
|    entropy_loss          | 0.883       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.266       |
|    n_updates             | 10030       |
|    policy_gradient_loss  | 0.00804     |
|    std                   | 0.261       |
|    value_loss            | 0.532       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.307492   |
| rollout/                 |             |
|    ep_len_mean           | 48.8        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 562         |
|    total_timesteps       | 2058240     |
| train/                   |             |
|    approx_kl             | 0.038063567 |
|    clip_fraction         | 0.268       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.487      |
|    entropy               | 0.873       |
|    entropy_loss          | 0.878       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.316       |
|    n_updates             | 10040       |
|    policy_gradient_loss  | 0.0155      |
|    std                   | 0.262       |
|    value_loss            | 0.574       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.15        |
| reward                   | -0.45111227 |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -17         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 584         |
|    total_timesteps       | 2060288     |
| train/                   |             |
|    approx_kl             | 0.04768195  |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.488      |
|    entropy               | 0.87        |
|    entropy_loss          | 0.871       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.54        |
|    n_updates             | 10050       |
|    policy_gradient_loss  | 0.00222     |
|    std                   | 0.263       |
|    value_loss            | 1.02        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5          |
| reward                   | -0.3598654 |
| rollout/                 |            |
|    ep_len_mean           | 50.5       |
|    ep_rew_mean           | -17.3      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 27         |
|    time_elapsed          | 607        |
|    total_timesteps       | 2062336    |
| train/                   |            |
|    approx_kl             | 0.02065653 |
|    clip_fraction         | 0.234      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.5       |
|    cost_value_loss       | 137        |
|    cost_values           | -0.493     |
|    entropy               | 0.883      |
|    entropy_loss          | 0.876      |
|    explained_variance    | 0.935      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.495      |
|    n_updates             | 10060      |
|    policy_gradient_loss  | 0.00306    |
|    std                   | 0.261      |
|    value_loss            | 0.995      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.14903677 |
| rollout/                 |             |
|    ep_len_mean           | 50.6        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 629         |
|    total_timesteps       | 2064384     |
| train/                   |             |
|    approx_kl             | 0.030799262 |
|    clip_fraction         | 0.253       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.485      |
|    entropy               | 0.886       |
|    entropy_loss          | 0.885       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.47        |
|    n_updates             | 10070       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.26        |
|    value_loss            | 0.914       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.58934015 |
| rollout/                 |             |
|    ep_len_mean           | 49.8        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 652         |
|    total_timesteps       | 2066432     |
| train/                   |             |
|    approx_kl             | 0.02617778  |
|    clip_fraction         | 0.266       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 141         |
|    cost_values           | -0.463      |
|    entropy               | 0.888       |
|    entropy_loss          | 0.887       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.528       |
|    n_updates             | 10080       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.259       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.29240572 |
| rollout/                 |             |
|    ep_len_mean           | 47.7        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 674         |
|    total_timesteps       | 2068480     |
| train/                   |             |
|    approx_kl             | 0.05473026  |
|    clip_fraction         | 0.276       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.485      |
|    entropy               | 0.889       |
|    entropy_loss          | 0.889       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.4         |
|    n_updates             | 10090       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.259       |
|    value_loss            | 0.692       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.30641386 |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 697         |
|    total_timesteps       | 2070528     |
| train/                   |             |
|    approx_kl             | 0.021358505 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.514      |
|    entropy               | 0.891       |
|    entropy_loss          | 0.89        |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.377       |
|    n_updates             | 10100       |
|    policy_gradient_loss  | 0.00878     |
|    std                   | 0.259       |
|    value_loss            | 0.766       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.26516452 |
| rollout/                 |             |
|    ep_len_mean           | 48.8        |
|    ep_rew_mean           | -16.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 719         |
|    total_timesteps       | 2072576     |
| train/                   |             |
|    approx_kl             | 0.013773482 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.496      |
|    entropy               | 0.891       |
|    entropy_loss          | 0.891       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.367       |
|    n_updates             | 10110       |
|    policy_gradient_loss  | 0.00599     |
|    std                   | 0.259       |
|    value_loss            | 0.887       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.23857027 |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 742         |
|    total_timesteps       | 2074624     |
| train/                   |             |
|    approx_kl             | 0.031349294 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.504      |
|    entropy               | 0.893       |
|    entropy_loss          | 0.892       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.421       |
|    n_updates             | 10120       |
|    policy_gradient_loss  | 0.00503     |
|    std                   | 0.259       |
|    value_loss            | 0.861       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.5727357  |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 764         |
|    total_timesteps       | 2076672     |
| train/                   |             |
|    approx_kl             | 0.027531538 |
|    clip_fraction         | 0.29        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.504      |
|    entropy               | 0.897       |
|    entropy_loss          | 0.895       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.627       |
|    n_updates             | 10130       |
|    policy_gradient_loss  | 0.00924     |
|    std                   | 0.258       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36868134 |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 787         |
|    total_timesteps       | 2078720     |
| train/                   |             |
|    approx_kl             | 0.031677257 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.497      |
|    entropy               | 0.899       |
|    entropy_loss          | 0.899       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.347       |
|    n_updates             | 10140       |
|    policy_gradient_loss  | 0.0123      |
|    std                   | 0.258       |
|    value_loss            | 0.726       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.25959143 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 809         |
|    total_timesteps       | 2080768     |
| train/                   |             |
|    approx_kl             | 0.017538467 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.51       |
|    entropy               | 0.902       |
|    entropy_loss          | 0.901       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.473       |
|    n_updates             | 10150       |
|    policy_gradient_loss  | 0.00333     |
|    std                   | 0.256       |
|    value_loss            | 0.958       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.77        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.77        |
| reward                   | -0.37605008 |
| rollout/                 |             |
|    ep_len_mean           | 48.5        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 832         |
|    total_timesteps       | 2082816     |
| train/                   |             |
|    approx_kl             | 0.051269427 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.501      |
|    entropy               | 0.917       |
|    entropy_loss          | 0.91        |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.325       |
|    n_updates             | 10160       |
|    policy_gradient_loss  | 0.0121      |
|    std                   | 0.254       |
|    value_loss            | 0.642       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.42885938 |
| rollout/                 |             |
|    ep_len_mean           | 49.3        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 855         |
|    total_timesteps       | 2084864     |
| train/                   |             |
|    approx_kl             | 0.027308159 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 144         |
|    cost_values           | -0.502      |
|    entropy               | 0.919       |
|    entropy_loss          | 0.919       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.55        |
|    n_updates             | 10170       |
|    policy_gradient_loss  | 0.00361     |
|    std                   | 0.253       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31303015 |
| rollout/                 |             |
|    ep_len_mean           | 48.2        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 39          |
|    time_elapsed          | 877         |
|    total_timesteps       | 2086912     |
| train/                   |             |
|    approx_kl             | 0.018807823 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.497      |
|    entropy               | 0.916       |
|    entropy_loss          | 0.917       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.465       |
|    n_updates             | 10180       |
|    policy_gradient_loss  | 0.00994     |
|    std                   | 0.254       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 5.6         |
| reward                   | -0.10984999 |
| rollout/                 |             |
|    ep_len_mean           | 50.1        |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 900         |
|    total_timesteps       | 2088960     |
| train/                   |             |
|    approx_kl             | 0.029274851 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.526      |
|    entropy               | 0.915       |
|    entropy_loss          | 0.915       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.508       |
|    n_updates             | 10190       |
|    policy_gradient_loss  | 0.00359     |
|    std                   | 0.254       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.5540732  |
| rollout/                 |             |
|    ep_len_mean           | 50.2        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 922         |
|    total_timesteps       | 2091008     |
| train/                   |             |
|    approx_kl             | 0.024577664 |
|    clip_fraction         | 0.282       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.485      |
|    entropy               | 0.914       |
|    entropy_loss          | 0.915       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.434       |
|    n_updates             | 10200       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.254       |
|    value_loss            | 0.963       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.2210359  |
| rollout/                 |             |
|    ep_len_mean           | 48.8        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 945         |
|    total_timesteps       | 2093056     |
| train/                   |             |
|    approx_kl             | 0.025954835 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 134         |
|    cost_values           | -0.487      |
|    entropy               | 0.914       |
|    entropy_loss          | 0.914       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.296       |
|    n_updates             | 10210       |
|    policy_gradient_loss  | 0.00567     |
|    std                   | 0.255       |
|    value_loss            | 0.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.18019548 |
| rollout/                 |             |
|    ep_len_mean           | 49.4        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 967         |
|    total_timesteps       | 2095104     |
| train/                   |             |
|    approx_kl             | 0.04136481  |
|    clip_fraction         | 0.261       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.486      |
|    entropy               | 0.911       |
|    entropy_loss          | 0.913       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.39        |
|    n_updates             | 10220       |
|    policy_gradient_loss  | 0.00987     |
|    std                   | 0.255       |
|    value_loss            | 0.828       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.42740265 |
| rollout/                 |             |
|    ep_len_mean           | 49.3        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 990         |
|    total_timesteps       | 2097152     |
| train/                   |             |
|    approx_kl             | 0.04208375  |
|    clip_fraction         | 0.328       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.495      |
|    entropy               | 0.908       |
|    entropy_loss          | 0.91        |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.51        |
|    n_updates             | 10230       |
|    policy_gradient_loss  | 0.0205      |
|    std                   | 0.255       |
|    value_loss            | 1           |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.4124128  |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 2099200     |
| train/                   |             |
|    approx_kl             | 0.034206927 |
|    clip_fraction         | 0.266       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 137         |
|    cost_values           | -0.514      |
|    entropy               | 0.907       |
|    entropy_loss          | 0.907       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.523       |
|    n_updates             | 10240       |
|    policy_gradient_loss  | 0.00634     |
|    std                   | 0.254       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.31548557 |
| rollout/                 |             |
|    ep_len_mean           | 50.6        |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1035        |
|    total_timesteps       | 2101248     |
| train/                   |             |
|    approx_kl             | 0.040961362 |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 142         |
|    cost_values           | -0.499      |
|    entropy               | 0.898       |
|    entropy_loss          | 0.903       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.767       |
|    n_updates             | 10250       |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.255       |
|    value_loss            | 1.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.5162983  |
| rollout/                 |             |
|    ep_len_mean           | 50.4        |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 2103296     |
| train/                   |             |
|    approx_kl             | 0.036190446 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.498      |
|    entropy               | 0.896       |
|    entropy_loss          | 0.897       |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.794       |
|    n_updates             | 10260       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.256       |
|    value_loss            | 1.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.33        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.33        |
| reward                   | -0.41370836 |
| rollout/                 |             |
|    ep_len_mean           | 50          |
|    ep_rew_mean           | -17.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1080        |
|    total_timesteps       | 2105344     |
| train/                   |             |
|    approx_kl             | 0.02888614  |
|    clip_fraction         | 0.251       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.498      |
|    entropy               | 0.899       |
|    entropy_loss          | 0.897       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.448       |
|    n_updates             | 10270       |
|    policy_gradient_loss  | 0.00633     |
|    std                   | 0.256       |
|    value_loss            | 0.963       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.41700056 |
| rollout/                 |             |
|    ep_len_mean           | 49          |
|    ep_rew_mean           | -17.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1102        |
|    total_timesteps       | 2107392     |
| train/                   |             |
|    approx_kl             | 0.029318735 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.517      |
|    entropy               | 0.899       |
|    entropy_loss          | 0.899       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.603       |
|    n_updates             | 10280       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.256       |
|    value_loss            | 1.14        |
------------------------------------------
Directory created: PPOL_New/models/seed-testing/an325vgg/model_epoch(20)
------------------------------------
| avg_speed          | 7.76        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 7.76        |
| reward             | -0.18419655 |
| rollout/           |             |
|    ep_len_mean     | 48.6        |
|    ep_rew_mean     | -16.8       |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2109440     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.11136258 |
| rollout/                 |             |
|    ep_len_mean           | 47.5        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2111488     |
| train/                   |             |
|    approx_kl             | 0.03980913  |
|    clip_fraction         | 0.319       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.496      |
|    entropy               | 0.896       |
|    entropy_loss          | 0.893       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.589       |
|    n_updates             | 10300       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.256       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.42368454 |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2113536     |
| train/                   |             |
|    approx_kl             | 0.026995547 |
|    clip_fraction         | 0.286       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.513      |
|    entropy               | 0.908       |
|    entropy_loss          | 0.902       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.657       |
|    n_updates             | 10310       |
|    policy_gradient_loss  | 0.019       |
|    std                   | 0.254       |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.4274508  |
| rollout/                 |             |
|    ep_len_mean           | 49.5        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2115584     |
| train/                   |             |
|    approx_kl             | 0.027613083 |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.512      |
|    entropy               | 0.914       |
|    entropy_loss          | 0.912       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.715       |
|    n_updates             | 10320       |
|    policy_gradient_loss  | 0.00615     |
|    std                   | 0.253       |
|    value_loss            | 1.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.32819396 |
| rollout/                 |             |
|    ep_len_mean           | 49.1        |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2117632     |
| train/                   |             |
|    approx_kl             | 0.030271074 |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.514      |
|    entropy               | 0.916       |
|    entropy_loss          | 0.915       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.57        |
|    n_updates             | 10330       |
|    policy_gradient_loss  | 0.0119      |
|    std                   | 0.253       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.48        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.48        |
| reward                   | -0.35227326 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2119680     |
| train/                   |             |
|    approx_kl             | 0.029253036 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.513      |
|    entropy               | 0.923       |
|    entropy_loss          | 0.919       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.577       |
|    n_updates             | 10340       |
|    policy_gradient_loss  | 0.00787     |
|    std                   | 0.252       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.33403513 |
| rollout/                 |             |
|    ep_len_mean           | 46.6        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2121728     |
| train/                   |             |
|    approx_kl             | 0.02603312  |
|    clip_fraction         | 0.247       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.96        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.507      |
|    entropy               | 0.929       |
|    entropy_loss          | 0.926       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.728       |
|    n_updates             | 10350       |
|    policy_gradient_loss  | 0.00619     |
|    std                   | 0.251       |
|    value_loss            | 1.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.32254022 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 179         |
|    total_timesteps       | 2123776     |
| train/                   |             |
|    approx_kl             | 0.047032103 |
|    clip_fraction         | 0.281       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.498      |
|    entropy               | 0.939       |
|    entropy_loss          | 0.934       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.603       |
|    n_updates             | 10360       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.249       |
|    value_loss            | 1.36        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.17       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.17       |
| reward                   | -0.1841766 |
| rollout/                 |            |
|    ep_len_mean           | 47.9       |
|    ep_rew_mean           | -16.6      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 9          |
|    time_elapsed          | 202        |
|    total_timesteps       | 2125824    |
| train/                   |            |
|    approx_kl             | 0.04780918 |
|    clip_fraction         | 0.232      |
|    clip_range            | 0.2        |
|    cost_returns          | 10         |
|    cost_value_loss       | 125        |
|    cost_values           | -0.503     |
|    entropy               | 0.939      |
|    entropy_loss          | 0.94       |
|    explained_variance    | 0.913      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.568      |
|    n_updates             | 10370      |
|    policy_gradient_loss  | 0.00524    |
|    std                   | 0.249      |
|    value_loss            | 1.21       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 8.04        |
| reward                   | -0.1108119  |
| rollout/                 |             |
|    ep_len_mean           | 50          |
|    ep_rew_mean           | -17.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 2127872     |
| train/                   |             |
|    approx_kl             | 0.019288799 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.497      |
|    entropy               | 0.943       |
|    entropy_loss          | 0.941       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.553       |
|    n_updates             | 10380       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.249       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.38814938 |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -16.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2129920     |
| train/                   |             |
|    approx_kl             | 0.0742292   |
|    clip_fraction         | 0.294       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 139         |
|    cost_values           | -0.477      |
|    entropy               | 0.952       |
|    entropy_loss          | 0.948       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.864       |
|    n_updates             | 10390       |
|    policy_gradient_loss  | 0.0135      |
|    std                   | 0.247       |
|    value_loss            | 1.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.18275632 |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 2131968     |
| train/                   |             |
|    approx_kl             | 0.030459937 |
|    clip_fraction         | 0.263       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.489      |
|    entropy               | 0.964       |
|    entropy_loss          | 0.957       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.817       |
|    n_updates             | 10400       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.246       |
|    value_loss            | 1.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.30156878 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 2134016     |
| train/                   |             |
|    approx_kl             | 0.01806772  |
|    clip_fraction         | 0.251       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.503      |
|    entropy               | 0.972       |
|    entropy_loss          | 0.968       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.895       |
|    n_updates             | 10410       |
|    policy_gradient_loss  | 0.00899     |
|    std                   | 0.245       |
|    value_loss            | 1.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.30571127 |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 314         |
|    total_timesteps       | 2136064     |
| train/                   |             |
|    approx_kl             | 0.059420034 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.491      |
|    entropy               | 0.984       |
|    entropy_loss          | 0.978       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.414       |
|    n_updates             | 10420       |
|    policy_gradient_loss  | 0.0081      |
|    std                   | 0.245       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.55368215 |
| rollout/                 |             |
|    ep_len_mean           | 47.6        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2138112     |
| train/                   |             |
|    approx_kl             | 0.025804264 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 138         |
|    cost_values           | -0.501      |
|    entropy               | 0.977       |
|    entropy_loss          | 0.981       |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.701       |
|    n_updates             | 10430       |
|    policy_gradient_loss  | 0.00532     |
|    std                   | 0.245       |
|    value_loss            | 1.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.30989707 |
| rollout/                 |             |
|    ep_len_mean           | 47.3        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 359         |
|    total_timesteps       | 2140160     |
| train/                   |             |
|    approx_kl             | 0.0370948   |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.502      |
|    entropy               | 0.982       |
|    entropy_loss          | 0.978       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.406       |
|    n_updates             | 10440       |
|    policy_gradient_loss  | 0.00325     |
|    std                   | 0.244       |
|    value_loss            | 0.905       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.5526418  |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 382         |
|    total_timesteps       | 2142208     |
| train/                   |             |
|    approx_kl             | 0.015352481 |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.505      |
|    entropy               | 0.983       |
|    entropy_loss          | 0.982       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.68        |
|    n_updates             | 10450       |
|    policy_gradient_loss  | 0.0144      |
|    std                   | 0.244       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.46893215 |
| rollout/                 |             |
|    ep_len_mean           | 47.1        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 404         |
|    total_timesteps       | 2144256     |
| train/                   |             |
|    approx_kl             | 0.0367195   |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.512      |
|    entropy               | 0.984       |
|    entropy_loss          | 0.984       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.47        |
|    n_updates             | 10460       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.245       |
|    value_loss            | 0.889       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.35222974 |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 427         |
|    total_timesteps       | 2146304     |
| train/                   |             |
|    approx_kl             | 0.042128246 |
|    clip_fraction         | 0.297       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.511      |
|    entropy               | 0.988       |
|    entropy_loss          | 0.987       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.718       |
|    n_updates             | 10470       |
|    policy_gradient_loss  | 0.00814     |
|    std                   | 0.245       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.50774586 |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 450         |
|    total_timesteps       | 2148352     |
| train/                   |             |
|    approx_kl             | 0.024899248 |
|    clip_fraction         | 0.278       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.511      |
|    entropy               | 0.986       |
|    entropy_loss          | 0.987       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.483       |
|    n_updates             | 10480       |
|    policy_gradient_loss  | 0.0116      |
|    std                   | 0.246       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.15        |
| reward                   | -0.2389174  |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 21          |
|    time_elapsed          | 472         |
|    total_timesteps       | 2150400     |
| train/                   |             |
|    approx_kl             | 0.021560797 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.73        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.516      |
|    entropy               | 0.987       |
|    entropy_loss          | 0.986       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.422       |
|    n_updates             | 10490       |
|    policy_gradient_loss  | 0.00663     |
|    std                   | 0.246       |
|    value_loss            | 0.913       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.21024752 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 495         |
|    total_timesteps       | 2152448     |
| train/                   |             |
|    approx_kl             | 0.06315158  |
|    clip_fraction         | 0.276       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.503      |
|    entropy               | 0.982       |
|    entropy_loss          | 0.984       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.444       |
|    n_updates             | 10500       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.247       |
|    value_loss            | 0.899       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.31599614 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 517         |
|    total_timesteps       | 2154496     |
| train/                   |             |
|    approx_kl             | 0.032507405 |
|    clip_fraction         | 0.245       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.503      |
|    entropy               | 0.98        |
|    entropy_loss          | 0.981       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.51        |
|    n_updates             | 10510       |
|    policy_gradient_loss  | 0.00422     |
|    std                   | 0.247       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.43546525 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 540         |
|    total_timesteps       | 2156544     |
| train/                   |             |
|    approx_kl             | 0.016521022 |
|    clip_fraction         | 0.29        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.501      |
|    entropy               | 0.978       |
|    entropy_loss          | 0.979       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.567       |
|    n_updates             | 10520       |
|    policy_gradient_loss  | 0.0176      |
|    std                   | 0.247       |
|    value_loss            | 1.15        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.18       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5.18       |
| reward                   | -0.2115711 |
| rollout/                 |            |
|    ep_len_mean           | 46.8       |
|    ep_rew_mean           | -16.1      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 25         |
|    time_elapsed          | 562        |
|    total_timesteps       | 2158592    |
| train/                   |            |
|    approx_kl             | 0.04992152 |
|    clip_fraction         | 0.242      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.2       |
|    cost_value_loss       | 130        |
|    cost_values           | -0.504     |
|    entropy               | 0.981      |
|    entropy_loss          | 0.979      |
|    explained_variance    | 0.891      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.674      |
|    n_updates             | 10530      |
|    policy_gradient_loss  | 0.0092     |
|    std                   | 0.246      |
|    value_loss            | 1.36       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.42653847 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 585         |
|    total_timesteps       | 2160640     |
| train/                   |             |
|    approx_kl             | 0.04654088  |
|    clip_fraction         | 0.282       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.51       |
|    entropy               | 0.981       |
|    entropy_loss          | 0.981       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.535       |
|    n_updates             | 10540       |
|    policy_gradient_loss  | 0.0164      |
|    std                   | 0.247       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.55551136 |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 27          |
|    time_elapsed          | 607         |
|    total_timesteps       | 2162688     |
| train/                   |             |
|    approx_kl             | 0.02463653  |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.502      |
|    entropy               | 0.985       |
|    entropy_loss          | 0.982       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.483       |
|    n_updates             | 10550       |
|    policy_gradient_loss  | 0.0166      |
|    std                   | 0.247       |
|    value_loss            | 0.968       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.12        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.12        |
| reward                   | -0.15311974 |
| rollout/                 |             |
|    ep_len_mean           | 46.9        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 630         |
|    total_timesteps       | 2164736     |
| train/                   |             |
|    approx_kl             | 0.028707195 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.503      |
|    entropy               | 0.983       |
|    entropy_loss          | 0.985       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.678       |
|    n_updates             | 10560       |
|    policy_gradient_loss  | 0.00589     |
|    std                   | 0.248       |
|    value_loss            | 1.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.72        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.72        |
| reward                   | -0.3308916  |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 653         |
|    total_timesteps       | 2166784     |
| train/                   |             |
|    approx_kl             | 0.030158216 |
|    clip_fraction         | 0.345       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.504      |
|    entropy               | 0.986       |
|    entropy_loss          | 0.984       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.645       |
|    n_updates             | 10570       |
|    policy_gradient_loss  | 0.0255      |
|    std                   | 0.247       |
|    value_loss            | 1.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3220256  |
| rollout/                 |             |
|    ep_len_mean           | 47.1        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 675         |
|    total_timesteps       | 2168832     |
| train/                   |             |
|    approx_kl             | 0.029480442 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.51       |
|    entropy               | 0.989       |
|    entropy_loss          | 0.988       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.722       |
|    n_updates             | 10580       |
|    policy_gradient_loss  | 0.00533     |
|    std                   | 0.246       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.16068108 |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 698         |
|    total_timesteps       | 2170880     |
| train/                   |             |
|    approx_kl             | 0.027188392 |
|    clip_fraction         | 0.272       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.511      |
|    entropy               | 0.992       |
|    entropy_loss          | 0.99        |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.589       |
|    n_updates             | 10590       |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.246       |
|    value_loss            | 1.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.37        |
| reward                   | -0.44699734 |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 720         |
|    total_timesteps       | 2172928     |
| train/                   |             |
|    approx_kl             | 0.03436458  |
|    clip_fraction         | 0.262       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.508      |
|    entropy               | 0.997       |
|    entropy_loss          | 0.994       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.602       |
|    n_updates             | 10600       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.245       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.3570229  |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 743         |
|    total_timesteps       | 2174976     |
| train/                   |             |
|    approx_kl             | 0.022438047 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.522      |
|    entropy               | 0.997       |
|    entropy_loss          | 0.997       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.544       |
|    n_updates             | 10610       |
|    policy_gradient_loss  | 0.00247     |
|    std                   | 0.244       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.31891766 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 765         |
|    total_timesteps       | 2177024     |
| train/                   |             |
|    approx_kl             | 0.055504274 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.499      |
|    entropy               | 0.996       |
|    entropy_loss          | 0.997       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.549       |
|    n_updates             | 10620       |
|    policy_gradient_loss  | 0.00692     |
|    std                   | 0.244       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.55        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.55        |
| reward                   | -0.40504014 |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 35          |
|    time_elapsed          | 788         |
|    total_timesteps       | 2179072     |
| train/                   |             |
|    approx_kl             | 0.02455863  |
|    clip_fraction         | 0.288       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.506      |
|    entropy               | 1           |
|    entropy_loss          | 0.998       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.581       |
|    n_updates             | 10630       |
|    policy_gradient_loss  | 0.00639     |
|    std                   | 0.243       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 8.06        |
| reward                   | -0.11620549 |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 36          |
|    time_elapsed          | 810         |
|    total_timesteps       | 2181120     |
| train/                   |             |
|    approx_kl             | 0.039690856 |
|    clip_fraction         | 0.256       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.509      |
|    entropy               | 1.01        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.619       |
|    n_updates             | 10640       |
|    policy_gradient_loss  | 0.00845     |
|    std                   | 0.242       |
|    value_loss            | 1.22        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.08       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.08       |
| reward                   | -0.2835025 |
| rollout/                 |            |
|    ep_len_mean           | 46         |
|    ep_rew_mean           | -15.8      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 37         |
|    time_elapsed          | 833        |
|    total_timesteps       | 2183168    |
| train/                   |            |
|    approx_kl             | 0.01982696 |
|    clip_fraction         | 0.285      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.1       |
|    cost_value_loss       | 126        |
|    cost_values           | -0.509     |
|    entropy               | 1.01       |
|    entropy_loss          | 1.01       |
|    explained_variance    | 0.935      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.494      |
|    n_updates             | 10650      |
|    policy_gradient_loss  | 0.0175     |
|    std                   | 0.243      |
|    value_loss            | 0.961      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.28029254 |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 856         |
|    total_timesteps       | 2185216     |
| train/                   |             |
|    approx_kl             | 0.027661515 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.513      |
|    entropy               | 0.992       |
|    entropy_loss          | 0.999       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.512       |
|    n_updates             | 10660       |
|    policy_gradient_loss  | 0.00191     |
|    std                   | 0.245       |
|    value_loss            | 1.12        |
------------------------------------------
----------------------------------------
| avg_speed                | 1.6       |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 1.6       |
| reward                   | -0.509045 |
| rollout/                 |           |
|    ep_len_mean           | 45        |
|    ep_rew_mean           | -15.7     |
| time/                    |           |
|    fps                   | 90        |
|    iterations            | 39        |
|    time_elapsed          | 878       |
|    total_timesteps       | 2187264   |
| train/                   |           |
|    approx_kl             | 0.0453103 |
|    clip_fraction         | 0.333     |
|    clip_range            | 0.2       |
|    cost_returns          | 10.1      |
|    cost_value_loss       | 126       |
|    cost_values           | -0.509    |
|    entropy               | 0.976     |
|    entropy_loss          | 0.983     |
|    explained_variance    | 0.899     |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 0.691     |
|    n_updates             | 10670     |
|    policy_gradient_loss  | 0.0202    |
|    std                   | 0.246     |
|    value_loss            | 1.33      |
----------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 7.64        |
| reward                   | -0.11546475 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -16.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 40          |
|    time_elapsed          | 901         |
|    total_timesteps       | 2189312     |
| train/                   |             |
|    approx_kl             | 0.028921764 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.501      |
|    entropy               | 0.98        |
|    entropy_loss          | 0.977       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.679       |
|    n_updates             | 10680       |
|    policy_gradient_loss  | 0.012       |
|    std                   | 0.245       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.3380295  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 923         |
|    total_timesteps       | 2191360     |
| train/                   |             |
|    approx_kl             | 0.024858538 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.486      |
|    entropy               | 0.979       |
|    entropy_loss          | 0.98        |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.661       |
|    n_updates             | 10690       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.245       |
|    value_loss            | 1.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.467321   |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 946         |
|    total_timesteps       | 2193408     |
| train/                   |             |
|    approx_kl             | 0.016899042 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.495      |
|    entropy               | 0.986       |
|    entropy_loss          | 0.981       |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.406       |
|    n_updates             | 10700       |
|    policy_gradient_loss  | 0.00565     |
|    std                   | 0.245       |
|    value_loss            | 0.878       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.31706044 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 43          |
|    time_elapsed          | 968         |
|    total_timesteps       | 2195456     |
| train/                   |             |
|    approx_kl             | 0.026345637 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 9.85        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.49       |
|    entropy               | 0.991       |
|    entropy_loss          | 0.989       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.645       |
|    n_updates             | 10710       |
|    policy_gradient_loss  | 0.000623    |
|    std                   | 0.245       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.33        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.33        |
| reward                   | -0.23277989 |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 991         |
|    total_timesteps       | 2197504     |
| train/                   |             |
|    approx_kl             | 0.04068543  |
|    clip_fraction         | 0.261       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.496      |
|    entropy               | 1.01        |
|    entropy_loss          | 0.997       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.6         |
|    n_updates             | 10720       |
|    policy_gradient_loss  | 0.0196      |
|    std                   | 0.243       |
|    value_loss            | 1.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.19        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.19        |
| reward                   | -0.3958653  |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 2199552     |
| train/                   |             |
|    approx_kl             | 0.028744547 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.495      |
|    entropy               | 1.01        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.77        |
|    n_updates             | 10730       |
|    policy_gradient_loss  | 0.00277     |
|    std                   | 0.242       |
|    value_loss            | 1.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.9         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.9         |
| reward                   | -0.35877994 |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1036        |
|    total_timesteps       | 2201600     |
| train/                   |             |
|    approx_kl             | 0.03955079  |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.492      |
|    entropy               | 1.02        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.567       |
|    n_updates             | 10740       |
|    policy_gradient_loss  | 0.0046      |
|    std                   | 0.241       |
|    value_loss            | 1.26        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.3199683 |
| rollout/                 |            |
|    ep_len_mean           | 45.9       |
|    ep_rew_mean           | -15.8      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 47         |
|    time_elapsed          | 1059       |
|    total_timesteps       | 2203648    |
| train/                   |            |
|    approx_kl             | 0.01627145 |
|    clip_fraction         | 0.2        |
|    clip_range            | 0.2        |
|    cost_returns          | 10.2       |
|    cost_value_loss       | 128        |
|    cost_values           | -0.504     |
|    entropy               | 1.02       |
|    entropy_loss          | 1.02       |
|    explained_variance    | 0.912      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.579      |
|    n_updates             | 10750      |
|    policy_gradient_loss  | 0.00582    |
|    std                   | 0.242      |
|    value_loss            | 1.1        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28780213 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1081        |
|    total_timesteps       | 2205696     |
| train/                   |             |
|    approx_kl             | 0.021118974 |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.497      |
|    entropy               | 1.01        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.513       |
|    n_updates             | 10760       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.242       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 4           |
| reward                   | -0.09253992 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1104        |
|    total_timesteps       | 2207744     |
| train/                   |             |
|    approx_kl             | 0.033527184 |
|    clip_fraction         | 0.304       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.504      |
|    entropy               | 1.01        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.634       |
|    n_updates             | 10770       |
|    policy_gradient_loss  | 0.0145      |
|    std                   | 0.243       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------
| avg_speed          | 7.58        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 7.58        |
| reward             | -0.31416747 |
| rollout/           |             |
|    ep_len_mean     | 43.7        |
|    ep_rew_mean     | -15.1       |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2209792     |
------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.44750053 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2211840     |
| train/                   |             |
|    approx_kl             | 0.030589413 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 126         |
|    cost_values           | -0.508      |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.527       |
|    n_updates             | 10790       |
|    policy_gradient_loss  | 0.00539     |
|    std                   | 0.241       |
|    value_loss            | 0.994       |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.25638556 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2213888     |
| train/                   |             |
|    approx_kl             | 0.043853424 |
|    clip_fraction         | 0.316       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.58        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.493      |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.692       |
|    n_updates             | 10800       |
|    policy_gradient_loss  | 0.0183      |
|    std                   | 0.242       |
|    value_loss            | 1.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.37698948 |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2215936     |
| train/                   |             |
|    approx_kl             | 0.029978227 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.492      |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.737       |
|    n_updates             | 10810       |
|    policy_gradient_loss  | 0.00892     |
|    std                   | 0.242       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.15        |
| reward                   | -0.3509145  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2217984     |
| train/                   |             |
|    approx_kl             | 0.020124188 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.479      |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.607       |
|    n_updates             | 10820       |
|    policy_gradient_loss  | 0.0022      |
|    std                   | 0.243       |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22949553 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2220032     |
| train/                   |             |
|    approx_kl             | 0.050456554 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.475      |
|    entropy               | 1.04        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.611       |
|    n_updates             | 10830       |
|    policy_gradient_loss  | 0.0146      |
|    std                   | 0.242       |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.23197475 |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2222080     |
| train/                   |             |
|    approx_kl             | 0.04715657  |
|    clip_fraction         | 0.286       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.49       |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.818       |
|    n_updates             | 10840       |
|    policy_gradient_loss  | 0.0173      |
|    std                   | 0.241       |
|    value_loss            | 1.43        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.6        |
| reward                   | -0.3352005 |
| rollout/                 |            |
|    ep_len_mean           | 43.7       |
|    ep_rew_mean           | -14.9      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 8          |
|    time_elapsed          | 179        |
|    total_timesteps       | 2224128    |
| train/                   |            |
|    approx_kl             | 0.02229698 |
|    clip_fraction         | 0.22       |
|    clip_range            | 0.2        |
|    cost_returns          | 9.94       |
|    cost_value_loss       | 124        |
|    cost_values           | -0.485     |
|    entropy               | 1.04       |
|    entropy_loss          | 1.04       |
|    explained_variance    | 0.9        |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.478      |
|    n_updates             | 10850      |
|    policy_gradient_loss  | 0.00362    |
|    std                   | 0.241      |
|    value_loss            | 1.21       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3848007  |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2226176     |
| train/                   |             |
|    approx_kl             | 0.028150111 |
|    clip_fraction         | 0.271       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.94        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.49       |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.614       |
|    n_updates             | 10860       |
|    policy_gradient_loss  | 0.00774     |
|    std                   | 0.241       |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.2431601  |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 2228224     |
| train/                   |             |
|    approx_kl             | 0.011786362 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.71        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.481      |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.382       |
|    n_updates             | 10870       |
|    policy_gradient_loss  | 0.0133      |
|    std                   | 0.24        |
|    value_loss            | 0.818       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.40337372 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2230272     |
| train/                   |             |
|    approx_kl             | 0.03198799  |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.486      |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.485       |
|    n_updates             | 10880       |
|    policy_gradient_loss  | 0.00755     |
|    std                   | 0.24        |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.33403483 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 2232320     |
| train/                   |             |
|    approx_kl             | 0.023448486 |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.487      |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.844       |
|    n_updates             | 10890       |
|    policy_gradient_loss  | 0.00792     |
|    std                   | 0.24        |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38649172 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -16.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 2234368     |
| train/                   |             |
|    approx_kl             | 0.038956355 |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.496      |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.671       |
|    n_updates             | 10900       |
|    policy_gradient_loss  | 0.00929     |
|    std                   | 0.24        |
|    value_loss            | 1.28        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.15       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.15       |
| reward                   | -0.2337832 |
| rollout/                 |            |
|    ep_len_mean           | 45.3       |
|    ep_rew_mean           | -16        |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 14         |
|    time_elapsed          | 314        |
|    total_timesteps       | 2236416    |
| train/                   |            |
|    approx_kl             | 0.03919863 |
|    clip_fraction         | 0.317      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.4       |
|    cost_value_loss       | 132        |
|    cost_values           | -0.479     |
|    entropy               | 1.05       |
|    entropy_loss          | 1.05       |
|    explained_variance    | 0.927      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.487      |
|    n_updates             | 10910      |
|    policy_gradient_loss  | 0.0196     |
|    std                   | 0.24       |
|    value_loss            | 0.975      |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.54        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.54        |
| reward                   | -0.25311714 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2238464     |
| train/                   |             |
|    approx_kl             | 0.025461745 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.496      |
|    entropy               | 1.06        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.529       |
|    n_updates             | 10920       |
|    policy_gradient_loss  | 0.00955     |
|    std                   | 0.24        |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.20744282 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 359         |
|    total_timesteps       | 2240512     |
| train/                   |             |
|    approx_kl             | 0.03647148  |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 126         |
|    cost_values           | -0.497      |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.848       |
|    n_updates             | 10930       |
|    policy_gradient_loss  | 0.0228      |
|    std                   | 0.24        |
|    value_loss            | 1.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3299155  |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 382         |
|    total_timesteps       | 2242560     |
| train/                   |             |
|    approx_kl             | 0.025883138 |
|    clip_fraction         | 0.255       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 126         |
|    cost_values           | -0.488      |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.579       |
|    n_updates             | 10940       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.24        |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.47129723 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 404         |
|    total_timesteps       | 2244608     |
| train/                   |             |
|    approx_kl             | 0.028775975 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.9         |
|    cost_value_loss       | 122         |
|    cost_values           | -0.488      |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.557       |
|    n_updates             | 10950       |
|    policy_gradient_loss  | 0.00342     |
|    std                   | 0.24        |
|    value_loss            | 1.19        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3703516 |
| rollout/                 |            |
|    ep_len_mean           | 45.1       |
|    ep_rew_mean           | -15.7      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 19         |
|    time_elapsed          | 427        |
|    total_timesteps       | 2246656    |
| train/                   |            |
|    approx_kl             | 0.0614872  |
|    clip_fraction         | 0.249      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.93       |
|    cost_value_loss       | 124        |
|    cost_values           | -0.496     |
|    entropy               | 1.06       |
|    entropy_loss          | 1.06       |
|    explained_variance    | 0.884      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.678      |
|    n_updates             | 10960      |
|    policy_gradient_loss  | 0.0176     |
|    std                   | 0.239      |
|    value_loss            | 1.54       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21349066 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 20          |
|    time_elapsed          | 450         |
|    total_timesteps       | 2248704     |
| train/                   |             |
|    approx_kl             | 0.0853734   |
|    clip_fraction         | 0.316       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.478      |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.536       |
|    n_updates             | 10970       |
|    policy_gradient_loss  | 0.0197      |
|    std                   | 0.24        |
|    value_loss            | 1.16        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5.6        |
| reward                   | -0.3085493 |
| rollout/                 |            |
|    ep_len_mean           | 43.9       |
|    ep_rew_mean           | -15.4      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 21         |
|    time_elapsed          | 472        |
|    total_timesteps       | 2250752    |
| train/                   |            |
|    approx_kl             | 0.03440199 |
|    clip_fraction         | 0.247      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.84       |
|    cost_value_loss       | 122        |
|    cost_values           | -0.493     |
|    entropy               | 1.06       |
|    entropy_loss          | 1.06       |
|    explained_variance    | 0.941      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.385      |
|    n_updates             | 10980      |
|    policy_gradient_loss  | 0.00665    |
|    std                   | 0.239      |
|    value_loss            | 0.855      |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.25076675 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 495         |
|    total_timesteps       | 2252800     |
| train/                   |             |
|    approx_kl             | 0.026891783 |
|    clip_fraction         | 0.281       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.91        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.495      |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.616       |
|    n_updates             | 10990       |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.24        |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.38689682 |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 518         |
|    total_timesteps       | 2254848     |
| train/                   |             |
|    approx_kl             | 0.024471601 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.484      |
|    entropy               | 1.04        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.373       |
|    n_updates             | 11000       |
|    policy_gradient_loss  | 0.00208     |
|    std                   | 0.242       |
|    value_loss            | 0.932       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.5122069  |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 540         |
|    total_timesteps       | 2256896     |
| train/                   |             |
|    approx_kl             | 0.058302056 |
|    clip_fraction         | 0.269       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.88        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.485      |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.71        |
|    n_updates             | 11010       |
|    policy_gradient_loss  | 0.0066      |
|    std                   | 0.244       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.3615317  |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 563         |
|    total_timesteps       | 2258944     |
| train/                   |             |
|    approx_kl             | 0.025424916 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.494      |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.717       |
|    n_updates             | 11020       |
|    policy_gradient_loss  | 0.00924     |
|    std                   | 0.243       |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.27869162 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 585         |
|    total_timesteps       | 2260992     |
| train/                   |             |
|    approx_kl             | 0.031743884 |
|    clip_fraction         | 0.257       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.82        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.489      |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.668       |
|    n_updates             | 11030       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.244       |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 8.01        |
| reward                   | -0.07966564 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 27          |
|    time_elapsed          | 608         |
|    total_timesteps       | 2263040     |
| train/                   |             |
|    approx_kl             | 0.039602354 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.492      |
|    entropy               | 1.01        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.918       |
|    n_updates             | 11040       |
|    policy_gradient_loss  | 0.00549     |
|    std                   | 0.246       |
|    value_loss            | 1.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.4087573  |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 630         |
|    total_timesteps       | 2265088     |
| train/                   |             |
|    approx_kl             | 0.026882239 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.7         |
|    cost_value_loss       | 118         |
|    cost_values           | -0.484      |
|    entropy               | 1.02        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.408       |
|    n_updates             | 11050       |
|    policy_gradient_loss  | 0.0146      |
|    std                   | 0.246       |
|    value_loss            | 0.976       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.568076   |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 653         |
|    total_timesteps       | 2267136     |
| train/                   |             |
|    approx_kl             | 0.032390602 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.484      |
|    entropy               | 1.03        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.417       |
|    n_updates             | 11060       |
|    policy_gradient_loss  | 0.00258     |
|    std                   | 0.245       |
|    value_loss            | 0.738       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.51528543 |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 675         |
|    total_timesteps       | 2269184     |
| train/                   |             |
|    approx_kl             | 0.016898073 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.493      |
|    entropy               | 1.04        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.542       |
|    n_updates             | 11070       |
|    policy_gradient_loss  | 0.00634     |
|    std                   | 0.243       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.4322206  |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 698         |
|    total_timesteps       | 2271232     |
| train/                   |             |
|    approx_kl             | 0.072474435 |
|    clip_fraction         | 0.307       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.495      |
|    entropy               | 1.05        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.362       |
|    n_updates             | 11080       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.242       |
|    value_loss            | 0.729       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.27105635 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 720         |
|    total_timesteps       | 2273280     |
| train/                   |             |
|    approx_kl             | 0.043935817 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.86        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.497      |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.51        |
|    n_updates             | 11090       |
|    policy_gradient_loss  | 0.00254     |
|    std                   | 0.24        |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31929308 |
| rollout/                 |             |
|    ep_len_mean           | 46          |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 743         |
|    total_timesteps       | 2275328     |
| train/                   |             |
|    approx_kl             | 0.030205023 |
|    clip_fraction         | 0.299       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.96        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.494      |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.394       |
|    n_updates             | 11100       |
|    policy_gradient_loss  | 0.0176      |
|    std                   | 0.239       |
|    value_loss            | 0.945       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.40990996 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 765         |
|    total_timesteps       | 2277376     |
| train/                   |             |
|    approx_kl             | 0.03863724  |
|    clip_fraction         | 0.264       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.49       |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.463       |
|    n_updates             | 11110       |
|    policy_gradient_loss  | 0.0073      |
|    std                   | 0.237       |
|    value_loss            | 1           |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.49479958 |
| rollout/                 |             |
|    ep_len_mean           | 46          |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 35          |
|    time_elapsed          | 788         |
|    total_timesteps       | 2279424     |
| train/                   |             |
|    approx_kl             | 0.035270244 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.475      |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.397       |
|    n_updates             | 11120       |
|    policy_gradient_loss  | 0.00316     |
|    std                   | 0.236       |
|    value_loss            | 0.913       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.22814226 |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 36          |
|    time_elapsed          | 810         |
|    total_timesteps       | 2281472     |
| train/                   |             |
|    approx_kl             | 0.020080296 |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.491      |
|    entropy               | 1.08        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.573       |
|    n_updates             | 11130       |
|    policy_gradient_loss  | 0.00625     |
|    std                   | 0.236       |
|    value_loss            | 1.36        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.5366807 |
| rollout/                 |            |
|    ep_len_mean           | 44.3       |
|    ep_rew_mean           | -15.4      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 37         |
|    time_elapsed          | 833        |
|    total_timesteps       | 2283520    |
| train/                   |            |
|    approx_kl             | 0.03951651 |
|    clip_fraction         | 0.237      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.68       |
|    cost_value_loss       | 118        |
|    cost_values           | -0.495     |
|    entropy               | 1.08       |
|    entropy_loss          | 1.08       |
|    explained_variance    | 0.912      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.68       |
|    n_updates             | 11140      |
|    policy_gradient_loss  | 0.00859    |
|    std                   | 0.236      |
|    value_loss            | 1.31       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.21914877 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 855         |
|    total_timesteps       | 2285568     |
| train/                   |             |
|    approx_kl             | 0.02427979  |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.484      |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.615       |
|    n_updates             | 11150       |
|    policy_gradient_loss  | 0.00756     |
|    std                   | 0.236       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.29417622 |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 878         |
|    total_timesteps       | 2287616     |
| train/                   |             |
|    approx_kl             | 0.030175969 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.484      |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.596       |
|    n_updates             | 11160       |
|    policy_gradient_loss  | 0.00603     |
|    std                   | 0.237       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.3781023  |
| rollout/                 |             |
|    ep_len_mean           | 47.1        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 40          |
|    time_elapsed          | 901         |
|    total_timesteps       | 2289664     |
| train/                   |             |
|    approx_kl             | 0.034412194 |
|    clip_fraction         | 0.293       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.478      |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.574       |
|    n_updates             | 11170       |
|    policy_gradient_loss  | 0.012       |
|    std                   | 0.237       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.77        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.77        |
| reward                   | -0.32069805 |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 923         |
|    total_timesteps       | 2291712     |
| train/                   |             |
|    approx_kl             | 0.03612981  |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.475      |
|    entropy               | 1.09        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.824       |
|    n_updates             | 11180       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.235       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.61449313 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 946         |
|    total_timesteps       | 2293760     |
| train/                   |             |
|    approx_kl             | 0.014324611 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | -0.465      |
|    entropy               | 1.09        |
|    entropy_loss          | 1.09        |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.635       |
|    n_updates             | 11190       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.235       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33239198 |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 43          |
|    time_elapsed          | 968         |
|    total_timesteps       | 2295808     |
| train/                   |             |
|    approx_kl             | 0.055347547 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.67        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.473      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.692       |
|    n_updates             | 11200       |
|    policy_gradient_loss  | 0.0059      |
|    std                   | 0.235       |
|    value_loss            | 1.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.21838993 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 991         |
|    total_timesteps       | 2297856     |
| train/                   |             |
|    approx_kl             | 0.047805484 |
|    clip_fraction         | 0.313       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.85        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.477      |
|    entropy               | 1.11        |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.59        |
|    n_updates             | 11210       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.233       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.3499949  |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1013        |
|    total_timesteps       | 2299904     |
| train/                   |             |
|    approx_kl             | 0.034345567 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.467      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.544       |
|    n_updates             | 11220       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.233       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.31        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.31        |
| reward                   | -0.35681236 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1036        |
|    total_timesteps       | 2301952     |
| train/                   |             |
|    approx_kl             | 0.039994214 |
|    clip_fraction         | 0.263       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.471      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.856       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.799       |
|    n_updates             | 11230       |
|    policy_gradient_loss  | 0.00957     |
|    std                   | 0.233       |
|    value_loss            | 1.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.3171074  |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1058        |
|    total_timesteps       | 2304000     |
| train/                   |             |
|    approx_kl             | 0.054306902 |
|    clip_fraction         | 0.296       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.474      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.813       |
|    n_updates             | 11240       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.233       |
|    value_loss            | 1.73        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.4        |
| reward                   | -0.229863  |
| rollout/                 |            |
|    ep_len_mean           | 44.3       |
|    ep_rew_mean           | -15.7      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 48         |
|    time_elapsed          | 1081       |
|    total_timesteps       | 2306048    |
| train/                   |            |
|    approx_kl             | 0.06592801 |
|    clip_fraction         | 0.268      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.99       |
|    cost_value_loss       | 127        |
|    cost_values           | -0.484     |
|    entropy               | 1.11       |
|    entropy_loss          | 1.11       |
|    explained_variance    | 0.814      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.944      |
|    n_updates             | 11250      |
|    policy_gradient_loss  | 0.0109     |
|    std                   | 0.232      |
|    value_loss            | 2.18       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.62224257 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1103        |
|    total_timesteps       | 2308096     |
| train/                   |             |
|    approx_kl             | 0.030056776 |
|    clip_fraction         | 0.336       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.479      |
|    entropy               | 1.11        |
|    entropy_loss          | 1.11        |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.783       |
|    n_updates             | 11260       |
|    policy_gradient_loss  | 0.0235      |
|    std                   | 0.232       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------
| avg_speed          | 6.19        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 6.19        |
| reward             | -0.20728965 |
| rollout/           |             |
|    ep_len_mean     | 43.1        |
|    ep_rew_mean     | -15         |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2310144     |
------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.31651214 |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2312192     |
| train/                   |             |
|    approx_kl             | 0.0218116   |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.98        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.472      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.544       |
|    n_updates             | 11280       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.233       |
|    value_loss            | 1.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.42300656 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2314240     |
| train/                   |             |
|    approx_kl             | 0.02230936  |
|    clip_fraction         | 0.269       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.96        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.477      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.534       |
|    n_updates             | 11290       |
|    policy_gradient_loss  | 0.0122      |
|    std                   | 0.234       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.55273783 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2316288     |
| train/                   |             |
|    approx_kl             | 0.02758627  |
|    clip_fraction         | 0.239       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.82        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.479      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.717       |
|    n_updates             | 11300       |
|    policy_gradient_loss  | 0.00782     |
|    std                   | 0.234       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24273087 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2318336     |
| train/                   |             |
|    approx_kl             | 0.039862774 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.485      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.624       |
|    n_updates             | 11310       |
|    policy_gradient_loss  | 0.0094      |
|    std                   | 0.234       |
|    value_loss            | 1.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.40106595 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 6           |
|    time_elapsed          | 135         |
|    total_timesteps       | 2320384     |
| train/                   |             |
|    approx_kl             | 0.038385767 |
|    clip_fraction         | 0.284       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.487      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.719       |
|    n_updates             | 11320       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.234       |
|    value_loss            | 1.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.216431   |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2322432     |
| train/                   |             |
|    approx_kl             | 0.027307857 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.468      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.473       |
|    n_updates             | 11330       |
|    policy_gradient_loss  | 0.000731    |
|    std                   | 0.233       |
|    value_loss            | 0.962       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.44305667 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 8           |
|    time_elapsed          | 180         |
|    total_timesteps       | 2324480     |
| train/                   |             |
|    approx_kl             | 0.035745353 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.489      |
|    entropy               | 1.11        |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.638       |
|    n_updates             | 11340       |
|    policy_gradient_loss  | 0.00612     |
|    std                   | 0.233       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.62847394 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2326528     |
| train/                   |             |
|    approx_kl             | 0.059838623 |
|    clip_fraction         | 0.324       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.468      |
|    entropy               | 1.11        |
|    entropy_loss          | 1.11        |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.546       |
|    n_updates             | 11350       |
|    policy_gradient_loss  | 0.0166      |
|    std                   | 0.232       |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34400004 |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 10          |
|    time_elapsed          | 225         |
|    total_timesteps       | 2328576     |
| train/                   |             |
|    approx_kl             | 0.030979905 |
|    clip_fraction         | 0.284       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.9         |
|    cost_value_loss       | 123         |
|    cost_values           | -0.495      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.11        |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.64        |
|    n_updates             | 11360       |
|    policy_gradient_loss  | 0.0156      |
|    std                   | 0.233       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35844946 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2330624     |
| train/                   |             |
|    approx_kl             | 0.015653025 |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.87        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.477      |
|    entropy               | 1.11        |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.736       |
|    n_updates             | 11370       |
|    policy_gradient_loss  | 0.0144      |
|    std                   | 0.233       |
|    value_loss            | 1.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36982945 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 12          |
|    time_elapsed          | 270         |
|    total_timesteps       | 2332672     |
| train/                   |             |
|    approx_kl             | 0.023784904 |
|    clip_fraction         | 0.263       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.464      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.11        |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.73        |
|    n_updates             | 11380       |
|    policy_gradient_loss  | 0.00638     |
|    std                   | 0.234       |
|    value_loss            | 1.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.14604193 |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 2334720     |
| train/                   |             |
|    approx_kl             | 0.021282244 |
|    clip_fraction         | 0.269       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.78        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.463      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.491       |
|    n_updates             | 11390       |
|    policy_gradient_loss  | 0.00674     |
|    std                   | 0.235       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.50416636 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 14          |
|    time_elapsed          | 315         |
|    total_timesteps       | 2336768     |
| train/                   |             |
|    approx_kl             | 0.06294726  |
|    clip_fraction         | 0.284       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.471      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.469       |
|    n_updates             | 11400       |
|    policy_gradient_loss  | 0.00867     |
|    std                   | 0.233       |
|    value_loss            | 0.968       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.2301015  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 15          |
|    time_elapsed          | 338         |
|    total_timesteps       | 2338816     |
| train/                   |             |
|    approx_kl             | 0.046489492 |
|    clip_fraction         | 0.298       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.476      |
|    entropy               | 1.1         |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.677       |
|    n_updates             | 11410       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.233       |
|    value_loss            | 1.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.2911254  |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 16          |
|    time_elapsed          | 360         |
|    total_timesteps       | 2340864     |
| train/                   |             |
|    approx_kl             | 0.061823703 |
|    clip_fraction         | 0.321       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.47       |
|    entropy               | 1.11        |
|    entropy_loss          | 1.1         |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.581       |
|    n_updates             | 11420       |
|    policy_gradient_loss  | 0.012       |
|    std                   | 0.233       |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13594818 |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 17          |
|    time_elapsed          | 383         |
|    total_timesteps       | 2342912     |
| train/                   |             |
|    approx_kl             | 0.023058861 |
|    clip_fraction         | 0.254       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.73        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.467      |
|    entropy               | 1.12        |
|    entropy_loss          | 1.11        |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.649       |
|    n_updates             | 11430       |
|    policy_gradient_loss  | 0.00805     |
|    std                   | 0.233       |
|    value_loss            | 1.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.56953245 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 18          |
|    time_elapsed          | 406         |
|    total_timesteps       | 2344960     |
| train/                   |             |
|    approx_kl             | 0.01857783  |
|    clip_fraction         | 0.247       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.474      |
|    entropy               | 1.12        |
|    entropy_loss          | 1.12        |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.586       |
|    n_updates             | 11440       |
|    policy_gradient_loss  | 0.0087      |
|    std                   | 0.232       |
|    value_loss            | 1.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.4980223  |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 19          |
|    time_elapsed          | 428         |
|    total_timesteps       | 2347008     |
| train/                   |             |
|    approx_kl             | 0.044678107 |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.73        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.49       |
|    entropy               | 1.13        |
|    entropy_loss          | 1.13        |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.802       |
|    n_updates             | 11450       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.231       |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.21020903 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 20          |
|    time_elapsed          | 451         |
|    total_timesteps       | 2349056     |
| train/                   |             |
|    approx_kl             | 0.033070907 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.79        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.481      |
|    entropy               | 1.14        |
|    entropy_loss          | 1.14        |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.611       |
|    n_updates             | 11460       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.23        |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.87        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.87        |
| reward                   | -0.26370174 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 21          |
|    time_elapsed          | 474         |
|    total_timesteps       | 2351104     |
| train/                   |             |
|    approx_kl             | 0.02624432  |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.94        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.49       |
|    entropy               | 1.16        |
|    entropy_loss          | 1.15        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.525       |
|    n_updates             | 11470       |
|    policy_gradient_loss  | 0.00502     |
|    std                   | 0.229       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.36596602 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 496         |
|    total_timesteps       | 2353152     |
| train/                   |             |
|    approx_kl             | 0.035173576 |
|    clip_fraction         | 0.263       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.481      |
|    entropy               | 1.17        |
|    entropy_loss          | 1.16        |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.582       |
|    n_updates             | 11480       |
|    policy_gradient_loss  | 0.0122      |
|    std                   | 0.228       |
|    value_loss            | 1.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.32591343 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 519         |
|    total_timesteps       | 2355200     |
| train/                   |             |
|    approx_kl             | 0.02791184  |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.481      |
|    entropy               | 1.17        |
|    entropy_loss          | 1.17        |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.584       |
|    n_updates             | 11490       |
|    policy_gradient_loss  | 0.00477     |
|    std                   | 0.227       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.40401205 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 542         |
|    total_timesteps       | 2357248     |
| train/                   |             |
|    approx_kl             | 0.040140793 |
|    clip_fraction         | 0.227       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.491      |
|    entropy               | 1.18        |
|    entropy_loss          | 1.17        |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.612       |
|    n_updates             | 11500       |
|    policy_gradient_loss  | 0.00667     |
|    std                   | 0.227       |
|    value_loss            | 1.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.4310272  |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 564         |
|    total_timesteps       | 2359296     |
| train/                   |             |
|    approx_kl             | 0.028152026 |
|    clip_fraction         | 0.261       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.9         |
|    cost_value_loss       | 123         |
|    cost_values           | -0.483      |
|    entropy               | 1.17        |
|    entropy_loss          | 1.17        |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.729       |
|    n_updates             | 11510       |
|    policy_gradient_loss  | 0.00678     |
|    std                   | 0.227       |
|    value_loss            | 1.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.32711428 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 587         |
|    total_timesteps       | 2361344     |
| train/                   |             |
|    approx_kl             | 0.036455013 |
|    clip_fraction         | 0.349       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.483      |
|    entropy               | 1.16        |
|    entropy_loss          | 1.17        |
|    explained_variance    | 0.811       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.88        |
|    n_updates             | 11520       |
|    policy_gradient_loss  | 0.0223      |
|    std                   | 0.227       |
|    value_loss            | 2.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.35030037 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 27          |
|    time_elapsed          | 609         |
|    total_timesteps       | 2363392     |
| train/                   |             |
|    approx_kl             | 0.03238744  |
|    clip_fraction         | 0.262       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.475      |
|    entropy               | 1.17        |
|    entropy_loss          | 1.17        |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.817       |
|    n_updates             | 11530       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.226       |
|    value_loss            | 1.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.23967536 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 632         |
|    total_timesteps       | 2365440     |
| train/                   |             |
|    approx_kl             | 0.083121754 |
|    clip_fraction         | 0.291       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.475      |
|    entropy               | 1.17        |
|    entropy_loss          | 1.17        |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.01        |
|    n_updates             | 11540       |
|    policy_gradient_loss  | 0.0181      |
|    std                   | 0.226       |
|    value_loss            | 2.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.42277578 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 654         |
|    total_timesteps       | 2367488     |
| train/                   |             |
|    approx_kl             | 0.04324797  |
|    clip_fraction         | 0.261       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.58        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.478      |
|    entropy               | 1.18        |
|    entropy_loss          | 1.17        |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.574       |
|    n_updates             | 11550       |
|    policy_gradient_loss  | 0.0153      |
|    std                   | 0.225       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.22173093 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 677         |
|    total_timesteps       | 2369536     |
| train/                   |             |
|    approx_kl             | 0.018284528 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.47       |
|    entropy               | 1.18        |
|    entropy_loss          | 1.18        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.585       |
|    n_updates             | 11560       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.224       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.35        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.35        |
| reward                   | -0.25432196 |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 700         |
|    total_timesteps       | 2371584     |
| train/                   |             |
|    approx_kl             | 0.025576906 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.459      |
|    entropy               | 1.18        |
|    entropy_loss          | 1.18        |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.728       |
|    n_updates             | 11570       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.225       |
|    value_loss            | 1.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.16508056 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 722         |
|    total_timesteps       | 2373632     |
| train/                   |             |
|    approx_kl             | 0.050403364 |
|    clip_fraction         | 0.283       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.56        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.446      |
|    entropy               | 1.18        |
|    entropy_loss          | 1.18        |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.669       |
|    n_updates             | 11580       |
|    policy_gradient_loss  | 0.0191      |
|    std                   | 0.224       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.3828367  |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 745         |
|    total_timesteps       | 2375680     |
| train/                   |             |
|    approx_kl             | 0.026832452 |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.89        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.466      |
|    entropy               | 1.18        |
|    entropy_loss          | 1.18        |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.594       |
|    n_updates             | 11590       |
|    policy_gradient_loss  | 0.00515     |
|    std                   | 0.224       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.21295027 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 768         |
|    total_timesteps       | 2377728     |
| train/                   |             |
|    approx_kl             | 0.061216474 |
|    clip_fraction         | 0.262       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.81        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.463      |
|    entropy               | 1.19        |
|    entropy_loss          | 1.18        |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.456       |
|    n_updates             | 11600       |
|    policy_gradient_loss  | 0.0165      |
|    std                   | 0.223       |
|    value_loss            | 0.888       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.41700056 |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 35          |
|    time_elapsed          | 790         |
|    total_timesteps       | 2379776     |
| train/                   |             |
|    approx_kl             | 0.03471529  |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.456      |
|    entropy               | 1.2         |
|    entropy_loss          | 1.19        |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.649       |
|    n_updates             | 11610       |
|    policy_gradient_loss  | 0.000933    |
|    std                   | 0.222       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.31316996 |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 36          |
|    time_elapsed          | 813         |
|    total_timesteps       | 2381824     |
| train/                   |             |
|    approx_kl             | 0.051796697 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.91        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.461      |
|    entropy               | 1.21        |
|    entropy_loss          | 1.21        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.47        |
|    n_updates             | 11620       |
|    policy_gradient_loss  | 0.0138      |
|    std                   | 0.221       |
|    value_loss            | 0.97        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.2        |
| reward                   | -0.5119776 |
| rollout/                 |            |
|    ep_len_mean           | 43.5       |
|    ep_rew_mean           | -14.7      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 37         |
|    time_elapsed          | 835        |
|    total_timesteps       | 2383872    |
| train/                   |            |
|    approx_kl             | 0.03551288 |
|    clip_fraction         | 0.271      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.1       |
|    cost_value_loss       | 126        |
|    cost_values           | -0.471     |
|    entropy               | 1.21       |
|    entropy_loss          | 1.21       |
|    explained_variance    | 0.921      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.504      |
|    n_updates             | 11630      |
|    policy_gradient_loss  | 0.0128     |
|    std                   | 0.221      |
|    value_loss            | 0.936      |
-----------------------------------------
-----------------------------------------
| avg_speed                | 6.2        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.2        |
| reward                   | -0.3472893 |
| rollout/                 |            |
|    ep_len_mean           | 43.1       |
|    ep_rew_mean           | -14.7      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 38         |
|    time_elapsed          | 858        |
|    total_timesteps       | 2385920    |
| train/                   |            |
|    approx_kl             | 0.02358152 |
|    clip_fraction         | 0.215      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.83       |
|    cost_value_loss       | 121        |
|    cost_values           | -0.476     |
|    entropy               | 1.22       |
|    entropy_loss          | 1.22       |
|    explained_variance    | 0.912      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.413      |
|    n_updates             | 11640      |
|    policy_gradient_loss  | 0.0077     |
|    std                   | 0.22       |
|    value_loss            | 0.985      |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 5.2         |
| reward                   | -0.09608558 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 881         |
|    total_timesteps       | 2387968     |
| train/                   |             |
|    approx_kl             | 0.026793052 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.79        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.474      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.382       |
|    n_updates             | 11650       |
|    policy_gradient_loss  | 0.0087      |
|    std                   | 0.219       |
|    value_loss            | 0.905       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.3459203  |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -14.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 40          |
|    time_elapsed          | 903         |
|    total_timesteps       | 2390016     |
| train/                   |             |
|    approx_kl             | 0.031397395 |
|    clip_fraction         | 0.284       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.48        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.487      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.48        |
|    n_updates             | 11660       |
|    policy_gradient_loss  | 0.0138      |
|    std                   | 0.219       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.37698948 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 926         |
|    total_timesteps       | 2392064     |
| train/                   |             |
|    approx_kl             | 0.12422002  |
|    clip_fraction         | 0.295       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.68        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.486      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.328       |
|    n_updates             | 11670       |
|    policy_gradient_loss  | 0.0167      |
|    std                   | 0.219       |
|    value_loss            | 0.799       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.54211575 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 948         |
|    total_timesteps       | 2394112     |
| train/                   |             |
|    approx_kl             | 0.030820195 |
|    clip_fraction         | 0.273       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.82        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.476      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.428       |
|    n_updates             | 11680       |
|    policy_gradient_loss  | 0.012       |
|    std                   | 0.219       |
|    value_loss            | 0.937       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.51554286 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 43          |
|    time_elapsed          | 971         |
|    total_timesteps       | 2396160     |
| train/                   |             |
|    approx_kl             | 0.056942567 |
|    clip_fraction         | 0.299       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.94        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.472      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.281       |
|    n_updates             | 11690       |
|    policy_gradient_loss  | 0.0169      |
|    std                   | 0.219       |
|    value_loss            | 0.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18544447 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 994         |
|    total_timesteps       | 2398208     |
| train/                   |             |
|    approx_kl             | 0.046434727 |
|    clip_fraction         | 0.253       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.98        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.481      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.646       |
|    n_updates             | 11700       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.219       |
|    value_loss            | 1.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34071177 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1016        |
|    total_timesteps       | 2400256     |
| train/                   |             |
|    approx_kl             | 0.039317824 |
|    clip_fraction         | 0.298       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.489      |
|    entropy               | 1.22        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.685       |
|    n_updates             | 11710       |
|    policy_gradient_loss  | 0.017       |
|    std                   | 0.22        |
|    value_loss            | 1.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.32870358 |
| rollout/                 |             |
|    ep_len_mean           | 48          |
|    ep_rew_mean           | -16.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1039        |
|    total_timesteps       | 2402304     |
| train/                   |             |
|    approx_kl             | 0.060861174 |
|    clip_fraction         | 0.304       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.479      |
|    entropy               | 1.22        |
|    entropy_loss          | 1.22        |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.737       |
|    n_updates             | 11720       |
|    policy_gradient_loss  | 0.0149      |
|    std                   | 0.22        |
|    value_loss            | 1.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.2427061  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1061        |
|    total_timesteps       | 2404352     |
| train/                   |             |
|    approx_kl             | 0.018483918 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 135         |
|    cost_values           | -0.478      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.722       |
|    n_updates             | 11730       |
|    policy_gradient_loss  | 0.0104      |
|    std                   | 0.219       |
|    value_loss            | 1.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.1675507  |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1084        |
|    total_timesteps       | 2406400     |
| train/                   |             |
|    approx_kl             | 0.053470902 |
|    clip_fraction         | 0.322       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.92        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.477      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.54        |
|    n_updates             | 11740       |
|    policy_gradient_loss  | 0.00636     |
|    std                   | 0.22        |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27319464 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1107        |
|    total_timesteps       | 2408448     |
| train/                   |             |
|    approx_kl             | 0.030113205 |
|    clip_fraction         | 0.3         |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.472      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.47        |
|    n_updates             | 11750       |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.219       |
|    value_loss            | 0.935       |
------------------------------------------
------------------------------------
| avg_speed          | 0.6         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.6         |
| reward             | -0.42885938 |
| rollout/           |             |
|    ep_len_mean     | 45.1        |
|    ep_rew_mean     | -15.6       |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2410496     |
------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5135277  |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2412544     |
| train/                   |             |
|    approx_kl             | 0.040810823 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.48       |
|    entropy               | 1.22        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.594       |
|    n_updates             | 11770       |
|    policy_gradient_loss  | 0.00356     |
|    std                   | 0.22        |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33540997 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2414592     |
| train/                   |             |
|    approx_kl             | 0.034940068 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.73        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.486      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.666       |
|    n_updates             | 11780       |
|    policy_gradient_loss  | 0.00343     |
|    std                   | 0.219       |
|    value_loss            | 1.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31941965 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2416640     |
| train/                   |             |
|    approx_kl             | 0.03918635  |
|    clip_fraction         | 0.266       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.483      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.547       |
|    n_updates             | 11790       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.218       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.51528543 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2418688     |
| train/                   |             |
|    approx_kl             | 0.0378818   |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.91        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.475      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.485       |
|    n_updates             | 11800       |
|    policy_gradient_loss  | 0.00725     |
|    std                   | 0.219       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.43678966 |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2420736     |
| train/                   |             |
|    approx_kl             | 0.054539315 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.83        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.485      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.398       |
|    n_updates             | 11810       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.22        |
|    value_loss            | 0.689       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.23579513 |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2422784     |
| train/                   |             |
|    approx_kl             | 0.038903095 |
|    clip_fraction         | 0.299       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.45        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.491      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.515       |
|    n_updates             | 11820       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.219       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.15787351 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 8           |
|    time_elapsed          | 180         |
|    total_timesteps       | 2424832     |
| train/                   |             |
|    approx_kl             | 0.025362544 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.71        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.484      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.446       |
|    n_updates             | 11830       |
|    policy_gradient_loss  | 0.00675     |
|    std                   | 0.219       |
|    value_loss            | 0.965       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.47625062 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2426880     |
| train/                   |             |
|    approx_kl             | 0.035086356 |
|    clip_fraction         | 0.302       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.89        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.495      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.471       |
|    n_updates             | 11840       |
|    policy_gradient_loss  | 0.0192      |
|    std                   | 0.218       |
|    value_loss            | 0.952       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.41159654 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 10          |
|    time_elapsed          | 225         |
|    total_timesteps       | 2428928     |
| train/                   |             |
|    approx_kl             | 0.07524875  |
|    clip_fraction         | 0.302       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.479      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.398       |
|    n_updates             | 11850       |
|    policy_gradient_loss  | 0.0193      |
|    std                   | 0.218       |
|    value_loss            | 0.919       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 7.8         |
| reward                   | -0.11200449 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 11          |
|    time_elapsed          | 248         |
|    total_timesteps       | 2430976     |
| train/                   |             |
|    approx_kl             | 0.044478524 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.94        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.482      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.626       |
|    n_updates             | 11860       |
|    policy_gradient_loss  | 0.013       |
|    std                   | 0.218       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.26389205 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 12          |
|    time_elapsed          | 270         |
|    total_timesteps       | 2433024     |
| train/                   |             |
|    approx_kl             | 0.031903632 |
|    clip_fraction         | 0.284       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.94        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.489      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.431       |
|    n_updates             | 11870       |
|    policy_gradient_loss  | 0.017       |
|    std                   | 0.218       |
|    value_loss            | 0.856       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.50562423 |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 13          |
|    time_elapsed          | 293         |
|    total_timesteps       | 2435072     |
| train/                   |             |
|    approx_kl             | 0.035217952 |
|    clip_fraction         | 0.342       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.81        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.461      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.387       |
|    n_updates             | 11880       |
|    policy_gradient_loss  | 0.0182      |
|    std                   | 0.218       |
|    value_loss            | 0.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.5659005  |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 14          |
|    time_elapsed          | 315         |
|    total_timesteps       | 2437120     |
| train/                   |             |
|    approx_kl             | 0.055433605 |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.88        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.464      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.49        |
|    n_updates             | 11890       |
|    policy_gradient_loss  | 0.00502     |
|    std                   | 0.217       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.38        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.38        |
| reward                   | -0.32792473 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 15          |
|    time_elapsed          | 338         |
|    total_timesteps       | 2439168     |
| train/                   |             |
|    approx_kl             | 0.036545828 |
|    clip_fraction         | 0.286       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.48       |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.392       |
|    n_updates             | 11900       |
|    policy_gradient_loss  | 0.015       |
|    std                   | 0.217       |
|    value_loss            | 0.798       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.5081734  |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 16          |
|    time_elapsed          | 361         |
|    total_timesteps       | 2441216     |
| train/                   |             |
|    approx_kl             | 0.039065696 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.95        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.468      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.463       |
|    n_updates             | 11910       |
|    policy_gradient_loss  | 0.0047      |
|    std                   | 0.218       |
|    value_loss            | 0.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.28908584 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 17          |
|    time_elapsed          | 383         |
|    total_timesteps       | 2443264     |
| train/                   |             |
|    approx_kl             | 0.045972615 |
|    clip_fraction         | 0.308       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.72        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.472      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.413       |
|    n_updates             | 11920       |
|    policy_gradient_loss  | 0.0212      |
|    std                   | 0.219       |
|    value_loss            | 0.754       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.5609968  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 18          |
|    time_elapsed          | 406         |
|    total_timesteps       | 2445312     |
| train/                   |             |
|    approx_kl             | 0.048070826 |
|    clip_fraction         | 0.282       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.476      |
|    entropy               | 1.23        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.444       |
|    n_updates             | 11930       |
|    policy_gradient_loss  | 0.0146      |
|    std                   | 0.219       |
|    value_loss            | 0.983       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39662176 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 19          |
|    time_elapsed          | 428         |
|    total_timesteps       | 2447360     |
| train/                   |             |
|    approx_kl             | 0.018478785 |
|    clip_fraction         | 0.245       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 133         |
|    cost_values           | -0.471      |
|    entropy               | 1.22        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.503       |
|    n_updates             | 11940       |
|    policy_gradient_loss  | 0.00824     |
|    std                   | 0.22        |
|    value_loss            | 1.03        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.6        |
| reward                   | -0.6026981 |
| rollout/                 |            |
|    ep_len_mean           | 41.9       |
|    ep_rew_mean           | -15.2      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 20         |
|    time_elapsed          | 451        |
|    total_timesteps       | 2449408    |
| train/                   |            |
|    approx_kl             | 0.041996   |
|    clip_fraction         | 0.228      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.56       |
|    cost_value_loss       | 116        |
|    cost_values           | -0.489     |
|    entropy               | 1.23       |
|    entropy_loss          | 1.22       |
|    explained_variance    | 0.926      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.522      |
|    n_updates             | 11950      |
|    policy_gradient_loss  | 0.00711    |
|    std                   | 0.22       |
|    value_loss            | 1.08       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.5088561  |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 21          |
|    time_elapsed          | 474         |
|    total_timesteps       | 2451456     |
| train/                   |             |
|    approx_kl             | 0.022842113 |
|    clip_fraction         | 0.266       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.78        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.467      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.23        |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.402       |
|    n_updates             | 11960       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.219       |
|    value_loss            | 0.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.3241415  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 496         |
|    total_timesteps       | 2453504     |
| train/                   |             |
|    approx_kl             | 0.020609414 |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.457      |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.571       |
|    n_updates             | 11970       |
|    policy_gradient_loss  | 0.0128      |
|    std                   | 0.218       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.46478188 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 519         |
|    total_timesteps       | 2455552     |
| train/                   |             |
|    approx_kl             | 0.05435079  |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 130         |
|    cost_values           | -0.47       |
|    entropy               | 1.24        |
|    entropy_loss          | 1.24        |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.438       |
|    n_updates             | 11980       |
|    policy_gradient_loss  | 0.00854     |
|    std                   | 0.217       |
|    value_loss            | 0.858       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.40374523 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 541         |
|    total_timesteps       | 2457600     |
| train/                   |             |
|    approx_kl             | 0.06940375  |
|    clip_fraction         | 0.281       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.91        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.48       |
|    entropy               | 1.25        |
|    entropy_loss          | 1.25        |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.472       |
|    n_updates             | 11990       |
|    policy_gradient_loss  | 0.0129      |
|    std                   | 0.217       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.47925895 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 564         |
|    total_timesteps       | 2459648     |
| train/                   |             |
|    approx_kl             | 0.017629076 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.48       |
|    entropy               | 1.25        |
|    entropy_loss          | 1.25        |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.57        |
|    n_updates             | 12000       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.217       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.3119595  |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 586         |
|    total_timesteps       | 2461696     |
| train/                   |             |
|    approx_kl             | 0.050590593 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.478      |
|    entropy               | 1.25        |
|    entropy_loss          | 1.25        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.673       |
|    n_updates             | 12010       |
|    policy_gradient_loss  | 7.3e-05     |
|    std                   | 0.218       |
|    value_loss            | 1.15        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.55       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.55       |
| reward                   | -0.2826832 |
| rollout/                 |            |
|    ep_len_mean           | 42.2       |
|    ep_rew_mean           | -15.2      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 27         |
|    time_elapsed          | 609        |
|    total_timesteps       | 2463744    |
| train/                   |            |
|    approx_kl             | 0.03737901 |
|    clip_fraction         | 0.284      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.7        |
|    cost_value_loss       | 117        |
|    cost_values           | -0.475     |
|    entropy               | 1.25       |
|    entropy_loss          | 1.25       |
|    explained_variance    | 0.937      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.539      |
|    n_updates             | 12020      |
|    policy_gradient_loss  | 0.0121     |
|    std                   | 0.218      |
|    value_loss            | 0.952      |
-----------------------------------------
-----------------------------------------
| avg_speed                | 3          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3          |
| reward                   | -0.6146592 |
| rollout/                 |            |
|    ep_len_mean           | 44.4       |
|    ep_rew_mean           | -15.8      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 28         |
|    time_elapsed          | 631        |
|    total_timesteps       | 2465792    |
| train/                   |            |
|    approx_kl             | 0.04089435 |
|    clip_fraction         | 0.254      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.72       |
|    cost_value_loss       | 118        |
|    cost_values           | -0.476     |
|    entropy               | 1.26       |
|    entropy_loss          | 1.26       |
|    explained_variance    | 0.938      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.335      |
|    n_updates             | 12030      |
|    policy_gradient_loss  | 0.01       |
|    std                   | 0.217      |
|    value_loss            | 0.765      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.61456907 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -16.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 654         |
|    total_timesteps       | 2467840     |
| train/                   |             |
|    approx_kl             | 0.029190917 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 131         |
|    cost_values           | -0.472      |
|    entropy               | 1.26        |
|    entropy_loss          | 1.26        |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.561       |
|    n_updates             | 12040       |
|    policy_gradient_loss  | 0.00745     |
|    std                   | 0.217       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37952423 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 676         |
|    total_timesteps       | 2469888     |
| train/                   |             |
|    approx_kl             | 0.046361536 |
|    clip_fraction         | 0.292       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.479      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.454       |
|    n_updates             | 12050       |
|    policy_gradient_loss  | 0.0214      |
|    std                   | 0.216       |
|    value_loss            | 0.838       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.33462024 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 699         |
|    total_timesteps       | 2471936     |
| train/                   |             |
|    approx_kl             | 0.032346927 |
|    clip_fraction         | 0.272       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.463      |
|    entropy               | 1.28        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.466       |
|    n_updates             | 12060       |
|    policy_gradient_loss  | 0.0081      |
|    std                   | 0.215       |
|    value_loss            | 0.942       |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.32156157 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 721         |
|    total_timesteps       | 2473984     |
| train/                   |             |
|    approx_kl             | 0.034682404 |
|    clip_fraction         | 0.239       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.469      |
|    entropy               | 1.28        |
|    entropy_loss          | 1.28        |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.48        |
|    n_updates             | 12070       |
|    policy_gradient_loss  | 0.00374     |
|    std                   | 0.214       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.5119776  |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 743         |
|    total_timesteps       | 2476032     |
| train/                   |             |
|    approx_kl             | 0.023626395 |
|    clip_fraction         | 0.292       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.98        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.464      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.28        |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.618       |
|    n_updates             | 12080       |
|    policy_gradient_loss  | 0.0163      |
|    std                   | 0.214       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.24387746 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 766         |
|    total_timesteps       | 2478080     |
| train/                   |             |
|    approx_kl             | 0.027761227 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.66        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.475      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.85        |
|    n_updates             | 12090       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.214       |
|    value_loss            | 1.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36309212 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 35          |
|    time_elapsed          | 788         |
|    total_timesteps       | 2480128     |
| train/                   |             |
|    approx_kl             | 0.018129334 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.7         |
|    cost_value_loss       | 118         |
|    cost_values           | -0.482      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.414       |
|    n_updates             | 12100       |
|    policy_gradient_loss  | 0.00443     |
|    std                   | 0.215       |
|    value_loss            | 0.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.24378982 |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 36          |
|    time_elapsed          | 811         |
|    total_timesteps       | 2482176     |
| train/                   |             |
|    approx_kl             | 0.04709693  |
|    clip_fraction         | 0.272       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.94        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.463      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.802       |
|    n_updates             | 12110       |
|    policy_gradient_loss  | 0.0156      |
|    std                   | 0.214       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.15506196 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 833         |
|    total_timesteps       | 2484224     |
| train/                   |             |
|    approx_kl             | 0.074364685 |
|    clip_fraction         | 0.284       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.58        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.474      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.728       |
|    n_updates             | 12120       |
|    policy_gradient_loss  | 0.00909     |
|    std                   | 0.215       |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.38146964 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 855         |
|    total_timesteps       | 2486272     |
| train/                   |             |
|    approx_kl             | 0.06709125  |
|    clip_fraction         | 0.313       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.483      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.555       |
|    n_updates             | 12130       |
|    policy_gradient_loss  | 0.0211      |
|    std                   | 0.215       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.19        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.19        |
| reward                   | -0.3800876  |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 878         |
|    total_timesteps       | 2488320     |
| train/                   |             |
|    approx_kl             | 0.040237922 |
|    clip_fraction         | 0.272       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.473      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.684       |
|    n_updates             | 12140       |
|    policy_gradient_loss  | 0.0151      |
|    std                   | 0.215       |
|    value_loss            | 1.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.39415148 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 40          |
|    time_elapsed          | 900         |
|    total_timesteps       | 2490368     |
| train/                   |             |
|    approx_kl             | 0.024496198 |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.466      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.431       |
|    n_updates             | 12150       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.214       |
|    value_loss            | 0.924       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.5372786  |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 923         |
|    total_timesteps       | 2492416     |
| train/                   |             |
|    approx_kl             | 0.048666585 |
|    clip_fraction         | 0.264       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.78        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.466      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.457       |
|    n_updates             | 12160       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.214       |
|    value_loss            | 0.884       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.42861488 |
| rollout/                 |             |
|    ep_len_mean           | 40.7        |
|    ep_rew_mean           | -14.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 945         |
|    total_timesteps       | 2494464     |
| train/                   |             |
|    approx_kl             | 0.022565063 |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.36        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.479      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.557       |
|    n_updates             | 12170       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.214       |
|    value_loss            | 1.03        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3          |
| reward                   | -0.5079512 |
| rollout/                 |            |
|    ep_len_mean           | 41.1       |
|    ep_rew_mean           | -14.5      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 43         |
|    time_elapsed          | 968        |
|    total_timesteps       | 2496512    |
| train/                   |            |
|    approx_kl             | 0.03720637 |
|    clip_fraction         | 0.288      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.75       |
|    cost_value_loss       | 119        |
|    cost_values           | -0.47      |
|    entropy               | 1.31       |
|    entropy_loss          | 1.3        |
|    explained_variance    | 0.933      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.465      |
|    n_updates             | 12180      |
|    policy_gradient_loss  | 0.0152     |
|    std                   | 0.213      |
|    value_loss            | 0.874      |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.24255066 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 990         |
|    total_timesteps       | 2498560     |
| train/                   |             |
|    approx_kl             | 0.04288997  |
|    clip_fraction         | 0.286       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.51        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.455      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.428       |
|    n_updates             | 12190       |
|    policy_gradient_loss  | 0.0159      |
|    std                   | 0.214       |
|    value_loss            | 0.831       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.19700678 |
| rollout/                 |             |
|    ep_len_mean           | 40.2        |
|    ep_rew_mean           | -14.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1013        |
|    total_timesteps       | 2500608     |
| train/                   |             |
|    approx_kl             | 0.031211963 |
|    clip_fraction         | 0.348       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.61        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.471      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.429       |
|    n_updates             | 12200       |
|    policy_gradient_loss  | 0.0273      |
|    std                   | 0.215       |
|    value_loss            | 0.833       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.26070404 |
| rollout/                 |             |
|    ep_len_mean           | 40.5        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1036        |
|    total_timesteps       | 2502656     |
| train/                   |             |
|    approx_kl             | 0.04019057  |
|    clip_fraction         | 0.402       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.28        |
|    cost_value_loss       | 108         |
|    cost_values           | -0.472      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.462       |
|    n_updates             | 12210       |
|    policy_gradient_loss  | 0.0374      |
|    std                   | 0.214       |
|    value_loss            | 0.852       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.44212314 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 2504704     |
| train/                   |             |
|    approx_kl             | 0.0168395   |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.65        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.472      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.419       |
|    n_updates             | 12220       |
|    policy_gradient_loss  | 0.0175      |
|    std                   | 0.213       |
|    value_loss            | 0.916       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.5293802  |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1082        |
|    total_timesteps       | 2506752     |
| train/                   |             |
|    approx_kl             | 0.042679224 |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.68        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.467      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.342       |
|    n_updates             | 12230       |
|    policy_gradient_loss  | 0.00536     |
|    std                   | 0.212       |
|    value_loss            | 0.865       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.14141391 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1104        |
|    total_timesteps       | 2508800     |
| train/                   |             |
|    approx_kl             | 0.036548194 |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.458      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.349       |
|    n_updates             | 12240       |
|    policy_gradient_loss  | 0.0111      |
|    std                   | 0.211       |
|    value_loss            | 0.825       |
------------------------------------------
------------------------------------
| avg_speed          | 5.2         |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 5.2         |
| reward             | -0.20383583 |
| rollout/           |             |
|    ep_len_mean     | 43.7        |
|    ep_rew_mean     | -15.3       |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2510848     |
------------------------------------
-----------------------------------------
| avg_speed                | 4.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.4        |
| reward                   | -0.4944278 |
| rollout/                 |            |
|    ep_len_mean           | 43.3       |
|    ep_rew_mean           | -15.3      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 2          |
|    time_elapsed          | 44         |
|    total_timesteps       | 2512896    |
| train/                   |            |
|    approx_kl             | 0.05551093 |
|    clip_fraction         | 0.29       |
|    clip_range            | 0.2        |
|    cost_returns          | 9.64       |
|    cost_value_loss       | 116        |
|    cost_values           | -0.462     |
|    entropy               | 1.31       |
|    entropy_loss          | 1.31       |
|    explained_variance    | 0.924      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.498      |
|    n_updates             | 12260      |
|    policy_gradient_loss  | 0.0142     |
|    std                   | 0.211      |
|    value_loss            | 1.01       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.41069242 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2514944     |
| train/                   |             |
|    approx_kl             | 0.018800272 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.95        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.466      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.407       |
|    n_updates             | 12270       |
|    policy_gradient_loss  | 0.0151      |
|    std                   | 0.212       |
|    value_loss            | 0.839       |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.23330294 |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2516992     |
| train/                   |             |
|    approx_kl             | 0.026019067 |
|    clip_fraction         | 0.255       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 124         |
|    cost_values           | -0.465      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.333       |
|    n_updates             | 12280       |
|    policy_gradient_loss  | 0.00783     |
|    std                   | 0.212       |
|    value_loss            | 0.753       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.5777102  |
| rollout/                 |             |
|    ep_len_mean           | 40.6        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2519040     |
| train/                   |             |
|    approx_kl             | 0.024680953 |
|    clip_fraction         | 0.254       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.54        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.471      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.519       |
|    n_updates             | 12290       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.213       |
|    value_loss            | 1.17        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.4354899 |
| rollout/                 |            |
|    ep_len_mean           | 41         |
|    ep_rew_mean           | -14.4      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 6          |
|    time_elapsed          | 134        |
|    total_timesteps       | 2521088    |
| train/                   |            |
|    approx_kl             | 0.06536664 |
|    clip_fraction         | 0.236      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.49       |
|    cost_value_loss       | 114        |
|    cost_values           | -0.458     |
|    entropy               | 1.31       |
|    entropy_loss          | 1.3        |
|    explained_variance    | 0.898      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.541      |
|    n_updates             | 12300      |
|    policy_gradient_loss  | 0.00664    |
|    std                   | 0.212      |
|    value_loss            | 1.24       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.23601854 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2523136     |
| train/                   |             |
|    approx_kl             | 0.054260135 |
|    clip_fraction         | 0.303       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.478      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.422       |
|    n_updates             | 12310       |
|    policy_gradient_loss  | 0.00702     |
|    std                   | 0.21        |
|    value_loss            | 0.963       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.44110265 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 180         |
|    total_timesteps       | 2525184     |
| train/                   |             |
|    approx_kl             | 0.03902337  |
|    clip_fraction         | 0.333       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.71        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.461      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.33        |
|    n_updates             | 12320       |
|    policy_gradient_loss  | 0.0231      |
|    std                   | 0.209       |
|    value_loss            | 0.742       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5485113  |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2527232     |
| train/                   |             |
|    approx_kl             | 0.042641383 |
|    clip_fraction         | 0.303       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.55        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.47       |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.534       |
|    n_updates             | 12330       |
|    policy_gradient_loss  | 0.0176      |
|    std                   | 0.209       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.29601365 |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 10          |
|    time_elapsed          | 225         |
|    total_timesteps       | 2529280     |
| train/                   |             |
|    approx_kl             | 0.037302144 |
|    clip_fraction         | 0.279       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.471      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.649       |
|    n_updates             | 12340       |
|    policy_gradient_loss  | 0.0122      |
|    std                   | 0.21        |
|    value_loss            | 1.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.38558513 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2531328     |
| train/                   |             |
|    approx_kl             | 0.022201292 |
|    clip_fraction         | 0.263       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.92        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.467      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.474       |
|    n_updates             | 12350       |
|    policy_gradient_loss  | 0.00837     |
|    std                   | 0.212       |
|    value_loss            | 0.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.2869765  |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 12          |
|    time_elapsed          | 270         |
|    total_timesteps       | 2533376     |
| train/                   |             |
|    approx_kl             | 0.021310696 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.467      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.331       |
|    n_updates             | 12360       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.212       |
|    value_loss            | 0.767       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.50941986 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 2535424     |
| train/                   |             |
|    approx_kl             | 0.03989285  |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.7         |
|    cost_value_loss       | 118         |
|    cost_values           | -0.47       |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.469       |
|    n_updates             | 12370       |
|    policy_gradient_loss  | 0.00405     |
|    std                   | 0.211       |
|    value_loss            | 0.989       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.22136731 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 14          |
|    time_elapsed          | 315         |
|    total_timesteps       | 2537472     |
| train/                   |             |
|    approx_kl             | 0.043959696 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.459      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.669       |
|    n_updates             | 12380       |
|    policy_gradient_loss  | 0.0129      |
|    std                   | 0.212       |
|    value_loss            | 1.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5485113  |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2539520     |
| train/                   |             |
|    approx_kl             | 0.047312032 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.71        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.464      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.534       |
|    n_updates             | 12390       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.212       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.16        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.16        |
| reward                   | -0.21936095 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 16          |
|    time_elapsed          | 360         |
|    total_timesteps       | 2541568     |
| train/                   |             |
|    approx_kl             | 0.029564263 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.459      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.53        |
|    n_updates             | 12400       |
|    policy_gradient_loss  | 0.0121      |
|    std                   | 0.212       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.37588814 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 17          |
|    time_elapsed          | 383         |
|    total_timesteps       | 2543616     |
| train/                   |             |
|    approx_kl             | 0.023111857 |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 124         |
|    cost_values           | -0.467      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.33        |
|    n_updates             | 12410       |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.212       |
|    value_loss            | 0.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.18139191 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 18          |
|    time_elapsed          | 405         |
|    total_timesteps       | 2545664     |
| train/                   |             |
|    approx_kl             | 0.01893604  |
|    clip_fraction         | 0.306       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.92        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.447      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.498       |
|    n_updates             | 12420       |
|    policy_gradient_loss  | 0.0147      |
|    std                   | 0.211       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.75        |
| reward                   | -0.39429605 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 19          |
|    time_elapsed          | 428         |
|    total_timesteps       | 2547712     |
| train/                   |             |
|    approx_kl             | 0.02868389  |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.77        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.453      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.536       |
|    n_updates             | 12430       |
|    policy_gradient_loss  | 0.00807     |
|    std                   | 0.21        |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.26760584 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 20          |
|    time_elapsed          | 451         |
|    total_timesteps       | 2549760     |
| train/                   |             |
|    approx_kl             | 0.047295243 |
|    clip_fraction         | 0.293       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.445      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.517       |
|    n_updates             | 12440       |
|    policy_gradient_loss  | 0.0165      |
|    std                   | 0.211       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.17750055 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 21          |
|    time_elapsed          | 473         |
|    total_timesteps       | 2551808     |
| train/                   |             |
|    approx_kl             | 0.04151451  |
|    clip_fraction         | 0.283       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.459      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.535       |
|    n_updates             | 12450       |
|    policy_gradient_loss  | 0.013       |
|    std                   | 0.21        |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.34610963 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 496         |
|    total_timesteps       | 2553856     |
| train/                   |             |
|    approx_kl             | 0.026294133 |
|    clip_fraction         | 0.272       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.465      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.418       |
|    n_updates             | 12460       |
|    policy_gradient_loss  | 0.013       |
|    std                   | 0.21        |
|    value_loss            | 0.999       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.2990179  |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 518         |
|    total_timesteps       | 2555904     |
| train/                   |             |
|    approx_kl             | 0.031128608 |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 132         |
|    cost_values           | -0.471      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.624       |
|    n_updates             | 12470       |
|    policy_gradient_loss  | 0.00358     |
|    std                   | 0.21        |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.4168322  |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 541         |
|    total_timesteps       | 2557952     |
| train/                   |             |
|    approx_kl             | 0.036586117 |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.82        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.466      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.604       |
|    n_updates             | 12480       |
|    policy_gradient_loss  | 0.0148      |
|    std                   | 0.21        |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.27230597 |
| rollout/                 |             |
|    ep_len_mean           | 40.1        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 564         |
|    total_timesteps       | 2560000     |
| train/                   |             |
|    approx_kl             | 0.030982979 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.7         |
|    cost_value_loss       | 118         |
|    cost_values           | -0.461      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.587       |
|    n_updates             | 12490       |
|    policy_gradient_loss  | 0.0148      |
|    std                   | 0.21        |
|    value_loss            | 1.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.5037351  |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 586         |
|    total_timesteps       | 2562048     |
| train/                   |             |
|    approx_kl             | 0.021241512 |
|    clip_fraction         | 0.253       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.33        |
|    cost_value_loss       | 110         |
|    cost_values           | -0.465      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.341       |
|    n_updates             | 12500       |
|    policy_gradient_loss  | 0.00765     |
|    std                   | 0.211       |
|    value_loss            | 0.956       |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.33830482 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 27          |
|    time_elapsed          | 609         |
|    total_timesteps       | 2564096     |
| train/                   |             |
|    approx_kl             | 0.07311932  |
|    clip_fraction         | 0.341       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.83        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.462      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.489       |
|    n_updates             | 12510       |
|    policy_gradient_loss  | 0.0164      |
|    std                   | 0.212       |
|    value_loss            | 0.899       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.3236899  |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 631         |
|    total_timesteps       | 2566144     |
| train/                   |             |
|    approx_kl             | 0.020738527 |
|    clip_fraction         | 0.328       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.92        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.466      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.303       |
|    n_updates             | 12520       |
|    policy_gradient_loss  | 0.0248      |
|    std                   | 0.212       |
|    value_loss            | 0.696       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.26283625 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 654         |
|    total_timesteps       | 2568192     |
| train/                   |             |
|    approx_kl             | 0.1046119   |
|    clip_fraction         | 0.284       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.73        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.458      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.438       |
|    n_updates             | 12530       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.212       |
|    value_loss            | 0.895       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.99        |
| reward                   | -0.24157445 |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 676         |
|    total_timesteps       | 2570240     |
| train/                   |             |
|    approx_kl             | 0.028741302 |
|    clip_fraction         | 0.315       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.66        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.452      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.405       |
|    n_updates             | 12540       |
|    policy_gradient_loss  | 0.0246      |
|    std                   | 0.212       |
|    value_loss            | 0.762       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25449267 |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 699         |
|    total_timesteps       | 2572288     |
| train/                   |             |
|    approx_kl             | 0.028741546 |
|    clip_fraction         | 0.29        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.62        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.454      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.37        |
|    n_updates             | 12550       |
|    policy_gradient_loss  | 0.0194      |
|    std                   | 0.212       |
|    value_loss            | 0.715       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.5358008  |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 722         |
|    total_timesteps       | 2574336     |
| train/                   |             |
|    approx_kl             | 0.059310194 |
|    clip_fraction         | 0.275       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.51        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.468      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.44        |
|    n_updates             | 12560       |
|    policy_gradient_loss  | 0.00928     |
|    std                   | 0.212       |
|    value_loss            | 0.704       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.519804   |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 744         |
|    total_timesteps       | 2576384     |
| train/                   |             |
|    approx_kl             | 0.028889172 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.6         |
|    cost_value_loss       | 115         |
|    cost_values           | -0.46       |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.441       |
|    n_updates             | 12570       |
|    policy_gradient_loss  | 0.00804     |
|    std                   | 0.213       |
|    value_loss            | 0.946       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.18928342 |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 767         |
|    total_timesteps       | 2578432     |
| train/                   |             |
|    approx_kl             | 0.019913264 |
|    clip_fraction         | 0.281       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.66        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.469      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.361       |
|    n_updates             | 12580       |
|    policy_gradient_loss  | 0.0209      |
|    std                   | 0.213       |
|    value_loss            | 0.614       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.18695614 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 35          |
|    time_elapsed          | 790         |
|    total_timesteps       | 2580480     |
| train/                   |             |
|    approx_kl             | 0.04496154  |
|    clip_fraction         | 0.287       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.464      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.38        |
|    n_updates             | 12590       |
|    policy_gradient_loss  | 0.0179      |
|    std                   | 0.213       |
|    value_loss            | 0.805       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.47192603 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 36          |
|    time_elapsed          | 812         |
|    total_timesteps       | 2582528     |
| train/                   |             |
|    approx_kl             | 0.029611666 |
|    clip_fraction         | 0.275       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.8         |
|    cost_value_loss       | 120         |
|    cost_values           | -0.452      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.493       |
|    n_updates             | 12600       |
|    policy_gradient_loss  | 0.00365     |
|    std                   | 0.213       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.29429197 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 835         |
|    total_timesteps       | 2584576     |
| train/                   |             |
|    approx_kl             | 0.051179796 |
|    clip_fraction         | 0.301       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.82        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.47       |
|    entropy               | 1.3         |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.457       |
|    n_updates             | 12610       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.212       |
|    value_loss            | 0.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.24852128 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 857         |
|    total_timesteps       | 2586624     |
| train/                   |             |
|    approx_kl             | 0.03673188  |
|    clip_fraction         | 0.307       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.62        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.474      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.394       |
|    n_updates             | 12620       |
|    policy_gradient_loss  | 0.0205      |
|    std                   | 0.212       |
|    value_loss            | 0.873       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.3729971  |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 880         |
|    total_timesteps       | 2588672     |
| train/                   |             |
|    approx_kl             | 0.020684524 |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.85        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.467      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.474       |
|    n_updates             | 12630       |
|    policy_gradient_loss  | 0.00528     |
|    std                   | 0.211       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.33638537 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 40          |
|    time_elapsed          | 903         |
|    total_timesteps       | 2590720     |
| train/                   |             |
|    approx_kl             | 0.024056204 |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.77        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.467      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.631       |
|    n_updates             | 12640       |
|    policy_gradient_loss  | 0.0172      |
|    std                   | 0.211       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 8.02        |
| reward                   | -0.09918799 |
| rollout/                 |             |
|    ep_len_mean           | 40.7        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 925         |
|    total_timesteps       | 2592768     |
| train/                   |             |
|    approx_kl             | 0.03394777  |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.64        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.452      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.579       |
|    n_updates             | 12650       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.211       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.31001827 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 948         |
|    total_timesteps       | 2594816     |
| train/                   |             |
|    approx_kl             | 0.036818165 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.5         |
|    cost_value_loss       | 114         |
|    cost_values           | -0.477      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.386       |
|    n_updates             | 12660       |
|    policy_gradient_loss  | 0.0079      |
|    std                   | 0.212       |
|    value_loss            | 0.874       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.47685188 |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 43          |
|    time_elapsed          | 970         |
|    total_timesteps       | 2596864     |
| train/                   |             |
|    approx_kl             | 0.024637729 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.95        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.455      |
|    entropy               | 1.28        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.314       |
|    n_updates             | 12670       |
|    policy_gradient_loss  | 0.00998     |
|    std                   | 0.213       |
|    value_loss            | 0.706       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.21914877 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 993         |
|    total_timesteps       | 2598912     |
| train/                   |             |
|    approx_kl             | 0.039783448 |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.86        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.449      |
|    entropy               | 1.28        |
|    entropy_loss          | 1.28        |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.403       |
|    n_updates             | 12680       |
|    policy_gradient_loss  | 0.00475     |
|    std                   | 0.214       |
|    value_loss            | 0.866       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.24090765 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1015        |
|    total_timesteps       | 2600960     |
| train/                   |             |
|    approx_kl             | 0.049556352 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.69        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.458      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.565       |
|    n_updates             | 12690       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.214       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.85        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.85        |
| reward                   | -0.14774974 |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1038        |
|    total_timesteps       | 2603008     |
| train/                   |             |
|    approx_kl             | 0.040530264 |
|    clip_fraction         | 0.311       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.454      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.384       |
|    n_updates             | 12700       |
|    policy_gradient_loss  | 0.0155      |
|    std                   | 0.214       |
|    value_loss            | 0.795       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.46893215 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1061        |
|    total_timesteps       | 2605056     |
| train/                   |             |
|    approx_kl             | 0.03828095  |
|    clip_fraction         | 0.335       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.68        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.449      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.48        |
|    n_updates             | 12710       |
|    policy_gradient_loss  | 0.0164      |
|    std                   | 0.214       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.34156483 |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1083        |
|    total_timesteps       | 2607104     |
| train/                   |             |
|    approx_kl             | 0.041988477 |
|    clip_fraction         | 0.247       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.93        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.452      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.436       |
|    n_updates             | 12720       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.215       |
|    value_loss            | 0.832       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.4322206  |
| rollout/                 |             |
|    ep_len_mean           | 39.9        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1106        |
|    total_timesteps       | 2609152     |
| train/                   |             |
|    approx_kl             | 0.037255656 |
|    clip_fraction         | 0.253       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.73        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.448      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.492       |
|    n_updates             | 12730       |
|    policy_gradient_loss  | 0.0111      |
|    std                   | 0.215       |
|    value_loss            | 0.974       |
------------------------------------------
Directory created: PPOL_New/models/seed-testing/an325vgg/model_epoch(25)
-----------------------------------
| avg_speed          | 1.4        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.4        |
| reward             | -0.5476288 |
| rollout/           |            |
|    ep_len_mean     | 41.2       |
|    ep_rew_mean     | -14.5      |
| time/              |            |
|    fps             | 92         |
|    iterations      | 1          |
|    time_elapsed    | 22         |
|    total_timesteps | 2611200    |
-----------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.29999715 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2613248     |
| train/                   |             |
|    approx_kl             | 0.03337393  |
|    clip_fraction         | 0.287       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.441      |
|    entropy               | 1.26        |
|    entropy_loss          | 1.26        |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.398       |
|    n_updates             | 12750       |
|    policy_gradient_loss  | 0.00815     |
|    std                   | 0.216       |
|    value_loss            | 0.955       |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.3483018 |
| rollout/                 |            |
|    ep_len_mean           | 43.6       |
|    ep_rew_mean           | -15        |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 3          |
|    time_elapsed          | 67         |
|    total_timesteps       | 2615296    |
| train/                   |            |
|    approx_kl             | 0.03242178 |
|    clip_fraction         | 0.286      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.83       |
|    cost_value_loss       | 120        |
|    cost_values           | -0.449     |
|    entropy               | 1.26       |
|    entropy_loss          | 1.26       |
|    explained_variance    | 0.943      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.374      |
|    n_updates             | 12760      |
|    policy_gradient_loss  | 0.0246     |
|    std                   | 0.216      |
|    value_loss            | 0.716      |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.2081882  |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2617344     |
| train/                   |             |
|    approx_kl             | 0.023706786 |
|    clip_fraction         | 0.334       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 125         |
|    cost_values           | -0.452      |
|    entropy               | 1.26        |
|    entropy_loss          | 1.26        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.426       |
|    n_updates             | 12770       |
|    policy_gradient_loss  | 0.0248      |
|    std                   | 0.216       |
|    value_loss            | 0.94        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.96       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.96       |
| reward                   | -0.282737  |
| rollout/                 |            |
|    ep_len_mean           | 45.3       |
|    ep_rew_mean           | -16.1      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 5          |
|    time_elapsed          | 112        |
|    total_timesteps       | 2619392    |
| train/                   |            |
|    approx_kl             | 0.01486918 |
|    clip_fraction         | 0.259      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.1       |
|    cost_value_loss       | 127        |
|    cost_values           | -0.459     |
|    entropy               | 1.26       |
|    entropy_loss          | 1.26       |
|    explained_variance    | 0.915      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.516      |
|    n_updates             | 12780      |
|    policy_gradient_loss  | 0.0105     |
|    std                   | 0.216      |
|    value_loss            | 1.1        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.21315596 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -16.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2621440     |
| train/                   |             |
|    approx_kl             | 0.06585832  |
|    clip_fraction         | 0.305       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.454      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.47        |
|    n_updates             | 12790       |
|    policy_gradient_loss  | 0.019       |
|    std                   | 0.217       |
|    value_loss            | 0.963       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3364809  |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2623488     |
| train/                   |             |
|    approx_kl             | 0.025790982 |
|    clip_fraction         | 0.32        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.43       |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.476       |
|    n_updates             | 12800       |
|    policy_gradient_loss  | 0.0177      |
|    std                   | 0.217       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.28137043 |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 180         |
|    total_timesteps       | 2625536     |
| train/                   |             |
|    approx_kl             | 0.03581889  |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.9         |
|    cost_value_loss       | 122         |
|    cost_values           | -0.446      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.627       |
|    n_updates             | 12810       |
|    policy_gradient_loss  | 0.0075      |
|    std                   | 0.216       |
|    value_loss            | 1.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.29220212 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2627584     |
| train/                   |             |
|    approx_kl             | 0.044699885 |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.8         |
|    cost_value_loss       | 119         |
|    cost_values           | -0.449      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.521       |
|    n_updates             | 12820       |
|    policy_gradient_loss  | 0.0082      |
|    std                   | 0.217       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.20643815 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 2629632     |
| train/                   |             |
|    approx_kl             | 0.035856165 |
|    clip_fraction         | 0.254       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 124         |
|    cost_values           | -0.445      |
|    entropy               | 1.26        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.352       |
|    n_updates             | 12830       |
|    policy_gradient_loss  | 0.00729     |
|    std                   | 0.218       |
|    value_loss            | 0.697       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.41965622 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2631680     |
| train/                   |             |
|    approx_kl             | 0.019680338 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.439      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.26        |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.408       |
|    n_updates             | 12840       |
|    policy_gradient_loss  | 0.00237     |
|    std                   | 0.218       |
|    value_loss            | 0.852       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.25394365 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 2633728     |
| train/                   |             |
|    approx_kl             | 0.032348223 |
|    clip_fraction         | 0.262       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.79        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.437      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.406       |
|    n_updates             | 12850       |
|    policy_gradient_loss  | 0.0116      |
|    std                   | 0.218       |
|    value_loss            | 0.832       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.47716027 |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 2635776     |
| train/                   |             |
|    approx_kl             | 0.038366526 |
|    clip_fraction         | 0.292       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.58        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.45       |
|    entropy               | 1.27        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.432       |
|    n_updates             | 12860       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.217       |
|    value_loss            | 0.918       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.2        |
| reward                   | -0.5501947 |
| rollout/                 |            |
|    ep_len_mean           | 44.6       |
|    ep_rew_mean           | -15.7      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 14         |
|    time_elapsed          | 314        |
|    total_timesteps       | 2637824    |
| train/                   |            |
|    approx_kl             | 0.02210652 |
|    clip_fraction         | 0.197      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.1       |
|    cost_value_loss       | 126        |
|    cost_values           | -0.452     |
|    entropy               | 1.27       |
|    entropy_loss          | 1.27       |
|    explained_variance    | 0.922      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.432      |
|    n_updates             | 12870      |
|    policy_gradient_loss  | 0.00817    |
|    std                   | 0.217      |
|    value_loss            | 0.924      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.34298888 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2639872     |
| train/                   |             |
|    approx_kl             | 0.041401654 |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.44       |
|    entropy               | 1.28        |
|    entropy_loss          | 1.27        |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.49        |
|    n_updates             | 12880       |
|    policy_gradient_loss  | 0.013       |
|    std                   | 0.216       |
|    value_loss            | 0.919       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.33156052 |
| rollout/                 |             |
|    ep_len_mean           | 40.5        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 16          |
|    time_elapsed          | 360         |
|    total_timesteps       | 2641920     |
| train/                   |             |
|    approx_kl             | 0.033982065 |
|    clip_fraction         | 0.257       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.64        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.434      |
|    entropy               | 1.27        |
|    entropy_loss          | 1.28        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.408       |
|    n_updates             | 12890       |
|    policy_gradient_loss  | 0.00671     |
|    std                   | 0.217       |
|    value_loss            | 0.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.34018415 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 17          |
|    time_elapsed          | 382         |
|    total_timesteps       | 2643968     |
| train/                   |             |
|    approx_kl             | 0.04769159  |
|    clip_fraction         | 0.227       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.3         |
|    cost_value_loss       | 108         |
|    cost_values           | -0.445      |
|    entropy               | 1.28        |
|    entropy_loss          | 1.28        |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.296       |
|    n_updates             | 12900       |
|    policy_gradient_loss  | 0.00928     |
|    std                   | 0.216       |
|    value_loss            | 0.563       |
------------------------------------------
-----------------------------------------
| avg_speed                | 1          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1          |
| reward                   | -0.5564972 |
| rollout/                 |            |
|    ep_len_mean           | 42.3       |
|    ep_rew_mean           | -15        |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 18         |
|    time_elapsed          | 405        |
|    total_timesteps       | 2646016    |
| train/                   |            |
|    approx_kl             | 0.02970905 |
|    clip_fraction         | 0.303      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.84       |
|    cost_value_loss       | 120        |
|    cost_values           | -0.439     |
|    entropy               | 1.29       |
|    entropy_loss          | 1.28       |
|    explained_variance    | 0.964      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.234      |
|    n_updates             | 12910      |
|    policy_gradient_loss  | 0.0218     |
|    std                   | 0.215      |
|    value_loss            | 0.496      |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.39925265 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 19          |
|    time_elapsed          | 428         |
|    total_timesteps       | 2648064     |
| train/                   |             |
|    approx_kl             | 0.021959158 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.445      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.201       |
|    n_updates             | 12920       |
|    policy_gradient_loss  | 0.00219     |
|    std                   | 0.213       |
|    value_loss            | 0.422       |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.28743348 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 20          |
|    time_elapsed          | 450         |
|    total_timesteps       | 2650112     |
| train/                   |             |
|    approx_kl             | 0.014332401 |
|    clip_fraction         | 0.263       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.441      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.543       |
|    n_updates             | 12930       |
|    policy_gradient_loss  | 0.00816     |
|    std                   | 0.214       |
|    value_loss            | 1.18        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.4        |
| reward                   | -0.383164  |
| rollout/                 |            |
|    ep_len_mean           | 43.8       |
|    ep_rew_mean           | -15.4      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 21         |
|    time_elapsed          | 473        |
|    total_timesteps       | 2652160    |
| train/                   |            |
|    approx_kl             | 0.03013835 |
|    clip_fraction         | 0.247      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.73       |
|    cost_value_loss       | 117        |
|    cost_values           | -0.444     |
|    entropy               | 1.3        |
|    entropy_loss          | 1.3        |
|    explained_variance    | 0.945      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.37       |
|    n_updates             | 12940      |
|    policy_gradient_loss  | 0.00938    |
|    std                   | 0.214      |
|    value_loss            | 0.707      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.51528543 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 496         |
|    total_timesteps       | 2654208     |
| train/                   |             |
|    approx_kl             | 0.068861574 |
|    clip_fraction         | 0.312       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.94        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.424      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.392       |
|    n_updates             | 12950       |
|    policy_gradient_loss  | 0.0181      |
|    std                   | 0.214       |
|    value_loss            | 0.815       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.29227987 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 518         |
|    total_timesteps       | 2656256     |
| train/                   |             |
|    approx_kl             | 0.029637937 |
|    clip_fraction         | 0.344       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.62        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.438      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.358       |
|    n_updates             | 12960       |
|    policy_gradient_loss  | 0.0197      |
|    std                   | 0.214       |
|    value_loss            | 0.788       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.3029253  |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 541         |
|    total_timesteps       | 2658304     |
| train/                   |             |
|    approx_kl             | 0.051585823 |
|    clip_fraction         | 0.278       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.73        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.45       |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.425       |
|    n_updates             | 12970       |
|    policy_gradient_loss  | 0.00956     |
|    std                   | 0.214       |
|    value_loss            | 0.934       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.1792323  |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 564         |
|    total_timesteps       | 2660352     |
| train/                   |             |
|    approx_kl             | 0.049495727 |
|    clip_fraction         | 0.291       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.458      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.433       |
|    n_updates             | 12980       |
|    policy_gradient_loss  | 0.0155      |
|    std                   | 0.214       |
|    value_loss            | 0.839       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.44203112 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 587         |
|    total_timesteps       | 2662400     |
| train/                   |             |
|    approx_kl             | 0.026865281 |
|    clip_fraction         | 0.239       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.442      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.441       |
|    n_updates             | 12990       |
|    policy_gradient_loss  | 0.00544     |
|    std                   | 0.214       |
|    value_loss            | 0.864       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.75        |
| reward                   | -0.34385276 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 27          |
|    time_elapsed          | 609         |
|    total_timesteps       | 2664448     |
| train/                   |             |
|    approx_kl             | 0.024951829 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.77        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.42       |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.556       |
|    n_updates             | 13000       |
|    policy_gradient_loss  | 0.00849     |
|    std                   | 0.214       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.37402853 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 632         |
|    total_timesteps       | 2666496     |
| train/                   |             |
|    approx_kl             | 0.022152118 |
|    clip_fraction         | 0.247       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.35        |
|    cost_value_loss       | 110         |
|    cost_values           | -0.455      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.401       |
|    n_updates             | 13010       |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.215       |
|    value_loss            | 0.826       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.5080112  |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 655         |
|    total_timesteps       | 2668544     |
| train/                   |             |
|    approx_kl             | 0.038526386 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.83        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.434      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.419       |
|    n_updates             | 13020       |
|    policy_gradient_loss  | 0.0099      |
|    std                   | 0.216       |
|    value_loss            | 0.737       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.93        |
| reward                   | -0.382762   |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 678         |
|    total_timesteps       | 2670592     |
| train/                   |             |
|    approx_kl             | 0.025227668 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.9         |
|    cost_value_loss       | 121         |
|    cost_values           | -0.435      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.283       |
|    n_updates             | 13030       |
|    policy_gradient_loss  | 0.00767     |
|    std                   | 0.218       |
|    value_loss            | 0.686       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.3719976  |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 701         |
|    total_timesteps       | 2672640     |
| train/                   |             |
|    approx_kl             | 0.069428205 |
|    clip_fraction         | 0.256       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.81        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.445      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.3         |
|    n_updates             | 13040       |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.218       |
|    value_loss            | 0.579       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27064303 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 724         |
|    total_timesteps       | 2674688     |
| train/                   |             |
|    approx_kl             | 0.023672638 |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.55        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.458      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.323       |
|    n_updates             | 13050       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.219       |
|    value_loss            | 0.673       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.98        |
| reward                   | -0.22377777 |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 747         |
|    total_timesteps       | 2676736     |
| train/                   |             |
|    approx_kl             | 0.057740346 |
|    clip_fraction         | 0.334       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.85        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.444      |
|    entropy               | 1.28        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.396       |
|    n_updates             | 13060       |
|    policy_gradient_loss  | 0.0177      |
|    std                   | 0.219       |
|    value_loss            | 0.691       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.50602764 |
| rollout/                 |             |
|    ep_len_mean           | 40.3        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 770         |
|    total_timesteps       | 2678784     |
| train/                   |             |
|    approx_kl             | 0.04362093  |
|    clip_fraction         | 0.321       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.36        |
|    cost_value_loss       | 110         |
|    cost_values           | -0.461      |
|    entropy               | 1.28        |
|    entropy_loss          | 1.28        |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.502       |
|    n_updates             | 13070       |
|    policy_gradient_loss  | 0.0209      |
|    std                   | 0.219       |
|    value_loss            | 0.974       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.35072246 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -14.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 35          |
|    time_elapsed          | 793         |
|    total_timesteps       | 2680832     |
| train/                   |             |
|    approx_kl             | 0.039227936 |
|    clip_fraction         | 0.358       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.56        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.448      |
|    entropy               | 1.28        |
|    entropy_loss          | 1.28        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.375       |
|    n_updates             | 13080       |
|    policy_gradient_loss  | 0.0284      |
|    std                   | 0.218       |
|    value_loss            | 0.783       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13222834 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 36          |
|    time_elapsed          | 815         |
|    total_timesteps       | 2682880     |
| train/                   |             |
|    approx_kl             | 0.09078255  |
|    clip_fraction         | 0.296       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.56        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.457      |
|    entropy               | 1.29        |
|    entropy_loss          | 1.29        |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.56        |
|    n_updates             | 13090       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.217       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.23040493 |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 838         |
|    total_timesteps       | 2684928     |
| train/                   |             |
|    approx_kl             | 0.036800202 |
|    clip_fraction         | 0.306       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.451      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.418       |
|    n_updates             | 13100       |
|    policy_gradient_loss  | 0.017       |
|    std                   | 0.217       |
|    value_loss            | 0.777       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.37730086 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 861         |
|    total_timesteps       | 2686976     |
| train/                   |             |
|    approx_kl             | 0.0739085   |
|    clip_fraction         | 0.275       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.88        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.434      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.266       |
|    n_updates             | 13110       |
|    policy_gradient_loss  | 0.0167      |
|    std                   | 0.217       |
|    value_loss            | 0.572       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.5174307  |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 884         |
|    total_timesteps       | 2689024     |
| train/                   |             |
|    approx_kl             | 0.038918734 |
|    clip_fraction         | 0.335       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.52        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.47       |
|    entropy               | 1.31        |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.269       |
|    n_updates             | 13120       |
|    policy_gradient_loss  | 0.0259      |
|    std                   | 0.215       |
|    value_loss            | 0.595       |
------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.5366807 |
| rollout/                 |            |
|    ep_len_mean           | 41.6       |
|    ep_rew_mean           | -14.5      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 40         |
|    time_elapsed          | 907        |
|    total_timesteps       | 2691072    |
| train/                   |            |
|    approx_kl             | 0.09006374 |
|    clip_fraction         | 0.339      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.63       |
|    cost_value_loss       | 116        |
|    cost_values           | -0.447     |
|    entropy               | 1.32       |
|    entropy_loss          | 1.32       |
|    explained_variance    | 0.93       |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.391      |
|    n_updates             | 13130      |
|    policy_gradient_loss  | 0.0136     |
|    std                   | 0.215      |
|    value_loss            | 0.818      |
-----------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.34491807 |
| rollout/                 |             |
|    ep_len_mean           | 40.9        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 930         |
|    total_timesteps       | 2693120     |
| train/                   |             |
|    approx_kl             | 0.053642113 |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.65        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.453      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.276       |
|    n_updates             | 13140       |
|    policy_gradient_loss  | 0.0129      |
|    std                   | 0.214       |
|    value_loss            | 0.526       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.50941986 |
| rollout/                 |             |
|    ep_len_mean           | 40.6        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 952         |
|    total_timesteps       | 2695168     |
| train/                   |             |
|    approx_kl             | 0.055343304 |
|    clip_fraction         | 0.329       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.43        |
|    cost_value_loss       | 112         |
|    cost_values           | -0.453      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.328       |
|    n_updates             | 13150       |
|    policy_gradient_loss  | 0.0184      |
|    std                   | 0.213       |
|    value_loss            | 0.515       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.18608095 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 43          |
|    time_elapsed          | 975         |
|    total_timesteps       | 2697216     |
| train/                   |             |
|    approx_kl             | 0.026842918 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.57        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.447      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.286       |
|    n_updates             | 13160       |
|    policy_gradient_loss  | 0.00794     |
|    std                   | 0.213       |
|    value_loss            | 0.588       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.24175379 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 998         |
|    total_timesteps       | 2699264     |
| train/                   |             |
|    approx_kl             | 0.021186527 |
|    clip_fraction         | 0.255       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.71        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.451      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.249       |
|    n_updates             | 13170       |
|    policy_gradient_loss  | 0.00636     |
|    std                   | 0.214       |
|    value_loss            | 0.587       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.3036363  |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 2701312     |
| train/                   |             |
|    approx_kl             | 0.071246214 |
|    clip_fraction         | 0.29        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.42        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.453      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.281       |
|    n_updates             | 13180       |
|    policy_gradient_loss  | 0.0151      |
|    std                   | 0.214       |
|    value_loss            | 0.563       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.52762496 |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1043        |
|    total_timesteps       | 2703360     |
| train/                   |             |
|    approx_kl             | 0.042692848 |
|    clip_fraction         | 0.293       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.86        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.443      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.371       |
|    n_updates             | 13190       |
|    policy_gradient_loss  | 0.00637     |
|    std                   | 0.215       |
|    value_loss            | 0.653       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.47898123 |
| rollout/                 |             |
|    ep_len_mean           | 40.3        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1066        |
|    total_timesteps       | 2705408     |
| train/                   |             |
|    approx_kl             | 0.083073504 |
|    clip_fraction         | 0.303       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.23        |
|    cost_value_loss       | 107         |
|    cost_values           | -0.444      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.34        |
|    n_updates             | 13200       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.215       |
|    value_loss            | 0.715       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.32608065 |
| rollout/                 |             |
|    ep_len_mean           | 40.9        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1089        |
|    total_timesteps       | 2707456     |
| train/                   |             |
|    approx_kl             | 0.04050748  |
|    clip_fraction         | 0.288       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.7         |
|    cost_value_loss       | 118         |
|    cost_values           | -0.447      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.498       |
|    n_updates             | 13210       |
|    policy_gradient_loss  | 0.0152      |
|    std                   | 0.214       |
|    value_loss            | 0.974       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.32771784 |
| rollout/                 |             |
|    ep_len_mean           | 40.1        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1111        |
|    total_timesteps       | 2709504     |
| train/                   |             |
|    approx_kl             | 0.021310255 |
|    clip_fraction         | 0.266       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.41        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.448      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.478       |
|    n_updates             | 13220       |
|    policy_gradient_loss  | 0.00956     |
|    std                   | 0.214       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------
| avg_speed          | 6           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 6           |
| reward             | -0.26819003 |
| rollout/           |             |
|    ep_len_mean     | 40.5        |
|    ep_rew_mean     | -14.4       |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2711552     |
------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.3268251  |
| rollout/                 |             |
|    ep_len_mean           | 40.5        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2713600     |
| train/                   |             |
|    approx_kl             | 0.031513676 |
|    clip_fraction         | 0.263       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.38        |
|    cost_value_loss       | 110         |
|    cost_values           | -0.441      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.285       |
|    n_updates             | 13240       |
|    policy_gradient_loss  | 0.00865     |
|    std                   | 0.213       |
|    value_loss            | 0.631       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.26494572 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -14.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2715648     |
| train/                   |             |
|    approx_kl             | 0.0184386   |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.56        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.443      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.289       |
|    n_updates             | 13250       |
|    policy_gradient_loss  | 0.00904     |
|    std                   | 0.213       |
|    value_loss            | 0.624       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.46        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.46        |
| reward                   | -0.20337178 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -14.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2717696     |
| train/                   |             |
|    approx_kl             | 0.026509926 |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.51        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.454      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.386       |
|    n_updates             | 13260       |
|    policy_gradient_loss  | 0.00771     |
|    std                   | 0.213       |
|    value_loss            | 0.734       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.35281032 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2719744     |
| train/                   |             |
|    approx_kl             | 0.021476552 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.65        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.439      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.439       |
|    n_updates             | 13270       |
|    policy_gradient_loss  | 0.000961    |
|    std                   | 0.213       |
|    value_loss            | 0.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.25944477 |
| rollout/                 |             |
|    ep_len_mean           | 40.9        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2721792     |
| train/                   |             |
|    approx_kl             | 0.034230094 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.58        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.459      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.36        |
|    n_updates             | 13280       |
|    policy_gradient_loss  | 0.00658     |
|    std                   | 0.214       |
|    value_loss            | 0.714       |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.4        |
| reward                   | -0.6013508 |
| rollout/                 |            |
|    ep_len_mean           | 41         |
|    ep_rew_mean           | -14.6      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 7          |
|    time_elapsed          | 157        |
|    total_timesteps       | 2723840    |
| train/                   |            |
|    approx_kl             | 0.02428682 |
|    clip_fraction         | 0.238      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.51       |
|    cost_value_loss       | 113        |
|    cost_values           | -0.443     |
|    entropy               | 1.34       |
|    entropy_loss          | 1.33       |
|    explained_variance    | 0.937      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.371      |
|    n_updates             | 13290      |
|    policy_gradient_loss  | 0.012      |
|    std                   | 0.213      |
|    value_loss            | 0.78       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.2675606  |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -14.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 8           |
|    time_elapsed          | 180         |
|    total_timesteps       | 2725888     |
| train/                   |             |
|    approx_kl             | 0.041487295 |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.58        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.455      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.331       |
|    n_updates             | 13300       |
|    policy_gradient_loss  | 0.00689     |
|    std                   | 0.213       |
|    value_loss            | 0.667       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.33657488 |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -14.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2727936     |
| train/                   |             |
|    approx_kl             | 0.01693075  |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.33        |
|    cost_value_loss       | 109         |
|    cost_values           | -0.447      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.229       |
|    n_updates             | 13310       |
|    policy_gradient_loss  | 0.0135      |
|    std                   | 0.214       |
|    value_loss            | 0.527       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.54965544 |
| rollout/                 |             |
|    ep_len_mean           | 40.7        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 10          |
|    time_elapsed          | 225         |
|    total_timesteps       | 2729984     |
| train/                   |             |
|    approx_kl             | 0.031037912 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.5         |
|    cost_value_loss       | 113         |
|    cost_values           | -0.451      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.267       |
|    n_updates             | 13320       |
|    policy_gradient_loss  | 0.00271     |
|    std                   | 0.214       |
|    value_loss            | 0.527       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.265578   |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2732032     |
| train/                   |             |
|    approx_kl             | 0.017373241 |
|    clip_fraction         | 0.255       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.48        |
|    cost_value_loss       | 112         |
|    cost_values           | -0.45       |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.198       |
|    n_updates             | 13330       |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.214       |
|    value_loss            | 0.469       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.4355332  |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 12          |
|    time_elapsed          | 270         |
|    total_timesteps       | 2734080     |
| train/                   |             |
|    approx_kl             | 0.029556457 |
|    clip_fraction         | 0.289       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.78        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.457      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.516       |
|    n_updates             | 13340       |
|    policy_gradient_loss  | 0.0123      |
|    std                   | 0.214       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.18        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.18        |
| reward                   | -0.30611238 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 2736128     |
| train/                   |             |
|    approx_kl             | 0.021838134 |
|    clip_fraction         | 0.323       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.448      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.386       |
|    n_updates             | 13350       |
|    policy_gradient_loss  | 0.0167      |
|    std                   | 0.213       |
|    value_loss            | 0.873       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.56123036 |
| rollout/                 |             |
|    ep_len_mean           | 40.1        |
|    ep_rew_mean           | -14         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 14          |
|    time_elapsed          | 315         |
|    total_timesteps       | 2738176     |
| train/                   |             |
|    approx_kl             | 0.028480642 |
|    clip_fraction         | 0.299       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.6         |
|    cost_value_loss       | 115         |
|    cost_values           | -0.458      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.398       |
|    n_updates             | 13360       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.213       |
|    value_loss            | 0.873       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.51554286 |
| rollout/                 |             |
|    ep_len_mean           | 39.5        |
|    ep_rew_mean           | -14         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 15          |
|    time_elapsed          | 338         |
|    total_timesteps       | 2740224     |
| train/                   |             |
|    approx_kl             | 0.023758657 |
|    clip_fraction         | 0.256       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.22        |
|    cost_value_loss       | 107         |
|    cost_values           | -0.448      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.248       |
|    n_updates             | 13370       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.214       |
|    value_loss            | 0.594       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.37        |
| reward                   | -0.378661   |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 16          |
|    time_elapsed          | 360         |
|    total_timesteps       | 2742272     |
| train/                   |             |
|    approx_kl             | 0.039932705 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.49        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.457      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.324       |
|    n_updates             | 13380       |
|    policy_gradient_loss  | 0.00547     |
|    std                   | 0.215       |
|    value_loss            | 0.703       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.30734947 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 17          |
|    time_elapsed          | 383         |
|    total_timesteps       | 2744320     |
| train/                   |             |
|    approx_kl             | 0.034446117 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.79        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.453      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.488       |
|    n_updates             | 13390       |
|    policy_gradient_loss  | 0.00526     |
|    std                   | 0.214       |
|    value_loss            | 1.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.29908875 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 18          |
|    time_elapsed          | 405         |
|    total_timesteps       | 2746368     |
| train/                   |             |
|    approx_kl             | 0.021332419 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.65        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.445      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.365       |
|    n_updates             | 13400       |
|    policy_gradient_loss  | 0.00879     |
|    std                   | 0.214       |
|    value_loss            | 0.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.48276788 |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 19          |
|    time_elapsed          | 428         |
|    total_timesteps       | 2748416     |
| train/                   |             |
|    approx_kl             | 0.028781796 |
|    clip_fraction         | 0.239       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.87        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.433      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.433       |
|    n_updates             | 13410       |
|    policy_gradient_loss  | 0.00766     |
|    std                   | 0.214       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.3591326  |
| rollout/                 |             |
|    ep_len_mean           | 40.3        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 20          |
|    time_elapsed          | 450         |
|    total_timesteps       | 2750464     |
| train/                   |             |
|    approx_kl             | 0.039051335 |
|    clip_fraction         | 0.239       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.55        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.456      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.601       |
|    n_updates             | 13420       |
|    policy_gradient_loss  | 0.00995     |
|    std                   | 0.215       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.32140878 |
| rollout/                 |             |
|    ep_len_mean           | 40.3        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 21          |
|    time_elapsed          | 473         |
|    total_timesteps       | 2752512     |
| train/                   |             |
|    approx_kl             | 0.040108543 |
|    clip_fraction         | 0.268       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.4         |
|    cost_value_loss       | 111         |
|    cost_values           | -0.441      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.478       |
|    n_updates             | 13430       |
|    policy_gradient_loss  | 0.00586     |
|    std                   | 0.214       |
|    value_loss            | 0.951       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.12869692 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 495         |
|    total_timesteps       | 2754560     |
| train/                   |             |
|    approx_kl             | 0.026927501 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.59        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.45       |
|    entropy               | 1.34        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.407       |
|    n_updates             | 13440       |
|    policy_gradient_loss  | 0.00501     |
|    std                   | 0.214       |
|    value_loss            | 0.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.2682502  |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 518         |
|    total_timesteps       | 2756608     |
| train/                   |             |
|    approx_kl             | 0.027440201 |
|    clip_fraction         | 0.245       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.76        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.442      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.258       |
|    n_updates             | 13450       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.214       |
|    value_loss            | 0.52        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.3584291 |
| rollout/                 |            |
|    ep_len_mean           | 42.4       |
|    ep_rew_mean           | -15.2      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 24         |
|    time_elapsed          | 540        |
|    total_timesteps       | 2758656    |
| train/                   |            |
|    approx_kl             | 0.05095277 |
|    clip_fraction         | 0.29       |
|    clip_range            | 0.2        |
|    cost_returns          | 9.34       |
|    cost_value_loss       | 110        |
|    cost_values           | -0.447     |
|    entropy               | 1.35       |
|    entropy_loss          | 1.35       |
|    explained_variance    | 0.942      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.484      |
|    n_updates             | 13460      |
|    policy_gradient_loss  | 0.0184     |
|    std                   | 0.214      |
|    value_loss            | 0.806      |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.29289776 |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 563         |
|    total_timesteps       | 2760704     |
| train/                   |             |
|    approx_kl             | 0.046080817 |
|    clip_fraction         | 0.292       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.429      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.442       |
|    n_updates             | 13470       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.214       |
|    value_loss            | 0.968       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.37347707 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 585         |
|    total_timesteps       | 2762752     |
| train/                   |             |
|    approx_kl             | 0.02761218  |
|    clip_fraction         | 0.268       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.92        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.447      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.456       |
|    n_updates             | 13480       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.214       |
|    value_loss            | 0.975       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.24184483 |
| rollout/                 |             |
|    ep_len_mean           | 40.9        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 27          |
|    time_elapsed          | 608         |
|    total_timesteps       | 2764800     |
| train/                   |             |
|    approx_kl             | 0.02770865  |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.52        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.447      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.412       |
|    n_updates             | 13490       |
|    policy_gradient_loss  | 0.00528     |
|    std                   | 0.215       |
|    value_loss            | 0.897       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.33477384 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 631         |
|    total_timesteps       | 2766848     |
| train/                   |             |
|    approx_kl             | 0.01691965  |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.51        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.448      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.289       |
|    n_updates             | 13500       |
|    policy_gradient_loss  | 0.00871     |
|    std                   | 0.215       |
|    value_loss            | 0.623       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.29108065 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 653         |
|    total_timesteps       | 2768896     |
| train/                   |             |
|    approx_kl             | 0.027746089 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.87        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.427      |
|    entropy               | 1.36        |
|    entropy_loss          | 1.36        |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.292       |
|    n_updates             | 13510       |
|    policy_gradient_loss  | 0.00427     |
|    std                   | 0.215       |
|    value_loss            | 0.504       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.24394383 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 676         |
|    total_timesteps       | 2770944     |
| train/                   |             |
|    approx_kl             | 0.018950246 |
|    clip_fraction         | 0.276       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.89        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.434      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.36        |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.449       |
|    n_updates             | 13520       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.214       |
|    value_loss            | 0.918       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.18082307 |
| rollout/                 |             |
|    ep_len_mean           | 39.5        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 698         |
|    total_timesteps       | 2772992     |
| train/                   |             |
|    approx_kl             | 0.025718924 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.36        |
|    cost_value_loss       | 110         |
|    cost_values           | -0.446      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.42        |
|    n_updates             | 13530       |
|    policy_gradient_loss  | 0.00826     |
|    std                   | 0.215       |
|    value_loss            | 0.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.6033718  |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 721         |
|    total_timesteps       | 2775040     |
| train/                   |             |
|    approx_kl             | 0.054022707 |
|    clip_fraction         | 0.272       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.4         |
|    cost_value_loss       | 111         |
|    cost_values           | -0.459      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.358       |
|    n_updates             | 13540       |
|    policy_gradient_loss  | 0.00632     |
|    std                   | 0.216       |
|    value_loss            | 0.707       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.4        |
| reward                   | -0.4699624 |
| rollout/                 |            |
|    ep_len_mean           | 44.6       |
|    ep_rew_mean           | -15.5      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 33         |
|    time_elapsed          | 744        |
|    total_timesteps       | 2777088    |
| train/                   |            |
|    approx_kl             | 0.03642722 |
|    clip_fraction         | 0.286      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.78       |
|    cost_value_loss       | 119        |
|    cost_values           | -0.44      |
|    entropy               | 1.37       |
|    entropy_loss          | 1.37       |
|    explained_variance    | 0.958      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.273      |
|    n_updates             | 13550      |
|    policy_gradient_loss  | 0.0261     |
|    std                   | 0.216      |
|    value_loss            | 0.554      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.46487775 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 766         |
|    total_timesteps       | 2779136     |
| train/                   |             |
|    approx_kl             | 0.03700048  |
|    clip_fraction         | 0.271       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 129         |
|    cost_values           | -0.424      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.347       |
|    n_updates             | 13560       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.216       |
|    value_loss            | 0.646       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.53884    |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 35          |
|    time_elapsed          | 789         |
|    total_timesteps       | 2781184     |
| train/                   |             |
|    approx_kl             | 0.041442666 |
|    clip_fraction         | 0.286       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.79        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.428      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.459       |
|    n_updates             | 13570       |
|    policy_gradient_loss  | 0.0226      |
|    std                   | 0.216       |
|    value_loss            | 0.926       |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.4        |
| reward                   | -0.4685858 |
| rollout/                 |            |
|    ep_len_mean           | 40.9       |
|    ep_rew_mean           | -14.7      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 36         |
|    time_elapsed          | 811        |
|    total_timesteps       | 2783232    |
| train/                   |            |
|    approx_kl             | 0.05001077 |
|    clip_fraction         | 0.297      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.44       |
|    cost_value_loss       | 112        |
|    cost_values           | -0.453     |
|    entropy               | 1.37       |
|    entropy_loss          | 1.37       |
|    explained_variance    | 0.93       |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.498      |
|    n_updates             | 13580      |
|    policy_gradient_loss  | 0.0144     |
|    std                   | 0.217      |
|    value_loss            | 1.01       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.3099419  |
| rollout/                 |             |
|    ep_len_mean           | 40.7        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 834         |
|    total_timesteps       | 2785280     |
| train/                   |             |
|    approx_kl             | 0.022671541 |
|    clip_fraction         | 0.325       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.64        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.443      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.245       |
|    n_updates             | 13590       |
|    policy_gradient_loss  | 0.0135      |
|    std                   | 0.217       |
|    value_loss            | 0.521       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.35338628 |
| rollout/                 |             |
|    ep_len_mean           | 40.9        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 856         |
|    total_timesteps       | 2787328     |
| train/                   |             |
|    approx_kl             | 0.04021305  |
|    clip_fraction         | 0.28        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.33        |
|    cost_value_loss       | 109         |
|    cost_values           | -0.432      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.237       |
|    n_updates             | 13600       |
|    policy_gradient_loss  | 0.00696     |
|    std                   | 0.217       |
|    value_loss            | 0.541       |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.32080686 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 879         |
|    total_timesteps       | 2789376     |
| train/                   |             |
|    approx_kl             | 0.10743763  |
|    clip_fraction         | 0.36        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.72        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.432      |
|    entropy               | 1.36        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.325       |
|    n_updates             | 13610       |
|    policy_gradient_loss  | 0.0201      |
|    std                   | 0.217       |
|    value_loss            | 0.595       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.4540948  |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 40          |
|    time_elapsed          | 901         |
|    total_timesteps       | 2791424     |
| train/                   |             |
|    approx_kl             | 0.040847704 |
|    clip_fraction         | 0.332       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.72        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.439      |
|    entropy               | 1.36        |
|    entropy_loss          | 1.36        |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.352       |
|    n_updates             | 13620       |
|    policy_gradient_loss  | 0.019       |
|    std                   | 0.218       |
|    value_loss            | 0.607       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.31356943 |
| rollout/                 |             |
|    ep_len_mean           | 40.5        |
|    ep_rew_mean           | -14         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 924         |
|    total_timesteps       | 2793472     |
| train/                   |             |
|    approx_kl             | 0.07253651  |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.49        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.431      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.394       |
|    n_updates             | 13630       |
|    policy_gradient_loss  | 0.00747     |
|    std                   | 0.219       |
|    value_loss            | 0.721       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.27452815 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 946         |
|    total_timesteps       | 2795520     |
| train/                   |             |
|    approx_kl             | 0.07268084  |
|    clip_fraction         | 0.279       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.54        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.424      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.421       |
|    n_updates             | 13640       |
|    policy_gradient_loss  | 0.00283     |
|    std                   | 0.219       |
|    value_loss            | 0.889       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.49857926 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 43          |
|    time_elapsed          | 969         |
|    total_timesteps       | 2797568     |
| train/                   |             |
|    approx_kl             | 0.03707948  |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.86        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.436      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.629       |
|    n_updates             | 13650       |
|    policy_gradient_loss  | 0.00846     |
|    std                   | 0.219       |
|    value_loss            | 1.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.36340538 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 44          |
|    time_elapsed          | 991         |
|    total_timesteps       | 2799616     |
| train/                   |             |
|    approx_kl             | 0.037364207 |
|    clip_fraction         | 0.324       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.438      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.39        |
|    n_updates             | 13660       |
|    policy_gradient_loss  | 0.0163      |
|    std                   | 0.219       |
|    value_loss            | 0.877       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.35973838 |
| rollout/                 |             |
|    ep_len_mean           | 40.1        |
|    ep_rew_mean           | -14.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 2801664     |
| train/                   |             |
|    approx_kl             | 0.038354505 |
|    clip_fraction         | 0.283       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.45        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.458      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.583       |
|    n_updates             | 13670       |
|    policy_gradient_loss  | 0.0161      |
|    std                   | 0.219       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.38934147 |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1036        |
|    total_timesteps       | 2803712     |
| train/                   |             |
|    approx_kl             | 0.0492781   |
|    clip_fraction         | 0.379       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.48        |
|    cost_value_loss       | 112         |
|    cost_values           | -0.431      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.294       |
|    n_updates             | 13680       |
|    policy_gradient_loss  | 0.029       |
|    std                   | 0.219       |
|    value_loss            | 0.582       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.31072345 |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 2805760     |
| train/                   |             |
|    approx_kl             | 0.03703093  |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.64        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.422      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.281       |
|    n_updates             | 13690       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.22        |
|    value_loss            | 0.747       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.6441799  |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1081        |
|    total_timesteps       | 2807808     |
| train/                   |             |
|    approx_kl             | 0.040267076 |
|    clip_fraction         | 0.304       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.93        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.427      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.377       |
|    n_updates             | 13700       |
|    policy_gradient_loss  | 0.0168      |
|    std                   | 0.221       |
|    value_loss            | 0.841       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.24276441 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1104        |
|    total_timesteps       | 2809856     |
| train/                   |             |
|    approx_kl             | 0.051159624 |
|    clip_fraction         | 0.385       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.62        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.422      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.395       |
|    n_updates             | 13710       |
|    policy_gradient_loss  | 0.035       |
|    std                   | 0.221       |
|    value_loss            | 0.881       |
------------------------------------------
-----------------------------------
| avg_speed          | 6.77       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 6.77       |
| reward             | -0.3669986 |
| rollout/           |            |
|    ep_len_mean     | 42.5       |
|    ep_rew_mean     | -15.1      |
| time/              |            |
|    fps             | 92         |
|    iterations      | 1          |
|    time_elapsed    | 22         |
|    total_timesteps | 2811904    |
-----------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.31125498 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2813952     |
| train/                   |             |
|    approx_kl             | 0.03891946  |
|    clip_fraction         | 0.303       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.88        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.425      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.682       |
|    n_updates             | 13730       |
|    policy_gradient_loss  | 0.0189      |
|    std                   | 0.222       |
|    value_loss            | 1.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.3099419  |
| rollout/                 |             |
|    ep_len_mean           | 40.7        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2816000     |
| train/                   |             |
|    approx_kl             | 0.044396877 |
|    clip_fraction         | 0.357       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.43        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.434      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.447       |
|    n_updates             | 13740       |
|    policy_gradient_loss  | 0.0208      |
|    std                   | 0.222       |
|    value_loss            | 0.939       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.42087463 |
| rollout/                 |             |
|    ep_len_mean           | 40.5        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2818048     |
| train/                   |             |
|    approx_kl             | 0.052019235 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.7         |
|    cost_value_loss       | 118         |
|    cost_values           | -0.431      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.573       |
|    n_updates             | 13750       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.221       |
|    value_loss            | 1.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.1432932  |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 2820096     |
| train/                   |             |
|    approx_kl             | 0.026159614 |
|    clip_fraction         | 0.246       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.45        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.443      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.51        |
|    n_updates             | 13760       |
|    policy_gradient_loss  | 0.0074      |
|    std                   | 0.22        |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34157658 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2822144     |
| train/                   |             |
|    approx_kl             | 0.054421715 |
|    clip_fraction         | 0.33        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 125         |
|    cost_values           | -0.421      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.497       |
|    n_updates             | 13770       |
|    policy_gradient_loss  | 0.0216      |
|    std                   | 0.221       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.21221538 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 156         |
|    total_timesteps       | 2824192     |
| train/                   |             |
|    approx_kl             | 0.06639595  |
|    clip_fraction         | 0.343       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.81        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.428      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.645       |
|    n_updates             | 13780       |
|    policy_gradient_loss  | 0.0279      |
|    std                   | 0.221       |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.35702118 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 179         |
|    total_timesteps       | 2826240     |
| train/                   |             |
|    approx_kl             | 0.08336548  |
|    clip_fraction         | 0.292       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.45        |
|    cost_value_loss       | 112         |
|    cost_values           | -0.439      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.704       |
|    n_updates             | 13790       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.221       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.5038744  |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 201         |
|    total_timesteps       | 2828288     |
| train/                   |             |
|    approx_kl             | 0.033078764 |
|    clip_fraction         | 0.309       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.96        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.449      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.497       |
|    n_updates             | 13800       |
|    policy_gradient_loss  | 0.0164      |
|    std                   | 0.221       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.31584102 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 2830336     |
| train/                   |             |
|    approx_kl             | 0.06291719  |
|    clip_fraction         | 0.343       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.98        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.437      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.344       |
|    n_updates             | 13810       |
|    policy_gradient_loss  | 0.0236      |
|    std                   | 0.222       |
|    value_loss            | 0.601       |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.2        |
| reward                   | -0.53797   |
| rollout/                 |            |
|    ep_len_mean           | 41.9       |
|    ep_rew_mean           | -14.7      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 11         |
|    time_elapsed          | 247        |
|    total_timesteps       | 2832384    |
| train/                   |            |
|    approx_kl             | 0.08432312 |
|    clip_fraction         | 0.336      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.91       |
|    cost_value_loss       | 122        |
|    cost_values           | -0.437     |
|    entropy               | 1.32       |
|    entropy_loss          | 1.31       |
|    explained_variance    | 0.915      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.508      |
|    n_updates             | 13820      |
|    policy_gradient_loss  | 0.0191     |
|    std                   | 0.221      |
|    value_loss            | 1.11       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.3324785  |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 269         |
|    total_timesteps       | 2834432     |
| train/                   |             |
|    approx_kl             | 0.037738323 |
|    clip_fraction         | 0.362       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.54        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.432      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.524       |
|    n_updates             | 13830       |
|    policy_gradient_loss  | 0.0139      |
|    std                   | 0.221       |
|    value_loss            | 1.19        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.6        |
| reward                   | -0.4840186 |
| rollout/                 |            |
|    ep_len_mean           | 41.2       |
|    ep_rew_mean           | -14.3      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 13         |
|    time_elapsed          | 292        |
|    total_timesteps       | 2836480    |
| train/                   |            |
|    approx_kl             | 0.03551425 |
|    clip_fraction         | 0.289      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.88       |
|    cost_value_loss       | 121        |
|    cost_values           | -0.438     |
|    entropy               | 1.31       |
|    entropy_loss          | 1.31       |
|    explained_variance    | 0.914      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.39       |
|    n_updates             | 13840      |
|    policy_gradient_loss  | 0.0135     |
|    std                   | 0.221      |
|    value_loss            | 0.947      |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.39995039 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 314         |
|    total_timesteps       | 2838528     |
| train/                   |             |
|    approx_kl             | 0.06338011  |
|    clip_fraction         | 0.276       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.29        |
|    cost_value_loss       | 108         |
|    cost_values           | -0.437      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.281       |
|    n_updates             | 13850       |
|    policy_gradient_loss  | 0.017       |
|    std                   | 0.219       |
|    value_loss            | 0.653       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.4        |
| reward                   | -0.5107491 |
| rollout/                 |            |
|    ep_len_mean           | 41.6       |
|    ep_rew_mean           | -14.8      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 15         |
|    time_elapsed          | 336        |
|    total_timesteps       | 2840576    |
| train/                   |            |
|    approx_kl             | 0.03816752 |
|    clip_fraction         | 0.275      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.84       |
|    cost_value_loss       | 119        |
|    cost_values           | -0.424     |
|    entropy               | 1.32       |
|    entropy_loss          | 1.32       |
|    explained_variance    | 0.912      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.506      |
|    n_updates             | 13860      |
|    policy_gradient_loss  | 0.00761    |
|    std                   | 0.219      |
|    value_loss            | 1.02       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 6.2        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.2        |
| reward                   | -0.2823701 |
| rollout/                 |            |
|    ep_len_mean           | 40.4       |
|    ep_rew_mean           | -14.7      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 16         |
|    time_elapsed          | 359        |
|    total_timesteps       | 2842624    |
| train/                   |            |
|    approx_kl             | 0.03335716 |
|    clip_fraction         | 0.251      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.41       |
|    cost_value_loss       | 110        |
|    cost_values           | -0.419     |
|    entropy               | 1.33       |
|    entropy_loss          | 1.33       |
|    explained_variance    | 0.925      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.491      |
|    n_updates             | 13870      |
|    policy_gradient_loss  | 0.00643    |
|    std                   | 0.218      |
|    value_loss            | 0.953      |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.31603417 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 381         |
|    total_timesteps       | 2844672     |
| train/                   |             |
|    approx_kl             | 0.033288293 |
|    clip_fraction         | 0.307       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.44       |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.435       |
|    n_updates             | 13880       |
|    policy_gradient_loss  | 0.0148      |
|    std                   | 0.217       |
|    value_loss            | 0.808       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32937044 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 404         |
|    total_timesteps       | 2846720     |
| train/                   |             |
|    approx_kl             | 0.024192946 |
|    clip_fraction         | 0.276       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.42        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.433      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.337       |
|    n_updates             | 13890       |
|    policy_gradient_loss  | 0.00499     |
|    std                   | 0.217       |
|    value_loss            | 0.654       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.34215695 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 426         |
|    total_timesteps       | 2848768     |
| train/                   |             |
|    approx_kl             | 0.017302454 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.8         |
|    cost_value_loss       | 118         |
|    cost_values           | -0.417      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.381       |
|    n_updates             | 13900       |
|    policy_gradient_loss  | 0.00511     |
|    std                   | 0.216       |
|    value_loss            | 0.868       |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.3886987  |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 449         |
|    total_timesteps       | 2850816     |
| train/                   |             |
|    approx_kl             | 0.058583945 |
|    clip_fraction         | 0.303       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.53        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.423      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.493       |
|    n_updates             | 13910       |
|    policy_gradient_loss  | 0.0225      |
|    std                   | 0.216       |
|    value_loss            | 0.995       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.2        |
| reward                   | -0.5119776 |
| rollout/                 |            |
|    ep_len_mean           | 42.5       |
|    ep_rew_mean           | -14.9      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 21         |
|    time_elapsed          | 471        |
|    total_timesteps       | 2852864    |
| train/                   |            |
|    approx_kl             | 0.03625025 |
|    clip_fraction         | 0.267      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.73       |
|    cost_value_loss       | 117        |
|    cost_values           | -0.436     |
|    entropy               | 1.34       |
|    entropy_loss          | 1.34       |
|    explained_variance    | 0.905      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.481      |
|    n_updates             | 13920      |
|    policy_gradient_loss  | 0.0116     |
|    std                   | 0.215      |
|    value_loss            | 1.02       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.4751678  |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 494         |
|    total_timesteps       | 2854912     |
| train/                   |             |
|    approx_kl             | 0.032941833 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.72        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.441      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.391       |
|    n_updates             | 13930       |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.214       |
|    value_loss            | 0.863       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.34238285 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 517         |
|    total_timesteps       | 2856960     |
| train/                   |             |
|    approx_kl             | 0.04588821  |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.43       |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.584       |
|    n_updates             | 13940       |
|    policy_gradient_loss  | 0.00927     |
|    std                   | 0.214       |
|    value_loss            | 1.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.5037351  |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 539         |
|    total_timesteps       | 2859008     |
| train/                   |             |
|    approx_kl             | 0.070455626 |
|    clip_fraction         | 0.38        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.59        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.402      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.683       |
|    n_updates             | 13950       |
|    policy_gradient_loss  | 0.0376      |
|    std                   | 0.216       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.44212314 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 561         |
|    total_timesteps       | 2861056     |
| train/                   |             |
|    approx_kl             | 0.051317826 |
|    clip_fraction         | 0.31        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.78        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.435      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.453       |
|    n_updates             | 13960       |
|    policy_gradient_loss  | 0.0209      |
|    std                   | 0.216       |
|    value_loss            | 0.763       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.5616697  |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 584         |
|    total_timesteps       | 2863104     |
| train/                   |             |
|    approx_kl             | 0.027167732 |
|    clip_fraction         | 0.263       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.53        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.431      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.326       |
|    n_updates             | 13970       |
|    policy_gradient_loss  | 0.00972     |
|    std                   | 0.216       |
|    value_loss            | 0.722       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.32608065 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 606         |
|    total_timesteps       | 2865152     |
| train/                   |             |
|    approx_kl             | 0.04027462  |
|    clip_fraction         | 0.377       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.424      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.279       |
|    n_updates             | 13980       |
|    policy_gradient_loss  | 0.03        |
|    std                   | 0.215       |
|    value_loss            | 0.573       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.5086096  |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 629         |
|    total_timesteps       | 2867200     |
| train/                   |             |
|    approx_kl             | 0.032505155 |
|    clip_fraction         | 0.255       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.8         |
|    cost_value_loss       | 118         |
|    cost_values           | -0.392      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.409       |
|    n_updates             | 13990       |
|    policy_gradient_loss  | 0.00796     |
|    std                   | 0.214       |
|    value_loss            | 0.833       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.3252092  |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 651         |
|    total_timesteps       | 2869248     |
| train/                   |             |
|    approx_kl             | 0.026299436 |
|    clip_fraction         | 0.323       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.423      |
|    entropy               | 1.33        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.392       |
|    n_updates             | 14000       |
|    policy_gradient_loss  | 0.0185      |
|    std                   | 0.215       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.29026723 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 674         |
|    total_timesteps       | 2871296     |
| train/                   |             |
|    approx_kl             | 0.043595083 |
|    clip_fraction         | 0.296       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 126         |
|    cost_values           | -0.425      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.486       |
|    n_updates             | 14010       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.217       |
|    value_loss            | 0.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.3268251  |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 697         |
|    total_timesteps       | 2873344     |
| train/                   |             |
|    approx_kl             | 0.036051396 |
|    clip_fraction         | 0.291       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.82        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.402      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.32        |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.661       |
|    n_updates             | 14020       |
|    policy_gradient_loss  | 0.0187      |
|    std                   | 0.218       |
|    value_loss            | 1.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.31001827 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 719         |
|    total_timesteps       | 2875392     |
| train/                   |             |
|    approx_kl             | 0.0259811   |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.45        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.409      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.466       |
|    n_updates             | 14030       |
|    policy_gradient_loss  | 0.00964     |
|    std                   | 0.218       |
|    value_loss            | 0.911       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.24524269 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 742         |
|    total_timesteps       | 2877440     |
| train/                   |             |
|    approx_kl             | 0.01763901  |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.8         |
|    cost_value_loss       | 119         |
|    cost_values           | -0.421      |
|    entropy               | 1.32        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.439       |
|    n_updates             | 14040       |
|    policy_gradient_loss  | 0.00878     |
|    std                   | 0.218       |
|    value_loss            | 0.947       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.40029567 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 764         |
|    total_timesteps       | 2879488     |
| train/                   |             |
|    approx_kl             | 0.039728664 |
|    clip_fraction         | 0.293       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.67        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.43       |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.51        |
|    n_updates             | 14050       |
|    policy_gradient_loss  | 0.0147      |
|    std                   | 0.219       |
|    value_loss            | 0.987       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.27956077 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 787         |
|    total_timesteps       | 2881536     |
| train/                   |             |
|    approx_kl             | 0.04713096  |
|    clip_fraction         | 0.338       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.417      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.527       |
|    n_updates             | 14060       |
|    policy_gradient_loss  | 0.0232      |
|    std                   | 0.219       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.49481747 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 809         |
|    total_timesteps       | 2883584     |
| train/                   |             |
|    approx_kl             | 0.026688714 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.87        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.429      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.425       |
|    n_updates             | 14070       |
|    policy_gradient_loss  | 0.00274     |
|    std                   | 0.219       |
|    value_loss            | 0.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.4333946  |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 832         |
|    total_timesteps       | 2885632     |
| train/                   |             |
|    approx_kl             | 0.028671304 |
|    clip_fraction         | 0.262       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.62        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.435      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.414       |
|    n_updates             | 14080       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.221       |
|    value_loss            | 0.942       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38988712 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 854         |
|    total_timesteps       | 2887680     |
| train/                   |             |
|    approx_kl             | 0.036868315 |
|    clip_fraction         | 0.328       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.97        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.417      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.606       |
|    n_updates             | 14090       |
|    policy_gradient_loss  | 0.0197      |
|    std                   | 0.221       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33498397 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 39          |
|    time_elapsed          | 877         |
|    total_timesteps       | 2889728     |
| train/                   |             |
|    approx_kl             | 0.034465484 |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 128         |
|    cost_values           | -0.423      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.897       |
|    n_updates             | 14100       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.223       |
|    value_loss            | 1.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.3753194  |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 40          |
|    time_elapsed          | 899         |
|    total_timesteps       | 2891776     |
| train/                   |             |
|    approx_kl             | 0.025419082 |
|    clip_fraction         | 0.258       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.81        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.426      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.688       |
|    n_updates             | 14110       |
|    policy_gradient_loss  | 0.00784     |
|    std                   | 0.223       |
|    value_loss            | 1.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.303008   |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 41          |
|    time_elapsed          | 922         |
|    total_timesteps       | 2893824     |
| train/                   |             |
|    approx_kl             | 0.026730098 |
|    clip_fraction         | 0.288       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.43        |
|    cost_value_loss       | 112         |
|    cost_values           | -0.44       |
|    entropy               | 1.29        |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.671       |
|    n_updates             | 14120       |
|    policy_gradient_loss  | 0.00624     |
|    std                   | 0.223       |
|    value_loss            | 1.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.29483813 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 42          |
|    time_elapsed          | 944         |
|    total_timesteps       | 2895872     |
| train/                   |             |
|    approx_kl             | 0.038817074 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.409      |
|    entropy               | 1.3         |
|    entropy_loss          | 1.3         |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.351       |
|    n_updates             | 14130       |
|    policy_gradient_loss  | 0.00667     |
|    std                   | 0.222       |
|    value_loss            | 0.775       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.47091702 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 43          |
|    time_elapsed          | 967         |
|    total_timesteps       | 2897920     |
| train/                   |             |
|    approx_kl             | 0.05834404  |
|    clip_fraction         | 0.307       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.91        |
|    cost_value_loss       | 121         |
|    cost_values           | -0.421      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.477       |
|    n_updates             | 14140       |
|    policy_gradient_loss  | 0.0235      |
|    std                   | 0.221       |
|    value_loss            | 0.868       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.31791383 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 44          |
|    time_elapsed          | 989         |
|    total_timesteps       | 2899968     |
| train/                   |             |
|    approx_kl             | 0.033085544 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.62        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.413      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.345       |
|    n_updates             | 14150       |
|    policy_gradient_loss  | 0.00617     |
|    std                   | 0.221       |
|    value_loss            | 0.687       |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.75       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.75       |
| reward                   | -0.3880744 |
| rollout/                 |            |
|    ep_len_mean           | 42.4       |
|    ep_rew_mean           | -15.3      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 45         |
|    time_elapsed          | 1012       |
|    total_timesteps       | 2902016    |
| train/                   |            |
|    approx_kl             | 0.06554415 |
|    clip_fraction         | 0.278      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.52       |
|    cost_value_loss       | 113        |
|    cost_values           | -0.416     |
|    entropy               | 1.31       |
|    entropy_loss          | 1.31       |
|    explained_variance    | 0.919      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.528      |
|    n_updates             | 14160      |
|    policy_gradient_loss  | 0.0161     |
|    std                   | 0.221      |
|    value_loss            | 0.972      |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.24756463 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -15.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 46          |
|    time_elapsed          | 1034        |
|    total_timesteps       | 2904064     |
| train/                   |             |
|    approx_kl             | 0.046801586 |
|    clip_fraction         | 0.338       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 123         |
|    cost_values           | -0.399      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.464       |
|    n_updates             | 14170       |
|    policy_gradient_loss  | 0.0187      |
|    std                   | 0.221       |
|    value_loss            | 0.823       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.5080112  |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 47          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 2906112     |
| train/                   |             |
|    approx_kl             | 0.037049875 |
|    clip_fraction         | 0.291       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.405      |
|    entropy               | 1.31        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.4         |
|    n_updates             | 14180       |
|    policy_gradient_loss  | 0.00916     |
|    std                   | 0.222       |
|    value_loss            | 1.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.124756716 |
| rollout/                 |              |
|    ep_len_mean           | 43.5         |
|    ep_rew_mean           | -15.6        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 48           |
|    time_elapsed          | 1079         |
|    total_timesteps       | 2908160      |
| train/                   |              |
|    approx_kl             | 0.048776943  |
|    clip_fraction         | 0.334        |
|    clip_range            | 0.2          |
|    cost_returns          | 10           |
|    cost_value_loss       | 123          |
|    cost_values           | -0.404       |
|    entropy               | 1.3          |
|    entropy_loss          | 1.31         |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.589        |
|    n_updates             | 14190        |
|    policy_gradient_loss  | 0.0204       |
|    std                   | 0.222        |
|    value_loss            | 1.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.32556567 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 49          |
|    time_elapsed          | 1102        |
|    total_timesteps       | 2910208     |
| train/                   |             |
|    approx_kl             | 0.016515763 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 123         |
|    cost_values           | -0.4        |
|    entropy               | 1.32        |
|    entropy_loss          | 1.31        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.573       |
|    n_updates             | 14200       |
|    policy_gradient_loss  | 0.00465     |
|    std                   | 0.22        |
|    value_loss            | 1.11        |
------------------------------------------
-----------------------------------
| avg_speed          | 4.2        |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 4.2        |
| reward             | -0.1389129 |
| rollout/           |            |
|    ep_len_mean     | 44.9       |
|    ep_rew_mean     | -15.5      |
| time/              |            |
|    fps             | 93         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 2912256    |
-----------------------------------
-----------------------------------------
| avg_speed                | 3.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.4        |
| reward                   | -0.314521  |
| rollout/                 |            |
|    ep_len_mean           | 45.3       |
|    ep_rew_mean           | -15.7      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 2          |
|    time_elapsed          | 44         |
|    total_timesteps       | 2914304    |
| train/                   |            |
|    approx_kl             | 0.04416438 |
|    clip_fraction         | 0.315      |
|    clip_range            | 0.2        |
|    cost_returns          | 10.2       |
|    cost_value_loss       | 126        |
|    cost_values           | -0.399     |
|    entropy               | 1.33       |
|    entropy_loss          | 1.33       |
|    explained_variance    | 0.937      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.322      |
|    n_updates             | 14220      |
|    policy_gradient_loss  | 0.0175     |
|    std                   | 0.217      |
|    value_loss            | 0.707      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.42528185 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -15.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 67          |
|    total_timesteps       | 2916352     |
| train/                   |             |
|    approx_kl             | 0.047105204 |
|    clip_fraction         | 0.276       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.388      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.33        |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.482       |
|    n_updates             | 14230       |
|    policy_gradient_loss  | 0.00697     |
|    std                   | 0.216       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.2682235  |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -15.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2918400     |
| train/                   |             |
|    approx_kl             | 0.038853344 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 127         |
|    cost_values           | -0.381      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.613       |
|    n_updates             | 14240       |
|    policy_gradient_loss  | 0.0078      |
|    std                   | 0.217       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.22865967 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -16         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 112         |
|    total_timesteps       | 2920448     |
| train/                   |             |
|    approx_kl             | 0.040918786 |
|    clip_fraction         | 0.291       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.93        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.396      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.363       |
|    n_updates             | 14250       |
|    policy_gradient_loss  | 0.0139      |
|    std                   | 0.217       |
|    value_loss            | 0.767       |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.18843976 |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -15.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2922496     |
| train/                   |             |
|    approx_kl             | 0.044911798 |
|    clip_fraction         | 0.269       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.395      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.435       |
|    n_updates             | 14260       |
|    policy_gradient_loss  | 0.0132      |
|    std                   | 0.216       |
|    value_loss            | 0.948       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.27207923 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 157         |
|    total_timesteps       | 2924544     |
| train/                   |             |
|    approx_kl             | 0.05268696  |
|    clip_fraction         | 0.28        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.91        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.393      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.331       |
|    n_updates             | 14270       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.216       |
|    value_loss            | 0.815       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.27618492 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -15.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 179         |
|    total_timesteps       | 2926592     |
| train/                   |             |
|    approx_kl             | 0.024273496 |
|    clip_fraction         | 0.283       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 123         |
|    cost_values           | -0.399      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.47        |
|    n_updates             | 14280       |
|    policy_gradient_loss  | 0.00816     |
|    std                   | 0.216       |
|    value_loss            | 0.869       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.34        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.34        |
| reward                   | -0.28247997 |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -15.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 202         |
|    total_timesteps       | 2928640     |
| train/                   |             |
|    approx_kl             | 0.025148183 |
|    clip_fraction         | 0.347       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.82        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.415      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.469       |
|    n_updates             | 14290       |
|    policy_gradient_loss  | 0.0239      |
|    std                   | 0.216       |
|    value_loss            | 0.911       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.39206922 |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 224         |
|    total_timesteps       | 2930688     |
| train/                   |             |
|    approx_kl             | 0.030282954 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.66        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.408      |
|    entropy               | 1.34        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.403       |
|    n_updates             | 14300       |
|    policy_gradient_loss  | 0.00987     |
|    std                   | 0.217       |
|    value_loss            | 0.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.20130897 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 11          |
|    time_elapsed          | 247         |
|    total_timesteps       | 2932736     |
| train/                   |             |
|    approx_kl             | 0.040533274 |
|    clip_fraction         | 0.303       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.409      |
|    entropy               | 1.35        |
|    entropy_loss          | 1.34        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.468       |
|    n_updates             | 14310       |
|    policy_gradient_loss  | 0.0141      |
|    std                   | 0.216       |
|    value_loss            | 0.921       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.53170514 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 12          |
|    time_elapsed          | 270         |
|    total_timesteps       | 2934784     |
| train/                   |             |
|    approx_kl             | 0.02767092  |
|    clip_fraction         | 0.272       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.41       |
|    entropy               | 1.35        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.413       |
|    n_updates             | 14320       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.215       |
|    value_loss            | 0.766       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.39        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.39        |
| reward                   | -0.2897056  |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 13          |
|    time_elapsed          | 292         |
|    total_timesteps       | 2936832     |
| train/                   |             |
|    approx_kl             | 0.036574963 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.68        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.413      |
|    entropy               | 1.36        |
|    entropy_loss          | 1.35        |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.456       |
|    n_updates             | 14330       |
|    policy_gradient_loss  | 0.00792     |
|    std                   | 0.215       |
|    value_loss            | 0.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.509045   |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 14          |
|    time_elapsed          | 315         |
|    total_timesteps       | 2938880     |
| train/                   |             |
|    approx_kl             | 0.023865134 |
|    clip_fraction         | 0.309       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.413      |
|    entropy               | 1.36        |
|    entropy_loss          | 1.36        |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.353       |
|    n_updates             | 14340       |
|    policy_gradient_loss  | 0.0237      |
|    std                   | 0.216       |
|    value_loss            | 0.772       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.55644405 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 15          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2940928     |
| train/                   |             |
|    approx_kl             | 0.023277368 |
|    clip_fraction         | 0.267       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 124         |
|    cost_values           | -0.395      |
|    entropy               | 1.36        |
|    entropy_loss          | 1.36        |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.499       |
|    n_updates             | 14350       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.215       |
|    value_loss            | 0.962       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.29020163 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 16          |
|    time_elapsed          | 360         |
|    total_timesteps       | 2942976     |
| train/                   |             |
|    approx_kl             | 0.10336624  |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.55        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.418      |
|    entropy               | 1.36        |
|    entropy_loss          | 1.36        |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.564       |
|    n_updates             | 14360       |
|    policy_gradient_loss  | 0.012       |
|    std                   | 0.215       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.94        |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 6.94        |
| reward                   | -0.11505914 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 17          |
|    time_elapsed          | 382         |
|    total_timesteps       | 2945024     |
| train/                   |             |
|    approx_kl             | 0.02583712  |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.412      |
|    entropy               | 1.36        |
|    entropy_loss          | 1.36        |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.452       |
|    n_updates             | 14370       |
|    policy_gradient_loss  | 0.00872     |
|    std                   | 0.214       |
|    value_loss            | 0.874       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.54416114 |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -15.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 18          |
|    time_elapsed          | 405         |
|    total_timesteps       | 2947072     |
| train/                   |             |
|    approx_kl             | 0.030461438 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.434      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.426       |
|    n_updates             | 14380       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.213       |
|    value_loss            | 0.907       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.24673542 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 19          |
|    time_elapsed          | 428         |
|    total_timesteps       | 2949120     |
| train/                   |             |
|    approx_kl             | 0.050572805 |
|    clip_fraction         | 0.288       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.444      |
|    entropy               | 1.38        |
|    entropy_loss          | 1.38        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.509       |
|    n_updates             | 14390       |
|    policy_gradient_loss  | 0.0126      |
|    std                   | 0.212       |
|    value_loss            | 0.967       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.35248804 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 20          |
|    time_elapsed          | 450         |
|    total_timesteps       | 2951168     |
| train/                   |             |
|    approx_kl             | 0.060942627 |
|    clip_fraction         | 0.246       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.441      |
|    entropy               | 1.38        |
|    entropy_loss          | 1.38        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.34        |
|    n_updates             | 14400       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.213       |
|    value_loss            | 0.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.23274295 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 21          |
|    time_elapsed          | 473         |
|    total_timesteps       | 2953216     |
| train/                   |             |
|    approx_kl             | 0.050095968 |
|    clip_fraction         | 0.324       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.72        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.438      |
|    entropy               | 1.38        |
|    entropy_loss          | 1.38        |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.331       |
|    n_updates             | 14410       |
|    policy_gradient_loss  | 0.0165      |
|    std                   | 0.213       |
|    value_loss            | 0.696       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.33908626 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 22          |
|    time_elapsed          | 495         |
|    total_timesteps       | 2955264     |
| train/                   |             |
|    approx_kl             | 0.022058496 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.59        |
|    cost_value_loss       | 114         |
|    cost_values           | -0.433      |
|    entropy               | 1.38        |
|    entropy_loss          | 1.38        |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.442       |
|    n_updates             | 14420       |
|    policy_gradient_loss  | 0.00716     |
|    std                   | 0.212       |
|    value_loss            | 0.845       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.37        |
| reward                   | -0.4496313  |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -14.8       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 23          |
|    time_elapsed          | 518         |
|    total_timesteps       | 2957312     |
| train/                   |             |
|    approx_kl             | 0.044879235 |
|    clip_fraction         | 0.321       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.81        |
|    cost_value_loss       | 120         |
|    cost_values           | -0.431      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.379       |
|    n_updates             | 14430       |
|    policy_gradient_loss  | 0.0205      |
|    std                   | 0.212       |
|    value_loss            | 0.765       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.21895806 |
| rollout/                 |             |
|    ep_len_mean           | 39.9        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 24          |
|    time_elapsed          | 541         |
|    total_timesteps       | 2959360     |
| train/                   |             |
|    approx_kl             | 0.045304473 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.42        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.437      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.369       |
|    n_updates             | 14440       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.213       |
|    value_loss            | 0.875       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.19825353 |
| rollout/                 |             |
|    ep_len_mean           | 40.2        |
|    ep_rew_mean           | -14.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 25          |
|    time_elapsed          | 563         |
|    total_timesteps       | 2961408     |
| train/                   |             |
|    approx_kl             | 0.046777844 |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.41        |
|    cost_value_loss       | 110         |
|    cost_values           | -0.437      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.435       |
|    n_updates             | 14450       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.211       |
|    value_loss            | 0.793       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.51554286 |
| rollout/                 |             |
|    ep_len_mean           | 40.6        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 26          |
|    time_elapsed          | 586         |
|    total_timesteps       | 2963456     |
| train/                   |             |
|    approx_kl             | 0.033621002 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.45        |
|    cost_value_loss       | 112         |
|    cost_values           | -0.442      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.474       |
|    n_updates             | 14460       |
|    policy_gradient_loss  | 0.00638     |
|    std                   | 0.211       |
|    value_loss            | 0.882       |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.39571542 |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 27          |
|    time_elapsed          | 608         |
|    total_timesteps       | 2965504     |
| train/                   |             |
|    approx_kl             | 0.02778126  |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.51        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.432      |
|    entropy               | 1.4         |
|    entropy_loss          | 1.4         |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.34        |
|    n_updates             | 14470       |
|    policy_gradient_loss  | 0.00338     |
|    std                   | 0.211       |
|    value_loss            | 0.749       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.3147585  |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -15.1       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 28          |
|    time_elapsed          | 631         |
|    total_timesteps       | 2967552     |
| train/                   |             |
|    approx_kl             | 0.054618314 |
|    clip_fraction         | 0.27        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.72        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.411      |
|    entropy               | 1.4         |
|    entropy_loss          | 1.4         |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.383       |
|    n_updates             | 14480       |
|    policy_gradient_loss  | 0.0133      |
|    std                   | 0.211       |
|    value_loss            | 0.728       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.249709   |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 29          |
|    time_elapsed          | 653         |
|    total_timesteps       | 2969600     |
| train/                   |             |
|    approx_kl             | 0.031514842 |
|    clip_fraction         | 0.303       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.77        |
|    cost_value_loss       | 118         |
|    cost_values           | -0.419      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.47        |
|    n_updates             | 14490       |
|    policy_gradient_loss  | 0.0174      |
|    std                   | 0.211       |
|    value_loss            | 1           |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.31875247 |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 30          |
|    time_elapsed          | 676         |
|    total_timesteps       | 2971648     |
| train/                   |             |
|    approx_kl             | 0.05002465  |
|    clip_fraction         | 0.352       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.62        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.442      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.36        |
|    n_updates             | 14500       |
|    policy_gradient_loss  | 0.027       |
|    std                   | 0.211       |
|    value_loss            | 0.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.41700056 |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 31          |
|    time_elapsed          | 699         |
|    total_timesteps       | 2973696     |
| train/                   |             |
|    approx_kl             | 0.026585504 |
|    clip_fraction         | 0.317       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.51        |
|    cost_value_loss       | 112         |
|    cost_values           | -0.429      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.37        |
|    n_updates             | 14510       |
|    policy_gradient_loss  | 0.0273      |
|    std                   | 0.211       |
|    value_loss            | 0.717       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.34275162 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -14.9       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 32          |
|    time_elapsed          | 721         |
|    total_timesteps       | 2975744     |
| train/                   |             |
|    approx_kl             | 0.06313196  |
|    clip_fraction         | 0.323       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.65        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.426      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.354       |
|    n_updates             | 14520       |
|    policy_gradient_loss  | 0.0213      |
|    std                   | 0.21        |
|    value_loss            | 0.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.51709545 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -15.3       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 33          |
|    time_elapsed          | 744         |
|    total_timesteps       | 2977792     |
| train/                   |             |
|    approx_kl             | 0.037487186 |
|    clip_fraction         | 0.29        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.74        |
|    cost_value_loss       | 117         |
|    cost_values           | -0.431      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.295       |
|    n_updates             | 14530       |
|    policy_gradient_loss  | 0.0139      |
|    std                   | 0.21        |
|    value_loss            | 0.719       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.97        |
| reward                   | -0.27314508 |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 34          |
|    time_elapsed          | 767         |
|    total_timesteps       | 2979840     |
| train/                   |             |
|    approx_kl             | 0.03232663  |
|    clip_fraction         | 0.262       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.92        |
|    cost_value_loss       | 122         |
|    cost_values           | -0.422      |
|    entropy               | 1.41        |
|    entropy_loss          | 1.4         |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.485       |
|    n_updates             | 14540       |
|    policy_gradient_loss  | 0.0104      |
|    std                   | 0.208       |
|    value_loss            | 0.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3757785  |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 35          |
|    time_elapsed          | 789         |
|    total_timesteps       | 2981888     |
| train/                   |             |
|    approx_kl             | 0.021419011 |
|    clip_fraction         | 0.332       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.41        |
|    cost_value_loss       | 110         |
|    cost_values           | -0.426      |
|    entropy               | 1.4         |
|    entropy_loss          | 1.41        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.486       |
|    n_updates             | 14550       |
|    policy_gradient_loss  | 0.0187      |
|    std                   | 0.208       |
|    value_loss            | 0.945       |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.2        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.2        |
| reward                   | -0.2639429 |
| rollout/                 |            |
|    ep_len_mean           | 42.5       |
|    ep_rew_mean           | -15.3      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 36         |
|    time_elapsed          | 812        |
|    total_timesteps       | 2983936    |
| train/                   |            |
|    approx_kl             | 0.03234541 |
|    clip_fraction         | 0.288      |
|    clip_range            | 0.2        |
|    cost_returns          | 10         |
|    cost_value_loss       | 124        |
|    cost_values           | -0.44      |
|    entropy               | 1.4        |
|    entropy_loss          | 1.4        |
|    explained_variance    | 0.898      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.554      |
|    n_updates             | 14560      |
|    policy_gradient_loss  | 0.0125     |
|    std                   | 0.209      |
|    value_loss            | 1.17       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.44325474 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -15         |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 37          |
|    time_elapsed          | 834         |
|    total_timesteps       | 2985984     |
| train/                   |             |
|    approx_kl             | 0.0394417   |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.435      |
|    entropy               | 1.4         |
|    entropy_loss          | 1.4         |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.587       |
|    n_updates             | 14570       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.208       |
|    value_loss            | 0.993       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29215634 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 38          |
|    time_elapsed          | 857         |
|    total_timesteps       | 2988032     |
| train/                   |             |
|    approx_kl             | 0.027189007 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.68        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.437      |
|    entropy               | 1.4         |
|    entropy_loss          | 1.4         |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.339       |
|    n_updates             | 14580       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.208       |
|    value_loss            | 0.692       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3111418  |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 39          |
|    time_elapsed          | 879         |
|    total_timesteps       | 2990080     |
| train/                   |             |
|    approx_kl             | 0.028191693 |
|    clip_fraction         | 0.344       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.65        |
|    cost_value_loss       | 116         |
|    cost_values           | -0.422      |
|    entropy               | 1.4         |
|    entropy_loss          | 1.4         |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.492       |
|    n_updates             | 14590       |
|    policy_gradient_loss  | 0.0213      |
|    std                   | 0.208       |
|    value_loss            | 0.892       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.42740265 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -14.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 40          |
|    time_elapsed          | 902         |
|    total_timesteps       | 2992128     |
| train/                   |             |
|    approx_kl             | 0.05702713  |
|    clip_fraction         | 0.304       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.81        |
|    cost_value_loss       | 119         |
|    cost_values           | -0.429      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.4         |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.558       |
|    n_updates             | 14600       |
|    policy_gradient_loss  | 0.0145      |
|    std                   | 0.208       |
|    value_loss            | 0.981       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.58218086 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 41          |
|    time_elapsed          | 925         |
|    total_timesteps       | 2994176     |
| train/                   |             |
|    approx_kl             | 0.03545018  |
|    clip_fraction         | 0.312       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.7         |
|    cost_value_loss       | 117         |
|    cost_values           | -0.428      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.507       |
|    n_updates             | 14610       |
|    policy_gradient_loss  | 0.0197      |
|    std                   | 0.208       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.3095662  |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 42          |
|    time_elapsed          | 947         |
|    total_timesteps       | 2996224     |
| train/                   |             |
|    approx_kl             | 0.051221624 |
|    clip_fraction         | 0.273       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.6         |
|    cost_value_loss       | 114         |
|    cost_values           | -0.433      |
|    entropy               | 1.39        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.335       |
|    n_updates             | 14620       |
|    policy_gradient_loss  | 0.0171      |
|    std                   | 0.209       |
|    value_loss            | 0.699       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38767698 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -14.5       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 43          |
|    time_elapsed          | 970         |
|    total_timesteps       | 2998272     |
| train/                   |             |
|    approx_kl             | 0.04222697  |
|    clip_fraction         | 0.349       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.43        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.436      |
|    entropy               | 1.38        |
|    entropy_loss          | 1.39        |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.412       |
|    n_updates             | 14630       |
|    policy_gradient_loss  | 0.029       |
|    std                   | 0.21        |
|    value_loss            | 0.761       |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.4        |
| reward                   | -0.5037351 |
| rollout/                 |            |
|    ep_len_mean           | 41.7       |
|    ep_rew_mean           | -14.9      |
| time/                    |            |
|    fps                   | 90         |
|    iterations            | 44         |
|    time_elapsed          | 992        |
|    total_timesteps       | 3000320    |
| train/                   |            |
|    approx_kl             | 0.03662136 |
|    clip_fraction         | 0.252      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.75       |
|    cost_value_loss       | 118        |
|    cost_values           | -0.422     |
|    entropy               | 1.38       |
|    entropy_loss          | 1.38       |
|    explained_variance    | 0.932      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.411      |
|    n_updates             | 14640      |
|    policy_gradient_loss  | 0.00238    |
|    std                   | 0.21       |
|    value_loss            | 0.83       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.5459628  |
| rollout/                 |             |
|    ep_len_mean           | 39.9        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 45          |
|    time_elapsed          | 1015        |
|    total_timesteps       | 3002368     |
| train/                   |             |
|    approx_kl             | 0.039663605 |
|    clip_fraction         | 0.328       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.44        |
|    cost_value_loss       | 111         |
|    cost_values           | -0.432      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.392       |
|    n_updates             | 14650       |
|    policy_gradient_loss  | 0.0223      |
|    std                   | 0.21        |
|    value_loss            | 0.827       |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.3166401  |
| rollout/                 |             |
|    ep_len_mean           | 40.2        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 46          |
|    time_elapsed          | 1037        |
|    total_timesteps       | 3004416     |
| train/                   |             |
|    approx_kl             | 0.039603192 |
|    clip_fraction         | 0.274       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.35        |
|    cost_value_loss       | 109         |
|    cost_values           | -0.435      |
|    entropy               | 1.38        |
|    entropy_loss          | 1.37        |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.364       |
|    n_updates             | 14660       |
|    policy_gradient_loss  | 0.0187      |
|    std                   | 0.209       |
|    value_loss            | 0.777       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.24914034 |
| rollout/                 |             |
|    ep_len_mean           | 39.8        |
|    ep_rew_mean           | -14.2       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 47          |
|    time_elapsed          | 1060        |
|    total_timesteps       | 3006464     |
| train/                   |             |
|    approx_kl             | 0.035022218 |
|    clip_fraction         | 0.301       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 115         |
|    cost_values           | -0.421      |
|    entropy               | 1.38        |
|    entropy_loss          | 1.38        |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.475       |
|    n_updates             | 14670       |
|    policy_gradient_loss  | 0.0173      |
|    std                   | 0.209       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.47109985 |
| rollout/                 |             |
|    ep_len_mean           | 40          |
|    ep_rew_mean           | -14.4       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 48          |
|    time_elapsed          | 1083        |
|    total_timesteps       | 3008512     |
| train/                   |             |
|    approx_kl             | 0.032951795 |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.25        |
|    cost_value_loss       | 108         |
|    cost_values           | -0.434      |
|    entropy               | 1.38        |
|    entropy_loss          | 1.38        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.385       |
|    n_updates             | 14680       |
|    policy_gradient_loss  | 0.016       |
|    std                   | 0.209       |
|    value_loss            | 0.869       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 1           |
| max_speed                | 5.2         |
| reward                   | -0.09993355 |
| rollout/                 |             |
|    ep_len_mean           | 40          |
|    ep_rew_mean           | -14.6       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 49          |
|    time_elapsed          | 1105        |
|    total_timesteps       | 3010560     |
| train/                   |             |
|    approx_kl             | 0.027678432 |
|    clip_fraction         | 0.314       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.55        |
|    cost_value_loss       | 113         |
|    cost_values           | -0.432      |
|    entropy               | 1.37        |
|    entropy_loss          | 1.38        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.412       |
|    n_updates             | 14690       |
|    policy_gradient_loss  | 0.0215      |
|    std                   | 0.209       |
|    value_loss            | 0.813       |
------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.2504280209541321
Final reward: -0.2559669613838196
Final reward: -0.26494571566581726
Final reward: -0.2762231230735779
Final reward: -0.2882359027862549
Final reward: -0.29901790618896484
Final reward: -0.3061847388744354
Final reward: -0.3068936765193939
Final reward: -0.2977721393108368
Final reward: -0.31001827120780945
Final reward: -0.33908626437187195
Final reward: -0.36103811860084534
Final reward: -0.37280115485191345
Final reward: -0.38002973794937134
Final reward: -0.38352254033088684
Final reward: -0.3844760060310364
Final reward: -0.3792228400707245
Final reward: -0.3799037039279938
Final reward: -0.36786946654319763
Final reward: -0.33630281686782837
Final reward: -0.2947900593280792
Final reward: -0.21214045584201813
Final reward: -0.19917148351669312
Final reward: -0.2493232637643814
Final reward: -0.2628192901611328
Final reward: -0.22895030677318573
Final reward: -0.2716493606567383
Final reward: -0.2696518898010254
Final reward: -0.23764166235923767
Final reward: -0.25594639778137207
Final reward: -0.30223551392555237
Final reward: -0.31681081652641296
Final reward: -0.18881627917289734
Final reward: -0.17166276276111603
Final reward: -0.26088592410087585
Final reward: -0.2769987881183624
Final reward: -0.3366010785102844
Final reward: -0.3067960739135742
Final reward: -0.07498287409543991
Final reward: -0.5496554374694824
Final reward: -0.5501572489738464
Final reward: -0.5512897372245789
Final reward: -0.5534695982933044
Final reward: -0.5572488307952881
Final reward: -0.563228189945221
Final reward: -0.5719112753868103
Final reward: -0.583497941493988
Final reward: -0.5976483225822449
Final reward: -0.6132791638374329
Final reward: -0.6284739375114441
Final reward: -0.6405845284461975
Final reward: -0.646678626537323
Final reward: -0.6448007225990295
Final reward: -0.6456877589225769
Final reward: -0.6406252980232239
Final reward: -0.6242052912712097
Final reward: -0.598774254322052
Final reward: -0.5690784454345703
Final reward: -0.5355622172355652
Final reward: -0.4964185655117035
Final reward: -0.4610597789287567
Final reward: -0.4174993634223938
Final reward: -0.35797035694122314
Final reward: -0.27147191762924194
Final reward: -0.11217925697565079
Final reward: -0.5493294596672058
Final reward: -0.5485113263130188
Final reward: -0.5472737550735474
Final reward: -0.5459628105163574
Final reward: -0.5451012849807739
Final reward: -0.5453845262527466
Final reward: -0.5476288199424744
Final reward: -0.5526418089866638
Final reward: -0.5609967708587646
Final reward: -0.5727357268333435
Final reward: -0.5870780944824219
Final reward: -0.6022543907165527
Final reward: -0.6155766248703003
Final reward: -0.6326479315757751
Final reward: -0.6463790535926819
Final reward: -0.6449330449104309
Final reward: -0.6231069564819336
Final reward: -0.5953947901725769
Final reward: -0.5644338130950928
Final reward: -0.529533863067627
Final reward: -0.4892549216747284
Final reward: -0.44289374351501465
Final reward: -0.3882596790790558
Final reward: -0.31948667764663696
Final reward: -0.2696235477924347
Final reward: -0.32346776127815247
Final reward: -0.3479115664958954
Final reward: -0.3017233908176422
Final reward: -0.18864692747592926
Final reward: -0.20969632267951965
Final reward: -0.28751325607299805
Final reward: -0.2620949447154999
Final reward: -0.3333907127380371
Final reward: -0.3606038987636566
Final reward: -0.28739604353904724
Final reward: -0.1117464154958725
Final reward: -0.427031546831131
Final reward: -0.42861488461494446
Final reward: -0.43102720379829407
Final reward: -0.43364274501800537
Final reward: -0.43553319573402405
Final reward: -0.4354652464389801
Final reward: -0.4319304823875427
Final reward: -0.4232337772846222
Final reward: -0.40767890214920044
Final reward: -0.3839110732078552
Final reward: -0.3515261113643646
Final reward: -0.3121686279773712
Final reward: -0.2715110778808594
Final reward: -0.2638920545578003
Final reward: -0.29417622089385986
Final reward: -0.3384915292263031
Final reward: -0.3831639885902405
Final reward: -0.4156525731086731
Final reward: -0.42688074707984924
Final reward: -0.4380541741847992
Final reward: -0.40129902958869934
Final reward: -0.35674747824668884
Final reward: -0.2738039493560791
Final reward: -0.20802706480026245
Final reward: -0.2690218985080719
Final reward: -0.3479096293449402
Final reward: -0.3933945894241333
Final reward: -0.4130183458328247
Final reward: -0.35889092087745667
Final reward: -0.28648841381073
Final reward: -0.1079854741692543
Final reward: -0.24852128326892853
Final reward: -0.24670760333538055
Final reward: -0.24394382536411285
Final reward: -0.24098841845989227
Final reward: -0.23903021216392517
Final reward: -0.2396753579378128
Final reward: -0.2447393536567688
Final reward: -0.2557595670223236
Final reward: -0.27334481477737427
Final reward: -0.2966920733451843
Final reward: -0.323513001203537
Final reward: -0.3503003716468811
Final reward: -0.3727392554283142
Final reward: -0.4003041088581085
Final reward: -0.4216703474521637
Final reward: -0.4195997714996338
Final reward: -0.38742685317993164
Final reward: -0.3374304175376892
Final reward: -0.27016305923461914
Final reward: -0.2652494013309479
Final reward: -0.2863420844078064
Final reward: -0.260648250579834
Final reward: -0.19504384696483612
Final reward: -0.2698782682418823
Final reward: -0.3345368206501007
Final reward: -0.33460739254951477
Final reward: -0.25419941544532776
Final reward: -0.30807259678840637
Final reward: -0.32726553082466125
Final reward: -0.248199000954628
Final reward: -0.21034705638885498
Final reward: -0.302560031414032
Final reward: -0.2523089051246643
Final reward: -0.33177685737609863
Final reward: -0.3722611367702484
Final reward: -0.314795583486557
Final reward: -0.14362691342830658
Final reward: -0.238900825381279
Final reward: -0.2739117443561554
Final reward: -0.338417649269104
Final reward: -0.2739635705947876
Final reward: -0.15105193853378296
Final reward: -0.24123604595661163
Final reward: -0.32763388752937317
Final reward: -0.3759517967700958
Final reward: -0.308717280626297
Final reward: -0.056630197912454605
Final reward: -0.47154632210731506
Final reward: -0.47298067808151245
Final reward: -0.47516781091690063
Final reward: -0.47754165530204773
Final reward: -0.4792589545249939
Final reward: -0.4791972041130066
Final reward: -0.4759873151779175
Final reward: -0.4681098461151123
Final reward: -0.454094797372818
Final reward: -0.43288302421569824
Final reward: -0.40443864464759827
Final reward: -0.37074148654937744
Final reward: -0.3372213840484619
Final reward: -0.33111780881881714
Final reward: -0.3557240962982178
Final reward: -0.39316219091415405
Final reward: -0.43222060799598694
Final reward: -0.460733026266098
Final reward: -0.471099853515625
Final reward: -0.47921961545944214
Final reward: -0.4411129653453827
Final reward: -0.40020790696144104
Final reward: -0.34105584025382996
Final reward: -0.25123539566993713
Final reward: -0.23907344043254852
Final reward: -0.31430473923683167
Final reward: -0.38516518473625183
Final reward: -0.41436097025871277
Final reward: -0.41781410574913025
Final reward: -0.34314247965812683
Final reward: -0.24121229350566864
Final reward: -0.30416664481163025
Final reward: -0.3915417790412903
Final reward: -0.4295239746570587
Final reward: -0.3913706839084625
Final reward: -0.33753982186317444
Final reward: -0.183583602309227
Final reward: -0.17073343694210052
Final reward: -0.29603976011276245
Final reward: -0.36071690917015076
Final reward: -0.32497650384902954
Final reward: -0.11893457919359207
Final reward: -0.42633652687072754
Final reward: -0.4252818524837494
Final reward: -0.4236845374107361
Final reward: -0.4219898283481598
Final reward: -0.42087462544441223
Final reward: -0.4212413430213928
Final reward: -0.42414307594299316
Final reward: -0.4305960536003113
Final reward: -0.4412679374217987
Final reward: -0.45609888434410095
Final reward: -0.4739838242530823
Final reward: -0.492656409740448
Final reward: -0.5088561177253723
Final reward: -0.529380202293396
Final reward: -0.5457159280776978
Final reward: -0.5441176295280457
Final reward: -0.5194677710533142
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.4839589297771454
Final reward: -0.44270560145378113
Final reward: -0.3942468464374542
Final reward: -0.3347383737564087
Final reward: -0.25144654512405396
Final reward: -0.2291228026151657
Final reward: -0.2436952292919159
Final reward: -0.16471007466316223
Final reward: -0.2572624385356903
Final reward: -0.32901492714881897
Final reward: -0.342155784368515
Final reward: -0.2520178556442261
Final reward: -0.28242072463035583
Final reward: -0.3082817494869232
Final reward: -0.2208593487739563
Final reward: -0.1902708113193512
Final reward: -0.2844073176383972
Final reward: -0.2610490024089813
Final reward: -0.3245442807674408
Final reward: -0.3001859188079834
Final reward: -0.10412417352199554
Final reward: -0.4709170162677765
Final reward: -0.46996238827705383
Final reward: -0.4685174226760864
Final reward: -0.46698546409606934
Final reward: -0.4659779369831085
Final reward: -0.46630921959877014
Final reward: -0.4689321517944336
Final reward: -0.4747767448425293
Final reward: -0.4844764173030853
Final reward: -0.49802228808403015
Final reward: -0.514451801776886
Final reward: -0.5317051410675049
Final reward: -0.5467490553855896
Final reward: -0.5659005045890808
Final reward: -0.581210732460022
Final reward: -0.5790742635726929
Final reward: -0.5559698939323425
Final reward: -0.5244446992874146
Final reward: -0.48730939626693726
Final reward: -0.4444257616996765
Final reward: -0.39441490173339844
Final reward: -0.33267661929130554
Final reward: -0.24980874359607697
Final reward: -0.2767486572265625
Final reward: -0.29856443405151367
Final reward: -0.2450644075870514
Final reward: -0.19479013979434967
Final reward: -0.2846907675266266
Final reward: -0.31217220425605774
Final reward: -0.2612571120262146
Final reward: -0.31274664402008057
Final reward: -0.3202767074108124
Final reward: -0.19220130145549774
Final reward: -0.2386101633310318
Final reward: -0.26594534516334534
Final reward: -0.32393068075180054
Final reward: -0.372075617313385
Final reward: -0.3146568238735199
Final reward: -0.13546700775623322
Final reward: -0.24067184329032898
Final reward: -0.2906036674976349
Final reward: -0.35101836919784546
Final reward: -0.28675612807273865
Final reward: -0.12045364081859589
Final reward: -0.23468592762947083
Final reward: -0.31551775336265564
Final reward: -0.36167120933532715
Final reward: -0.2711617946624756
Final reward: -0.1544027030467987
Final reward: -0.24675004184246063
Final reward: -0.3180094361305237
Final reward: -0.3645531237125397
Final reward: -0.281710147857666
Final reward: -0.1398719996213913
Final reward: -0.22268988192081451
Final reward: -0.33761101961135864
Final reward: -0.3843642771244049
Final reward: -0.3175381124019623
Final reward: -0.09543528407812119
Final reward: -0.24852128326892853
Final reward: -0.24670760333538055
Final reward: -0.24394382536411285
Final reward: -0.24098841845989227
Final reward: -0.23903021216392517
Final reward: -0.2396753579378128
Final reward: -0.2447393536567688
Final reward: -0.2557595670223236
Final reward: -0.27334481477737427
Final reward: -0.2966920733451843
Final reward: -0.323513001203537
Final reward: -0.3503003716468811
Final reward: -0.3727392554283142
Final reward: -0.4003041088581085
Final reward: -0.4216703474521637
Final reward: -0.4195997714996338
Final reward: -0.38757139444351196
Final reward: -0.337562620639801
Final reward: -0.2711295783519745
Final reward: -0.2695961892604828
Final reward: -0.2907082140445709
Final reward: -0.27022403478622437
Final reward: -0.1804480403661728
Final reward: -0.2604844570159912
Final reward: -0.32704436779022217
Final reward: -0.3324149250984192
Final reward: -0.2562367618083954
Final reward: -0.3225664794445038
Final reward: -0.3529438376426697
Final reward: -0.31301799416542053
Final reward: -0.19397085905075073
Final reward: -0.21374823153018951
Final reward: -0.2711982727050781
Final reward: -0.2986353635787964
Final reward: -0.3521292805671692
Final reward: -0.3296958804130554
Final reward: -0.16025686264038086
Final reward: -0.2214655876159668
Final reward: -0.3173498511314392
Final reward: -0.37471747398376465
Final reward: -0.3131917119026184
Final reward: -0.08600692451000214
Final reward: -0.3765140473842621
Final reward: -0.37531939148902893
Final reward: -0.373508483171463
Final reward: -0.37158501148223877
Final reward: -0.3703180253505707
Final reward: -0.3707347810268402
Final reward: -0.3740285336971283
Final reward: -0.3813305199146271
Final reward: -0.3933413028717041
Final reward: -0.4099099636077881
Final reward: -0.4297215938568115
Final reward: -0.45023366808891296
Final reward: -0.4679044485092163
Final reward: -0.490146279335022
Final reward: -0.5077458620071411
Final reward: -0.5060276389122009
Final reward: -0.4793621003627777
Final reward: -0.44064953923225403
Final reward: -0.3942869305610657
Final reward: -0.3370770812034607
Final reward: -0.24961771070957184
Final reward: -0.21250124275684357
Final reward: -0.1904681921005249
Final reward: -0.2508714199066162
Final reward: -0.31545332074165344
Final reward: -0.3742036521434784
Final reward: -0.3710187077522278
Final reward: -0.28854501247406006
Final reward: -0.26465168595314026
Final reward: -0.2963756024837494
Final reward: -0.22746911644935608
Final reward: -0.21156147122383118
Final reward: -0.3065762519836426
Final reward: -0.25640493631362915
Final reward: -0.32169947028160095
Final reward: -0.3719305992126465
Final reward: -0.33218348026275635
Final reward: -0.21190010011196136
Final reward: -0.1915283203125
Final reward: -0.2768344283103943
Final reward: -0.3461395502090454
Final reward: -0.3042333722114563
Final reward: -0.09693823754787445
Final reward: -0.5493294596672058
Final reward: -0.5485113263130188
Final reward: -0.5472737550735474
Final reward: -0.5459628105163574
Final reward: -0.5451012849807739
Final reward: -0.5453845262527466
Final reward: -0.5476288199424744
Final reward: -0.5526418089866638
Final reward: -0.5609967708587646
Final reward: -0.5727357268333435
Final reward: -0.5870780944824219
Final reward: -0.6022543907165527
Final reward: -0.6155766248703003
Final reward: -0.6326479315757751
Final reward: -0.6463790535926819
Final reward: -0.6448837518692017
Final reward: -0.6232627034187317
Final reward: -0.5953757762908936
Final reward: -0.56424480676651
Final reward: -0.5289012789726257
Final reward: -0.48891592025756836
Final reward: -0.4424194395542145
Final reward: -0.3876856565475464
Final reward: -0.3187091648578644
Final reward: -0.26840531826019287
Final reward: -0.32243967056274414
Final reward: -0.3469654321670532
Final reward: -0.30125582218170166
Final reward: -0.18588443100452423
Final reward: -0.21058784425258636
Final reward: -0.2856203317642212
Final reward: -0.2644709646701813
Final reward: -0.3257649838924408
Final reward: -0.3402736186981201
Final reward: -0.2269895374774933
Final reward: -0.19060775637626648
Final reward: -0.23444189131259918
Final reward: -0.34290388226509094
Final reward: -0.38222306966781616
Final reward: -0.31506219506263733
Final reward: -0.08761419355869293
Final reward: -0.5501946806907654
Final reward: -0.552737832069397
Final reward: -0.5569526553153992
Final reward: -0.5624048709869385
Final reward: -0.5684012174606323
Final reward: -0.5739439725875854
Final reward: -0.5777102112770081
Final reward: -0.578086256980896
Final reward: -0.5732959508895874
Final reward: -0.5616697072982788
Final reward: -0.5421157479286194
Final reward: -0.5168254971504211
Final reward: -0.49435603618621826
Final reward: -0.46787336468696594
Final reward: -0.4395291805267334
Final reward: -0.40500202775001526
Final reward: -0.3708775043487549
Final reward: -0.3247877061367035
Final reward: -0.2741866409778595
Final reward: -0.20250575244426727
Final reward: -0.12797777354717255
Final reward: -0.1835150122642517
Final reward: -0.27024757862091064
Final reward: -0.341937780380249
Final reward: -0.37162473797798157
Final reward: -0.38517534732818604
Final reward: -0.32769984006881714
Final reward: -0.2303888201713562
Final reward: -0.10138702392578125
Final reward: -0.5116276144981384
Final reward: -0.510749101638794
Final reward: -0.509419858455658
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.5080112218856812
Final reward: -0.5070852637290955
Final reward: -0.5073896646499634
Final reward: -0.5098012685775757
Final reward: -0.5151824355125427
Final reward: -0.5241348743438721
Final reward: -0.5366806983947754
Final reward: -0.5519607663154602
Final reward: -0.5680760145187378
Final reward: -0.5821808576583862
Final reward: -0.6002027988433838
Final reward: -0.6146591901779175
Final reward: -0.6132405400276184
Final reward: -0.5903014540672302
Final reward: -0.5609309077262878
Final reward: -0.5269689559936523
Final reward: -0.4884921610355377
Final reward: -0.44375643134117126
Final reward: -0.3911810517311096
Final reward: -0.3258458077907562
Final reward: -0.24455119669437408
Final reward: -0.29088419675827026
Final reward: -0.3105083703994751
Final reward: -0.24699313938617706
Final reward: -0.19509364664554596
Final reward: -0.28897443413734436
Final reward: -0.29126521944999695
Final reward: -0.29669898748397827
Final reward: -0.3449711203575134
Final reward: -0.34456533193588257
Final reward: -0.21835103631019592
Final reward: -0.20814427733421326
Final reward: -0.2638777792453766
Final reward: -0.3629554212093353
Final reward: -0.4074501097202301
Final reward: -0.3490574061870575
Final reward: -0.2570614814758301
Final reward: -0.14250147342681885
Final reward: -0.24939386546611786
Final reward: -0.35413479804992676
Final reward: -0.3881118893623352
Final reward: -0.32458940148353577
Final reward: -0.12461740523576736
Final reward: -0.25657618045806885
Final reward: -0.35783690214157104
Final reward: -0.3964194357395172
Final reward: -0.3213605582714081
Final reward: -0.15075144171714783
Final reward: -0.25532081723213196
Final reward: -0.3668590784072876
Final reward: -0.3991934657096863
Final reward: -0.3024134039878845
Final reward: -0.08021154999732971
Final reward: -0.3195638656616211
Final reward: -0.3204262852668762
Final reward: -0.3223668336868286
Final reward: -0.32608065009117126
Final reward: -0.3324548602104187
Final reward: -0.34238284826278687
Final reward: -0.35648635029792786
Final reward: -0.37479308247566223
Final reward: -0.3964638113975525
Final reward: -0.4196562170982361
Final reward: -0.4415648281574249
Final reward: -0.45863768458366394
Final reward: -0.4677446186542511
Final reward: -0.47074103355407715
Final reward: -0.4690651595592499
Final reward: -0.4654414653778076
Final reward: -0.46208468079566956
Final reward: -0.44860902428627014
Final reward: -0.4190969467163086
Final reward: -0.3750472366809845
Final reward: -0.32969093322753906
Final reward: -0.2531318962574005
Final reward: -0.07782658189535141
Final reward: -0.376989483833313
Final reward: -0.37772080302238464
Final reward: -0.379368394613266
Final reward: -0.38252919912338257
Final reward: -0.38797709345817566
Final reward: -0.3965173661708832
Final reward: -0.4087572991847992
Final reward: -0.42481744289398193
Final reward: -0.4440535604953766
Final reward: -0.46487775444984436
Final reward: -0.4847468435764313
Final reward: -0.5003483891487122
Final reward: -0.5085356831550598
Final reward: -0.5096477270126343
Final reward: -0.506554901599884
Final reward: -0.504869282245636
Final reward: -0.49837109446525574
Final reward: -0.4825727939605713
Final reward: -0.45033514499664307
Final reward: -0.4074975550174713
Final reward: -0.3611692190170288
Final reward: -0.29937899112701416
Final reward: -0.19254842400550842
Final reward: -0.1461806446313858
Final reward: -0.21911361813545227
Final reward: -0.27666425704956055
Final reward: -0.32877764105796814
Final reward: -0.32831695675849915
Final reward: -0.33162909746170044
Final reward: -0.26766863465309143
Final reward: -0.22836832702159882
Final reward: -0.28511515259742737
Final reward: -0.31664448976516724
Final reward: -0.1900506317615509
Final reward: -0.1964823305606842
Final reward: -0.2772141396999359
Final reward: -0.2520310878753662
Final reward: -0.32222339510917664
Final reward: -0.2950855791568756
Final reward: -0.11377005279064178
Final reward: -0.4274508059024811
Final reward: -0.430719256401062
Final reward: -0.43611493706703186
Final reward: -0.4430566728115082
Final reward: -0.4506438970565796
Final reward: -0.4576152563095093
Final reward: -0.46233007311820984
Final reward: -0.46279987692832947
Final reward: -0.45680221915245056
Final reward: -0.442123144865036
Final reward: -0.41700056195259094
Final reward: -0.380903422832489
Final reward: -0.35295677185058594
Final reward: -0.3191622197628021
Final reward: -0.27669838070869446
Final reward: -0.2254263162612915
Final reward: -0.23344337940216064
Final reward: -0.24325492978096008
Final reward: -0.24078761041164398
Final reward: -0.24637940526008606
Final reward: -0.27564537525177
Final reward: -0.22788159549236298
Final reward: -0.2585444152355194
Final reward: -0.29293563961982727
Final reward: -0.31076520681381226
Final reward: -0.2887805998325348
Final reward: -0.14742223918437958
Final reward: -0.1709265261888504
Final reward: -0.26240548491477966
Final reward: -0.24189159274101257
Final reward: -0.3218279480934143
Final reward: -0.3528355658054352
Final reward: -0.30708712339401245
Final reward: -0.1583631932735443
Final reward: -0.19986091554164886
Final reward: -0.24885548651218414
Final reward: -0.3144644796848297
Final reward: -0.3550259470939636
Final reward: -0.27422264218330383
Final reward: -0.14616282284259796
Final reward: -0.23443008959293365
Final reward: -0.3260273039340973
Final reward: -0.36783772706985474
Final reward: -0.28013840317726135
Final reward: -0.1435999721288681
Final reward: -0.22396786510944366
Final reward: -0.3289448022842407
Final reward: -0.3641631603240967
Final reward: -0.26864543557167053
Final reward: -0.16785366833209991
Final reward: -0.21493634581565857
Final reward: -0.3299716114997864
Final reward: -0.36572393774986267
Final reward: -0.29379701614379883
Final reward: -0.13092055916786194
Final reward: -0.22930118441581726
Final reward: -0.3372189700603485
Final reward: -0.377250611782074
Final reward: -0.3017662465572357
Final reward: -0.11450868099927902
Final reward: -0.5493294596672058
Final reward: -0.5485113263130188
Final reward: -0.5472737550735474
Final reward: -0.5459628105163574
Final reward: -0.5451012849807739
Final reward: -0.5453845262527466
Final reward: -0.5476288199424744
Final reward: -0.5526418089866638
Final reward: -0.5609967708587646
Final reward: -0.5727357268333435
Final reward: -0.5870780944824219
Final reward: -0.6022543907165527
Final reward: -0.6155766248703003
Final reward: -0.6326479315757751
Final reward: -0.6463790535926819
Final reward: -0.6448059678077698
Final reward: -0.6232306361198425
Final reward: -0.5958002805709839
Final reward: -0.5636895298957825
Final reward: -0.5286015272140503
Final reward: -0.4886264204978943
Final reward: -0.4419592618942261
Final reward: -0.3865243196487427
Final reward: -0.316868394613266
Final reward: -0.26256313920021057
Final reward: -0.3085605204105377
Final reward: -0.3266966640949249
Final reward: -0.2588464915752411
Final reward: -0.18102173507213593
Final reward: -0.2812354862689972
Final reward: -0.2595207095146179
Final reward: -0.3277486562728882
Final reward: -0.37418198585510254
Final reward: -0.36921757459640503
Final reward: -0.24710094928741455
Final reward: -0.1896549016237259
Final reward: -0.313929945230484
Final reward: -0.3818223476409912
Final reward: -0.39819854497909546
Final reward: -0.28986629843711853
Final reward: -0.22115501761436462
Final reward: -0.33870500326156616
Final reward: -0.3961310088634491
Final reward: -0.3908928334712982
Final reward: -0.24936328828334808
Final reward: -0.2775738537311554
Final reward: -0.38379794359207153
Final reward: -0.4184557795524597
Final reward: -0.3340863287448883
Final reward: -0.1483890861272812
Final reward: -0.20317617058753967
Final reward: -0.33845704793930054
Final reward: -0.38184991478919983
Final reward: -0.31042397022247314
Final reward: -0.10210924595594406
Final reward: -0.4274508059024811
Final reward: -0.430719256401062
Final reward: -0.43611493706703186
Final reward: -0.4430566728115082
Final reward: -0.4506438970565796
Final reward: -0.4576152563095093
Final reward: -0.46233007311820984
Final reward: -0.46279987692832947
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.45680221915245056
Final reward: -0.442123144865036
Final reward: -0.41700056195259094
Final reward: -0.380903422832489
Final reward: -0.35305196046829224
Final reward: -0.3182808458805084
Final reward: -0.27752307057380676
Final reward: -0.22507643699645996
Final reward: -0.231644868850708
Final reward: -0.24026282131671906
Final reward: -0.2368382215499878
Final reward: -0.2436646819114685
Final reward: -0.2658458948135376
Final reward: -0.21053647994995117
Final reward: -0.26871442794799805
Final reward: -0.29823192954063416
Final reward: -0.3171277940273285
Final reward: -0.2866429388523102
Final reward: -0.14153917133808136
Final reward: -0.16603858768939972
Final reward: -0.25924962759017944
Final reward: -0.25317221879959106
Final reward: -0.32631349563598633
Final reward: -0.35221701860427856
Final reward: -0.29367053508758545
Final reward: -0.1171264797449112
Final reward: -0.5122069120407104
Final reward: -0.5135276913642883
Final reward: -0.5155428647994995
Final reward: -0.5177316069602966
Final reward: -0.5193160176277161
Final reward: -0.5192590355873108
Final reward: -0.5162982940673828
Final reward: -0.5090450048446655
Final reward: -0.49618756771087646
Final reward: -0.4768518805503845
Final reward: -0.45118799805641174
Final reward: -0.421247273683548
Final reward: -0.3927393853664398
Final reward: -0.38622885942459106
Final reward: -0.4064582884311676
Final reward: -0.43905535340309143
Final reward: -0.4745052754878998
Final reward: -0.5014457702636719
Final reward: -0.5108243227005005
Final reward: -0.5198966860771179
Final reward: -0.48107650876045227
Final reward: -0.44313713908195496
Final reward: -0.4056331217288971
Final reward: -0.39399877190589905
Final reward: -0.35392242670059204
Final reward: -0.24600578844547272
Final reward: -0.1679653823375702
Final reward: -0.24371957778930664
Final reward: -0.3372115194797516
Final reward: -0.376006543636322
Final reward: -0.38421493768692017
Final reward: -0.32338738441467285
Final reward: -0.16792134940624237
Final reward: -0.250204861164093
Final reward: -0.35339534282684326
Final reward: -0.39378178119659424
Final reward: -0.345092236995697
Final reward: -0.23884133994579315
Final reward: -0.14651241898536682
Final reward: -0.23198015987873077
Final reward: -0.3443206548690796
Final reward: -0.3750913739204407
Final reward: -0.2890647351741791
Final reward: -0.12905319035053253
Final reward: -0.24491339921951294
Final reward: -0.35506242513656616
Final reward: -0.39674824476242065
Final reward: -0.3564876616001129
Final reward: -0.19512876868247986
Final reward: -0.14584366977214813
Final reward: -0.2998959422111511
Final reward: -0.36529234051704407
Final reward: -0.33897748589515686
Final reward: -0.1506219208240509
Final reward: -0.19164642691612244
Final reward: -0.3343249559402466
Final reward: -0.38776031136512756
Final reward: -0.3376627266407013
Final reward: -0.14702387154102325
Final reward: -0.2016163319349289
Final reward: -0.33931151032447815
Final reward: -0.3914845883846283
Final reward: -0.3318862318992615
Final reward: -0.16880019009113312
Final reward: -0.19931785762310028
Final reward: -0.30783388018608093
Final reward: -0.3645305335521698
Final reward: -0.3135826587677002
Final reward: -0.07173828780651093
Final reward: -0.37777531147003174
Final reward: -0.38146963715553284
Final reward: -0.38755157589912415
Final reward: -0.3953469395637512
Final reward: -0.4038315713405609
Final reward: -0.41159653663635254
Final reward: -0.41683220863342285
Final reward: -0.41735324263572693
Final reward: -0.410692423582077
Final reward: -0.3943004906177521
Final reward: -0.36590906977653503
Final reward: -0.32417190074920654
Final reward: -0.28812849521636963
Final reward: -0.25892066955566406
Final reward: -0.27282196283340454
Final reward: -0.2832318842411041
Final reward: -0.29145506024360657
Final reward: -0.2893046438694
Final reward: -0.2889286279678345
Final reward: -0.29001128673553467
Final reward: -0.2791863679885864
Final reward: -0.20798462629318237
Final reward: -0.24508929252624512
Final reward: -0.2735835015773773
Final reward: -0.28499412536621094
Final reward: -0.2040729522705078
Final reward: -0.21748562157154083
Final reward: -0.25098156929016113
Final reward: -0.2311299592256546
Final reward: -0.28764471411705017
Final reward: -0.33354976773262024
Final reward: -0.3421758711338043
Final reward: -0.2512246072292328
Final reward: -0.10890700668096542
Final reward: -0.4274508059024811
Final reward: -0.430719256401062
Final reward: -0.43611493706703186
Final reward: -0.4430566728115082
Final reward: -0.4506438970565796
Final reward: -0.4576152563095093
Final reward: -0.46233007311820984
Final reward: -0.46279987692832947
Final reward: -0.45680221915245056
Final reward: -0.442123144865036
Final reward: -0.41700056195259094
Final reward: -0.380903422832489
Final reward: -0.35407352447509766
Final reward: -0.31779730319976807
Final reward: -0.2766554355621338
Final reward: -0.22492511570453644
Final reward: -0.234345942735672
Final reward: -0.2446361929178238
Final reward: -0.23877471685409546
Final reward: -0.2430362105369568
Final reward: -0.2710452973842621
Final reward: -0.21677997708320618
Final reward: -0.26286396384239197
Final reward: -0.29303407669067383
Final reward: -0.3151094615459442
Final reward: -0.28613364696502686
Final reward: -0.1490204632282257
Final reward: -0.17391331493854523
Final reward: -0.2554495930671692
Final reward: -0.25700879096984863
Final reward: -0.3205779492855072
Final reward: -0.3364257216453552
Final reward: -0.25538861751556396
Final reward: -0.14037081599235535
Final reward: -0.21920901536941528
Final reward: -0.3194425702095032
Final reward: -0.3655243515968323
Final reward: -0.32140976190567017
Final reward: -0.1334802657365799
Final reward: -0.20368507504463196
Final reward: -0.30292072892189026
Final reward: -0.35778191685676575
Final reward: -0.29083096981048584
Final reward: -0.12167493253946304
Final reward: -0.2092677354812622
Final reward: -0.33326539397239685
Final reward: -0.36298972368240356
Final reward: -0.2651670277118683
Final reward: -0.16860967874526978
Final reward: -0.2581137716770172
Final reward: -0.3549886643886566
Final reward: -0.3819957673549652
Final reward: -0.3089180588722229
Final reward: -0.09679481387138367
Final reward: -0.37730085849761963
Final reward: -0.37909194827079773
Final reward: -0.3818172812461853
Final reward: -0.3847675025463104
Final reward: -0.3868968188762665
Final reward: -0.38682034611701965
Final reward: -0.3828366994857788
Final reward: -0.37299710512161255
Final reward: -0.3552493453025818
Final reward: -0.3277006447315216
Final reward: -0.28908583521842957
Final reward: -0.23968574404716492
Final reward: -0.18362535536289215
Final reward: -0.2006075233221054
Final reward: -0.24042855203151703
Final reward: -0.2730870246887207
Final reward: -0.326945960521698
Final reward: -0.3661692142486572
Final reward: -0.3831937909126282
Final reward: -0.3970402777194977
Final reward: -0.36522746086120605
Final reward: -0.31409019231796265
Final reward: -0.215164452791214
Final reward: -0.18824619054794312
Final reward: -0.2455615997314453
Final reward: -0.30962705612182617
Final reward: -0.36279454827308655
Final reward: -0.3868120610713959
Final reward: -0.34025445580482483
Final reward: -0.2612152695655823
Final reward: -0.11581678688526154
Final reward: -0.5493294596672058
Final reward: -0.5485113263130188
Final reward: -0.5472737550735474
Final reward: -0.5459628105163574
Final reward: -0.5451012849807739
Final reward: -0.5453845262527466
Final reward: -0.5476288199424744
Final reward: -0.5526418089866638
Final reward: -0.5609967708587646
Final reward: -0.5727357268333435
Final reward: -0.5870780944824219
Final reward: -0.6022543907165527
Final reward: -0.6155766248703003
Final reward: -0.6326479315757751
Final reward: -0.6463790535926819
Final reward: -0.6450256109237671
Final reward: -0.6231371760368347
Final reward: -0.5954781770706177
Final reward: -0.5639708638191223
Final reward: -0.5287801027297974
Final reward: -0.4883284568786621
Final reward: -0.4416554868221283
Final reward: -0.3863389492034912
Final reward: -0.3172588050365448
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.26845699548721313
Final reward: -0.3290635049343109
Final reward: -0.3573787808418274
Final reward: -0.3384925425052643
Final reward: -0.24253100156784058
Final reward: -0.14515691995620728
Final reward: -0.24326743185520172
Final reward: -0.3030029833316803
Final reward: -0.3530404269695282
Final reward: -0.35080665349960327
Final reward: -0.22058700025081635
Final reward: -0.19518345594406128
Final reward: -0.28704899549484253
Final reward: -0.36920028924942017
Final reward: -0.40071365237236023
Final reward: -0.3265126049518585
Final reward: -0.1154969185590744
Final reward: -0.5116276144981384
Final reward: -0.510749101638794
Final reward: -0.509419858455658
Final reward: -0.5080112218856812
Final reward: -0.5070852637290955
Final reward: -0.5073896646499634
Final reward: -0.5098012685775757
Final reward: -0.5151824355125427
Final reward: -0.5241348743438721
Final reward: -0.5366806983947754
Final reward: -0.5519607663154602
Final reward: -0.5680760145187378
Final reward: -0.5821808576583862
Final reward: -0.6002027988433838
Final reward: -0.6146591901779175
Final reward: -0.6132405400276184
Final reward: -0.5905937552452087
Final reward: -0.5607614517211914
Final reward: -0.5264714956283569
Final reward: -0.4880407750606537
Final reward: -0.44391319155693054
Final reward: -0.3911684453487396
Final reward: -0.3256191909313202
Final reward: -0.24251344799995422
Final reward: -0.28821808099746704
Final reward: -0.3076310157775879
Final reward: -0.24194535613059998
Final reward: -0.19838683307170868
Final reward: -0.2911732792854309
Final reward: -0.29166293144226074
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                   avg_speed ‚ñá‚ñÉ‚ñà‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñÇ‚ñá‚ñÜ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÇ‚ñà‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÑ‚ñÖ
wandb:                        cost ‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà
wandb:                  is_success ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   max_speed ‚ñá‚ñÉ‚ñà‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñÇ‚ñá‚ñÜ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÇ‚ñà‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÑ‚ñÖ
wandb:                      reward ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñà
wandb:             train/approx_kl ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÑ
wandb:         train/clip_fraction ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñà
wandb:            train/clip_range ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/cost_returns ‚ñÖ‚ñÅ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ
wandb:       train/cost_value_loss ‚ñÜ‚ñÉ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           train/cost_values ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:               train/entropy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:          train/entropy_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    train/explained_variance ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/lagrangian_multiplier ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train/loss ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             train/n_updates ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  train/policy_gradient_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñá
wandb:                   train/std ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            train/value_loss ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                   avg_speed 5.2
wandb:                        cost 1
wandb:                  is_success 1
wandb:                   max_speed 5.2
wandb:                      reward -0.09993
wandb:             train/approx_kl 0.02768
wandb:         train/clip_fraction 0.31401
wandb:            train/clip_range 0.2
wandb:          train/cost_returns 9.55022
wandb:       train/cost_value_loss 113.4815
wandb:           train/cost_values -0.43238
wandb:               train/entropy 1.37372
wandb:          train/entropy_loss 1.37756
wandb:    train/explained_variance 0.93568
wandb: train/lagrangian_multiplier 0.0
wandb:         train/learning_rate 0.0003
wandb:                  train/loss 0.41211
wandb:             train/n_updates 14690
wandb:  train/policy_gradient_loss 0.02153
wandb:                   train/std 0.20905
wandb:            train/value_loss 0.81288
wandb: 
wandb: üöÄ View run smooth-elevator-47 at: https://wandb.ai/ecrl/seed-testing/runs/an325vgg
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240123_021636-an325vgg/logs
