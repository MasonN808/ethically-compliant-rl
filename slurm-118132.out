wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240118_070015-6t248l2y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-plant-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/QUALITATIVE-TEST
wandb: üöÄ View run at https://wandb.ai/ecrl/QUALITATIVE-TEST/runs/6t248l2y
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240118_070015-hq0uahmd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-dream-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/QUALITATIVE-TEST
wandb: üöÄ View run at https://wandb.ai/ecrl/QUALITATIVE-TEST/runs/hq0uahmd
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240117_230015-pz9fksqe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-elevator-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/QUALITATIVE-TEST
wandb: üöÄ View run at https://wandb.ai/ecrl/QUALITATIVE-TEST/runs/pz9fksqe
Using cpu device
INITIALIZATION-_build_mlp()
weight : tensor([[ 0.0033, -0.0867, -0.2115,  ...,  0.2057, -0.0073,  0.0267],
        [ 0.0202,  0.1857,  0.0367,  ...,  0.1854, -0.1087,  0.0276],
        [-0.0432,  0.1964, -0.1853,  ...,  0.1022, -0.0665,  0.0796],
        ...,
        [-0.0986,  0.1507, -0.1287,  ...,  0.1463,  0.1655,  0.1827],
        [ 0.1647,  0.1103,  0.2244,  ...,  0.2166, -0.1351, -0.0444],
        [ 0.1720, -0.2087,  0.0381,  ..., -0.1565, -0.0987, -0.0804]])
bias : tensor([-0.0256, -0.1912,  0.1444,  0.0331,  0.1477, -0.1850, -0.0816,  0.0812,
         0.0613, -0.2049, -0.2068, -0.1219, -0.0595, -0.0814,  0.1651,  0.1042,
         0.0290,  0.2246,  0.1717,  0.2218,  0.0485, -0.1197, -0.1260, -0.1119,
         0.0116, -0.1922,  0.2264,  0.1223,  0.1190, -0.2109,  0.1177, -0.1132,
        -0.1178, -0.1953,  0.0707, -0.2141,  0.1392, -0.0947,  0.0950, -0.1275,
        -0.1255, -0.1221, -0.0504,  0.1605,  0.0617, -0.2255, -0.0619,  0.1421,
         0.0813,  0.1273,  0.0741,  0.2061,  0.2278,  0.0332, -0.0221,  0.0872,
         0.0526,  0.1324, -0.2196, -0.2029, -0.1558,  0.0261,  0.2179,  0.0762])
weight : tensor([[ 0.1073,  0.0962,  0.0901,  ...,  0.0387, -0.0410, -0.0933],
        [-0.0600,  0.0746,  0.0021,  ...,  0.0785,  0.0327,  0.0257],
        [ 0.0444,  0.0656,  0.0416,  ..., -0.0693,  0.0834, -0.0281],
        ...,
        [ 0.0464,  0.1121, -0.0888,  ...,  0.0006,  0.0366,  0.0360],
        [-0.1001, -0.1089,  0.0913,  ...,  0.0384,  0.0866,  0.1072],
        [-0.0046,  0.1113,  0.0822,  ..., -0.0404, -0.1173, -0.0959]])
bias : tensor([ 0.0483,  0.0380,  0.1058,  0.1005,  0.0997,  0.0382, -0.0767, -0.0639,
        -0.0028, -0.0031,  0.0972,  0.0344, -0.0457,  0.0713, -0.1138,  0.0714,
        -0.0971, -0.0197,  0.0574,  0.0083, -0.0867, -0.0307,  0.1080,  0.0762,
         0.0015,  0.1223,  0.1176, -0.1159,  0.0113,  0.1080, -0.0231,  0.0469,
         0.0348,  0.0040,  0.0811,  0.1084, -0.1027,  0.0329, -0.0082, -0.0576,
        -0.0428, -0.0968,  0.0297, -0.0291, -0.0286, -0.0895, -0.0936, -0.1221,
         0.0118,  0.0244, -0.0066,  0.0125,  0.0227, -0.0596,  0.0622, -0.0909,
         0.0634,  0.0780,  0.0378, -0.0363,  0.0550, -0.0568, -0.0143,  0.0663])
INITIALIZATION-_build()
weight : tensor([[ 0.0791,  0.4123,  0.2371,  ..., -0.0439,  0.0338,  0.3011],
        [ 0.1200,  0.3280,  0.1122,  ..., -0.1007, -0.3104, -0.1930],
        [ 0.1160,  0.1786,  0.0252,  ...,  0.4173, -0.1218,  0.4004],
        ...,
        [ 0.0276,  0.1466, -0.2631,  ..., -0.3851, -0.0770, -0.1395],
        [-0.2690,  0.0038,  0.0762,  ..., -0.0083,  0.0139, -0.1105],
        [ 0.1468,  0.1601,  0.3133,  ..., -0.1198,  0.1924,  0.2711]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
weight : tensor([[-0.1733,  0.0856,  0.1613,  ..., -0.2977,  0.0026, -0.0797],
        [ 0.0459, -0.2644,  0.0887,  ...,  0.1023,  0.0808,  0.3136],
        [-0.0707,  0.2351, -0.1154,  ..., -0.1615, -0.2249,  0.1527],
        ...,
        [ 0.2287,  0.3861,  0.1879,  ..., -0.0481,  0.4153,  0.2052],
        [-0.0497,  0.2787,  0.1176,  ..., -0.2083,  0.1529, -0.2262],
        [ 0.0446, -0.0550,  0.3608,  ...,  0.0101,  0.0279, -0.2456]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
-----------------------------------
| avg_speed          | 0.322      |
| is_success         | 0          |
| max_speed          | 0.322      |
| reward             | -0.3334257 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.38e+03  |
| time/              |            |
|    fps             | 133        |
|    iterations      | 1          |
|    time_elapsed    | 15         |
|    total_timesteps | 2048       |
-----------------------------------
Using cpu device
INITIALIZATION-_build_mlp()
weight : tensor([[-0.1955,  0.2186,  0.1943,  ...,  0.1395, -0.1394,  0.2188],
        [ 0.0065,  0.2067,  0.0895,  ...,  0.1449, -0.1150,  0.1972],
        [ 0.1543,  0.1432,  0.1589,  ..., -0.0465,  0.0903, -0.1826],
        ...,
        [ 0.1704, -0.1868,  0.1862,  ...,  0.0584, -0.1076,  0.1868],
        [-0.1036,  0.1978, -0.0847,  ...,  0.0364,  0.2208,  0.1754],
        [-0.2231, -0.0740,  0.0970,  ...,  0.1206, -0.0272,  0.2327]])
bias : tensor([ 0.1250,  0.1107,  0.0219, -0.1962,  0.1467,  0.2163, -0.0081,  0.1352,
         0.1054, -0.0836, -0.0622, -0.0657, -0.2228, -0.1929,  0.1944, -0.1002,
        -0.1077, -0.1203, -0.1359,  0.0012,  0.0310,  0.0447,  0.2211,  0.0578,
         0.1872,  0.1029,  0.2052, -0.1699, -0.1169,  0.0913, -0.0113,  0.0224,
         0.0079, -0.1091, -0.1355,  0.1377,  0.0952,  0.1508,  0.1941, -0.0749,
        -0.1212,  0.0356, -0.2013, -0.0286,  0.1190, -0.0381,  0.1594,  0.0555,
         0.0118,  0.0021, -0.1730, -0.0559,  0.0957, -0.1174, -0.0558, -0.2112,
         0.1049, -0.0094, -0.1347,  0.2225,  0.1623,  0.2138, -0.0784, -0.1687])
weight : tensor([[ 0.0893, -0.0854, -0.0888,  ...,  0.1177, -0.0011,  0.1077],
        [-0.0388, -0.0413,  0.0435,  ...,  0.0205, -0.0615, -0.0453],
        [ 0.0134,  0.0401, -0.1127,  ...,  0.1116, -0.0162, -0.0051],
        ...,
        [-0.1223, -0.0735, -0.0422,  ..., -0.0725, -0.0980, -0.0858],
        [-0.0770, -0.0370,  0.0510,  ...,  0.0647,  0.0654,  0.0288],
        [ 0.0164, -0.0700,  0.0155,  ..., -0.0016, -0.0777, -0.0766]])
bias : tensor([ 0.0770, -0.0868,  0.0195,  0.0259,  0.0469, -0.0143,  0.1239, -0.0394,
        -0.0433,  0.0308,  0.1166,  0.0335, -0.0205, -0.1136,  0.0155, -0.0270,
        -0.0991, -0.0075,  0.1087, -0.0396, -0.1014,  0.0451, -0.0087,  0.1198,
        -0.0455, -0.0899, -0.0789,  0.0804,  0.0629,  0.0297, -0.0682, -0.0611,
        -0.0806,  0.1129, -0.0444, -0.0519,  0.0356,  0.1090, -0.1210,  0.1131,
         0.0276, -0.0582, -0.1145,  0.0724, -0.1025,  0.0819,  0.0684, -0.1103,
         0.1134, -0.0588, -0.0984,  0.1155, -0.0299, -0.0625,  0.0026,  0.0852,
         0.0176, -0.1121,  0.0060, -0.0893, -0.0640,  0.0859,  0.0542,  0.0842])
INITIALIZATION-_build()
weight : tensor([[ 0.1839, -0.3629, -0.0635,  ..., -0.0120, -0.2180, -0.3020],
        [ 0.0222,  0.1495, -0.0079,  ..., -0.0751, -0.0083, -0.0477],
        [-0.0701,  0.0535,  0.0299,  ..., -0.1731, -0.1297,  0.2240],
        ...,
        [ 0.2438, -0.0865,  0.2166,  ...,  0.2005, -0.2127,  0.3164],
        [-0.0449, -0.2547, -0.0565,  ..., -0.1384, -0.2717,  0.3087],
        [-0.0027,  0.0983, -0.1736,  ..., -0.0737,  0.0879,  0.0961]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
weight : tensor([[-0.2156,  0.3493, -0.3289,  ..., -0.1695,  0.3023,  0.1746],
        [-0.1659, -0.1414, -0.0259,  ...,  0.0577, -0.3301,  0.0934],
        [-0.1283, -0.4215, -0.1417,  ...,  0.1921,  0.1347,  0.0136],
        ...,
        [ 0.2258,  0.1354, -0.2863,  ..., -0.0847,  0.0157, -0.0865],
        [-0.2401, -0.1291,  0.1511,  ...,  0.0461,  0.3094,  0.0838],
        [ 0.2039, -0.2014, -0.0128,  ..., -0.0753,  0.0355, -0.1201]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
------------------------------------
| avg_speed          | 0.0953      |
| is_success         | 0           |
| max_speed          | 0.0953      |
| reward             | -0.56444377 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.18e+03   |
| time/              |             |
|    fps             | 118         |
|    iterations      | 1           |
|    time_elapsed    | 17          |
|    total_timesteps | 2048        |
------------------------------------
Using cpu device
INITIALIZATION-_build_mlp()
weight : tensor([[-0.2325, -0.2295,  0.1438,  ..., -0.0474,  0.2355,  0.0813],
        [ 0.0098,  0.1823,  0.0895,  ...,  0.0284, -0.2106,  0.0764],
        [-0.0535,  0.0744,  0.1950,  ...,  0.0429,  0.1669, -0.1887],
        ...,
        [ 0.0661, -0.0597,  0.0488,  ...,  0.1175, -0.1446,  0.0656],
        [ 0.0125,  0.1250, -0.0571,  ..., -0.0730,  0.0076,  0.0719],
        [ 0.0808,  0.1178,  0.0284,  ...,  0.2016,  0.1824,  0.1262]])
bias : tensor([-2.1665e-01,  8.0007e-02,  1.7332e-01,  9.9430e-02,  1.5854e-02,
        -6.8220e-02,  2.7358e-02, -2.5563e-02,  2.1621e-01, -6.3833e-02,
         1.5914e-01, -3.0701e-02, -5.0049e-02,  2.1608e-01, -2.2505e-01,
         1.2472e-01, -2.1919e-01, -2.2898e-01,  1.3710e-01,  1.6581e-01,
        -9.5879e-02, -4.7231e-02, -5.1038e-02,  2.1938e-01,  2.3225e-01,
        -2.1517e-01, -8.1058e-02,  2.6631e-02, -2.0568e-01, -1.8384e-01,
        -4.3093e-02, -1.5826e-01, -1.1006e-01, -1.2754e-01, -2.2061e-01,
         1.1404e-01,  2.8411e-02, -1.8096e-01, -4.1097e-02,  2.3521e-01,
         3.9978e-02, -1.3151e-02, -1.3797e-01,  1.6069e-01,  1.8513e-01,
         1.7888e-01, -1.1269e-01,  1.2448e-01, -2.2409e-01, -9.9315e-02,
         1.0827e-01,  9.8500e-02,  3.9757e-02, -2.1568e-01, -9.8079e-02,
        -7.2630e-02, -1.1271e-01,  7.3445e-02,  4.4028e-02, -1.2378e-02,
         1.3637e-01, -1.9943e-02,  1.4367e-01, -1.1290e-04])
weight : tensor([[ 0.0853,  0.0647,  0.0955,  ...,  0.0020,  0.0421,  0.0377],
        [ 0.0193,  0.0349,  0.1137,  ...,  0.1035, -0.0018, -0.0391],
        [-0.0058, -0.0396, -0.0934,  ...,  0.0032,  0.0876, -0.0581],
        ...,
        [ 0.0407,  0.1151, -0.1040,  ..., -0.0307,  0.0630,  0.0671],
        [ 0.0001,  0.0545, -0.1164,  ..., -0.0833,  0.1015, -0.0987],
        [ 0.0297, -0.0124,  0.0841,  ...,  0.0056, -0.0526,  0.0141]])
bias : tensor([ 0.0055, -0.0997, -0.0419,  0.0831, -0.0414,  0.0307, -0.0542,  0.0676,
        -0.0635,  0.0535, -0.0850, -0.0457, -0.1233,  0.1192,  0.1244,  0.1136,
         0.0545, -0.0650, -0.0765, -0.0182,  0.0413, -0.1005,  0.1091, -0.1135,
         0.0485, -0.0560, -0.0883, -0.0795,  0.1197, -0.0986, -0.0031,  0.0796,
         0.0554, -0.0294,  0.0458, -0.1043, -0.0174, -0.0375, -0.1214,  0.0866,
         0.0456,  0.0828, -0.0699,  0.0957,  0.0883,  0.0088, -0.1222,  0.0850,
        -0.0548, -0.1031,  0.0664,  0.1177, -0.0587,  0.0570,  0.0129,  0.0655,
        -0.0729, -0.0266, -0.1233, -0.0325,  0.0197,  0.0753, -0.0951, -0.0888])
INITIALIZATION-_build()
weight : tensor([[ 0.2377, -0.2985,  0.1523,  ...,  0.0422,  0.3538, -0.0142],
        [-0.1625,  0.1164, -0.0373,  ..., -0.1564, -0.1304,  0.2503],
        [-0.0627, -0.2321,  0.3671,  ...,  0.1778,  0.0251,  0.0553],
        ...,
        [-0.1354, -0.0477,  0.0668,  ...,  0.0501,  0.3755,  0.0627],
        [-0.2559, -0.3570,  0.2091,  ...,  0.0676, -0.1440,  0.0525],
        [-0.1719, -0.1500,  0.1250,  ...,  0.2094, -0.3270,  0.0180]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
weight : tensor([[-0.3343, -0.1542, -0.0148,  ..., -0.2049,  0.1401,  0.0005],
        [ 0.2543,  0.0902, -0.1824,  ...,  0.1371, -0.2467,  0.2415],
        [ 0.0857, -0.1899, -0.1910,  ...,  0.0361, -0.0216,  0.2585],
        ...,
        [ 0.0676, -0.0693, -0.2759,  ...,  0.1750, -0.0246, -0.3440],
        [ 0.2614,  0.0598, -0.0185,  ..., -0.0882, -0.2103, -0.1095],
        [-0.2267,  0.0097,  0.0470,  ...,  0.0743,  0.0291, -0.0111]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
-----------------------------------
| avg_speed          | 1.95       |
| is_success         | 0          |
| max_speed          | 1.95       |
| reward             | -0.7047235 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.1e+03   |
| time/              |            |
|    fps             | 116        |
|    iterations      | 1          |
|    time_elapsed    | 17         |
|    total_timesteps | 2048       |
-----------------------------------
TRAINING:
weight : tensor([[ 0.0791,  0.4123,  0.2371,  ..., -0.0439,  0.0338,  0.3011],
        [ 0.1200,  0.3280,  0.1122,  ..., -0.1007, -0.3104, -0.1930],
        [ 0.1160,  0.1786,  0.0252,  ...,  0.4173, -0.1218,  0.4004],
        ...,
        [ 0.0276,  0.1466, -0.2631,  ..., -0.3851, -0.0770, -0.1395],
        [-0.2690,  0.0038,  0.0762,  ..., -0.0083,  0.0139, -0.1105],
        [ 0.1468,  0.1601,  0.3133,  ..., -0.1198,  0.1924,  0.2711]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
weight : tensor([[-0.1733,  0.0856,  0.1613,  ..., -0.2977,  0.0026, -0.0797],
        [ 0.0459, -0.2644,  0.0887,  ...,  0.1023,  0.0808,  0.3136],
        [-0.0707,  0.2351, -0.1154,  ..., -0.1615, -0.2249,  0.1527],
        ...,
        [ 0.2287,  0.3861,  0.1879,  ..., -0.0481,  0.4153,  0.2052],
        [-0.0497,  0.2787,  0.1176,  ..., -0.2083,  0.1529, -0.2262],
        [ 0.0446, -0.0550,  0.3608,  ...,  0.0101,  0.0279, -0.2456]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
policy_loss: 2.7008354663848877e-08
entropy_loss: -2.837876796722412
value_loss: 670.3168334960938
loss: 335.1584167480469
policy_loss: 0.0006463918834924698
entropy_loss: -2.837352991104126
value_loss: 655.5706787109375
loss: 327.7859802246094
policy_loss: -0.0004735458642244339
entropy_loss: -2.8372511863708496
value_loss: 656.0308837890625
loss: 328.01495361328125
policy_loss: 0.000503145158290863
entropy_loss: -2.837211847305298
value_loss: 676.6134033203125
loss: 338.30718994140625
policy_loss: -0.0011367853730916977
entropy_loss: -2.8370728492736816
value_loss: 688.5106811523438
loss: 344.25421142578125
policy_loss: -0.0002884846180677414
entropy_loss: -2.836803674697876
value_loss: 643.0380249023438
loss: 321.51873779296875
policy_loss: -0.00047048041597008705
entropy_loss: -2.836609125137329
value_loss: 625.6612548828125
loss: 312.8301696777344
policy_loss: -0.00012983474880456924
entropy_loss: -2.8363585472106934
value_loss: 671.9069213867188
loss: 335.9533386230469
policy_loss: -0.001918833702802658
entropy_loss: -2.8362059593200684
value_loss: 608.684326171875
loss: 304.3402404785156
policy_loss: -0.0013448428362607956
entropy_loss: -2.836097478866577
value_loss: 657.635009765625
loss: 328.816162109375
policy_loss: -0.0006817695684731007
entropy_loss: -2.836045980453491
value_loss: 661.5679321289062
loss: 330.7832946777344
policy_loss: -0.0001812046393752098
entropy_loss: -2.8360350131988525
value_loss: 671.2125244140625
loss: 335.6060791015625
policy_loss: -0.002125076949596405
entropy_loss: -2.835893154144287
value_loss: 639.947021484375
loss: 319.97137451171875
policy_loss: -0.002613220363855362
entropy_loss: -2.8357279300689697
value_loss: 667.5524291992188
loss: 333.7735900878906
policy_loss: -0.0006044767796993256
entropy_loss: -2.835552453994751
value_loss: 666.1742553710938
loss: 333.0865173339844
policy_loss: -0.0009374944493174553
entropy_loss: -2.8354058265686035
value_loss: 596.4151611328125
loss: 298.2066345214844
policy_loss: -0.0034344494342803955
entropy_loss: -2.8352980613708496
value_loss: 629.5211181640625
loss: 314.7571105957031
policy_loss: -0.0016066688112914562
entropy_loss: -2.835115909576416
value_loss: 635.4408569335938
loss: 317.71881103515625
policy_loss: -0.0012173671275377274
entropy_loss: -2.834974765777588
value_loss: 623.6241455078125
loss: 311.81085205078125
policy_loss: -0.0018297992646694183
entropy_loss: -2.834857702255249
value_loss: 651.609619140625
loss: 325.802978515625
policy_loss: 1.4837831258773804e-05
entropy_loss: -2.8347699642181396
value_loss: 582.8325805664062
loss: 291.4162902832031
policy_loss: -0.003882579505443573
entropy_loss: -2.834686279296875
value_loss: 651.671875
loss: 325.8320617675781
policy_loss: -0.00328768789768219
entropy_loss: -2.8345932960510254
value_loss: 645.2191162109375
loss: 322.60626220703125
policy_loss: -0.003153029829263687
entropy_loss: -2.834512233734131
value_loss: 630.91650390625
loss: 315.4551086425781
policy_loss: -0.004692564718425274
entropy_loss: -2.8344080448150635
value_loss: 595.5911254882812
loss: 297.7908630371094
policy_loss: -0.001846641767770052
entropy_loss: -2.8343088626861572
value_loss: 688.8743286132812
loss: 344.435302734375
policy_loss: -0.0024562329053878784
entropy_loss: -2.834240198135376
value_loss: 617.09619140625
loss: 308.545654296875
policy_loss: -0.0032702451571822166
entropy_loss: -2.834179162979126
value_loss: 579.9163818359375
loss: 289.9549255371094
policy_loss: -0.004329890478402376
entropy_loss: -2.8340494632720947
value_loss: 648.3576049804688
loss: 324.1744689941406
policy_loss: -0.003042355179786682
entropy_loss: -2.8339040279388428
value_loss: 659.4590454101562
loss: 329.7264709472656
policy_loss: -0.0019071754068136215
entropy_loss: -2.833810329437256
value_loss: 577.4038696289062
loss: 288.7000427246094
policy_loss: -0.004501975141465664
entropy_loss: -2.833702325820923
value_loss: 567.1045532226562
loss: 283.5477600097656
policy_loss: -0.003056846559047699
entropy_loss: -2.8335835933685303
value_loss: 635.326904296875
loss: 317.660400390625
policy_loss: -0.0043390896171331406
entropy_loss: -2.833448886871338
value_loss: 568.9815063476562
loss: 284.4864196777344
policy_loss: -0.005288466811180115
entropy_loss: -2.833270788192749
value_loss: 594.2162475585938
loss: 297.10284423828125
policy_loss: -0.002638481557369232
entropy_loss: -2.8331339359283447
value_loss: 623.9765014648438
loss: 311.9856262207031
policy_loss: -0.00418489146977663
entropy_loss: -2.833005428314209
value_loss: 569.6409912109375
loss: 284.8163146972656
policy_loss: -0.0011842474341392517
entropy_loss: -2.8328588008880615
value_loss: 636.60791015625
loss: 318.3027648925781
policy_loss: -0.0016243299469351768
entropy_loss: -2.8327791690826416
value_loss: 590.9490356445312
loss: 295.472900390625
policy_loss: -0.009401964023709297
entropy_loss: -2.832660436630249
value_loss: 595.8056640625
loss: 297.8934326171875
-----------------------------------------
| avg_speed               | 0.392       |
| is_success              | 0           |
| max_speed               | 0.392       |
| reward                  | -0.41856182 |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.47e+03   |
| time/                   |             |
|    fps                  | 130         |
|    iterations           | 2           |
|    time_elapsed         | 31          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.002422669 |
|    clip_fraction        | 0.00454     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.83       |
|    explained_variance   | -0.00856    |
|    learning_rate        | 0.0003      |
|    loss                 | 298         |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0022     |
|    std                  | 0.997       |
|    value_loss           | 631         |
-----------------------------------------
TRAINING:
weight : tensor([[ 0.1839, -0.3629, -0.0635,  ..., -0.0120, -0.2180, -0.3020],
        [ 0.0222,  0.1495, -0.0079,  ..., -0.0751, -0.0083, -0.0477],
        [-0.0701,  0.0535,  0.0299,  ..., -0.1731, -0.1297,  0.2240],
        ...,
        [ 0.2438, -0.0865,  0.2166,  ...,  0.2005, -0.2127,  0.3164],
        [-0.0449, -0.2547, -0.0565,  ..., -0.1384, -0.2717,  0.3087],
        [-0.0027,  0.0983, -0.1736,  ..., -0.0737,  0.0879,  0.0961]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
weight : tensor([[-0.2156,  0.3493, -0.3289,  ..., -0.1695,  0.3023,  0.1746],
        [-0.1659, -0.1414, -0.0259,  ...,  0.0577, -0.3301,  0.0934],
        [-0.1283, -0.4215, -0.1417,  ...,  0.1921,  0.1347,  0.0136],
        ...,
        [ 0.2258,  0.1354, -0.2863,  ..., -0.0847,  0.0157, -0.0865],
        [-0.2401, -0.1291,  0.1511,  ...,  0.0461,  0.3094,  0.0838],
        [ 0.2039, -0.2014, -0.0128,  ..., -0.0753,  0.0355, -0.1201]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
policy_loss: -4.190951585769653e-08
entropy_loss: -2.837876796722412
value_loss: 425.83953857421875
loss: 212.91976928710938
policy_loss: 0.0003949408419430256
entropy_loss: -2.8378777503967285
value_loss: 397.580810546875
loss: 198.79080200195312
policy_loss: -1.8065795302391052e-05
entropy_loss: -2.8379263877868652
value_loss: 427.9893493652344
loss: 213.99465942382812
policy_loss: -0.00020650960505008698
entropy_loss: -2.8378052711486816
value_loss: 414.86810302734375
loss: 207.433837890625
policy_loss: -0.0009142663329839706
entropy_loss: -2.8379194736480713
value_loss: 402.634521484375
loss: 201.31634521484375
policy_loss: -0.0014561954885721207
entropy_loss: -2.8379034996032715
value_loss: 406.9530334472656
loss: 203.47506713867188
policy_loss: 0.0006355131044983864
entropy_loss: -2.837775945663452
value_loss: 405.7118225097656
loss: 202.85655212402344
policy_loss: -0.0020613502711057663
entropy_loss: -2.8378167152404785
value_loss: 429.99102783203125
loss: 214.9934539794922
policy_loss: -0.0009875744581222534
entropy_loss: -2.837937831878662
value_loss: 411.98052978515625
loss: 205.98927307128906
policy_loss: -0.0028668269515037537
entropy_loss: -2.8381192684173584
value_loss: 415.8256530761719
loss: 207.9099578857422
policy_loss: -0.002737840637564659
entropy_loss: -2.8382017612457275
value_loss: 384.2434997558594
loss: 192.1190185546875
policy_loss: -0.001251942478120327
entropy_loss: -2.838226556777954
value_loss: 412.5130310058594
loss: 206.25526428222656
policy_loss: -0.003329206258058548
entropy_loss: -2.838327169418335
value_loss: 404.2972412109375
loss: 202.14529418945312
policy_loss: -0.0023164183367043734
entropy_loss: -2.8384108543395996
value_loss: 394.39666748046875
loss: 197.19601440429688
policy_loss: -0.003477495163679123
entropy_loss: -2.83843994140625
value_loss: 403.9731140136719
loss: 201.9830780029297
policy_loss: -0.0016303015872836113
entropy_loss: -2.8385567665100098
value_loss: 401.5404052734375
loss: 200.76856994628906
policy_loss: 0.00019348692148923874
entropy_loss: -2.8387033939361572
value_loss: 421.7312316894531
loss: 210.86581420898438
policy_loss: -0.0028199658263474703
entropy_loss: -2.8388822078704834
value_loss: 375.23291015625
loss: 187.61363220214844
policy_loss: -0.005884332582354546
entropy_loss: -2.839081048965454
value_loss: 408.6451110839844
loss: 204.31666564941406
policy_loss: -0.006099388934671879
entropy_loss: -2.8393290042877197
value_loss: 378.067626953125
loss: 189.0277099609375
policy_loss: -0.000995926558971405
entropy_loss: -2.8394663333892822
value_loss: 399.47393798828125
loss: 199.73597717285156
policy_loss: -0.008178840391337872
entropy_loss: -2.8396201133728027
value_loss: 388.4624328613281
loss: 194.22303771972656
policy_loss: -0.004305648617446423
entropy_loss: -2.839790105819702
value_loss: 394.9666442871094
loss: 197.47901916503906
policy_loss: -0.003188042901456356
entropy_loss: -2.840008020401001
value_loss: 380.3857116699219
loss: 190.18966674804688
policy_loss: -0.0036416128277778625
entropy_loss: -2.840198278427124
value_loss: 396.2063903808594
loss: 198.09954833984375
policy_loss: -0.005098460242152214
entropy_loss: -2.840355157852173
value_loss: 389.9232177734375
loss: 194.95651245117188
policy_loss: -0.008355509489774704
entropy_loss: -2.8405954837799072
value_loss: 390.0466003417969
loss: 195.0149383544922
policy_loss: -0.00115123949944973
entropy_loss: -2.8408684730529785
value_loss: 366.5384521484375
loss: 183.26808166503906
policy_loss: -0.006258551962673664
entropy_loss: -2.8411102294921875
value_loss: 378.54541015625
loss: 189.26644897460938
policy_loss: 0.001364152878522873
entropy_loss: -2.841338872909546
value_loss: 379.74713134765625
loss: 189.8749237060547
policy_loss: -0.0036296015605330467
entropy_loss: -2.8416097164154053
value_loss: 382.368408203125
loss: 191.18057250976562
policy_loss: -0.01077323779463768
entropy_loss: -2.8418478965759277
value_loss: 381.6454772949219
loss: 190.8119659423828
policy_loss: 0.0008841734379529953
entropy_loss: -2.8421366214752197
value_loss: 382.6319580078125
loss: 191.31686401367188
policy_loss: -0.004460526630282402
entropy_loss: -2.8423995971679688
value_loss: 388.6280517578125
loss: 194.3095703125
policy_loss: -0.010775843635201454
entropy_loss: -2.8426706790924072
value_loss: 366.47607421875
loss: 183.22726440429688
policy_loss: -0.006939309183508158
entropy_loss: -2.8429388999938965
value_loss: 364.4945068359375
loss: 182.2403106689453
policy_loss: -0.006837084889411926
entropy_loss: -2.8432576656341553
value_loss: 380.79376220703125
loss: 190.39004516601562
policy_loss: -0.002741602249443531
entropy_loss: -2.843635320663452
value_loss: 382.6462707519531
loss: 191.3203887939453
policy_loss: -0.008321138098835945
entropy_loss: -2.8440096378326416
value_loss: 355.6700439453125
loss: 177.8267059326172
policy_loss: -0.0038576312363147736
entropy_loss: -2.8443360328674316
value_loss: 362.840576171875
loss: 181.4164276123047
-----------------------------------------
| avg_speed               | 1.22        |
| is_success              | 0           |
| max_speed               | 1.22        |
| reward                  | -0.4878988  |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.43e+03   |
| time/                   |             |
|    fps                  | 119         |
|    iterations           | 2           |
|    time_elapsed         | 34          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.004184275 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.84       |
|    explained_variance   | -0.015      |
|    learning_rate        | 0.0003      |
|    loss                 | 181         |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00335    |
|    std                  | 1           |
|    value_loss           | 393         |
-----------------------------------------
TRAINING:
weight : tensor([[ 0.2377, -0.2985,  0.1523,  ...,  0.0422,  0.3538, -0.0142],
        [-0.1625,  0.1164, -0.0373,  ..., -0.1564, -0.1304,  0.2503],
        [-0.0627, -0.2321,  0.3671,  ...,  0.1778,  0.0251,  0.0553],
        ...,
        [-0.1354, -0.0477,  0.0668,  ...,  0.0501,  0.3755,  0.0627],
        [-0.2559, -0.3570,  0.2091,  ...,  0.0676, -0.1440,  0.0525],
        [-0.1719, -0.1500,  0.1250,  ...,  0.2094, -0.3270,  0.0180]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
weight : tensor([[-0.3343, -0.1542, -0.0148,  ..., -0.2049,  0.1401,  0.0005],
        [ 0.2543,  0.0902, -0.1824,  ...,  0.1371, -0.2467,  0.2415],
        [ 0.0857, -0.1899, -0.1910,  ...,  0.0361, -0.0216,  0.2585],
        ...,
        [ 0.0676, -0.0693, -0.2759,  ...,  0.1750, -0.0246, -0.3440],
        [ 0.2614,  0.0598, -0.0185,  ..., -0.0882, -0.2103, -0.1095],
        [-0.2267,  0.0097,  0.0470,  ...,  0.0743,  0.0291, -0.0111]])
bias : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
policy_loss: 1.3504177331924438e-07
entropy_loss: -2.837876796722412
value_loss: 376.69586181640625
loss: 188.34793090820312
policy_loss: -0.00035706162452697754
entropy_loss: -2.8378965854644775
value_loss: 349.2204895019531
loss: 174.60989379882812
policy_loss: 0.00026442669332027435
entropy_loss: -2.838326930999756
value_loss: 397.2369384765625
loss: 198.6187286376953
policy_loss: -6.6086649894714355e-06
entropy_loss: -2.8385465145111084
value_loss: 387.5847473144531
loss: 193.79237365722656
policy_loss: -0.0012219888158142567
entropy_loss: -2.83894944190979
value_loss: 381.76055908203125
loss: 190.87905883789062
policy_loss: -0.000959611963480711
entropy_loss: -2.8392958641052246
value_loss: 373.7781066894531
loss: 186.88809204101562
policy_loss: -0.001438044011592865
entropy_loss: -2.8396494388580322
value_loss: 367.91180419921875
loss: 183.9544677734375
policy_loss: 0.0003056027926504612
entropy_loss: -2.8399062156677246
value_loss: 374.6904602050781
loss: 187.3455352783203
policy_loss: -0.0008439281955361366
entropy_loss: -2.840240478515625
value_loss: 378.5359802246094
loss: 189.26715087890625
policy_loss: -0.0014437641948461533
entropy_loss: -2.840623378753662
value_loss: 367.0099182128906
loss: 183.50350952148438
policy_loss: -0.0043121203780174255
entropy_loss: -2.8409693241119385
value_loss: 364.6298522949219
loss: 182.31060791015625
policy_loss: 0.0005265558138489723
entropy_loss: -2.841306209564209
value_loss: 375.2026672363281
loss: 187.60186767578125
policy_loss: -0.0054090917110443115
entropy_loss: -2.8416173458099365
value_loss: 373.5520324707031
loss: 186.77061462402344
policy_loss: -8.758343756198883e-05
entropy_loss: -2.841897487640381
value_loss: 365.70037841796875
loss: 182.85009765625
policy_loss: -0.00156339630484581
entropy_loss: -2.8421671390533447
value_loss: 371.425048828125
loss: 185.71096801757812
policy_loss: -0.0008923867717385292
entropy_loss: -2.8424630165100098
value_loss: 362.3262634277344
loss: 181.16224670410156
policy_loss: -0.0034295059740543365
entropy_loss: -2.842785120010376
value_loss: 376.70477294921875
loss: 188.3489532470703
policy_loss: -0.005066751502454281
entropy_loss: -2.8431413173675537
value_loss: 366.9646301269531
loss: 183.4772491455078
policy_loss: -0.003227822482585907
entropy_loss: -2.8435099124908447
value_loss: 348.8443908691406
loss: 174.41896057128906
policy_loss: 0.0016735917888581753
entropy_loss: -2.843799352645874
value_loss: 368.3446044921875
loss: 184.17398071289062
policy_loss: -0.003297284245491028
entropy_loss: -2.844104528427124
value_loss: 379.3189392089844
loss: 189.6561737060547
policy_loss: -0.005410932004451752
entropy_loss: -2.8444466590881348
value_loss: 365.0545959472656
loss: 182.52188110351562
policy_loss: -0.003134036436676979
entropy_loss: -2.8448166847229004
value_loss: 360.21856689453125
loss: 180.1061553955078
policy_loss: 0.00021855812519788742
entropy_loss: -2.8451955318450928
value_loss: 344.35089111328125
loss: 172.1756591796875
policy_loss: -0.01012871228158474
entropy_loss: -2.845468282699585
value_loss: 372.67657470703125
loss: 186.32815551757812
policy_loss: -0.00161786749958992
entropy_loss: -2.8456990718841553
value_loss: 358.3711242675781
loss: 179.18394470214844
policy_loss: 0.002545383758842945
entropy_loss: -2.8459837436676025
value_loss: 357.8157958984375
loss: 178.9104461669922
policy_loss: -0.0035409231204539537
entropy_loss: -2.8462679386138916
value_loss: 348.155029296875
loss: 174.073974609375
policy_loss: 0.0010212194174528122
entropy_loss: -2.846579074859619
value_loss: 349.5758056640625
loss: 174.78892517089844
policy_loss: -0.008533545769751072
entropy_loss: -2.8468592166900635
value_loss: 346.90966796875
loss: 173.44630432128906
policy_loss: -0.0018859384581446648
entropy_loss: -2.8471932411193848
value_loss: 371.67120361328125
loss: 185.83370971679688
policy_loss: -0.004740831442177296
entropy_loss: -2.847534418106079
value_loss: 356.95086669921875
loss: 178.47068786621094
policy_loss: -0.008750500157475471
entropy_loss: -2.8478775024414062
value_loss: 357.7108459472656
loss: 178.8466796875
policy_loss: -0.001634441316127777
entropy_loss: -2.848254919052124
value_loss: 357.4830322265625
loss: 178.73988342285156
policy_loss: -0.001972945872694254
entropy_loss: -2.8486521244049072
value_loss: 354.00433349609375
loss: 177.0001983642578
policy_loss: -0.0034303944557905197
entropy_loss: -2.8490145206451416
value_loss: 344.5201416015625
loss: 172.2566375732422
policy_loss: -0.003774767741560936
entropy_loss: -2.8493714332580566
value_loss: 354.6741638183594
loss: 177.33331298828125
policy_loss: 0.0007280167192220688
entropy_loss: -2.8497812747955322
value_loss: 350.16650390625
loss: 175.083984375
policy_loss: -0.00549090001732111
entropy_loss: -2.850208282470703
value_loss: 355.6203308105469
loss: 177.80467224121094
policy_loss: -0.00775537732988596
entropy_loss: -2.8506202697753906
value_loss: 341.8665771484375
loss: 170.925537109375
------------------------------------------
| avg_speed               | 0.661        |
| is_success              | 0            |
| max_speed               | 0.661        |
| reward                  | -0.5394556   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.09e+03    |
| time/                   |              |
|    fps                  | 114          |
|    iterations           | 2            |
|    time_elapsed         | 35           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0035883202 |
|    clip_fraction        | 0.0108       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0789      |
|    learning_rate        | 0.0003       |
|    loss                 | 171          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00245     |
|    std                  | 1.01         |
|    value_loss           | 364          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.0793,  0.4126,  0.2368,  ..., -0.0435,  0.0340,  0.3010],
        [ 0.1214,  0.3284,  0.1120,  ..., -0.1007, -0.3108, -0.1933],
        [ 0.1161,  0.1787,  0.0251,  ...,  0.4175, -0.1217,  0.4004],
        ...,
        [ 0.0273,  0.1463, -0.2635,  ..., -0.3854, -0.0772, -0.1395],
        [-0.2692,  0.0036,  0.0762,  ..., -0.0083,  0.0140, -0.1106],
        [ 0.1466,  0.1600,  0.3134,  ..., -0.1199,  0.1923,  0.2710]])
bias : tensor([ 7.1937e-05,  3.4463e-04, -1.2311e-04,  2.0384e-05, -2.9553e-04,
        -2.4573e-04,  4.7379e-05, -2.7200e-04, -4.2831e-04,  5.8090e-05,
        -2.8700e-04,  1.9658e-04,  4.3662e-05,  3.2733e-04, -5.9395e-05,
         9.3708e-05, -1.1302e-04,  2.4534e-04, -2.9935e-04,  5.1246e-05,
         2.2861e-04,  1.5978e-04,  1.8130e-04, -3.0535e-05,  2.4647e-04,
        -8.5263e-05, -2.5323e-04,  2.8648e-05,  3.2040e-04, -4.8387e-05,
        -5.8923e-04, -9.6675e-05,  2.4835e-04,  7.6663e-04,  4.9642e-04,
        -4.5192e-04, -2.3547e-04,  1.2082e-04, -2.3770e-04,  4.6843e-04,
        -2.8433e-04,  3.8630e-04,  7.8880e-05,  2.1435e-04, -4.4575e-04,
        -2.6470e-05, -1.8497e-04,  7.0826e-05, -1.0841e-04,  1.6817e-04,
        -1.6319e-05,  1.2882e-04,  1.7578e-05,  2.3590e-04,  7.7007e-04,
        -8.8902e-05,  2.8810e-04,  4.1303e-05, -7.6327e-05, -3.5253e-04,
        -3.8707e-05,  2.8732e-05, -5.3248e-06,  6.1670e-05])
weight : tensor([[-0.1733,  0.0856,  0.1613,  ..., -0.2977,  0.0026, -0.0797],
        [ 0.0457, -0.2646,  0.0884,  ...,  0.1019,  0.0812,  0.3133],
        [-0.0708,  0.2352, -0.1154,  ..., -0.1613, -0.2249,  0.1526],
        ...,
        [ 0.2287,  0.3862,  0.1880,  ..., -0.0479,  0.4152,  0.2052],
        [-0.0496,  0.2787,  0.1175,  ..., -0.2083,  0.1528, -0.2262],
        [ 0.0446, -0.0550,  0.3607,  ...,  0.0101,  0.0278, -0.2456]])
bias : tensor([-1.2762e-04, -3.1522e-04, -8.1595e-05, -1.7102e-04, -5.8224e-05,
         1.2812e-04,  2.3326e-04,  1.5479e-04,  4.0857e-05, -5.6227e-04,
         3.8000e-05, -2.3164e-05, -1.9672e-04,  3.5821e-04,  2.7379e-04,
        -1.7289e-04, -5.8038e-07, -3.9887e-05,  2.6259e-04,  1.1210e-04,
         1.0468e-04,  5.1765e-06,  2.7217e-04,  5.4314e-05,  1.6913e-04,
         9.7281e-05,  8.4051e-05, -1.4475e-04,  6.4000e-05, -7.2588e-05,
         4.7380e-04, -3.9162e-04, -3.3185e-06,  1.5392e-04,  7.5740e-05,
         2.9120e-05, -3.8002e-04,  3.6786e-04, -1.6389e-04,  1.1517e-05,
         3.6327e-04,  5.5714e-06, -3.1402e-04,  2.8624e-04,  5.1743e-05,
        -1.5421e-04,  2.3713e-04, -3.0041e-04,  1.3018e-04, -3.2074e-04,
         4.9598e-04,  3.8069e-04,  4.4624e-04,  3.0866e-04,  4.5696e-04,
        -4.6147e-04,  6.0199e-05, -6.6732e-05,  2.9347e-06,  3.1269e-04,
         4.0099e-04, -5.4409e-05,  1.6970e-04,  1.7139e-04])
policy_loss: 1.9278377294540405e-07
entropy_loss: -2.832502841949463
value_loss: 835.9984130859375
loss: 417.99920654296875
policy_loss: -6.116554141044617e-05
entropy_loss: -2.832411050796509
value_loss: 789.681640625
loss: 394.84075927734375
policy_loss: -0.00013235490769147873
entropy_loss: -2.8323824405670166
value_loss: 817.3589477539062
loss: 408.6793518066406
policy_loss: 5.60712069272995e-05
entropy_loss: -2.832355260848999
value_loss: 806.63525390625
loss: 403.31768798828125
policy_loss: -0.00028651393949985504
entropy_loss: -2.832313299179077
value_loss: 846.333740234375
loss: 423.1665954589844
policy_loss: -2.6755966246128082e-05
entropy_loss: -2.832287073135376
value_loss: 789.1281127929688
loss: 394.56402587890625
policy_loss: -0.0006422661244869232
entropy_loss: -2.832305669784546
value_loss: 802.806396484375
loss: 401.4025573730469
policy_loss: -0.0002454714849591255
entropy_loss: -2.8323323726654053
value_loss: 805.5166015625
loss: 402.758056640625
policy_loss: -0.0003818739205598831
entropy_loss: -2.8323709964752197
value_loss: 826.2069702148438
loss: 413.10308837890625
policy_loss: -0.0008385893888771534
entropy_loss: -2.832418918609619
value_loss: 860.392822265625
loss: 430.1955871582031
policy_loss: -0.0022340333089232445
entropy_loss: -2.832542657852173
value_loss: 753.6351318359375
loss: 376.8153381347656
policy_loss: 0.00033585820347070694
entropy_loss: -2.832557439804077
value_loss: 782.4151611328125
loss: 391.2079162597656
policy_loss: -0.002441832795739174
entropy_loss: -2.8326456546783447
value_loss: 822.6353759765625
loss: 411.31524658203125
policy_loss: -0.00038629956543445587
entropy_loss: -2.8327295780181885
value_loss: 803.501953125
loss: 401.7505798339844
policy_loss: -0.0009673219174146652
entropy_loss: -2.8328440189361572
value_loss: 774.7109985351562
loss: 387.3545227050781
policy_loss: -0.0012660305947065353
entropy_loss: -2.832986354827881
value_loss: 791.8111572265625
loss: 395.9043273925781
policy_loss: -0.0034094946458935738
entropy_loss: -2.833118438720703
value_loss: 817.9913940429688
loss: 408.9922790527344
policy_loss: -0.00015565077774226665
entropy_loss: -2.8332390785217285
value_loss: 773.718017578125
loss: 386.8588562011719
policy_loss: 0.0007004332728683949
entropy_loss: -2.833343744277954
value_loss: 813.3545532226562
loss: 406.677978515625
policy_loss: -0.004689907189458609
entropy_loss: -2.833493709564209
value_loss: 752.9807739257812
loss: 376.4856872558594
policy_loss: -0.0028924494981765747
entropy_loss: -2.833656072616577
value_loss: 802.344482421875
loss: 401.1693420410156
policy_loss: -0.0024665817618370056
entropy_loss: -2.8338301181793213
value_loss: 793.1940307617188
loss: 396.59454345703125
policy_loss: -0.003739146050065756
entropy_loss: -2.8339781761169434
value_loss: 751.0490112304688
loss: 375.520751953125
policy_loss: -0.0005539581179618835
entropy_loss: -2.8341712951660156
value_loss: 774.015869140625
loss: 387.00738525390625
policy_loss: -0.002816741354763508
entropy_loss: -2.8343541622161865
value_loss: 736.0997314453125
loss: 368.04705810546875
policy_loss: -0.0015492355450987816
entropy_loss: -2.8345284461975098
value_loss: 838.0134887695312
loss: 419.00518798828125
policy_loss: -0.006440372671931982
entropy_loss: -2.8347513675689697
value_loss: 758.1925048828125
loss: 379.0898132324219
policy_loss: -0.002013414166867733
entropy_loss: -2.8349967002868652
value_loss: 749.3270874023438
loss: 374.6615295410156
policy_loss: -0.0045745279639959335
entropy_loss: -2.8351857662200928
value_loss: 738.9158935546875
loss: 369.453369140625
policy_loss: -0.0032785721123218536
entropy_loss: -2.835327386856079
value_loss: 767.98779296875
loss: 383.9906311035156
policy_loss: 0.00021135248243808746
entropy_loss: -2.835498809814453
value_loss: 744.5294189453125
loss: 372.2649230957031
policy_loss: -0.0068540554493665695
entropy_loss: -2.8357083797454834
value_loss: 790.3810424804688
loss: 395.18365478515625
policy_loss: -0.0030922689475119114
entropy_loss: -2.8359220027923584
value_loss: 756.5270385742188
loss: 378.26043701171875
policy_loss: -0.004002677276730537
entropy_loss: -2.8361012935638428
value_loss: 723.9909057617188
loss: 361.991455078125
policy_loss: -0.005681460723280907
entropy_loss: -2.836312770843506
value_loss: 744.3585205078125
loss: 372.173583984375
policy_loss: -0.004029272124171257
entropy_loss: -2.8365514278411865
value_loss: 777.4052734375
loss: 388.6986083984375
policy_loss: -0.0035335738211870193
entropy_loss: -2.836791753768921
value_loss: 774.5762939453125
loss: 387.28460693359375
policy_loss: -0.005554026924073696
entropy_loss: -2.8370566368103027
value_loss: 715.4369506835938
loss: 357.7129211425781
policy_loss: -0.007052116096019745
entropy_loss: -2.837261438369751
value_loss: 767.6228637695312
loss: 383.80438232421875
policy_loss: -0.0011446289718151093
entropy_loss: -2.8374953269958496
value_loss: 705.4229736328125
loss: 352.7103271484375
------------------------------------------
| avg_speed               | 3.93         |
| is_success              | 0            |
| max_speed               | 3.93         |
| reward                  | -0.8816635   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.58e+03    |
| time/                   |              |
|    fps                  | 126          |
|    iterations           | 3            |
|    time_elapsed         | 48           |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0026239874 |
|    clip_fraction        | 0.00444      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | -0.128       |
|    learning_rate        | 0.0003       |
|    loss                 | 353          |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.0022      |
|    std                  | 1            |
|    value_loss           | 782          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.1840, -0.3630, -0.0636,  ..., -0.0122, -0.2179, -0.3020],
        [ 0.0229,  0.1494, -0.0074,  ..., -0.0746, -0.0081, -0.0475],
        [-0.0700,  0.0536,  0.0295,  ..., -0.1725, -0.1299,  0.2241],
        ...,
        [ 0.2450, -0.0849,  0.2167,  ...,  0.2006, -0.2131,  0.3165],
        [-0.0454, -0.2549, -0.0567,  ..., -0.1379, -0.2717,  0.3086],
        [-0.0026,  0.0985, -0.1735,  ..., -0.0734,  0.0878,  0.0961]])
bias : tensor([ 1.6727e-04,  2.0015e-04, -4.4244e-05, -2.1915e-04, -9.6966e-05,
         5.3170e-04, -7.0690e-05, -4.7420e-04,  3.3244e-04,  3.0266e-04,
         2.4479e-04,  8.3511e-05, -1.2097e-04,  4.9806e-04,  4.7528e-04,
         1.5794e-04, -3.0569e-04,  2.1101e-04,  6.9164e-04, -9.7075e-05,
         3.5403e-05, -1.6692e-04,  1.6493e-04, -2.8624e-04,  1.1383e-04,
         1.0825e-04, -1.7306e-04, -6.9472e-05,  7.3134e-05, -2.2581e-05,
         2.2428e-04,  5.8369e-04, -3.1411e-04,  6.4769e-04,  2.8029e-04,
        -3.6071e-04,  1.9483e-04, -1.0187e-04,  3.2809e-04,  2.2440e-05,
         2.2761e-04,  1.6162e-04,  2.5320e-04,  3.6546e-04, -2.5617e-04,
         2.8064e-04,  1.7365e-04,  2.3615e-04,  1.7557e-06,  8.8432e-05,
        -4.8569e-04, -2.6405e-04,  3.4824e-04, -5.4429e-05,  1.9096e-05,
        -3.2413e-05,  4.6390e-05, -5.7367e-05,  1.2160e-04, -1.6707e-04,
        -2.4976e-05, -9.5071e-04,  1.3501e-04, -3.2722e-04])
weight : tensor([[-0.2156,  0.3492, -0.3289,  ..., -0.1695,  0.3024,  0.1746],
        [-0.1658, -0.1415, -0.0259,  ...,  0.0576, -0.3301,  0.0934],
        [-0.1282, -0.4216, -0.1417,  ...,  0.1920,  0.1348,  0.0136],
        ...,
        [ 0.2261,  0.1353, -0.2863,  ..., -0.0852,  0.0160, -0.0866],
        [-0.2399, -0.1294,  0.1510,  ...,  0.0459,  0.3096,  0.0836],
        [ 0.2041, -0.2015, -0.0128,  ..., -0.0756,  0.0356, -0.1202]])
bias : tensor([ 5.9177e-05,  2.3873e-04,  7.3128e-05, -2.3790e-04, -1.3113e-04,
        -2.2457e-04, -4.2366e-05, -3.4255e-05, -2.3411e-04, -3.0290e-04,
        -1.9665e-04, -1.3632e-05,  2.8261e-04,  3.2785e-05,  2.0313e-05,
         3.0556e-04,  2.8697e-04, -1.2633e-04,  8.0554e-05,  8.5029e-05,
        -2.1047e-04, -1.3463e-04,  2.1623e-04,  2.5843e-04,  6.9332e-05,
         5.6226e-05, -1.6109e-04, -2.5204e-05, -2.5321e-04, -1.4483e-04,
        -1.2385e-04,  6.0384e-04,  7.2052e-05, -2.7811e-04, -1.2154e-04,
         6.9618e-05,  1.9201e-04,  2.9315e-04,  4.2862e-04,  2.3660e-05,
        -7.5574e-05, -2.3655e-04, -3.8572e-05,  3.0725e-05,  1.9967e-05,
         9.7211e-05,  2.4255e-04, -1.1505e-04, -5.1168e-05, -1.2321e-04,
        -4.2429e-05, -2.5520e-04,  7.1225e-05, -2.1382e-05, -3.7125e-04,
         3.2040e-04,  1.4894e-04, -4.2638e-04,  8.9018e-05,  1.5555e-04,
         2.7632e-04,  1.0378e-04,  1.2395e-04,  2.4512e-04])
policy_loss: 1.3085082173347473e-07
entropy_loss: -2.844635248184204
value_loss: 932.4616088867188
loss: 466.2308044433594
policy_loss: -7.794611155986786e-05
entropy_loss: -2.8450140953063965
value_loss: 937.8138427734375
loss: 468.9068298339844
policy_loss: -0.00016182288527488708
entropy_loss: -2.8453328609466553
value_loss: 876.8309326171875
loss: 438.4153137207031
policy_loss: 4.511326551437378e-05
entropy_loss: -2.8457274436950684
value_loss: 877.1260375976562
loss: 438.56304931640625
policy_loss: -0.0005030492320656776
entropy_loss: -2.846122980117798
value_loss: 888.5250854492188
loss: 444.2620544433594
policy_loss: -0.0004453086294233799
entropy_loss: -2.846534490585327
value_loss: 975.8085327148438
loss: 487.90380859375
policy_loss: -0.0006822478026151657
entropy_loss: -2.846985101699829
value_loss: 887.495361328125
loss: 443.74700927734375
policy_loss: -0.0006914837285876274
entropy_loss: -2.847379207611084
value_loss: 863.8084106445312
loss: 431.90350341796875
policy_loss: -0.0011801980435848236
entropy_loss: -2.847822666168213
value_loss: 894.669189453125
loss: 447.3334045410156
policy_loss: -0.0016202828846871853
entropy_loss: -2.8483335971832275
value_loss: 881.2103271484375
loss: 440.6035461425781
policy_loss: -0.0008562067523598671
entropy_loss: -2.848832607269287
value_loss: 929.686279296875
loss: 464.84228515625
policy_loss: -0.0015062051825225353
entropy_loss: -2.849313259124756
value_loss: 896.9260864257812
loss: 448.4615478515625
policy_loss: -0.001445583999156952
entropy_loss: -2.849769353866577
value_loss: 921.387451171875
loss: 460.6922912597656
policy_loss: -0.002614881843328476
entropy_loss: -2.8502137660980225
value_loss: 875.1773681640625
loss: 437.5860595703125
policy_loss: -0.0013391021639108658
entropy_loss: -2.8506760597229004
value_loss: 933.9917602539062
loss: 466.9945373535156
policy_loss: -0.003146084025502205
entropy_loss: -2.8511834144592285
value_loss: 856.3218383789062
loss: 428.15777587890625
policy_loss: -0.0012776795774698257
entropy_loss: -2.8516554832458496
value_loss: 888.1781616210938
loss: 444.0877990722656
policy_loss: -0.004974657669663429
entropy_loss: -2.852083683013916
value_loss: 885.5316162109375
loss: 442.7608337402344
policy_loss: -0.0005803890526294708
entropy_loss: -2.852508306503296
value_loss: 885.2922973632812
loss: 442.64556884765625
policy_loss: -0.0055892858654260635
entropy_loss: -2.8529393672943115
value_loss: 910.8070068359375
loss: 455.3979187011719
policy_loss: -0.0056477757170796394
entropy_loss: -2.853416681289673
value_loss: 863.164794921875
loss: 431.5767517089844
policy_loss: -0.004991501569747925
entropy_loss: -2.8538858890533447
value_loss: 927.3446655273438
loss: 463.6673278808594
policy_loss: 0.0015922347083687782
entropy_loss: -2.8544135093688965
value_loss: 878.3087768554688
loss: 439.1559753417969
policy_loss: -0.006583092734217644
entropy_loss: -2.8548951148986816
value_loss: 883.2780151367188
loss: 441.6324157714844
policy_loss: -0.006082743406295776
entropy_loss: -2.8553426265716553
value_loss: 843.968994140625
loss: 421.9784240722656
policy_loss: -0.003787453519180417
entropy_loss: -2.8557469844818115
value_loss: 917.8856201171875
loss: 458.93902587890625
policy_loss: -0.004033392295241356
entropy_loss: -2.8561556339263916
value_loss: 914.1055297851562
loss: 457.0487365722656
policy_loss: -0.005744835361838341
entropy_loss: -2.856578826904297
value_loss: 858.0261840820312
loss: 429.0073547363281
policy_loss: -0.004986150190234184
entropy_loss: -2.8570289611816406
value_loss: 917.9107666015625
loss: 458.9504089355469
policy_loss: -0.005731157958507538
entropy_loss: -2.8575022220611572
value_loss: 893.6918334960938
loss: 446.8401794433594
policy_loss: -0.007342986762523651
entropy_loss: -2.8579750061035156
value_loss: 860.736328125
loss: 430.3608093261719
policy_loss: -0.005269981920719147
entropy_loss: -2.858476161956787
value_loss: 843.2984619140625
loss: 421.6439514160156
policy_loss: -0.009691521525382996
entropy_loss: -2.858903646469116
value_loss: 913.5242309570312
loss: 456.7524108886719
policy_loss: -0.005688742268830538
entropy_loss: -2.8593087196350098
value_loss: 841.635498046875
loss: 420.81207275390625
policy_loss: -0.0057179685682058334
entropy_loss: -2.859731912612915
value_loss: 883.3651123046875
loss: 441.6768493652344
policy_loss: -0.004104871302843094
entropy_loss: -2.860124111175537
value_loss: 858.6734619140625
loss: 429.3326110839844
policy_loss: -0.011279869824647903
entropy_loss: -2.8605501651763916
value_loss: 871.1744995117188
loss: 435.5759582519531
policy_loss: -0.0038043735548853874
entropy_loss: -2.860954523086548
value_loss: 870.614501953125
loss: 435.3034362792969
policy_loss: -0.006838571280241013
entropy_loss: -2.8613665103912354
value_loss: 873.7500610351562
loss: 436.8681945800781
policy_loss: -0.004626326262950897
entropy_loss: -2.8617665767669678
value_loss: 862.8465576171875
loss: 431.41864013671875
-----------------------------------------
| avg_speed               | 2.25        |
| is_success              | 0           |
| max_speed               | 2.25        |
| reward                  | -1.5296576  |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.23e+03   |
| time/                   |             |
|    fps                  | 119         |
|    iterations           | 3           |
|    time_elapsed         | 51          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.006078748 |
|    clip_fraction        | 0.0187      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.85       |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | 431         |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00348    |
|    std                  | 1.01        |
|    value_loss           | 889         |
-----------------------------------------
TRAINING:
weight : tensor([[ 0.2377, -0.2989,  0.1525,  ...,  0.0424,  0.3537, -0.0139],
        [-0.1636,  0.1177, -0.0391,  ..., -0.1565, -0.1298,  0.2503],
        [-0.0625, -0.2327,  0.3670,  ...,  0.1785,  0.0251,  0.0552],
        ...,
        [-0.1348, -0.0485,  0.0672,  ...,  0.0494,  0.3751,  0.0626],
        [-0.2558, -0.3575,  0.2094,  ...,  0.0684, -0.1439,  0.0525],
        [-0.1709, -0.1510,  0.1254,  ...,  0.2093, -0.3274,  0.0183]])
bias : tensor([-7.0688e-04,  5.7150e-04, -3.6001e-04,  4.3308e-04,  6.4513e-04,
         4.9355e-04, -8.2859e-05, -8.4317e-04,  1.8378e-04,  2.9597e-04,
        -3.6730e-05,  5.6277e-05,  1.2788e-04,  1.0624e-04,  3.6200e-04,
        -9.9206e-05, -4.3545e-04,  4.1413e-04, -1.0157e-04, -8.2520e-04,
        -3.3249e-04,  4.9569e-04, -2.0186e-04,  8.3513e-04, -7.3934e-04,
        -5.4656e-04, -7.1175e-04,  5.5681e-04, -1.3090e-04,  6.9281e-05,
         1.9182e-04, -1.6630e-05, -1.1064e-04,  7.6434e-05,  8.4665e-05,
         3.6707e-04, -6.2018e-04,  9.5714e-05,  6.9226e-04,  1.1663e-03,
         3.1326e-04, -2.0276e-05, -8.8875e-04,  5.1564e-04, -1.7725e-04,
        -3.6491e-04, -3.6756e-04,  1.9833e-04,  9.8339e-05,  4.1076e-04,
        -1.7709e-04,  8.8396e-04,  2.4580e-04, -2.1242e-04,  1.4996e-04,
         3.5036e-04, -4.2248e-04,  6.2918e-04, -3.1570e-04, -1.8767e-04,
        -7.1279e-06, -2.7045e-04, -4.2460e-04, -6.3560e-04])
weight : tensor([[-0.3343, -0.1547, -0.0149,  ..., -0.2043,  0.1395,  0.0008],
        [ 0.2543,  0.0902, -0.1825,  ...,  0.1372, -0.2468,  0.2414],
        [ 0.0856, -0.1897, -0.1909,  ...,  0.0359, -0.0212,  0.2585],
        ...,
        [ 0.0675, -0.0693, -0.2761,  ...,  0.1750, -0.0248, -0.3441],
        [ 0.2613,  0.0598, -0.0188,  ..., -0.0882, -0.2107, -0.1096],
        [-0.2265,  0.0097,  0.0472,  ...,  0.0742,  0.0294, -0.0110]])
bias : tensor([ 3.3481e-04,  2.3398e-04, -7.8160e-04,  7.1936e-05,  8.0262e-04,
         3.0119e-06, -1.3001e-04,  8.0268e-04,  4.2779e-04,  1.4172e-04,
         3.7092e-05,  2.3615e-04, -1.4160e-04, -3.9158e-04,  9.8226e-04,
         8.1147e-04,  2.1519e-04,  2.9576e-04,  4.5560e-04, -1.7218e-04,
         2.5995e-04,  6.0126e-04, -1.7561e-04, -6.5401e-05, -3.7420e-04,
         7.2945e-05,  3.3643e-04, -4.6831e-04, -2.9066e-05, -3.0495e-04,
         6.9970e-04,  2.1416e-04, -2.2318e-04,  3.4774e-04, -1.1358e-03,
        -7.6276e-04, -7.7238e-04, -5.1974e-04,  6.4125e-05,  5.7325e-04,
         7.0291e-04,  3.6758e-04,  3.5844e-04,  4.5517e-04,  2.2013e-04,
        -3.0747e-04,  5.0792e-04, -2.4035e-04,  8.1011e-04, -2.9600e-04,
        -8.5204e-05,  7.0187e-04,  5.1289e-04,  3.8528e-04, -1.1200e-03,
         1.6247e-04,  1.0584e-04, -6.4159e-04,  2.8826e-04, -1.3275e-05,
         6.8725e-04,  4.7704e-04,  5.5937e-04, -4.0640e-04])
policy_loss: 9.499490261077881e-08
entropy_loss: -2.8509812355041504
value_loss: 356.9854736328125
loss: 178.49273681640625
policy_loss: -6.430596113204956e-05
entropy_loss: -2.851285457611084
value_loss: 367.2056884765625
loss: 183.602783203125
policy_loss: 0.00014611706137657166
entropy_loss: -2.8516106605529785
value_loss: 355.1881408691406
loss: 177.59422302246094
policy_loss: 8.83371103554964e-05
entropy_loss: -2.8519136905670166
value_loss: 351.59515380859375
loss: 175.79766845703125
policy_loss: -0.00021973159164190292
entropy_loss: -2.852186679840088
value_loss: 368.0152893066406
loss: 184.00743103027344
policy_loss: -0.00028354860842227936
entropy_loss: -2.8524184226989746
value_loss: 364.73101806640625
loss: 182.36521911621094
policy_loss: 0.00010075513273477554
entropy_loss: -2.8526663780212402
value_loss: 344.2554016113281
loss: 172.1278076171875
policy_loss: 0.00020498968660831451
entropy_loss: -2.852891683578491
value_loss: 337.7069396972656
loss: 168.85366821289062
policy_loss: -0.00042839348316192627
entropy_loss: -2.853109836578369
value_loss: 344.5532531738281
loss: 172.2761993408203
policy_loss: -0.0004905126988887787
entropy_loss: -2.853311061859131
value_loss: 359.2720947265625
loss: 179.63555908203125
policy_loss: 0.0005589378997683525
entropy_loss: -2.853494167327881
value_loss: 340.1438293457031
loss: 170.07247924804688
policy_loss: -0.000568087212741375
entropy_loss: -2.8536603450775146
value_loss: 349.424560546875
loss: 174.7117156982422
policy_loss: -5.499459803104401e-06
entropy_loss: -2.8538358211517334
value_loss: 346.48638916015625
loss: 173.24319458007812
policy_loss: -0.0008954755030572414
entropy_loss: -2.8540077209472656
value_loss: 344.19775390625
loss: 172.0979766845703
policy_loss: 0.00025362707674503326
entropy_loss: -2.854163885116577
value_loss: 335.26904296875
loss: 167.63478088378906
policy_loss: -0.001458299346268177
entropy_loss: -2.8543360233306885
value_loss: 344.6333923339844
loss: 172.3152313232422
policy_loss: -0.0006952229887247086
entropy_loss: -2.8544821739196777
value_loss: 347.36187744140625
loss: 173.68023681640625
policy_loss: -0.001825026236474514
entropy_loss: -2.8546597957611084
value_loss: 339.76861572265625
loss: 169.88247680664062
policy_loss: 0.0008033402264118195
entropy_loss: -2.8547921180725098
value_loss: 322.6968994140625
loss: 161.34925842285156
policy_loss: -0.0012409072369337082
entropy_loss: -2.854900360107422
value_loss: 337.1517028808594
loss: 168.57461547851562
policy_loss: -0.0006387569010257721
entropy_loss: -2.8550264835357666
value_loss: 342.5728759765625
loss: 171.28579711914062
policy_loss: -0.0017029233276844025
entropy_loss: -2.855156183242798
value_loss: 325.8488464355469
loss: 162.92271423339844
policy_loss: -0.0015218667685985565
entropy_loss: -2.8553011417388916
value_loss: 323.54876708984375
loss: 161.77285766601562
policy_loss: -0.0005009286105632782
entropy_loss: -2.8554227352142334
value_loss: 330.9235534667969
loss: 165.46127319335938
policy_loss: -0.001139872707426548
entropy_loss: -2.8555333614349365
value_loss: 338.6166687011719
loss: 169.30718994140625
policy_loss: -0.001985873095691204
entropy_loss: -2.855642795562744
value_loss: 312.1225280761719
loss: 156.0592803955078
policy_loss: -0.00022803759202361107
entropy_loss: -2.8557610511779785
value_loss: 324.0293884277344
loss: 162.01446533203125
policy_loss: -0.0025575850158929825
entropy_loss: -2.8558695316314697
value_loss: 324.2416687011719
loss: 162.11827087402344
policy_loss: -0.0013253698125481606
entropy_loss: -2.855976104736328
value_loss: 307.6062316894531
loss: 153.80178833007812
policy_loss: 0.00027998024597764015
entropy_loss: -2.856031656265259
value_loss: 331.1589660644531
loss: 165.5797576904297
policy_loss: -0.0031483767088502645
entropy_loss: -2.8560945987701416
value_loss: 310.6904296875
loss: 155.34207153320312
policy_loss: -0.0034792902879416943
entropy_loss: -2.856198787689209
value_loss: 325.5554504394531
loss: 162.7742462158203
policy_loss: 0.0001341644674539566
entropy_loss: -2.856309652328491
value_loss: 304.32867431640625
loss: 152.1644744873047
policy_loss: -0.005618436262011528
entropy_loss: -2.8564112186431885
value_loss: 309.580322265625
loss: 154.7845458984375
policy_loss: -0.0010332800447940826
entropy_loss: -2.8565101623535156
value_loss: 311.9049072265625
loss: 155.951416015625
policy_loss: -0.0017131357453763485
entropy_loss: -2.856580972671509
value_loss: 325.9319152832031
loss: 162.96424865722656
policy_loss: -0.003124253824353218
entropy_loss: -2.856689691543579
value_loss: 307.14825439453125
loss: 153.5709991455078
policy_loss: 0.0001169443130493164
entropy_loss: -2.8568215370178223
value_loss: 311.223388671875
loss: 155.61181640625
policy_loss: -0.00357899721711874
entropy_loss: -2.8569388389587402
value_loss: 310.28057861328125
loss: 155.13670349121094
policy_loss: -0.0037847310304641724
entropy_loss: -2.8570199012756348
value_loss: 300.49505615234375
loss: 150.24374389648438
------------------------------------------
| avg_speed               | 0.276        |
| is_success              | 0            |
| max_speed               | 0.276        |
| reward                  | -0.4947303   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.06e+03    |
| time/                   |              |
|    fps                  | 114          |
|    iterations           | 3            |
|    time_elapsed         | 53           |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0011471385 |
|    clip_fraction        | 0.000146     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | -0.0489      |
|    learning_rate        | 0.0003       |
|    loss                 | 150          |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00106     |
|    std                  | 1.01         |
|    value_loss           | 333          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.0795,  0.4124,  0.2362,  ..., -0.0432,  0.0340,  0.3011],
        [ 0.1218,  0.3289,  0.1110,  ..., -0.1010, -0.3112, -0.1929],
        [ 0.1152,  0.1783,  0.0247,  ...,  0.4177, -0.1214,  0.4003],
        ...,
        [ 0.0271,  0.1468, -0.2633,  ..., -0.3859, -0.0778, -0.1391],
        [-0.2699,  0.0036,  0.0759,  ..., -0.0078,  0.0142, -0.1107],
        [ 0.1469,  0.1596,  0.3137,  ..., -0.1199,  0.1924,  0.2710]])
bias : tensor([-1.1459e-04, -1.6761e-04,  4.1963e-04,  2.7340e-04,  5.3975e-04,
         1.5753e-04, -2.1275e-04, -2.5058e-05, -1.9010e-04,  7.3635e-04,
         3.6991e-05, -3.1624e-04,  2.3782e-04,  1.3155e-04, -1.7788e-04,
         7.0562e-04, -1.3045e-03,  2.3265e-04, -1.9903e-04,  8.2660e-04,
         6.1690e-04, -1.6694e-04, -9.8926e-04, -6.5854e-05, -5.1784e-05,
         2.3523e-04,  1.5385e-04,  5.4072e-04, -2.1340e-04, -6.9234e-04,
        -2.2541e-05,  7.3033e-05, -4.4948e-04,  3.6609e-04,  1.1355e-04,
        -4.0890e-04, -7.6904e-05,  2.8035e-05,  5.2612e-04,  3.4031e-04,
        -6.1080e-04,  5.1202e-04, -3.1204e-04, -3.1991e-05, -6.6001e-04,
        -2.5726e-04, -9.0824e-05,  3.3637e-05,  7.1072e-04,  1.3381e-04,
        -1.6883e-04, -2.8858e-04,  1.4929e-04,  1.5362e-04,  1.3704e-04,
        -5.4121e-05,  8.6411e-05, -9.2087e-05,  5.6124e-04,  3.1032e-04,
         1.4093e-04, -8.0300e-04,  3.7357e-04, -1.2229e-04])
weight : tensor([[-0.1735,  0.0859,  0.1613,  ..., -0.2976,  0.0027, -0.0797],
        [ 0.0454, -0.2652,  0.0879,  ...,  0.1013,  0.0814,  0.3124],
        [-0.0708,  0.2355, -0.1154,  ..., -0.1612, -0.2248,  0.1526],
        ...,
        [ 0.2286,  0.3864,  0.1879,  ..., -0.0477,  0.4152,  0.2052],
        [-0.0496,  0.2789,  0.1176,  ..., -0.2082,  0.1528, -0.2261],
        [ 0.0446, -0.0549,  0.3606,  ...,  0.0102,  0.0277, -0.2454]])
bias : tensor([-5.3040e-04,  7.7022e-04, -2.3109e-04, -3.9135e-04,  2.5188e-04,
        -1.0387e-03, -2.6068e-06, -1.4810e-04, -3.4995e-04, -3.2779e-04,
         2.7226e-04, -1.8961e-04,  1.5554e-06, -1.2955e-05,  2.2816e-04,
         4.2647e-04, -1.4888e-04, -3.0464e-04, -5.3771e-05, -1.3140e-04,
        -2.1149e-04,  6.2404e-05, -3.7873e-04,  2.9751e-04, -1.9697e-04,
        -3.1855e-04,  1.8914e-04,  1.6089e-04,  2.3628e-04,  2.2095e-04,
        -4.5361e-04,  8.5359e-05, -5.2049e-06,  2.2255e-04, -2.1985e-04,
        -6.6649e-06,  6.5491e-04, -2.0067e-04, -7.2243e-04,  3.6878e-04,
        -3.9681e-04, -7.9217e-05, -3.9487e-05, -1.6659e-04,  7.6880e-04,
        -9.4703e-06,  3.0556e-04,  5.2460e-04, -3.3345e-04,  1.0115e-04,
        -1.7792e-04,  5.9946e-04,  4.1852e-04, -3.0160e-04,  1.9418e-04,
         1.0443e-05, -8.4905e-06,  1.6775e-04, -5.8202e-04, -2.0010e-04,
        -1.5132e-04, -2.5857e-04, -1.1295e-04, -1.0857e-04])
policy_loss: -1.862645149230957e-09
entropy_loss: -2.8377606868743896
value_loss: 1072.5186767578125
loss: 536.2593383789062
policy_loss: -2.1705403923988342e-05
entropy_loss: -2.8379857540130615
value_loss: 1114.673095703125
loss: 557.3365478515625
policy_loss: -7.609650492668152e-05
entropy_loss: -2.8382112979888916
value_loss: 1119.1402587890625
loss: 559.570068359375
policy_loss: 1.2674368917942047e-05
entropy_loss: -2.8384604454040527
value_loss: 1108.2935791015625
loss: 554.1467895507812
policy_loss: -0.00030490197241306305
entropy_loss: -2.838683843612671
value_loss: 1125.8447265625
loss: 562.9220581054688
policy_loss: 9.188428521156311e-05
entropy_loss: -2.8389089107513428
value_loss: 1099.3529052734375
loss: 549.6765747070312
policy_loss: -0.00048546213656663895
entropy_loss: -2.8391377925872803
value_loss: 1100.981689453125
loss: 550.4903564453125
policy_loss: -0.0006134770810604095
entropy_loss: -2.8393137454986572
value_loss: 1094.5771484375
loss: 547.2879638671875
policy_loss: -0.0007950686849653721
entropy_loss: -2.8395040035247803
value_loss: 1061.9520263671875
loss: 530.9752197265625
policy_loss: -0.0007029669359326363
entropy_loss: -2.8397157192230225
value_loss: 1130.39208984375
loss: 565.1953125
policy_loss: -0.0009328015148639679
entropy_loss: -2.839891195297241
value_loss: 1086.063232421875
loss: 543.0307006835938
policy_loss: -0.000767536461353302
entropy_loss: -2.8400533199310303
value_loss: 1125.0040283203125
loss: 562.501220703125
policy_loss: -0.0008247792720794678
entropy_loss: -2.8402254581451416
value_loss: 1045.177734375
loss: 522.5880126953125
policy_loss: -0.0008716974407434464
entropy_loss: -2.8403818607330322
value_loss: 1080.1317138671875
loss: 540.0650024414062
policy_loss: -0.0033457158133387566
entropy_loss: -2.8405532836914062
value_loss: 1096.4329833984375
loss: 548.213134765625
policy_loss: -0.0011626603081822395
entropy_loss: -2.8407111167907715
value_loss: 1149.8013916015625
loss: 574.8995361328125
policy_loss: -0.0028749024495482445
entropy_loss: -2.8408663272857666
value_loss: 1092.1014404296875
loss: 546.0478515625
policy_loss: -0.0016521718353033066
entropy_loss: -2.8410210609436035
value_loss: 1062.3724365234375
loss: 531.1845703125
policy_loss: -0.0031960210762917995
entropy_loss: -2.8411965370178223
value_loss: 1046.9927978515625
loss: 523.4932250976562
policy_loss: -0.0017404742538928986
entropy_loss: -2.841386556625366
value_loss: 1130.200927734375
loss: 565.0986938476562
policy_loss: -0.0038017858751118183
entropy_loss: -2.841531276702881
value_loss: 1097.757080078125
loss: 548.874755859375
policy_loss: -0.0034159496426582336
entropy_loss: -2.8416783809661865
value_loss: 1087.2633056640625
loss: 543.6282348632812
policy_loss: -0.000996605260297656
entropy_loss: -2.841827154159546
value_loss: 1045.695556640625
loss: 522.8468017578125
policy_loss: -0.00444700475782156
entropy_loss: -2.8419532775878906
value_loss: 1056.3720703125
loss: 528.1815795898438
policy_loss: -0.004300642758607864
entropy_loss: -2.8420920372009277
value_loss: 1075.9354248046875
loss: 537.9634399414062
policy_loss: -0.0062342360615730286
entropy_loss: -2.8422696590423584
value_loss: 1043.25732421875
loss: 521.6224365234375
policy_loss: -0.005751797463744879
entropy_loss: -2.842460870742798
value_loss: 1066.6644287109375
loss: 533.3264770507812
policy_loss: 3.842078149318695e-05
entropy_loss: -2.842663049697876
value_loss: 1053.2423095703125
loss: 526.6212158203125
policy_loss: -0.006822207942605019
entropy_loss: -2.842794895172119
value_loss: 1049.0203857421875
loss: 524.5033569335938
policy_loss: -0.0025984444655478
entropy_loss: -2.842918634414673
value_loss: 1046.4639892578125
loss: 523.2293701171875
policy_loss: -0.006165359169244766
entropy_loss: -2.843024969100952
value_loss: 1003.634765625
loss: 501.81121826171875
policy_loss: -0.00372195802628994
entropy_loss: -2.8431992530822754
value_loss: 1090.8319091796875
loss: 545.4122314453125
policy_loss: -0.00778527045622468
entropy_loss: -2.8433585166931152
value_loss: 973.4992065429688
loss: 486.7418212890625
policy_loss: -0.0011205272749066353
entropy_loss: -2.8435401916503906
value_loss: 1055.420654296875
loss: 527.709228515625
policy_loss: -0.005976788699626923
entropy_loss: -2.8437294960021973
value_loss: 1041.296630859375
loss: 520.642333984375
policy_loss: -0.006407625041902065
entropy_loss: -2.8439061641693115
value_loss: 1069.659912109375
loss: 534.8235473632812
policy_loss: -0.00773225724697113
entropy_loss: -2.8440794944763184
value_loss: 975.4736938476562
loss: 487.7291259765625
policy_loss: -0.009677242487668991
entropy_loss: -2.8442740440368652
value_loss: 1068.896240234375
loss: 534.4384155273438
policy_loss: -0.0007695471867918968
entropy_loss: -2.844501256942749
value_loss: 945.5120239257812
loss: 472.7552490234375
policy_loss: -0.005449555814266205
entropy_loss: -2.8446907997131348
value_loss: 1100.1077880859375
loss: 550.0484619140625
------------------------------------------
| avg_speed               | 0.867        |
| is_success              | 0            |
| max_speed               | 0.867        |
| reward                  | -0.6501145   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.53e+03    |
| time/                   |              |
|    fps                  | 125          |
|    iterations           | 4            |
|    time_elapsed         | 65           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0046650404 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0346      |
|    learning_rate        | 0.0003       |
|    loss                 | 550          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00284     |
|    std                  | 1            |
|    value_loss           | 1.07e+03     |
------------------------------------------
TRAINING:
weight : tensor([[ 1.8391e-01, -3.6260e-01, -6.3885e-02,  ..., -1.1139e-02,
         -2.1749e-01, -3.0269e-01],
        [ 2.3604e-02,  1.4960e-01, -7.7998e-03,  ..., -7.4012e-02,
         -7.8431e-03, -4.7837e-02],
        [-7.0635e-02,  5.2569e-02,  2.9476e-02,  ..., -1.7357e-01,
         -1.2989e-01,  2.2458e-01],
        ...,
        [ 2.4588e-01, -8.4849e-02,  2.1692e-01,  ...,  2.0005e-01,
         -2.1237e-01,  3.1678e-01],
        [-4.5827e-02, -2.5501e-01, -5.5911e-02,  ..., -1.3779e-01,
         -2.7226e-01,  3.0929e-01],
        [-1.5596e-04,  1.0016e-01, -1.7099e-01,  ..., -7.2052e-02,
          8.8363e-02,  9.5969e-02]])
bias : tensor([ 5.9584e-04,  5.4755e-04, -7.3337e-04, -1.1959e-03,  6.8810e-04,
         1.1588e-03, -6.3564e-04, -9.8452e-05,  2.1673e-04,  1.3927e-03,
        -7.1903e-04,  9.0221e-04, -1.0430e-03,  1.5958e-04,  1.0202e-03,
         5.6850e-04,  9.2433e-04,  8.3590e-04,  2.9044e-04,  7.8095e-04,
         3.5955e-04, -3.8908e-04,  1.2298e-03,  5.8268e-04,  8.7536e-04,
         1.2606e-03,  1.0144e-04, -8.2459e-04,  2.6972e-04, -2.4307e-04,
         6.4899e-04,  1.8322e-03, -1.3222e-03,  1.3798e-03, -6.3291e-04,
        -3.3817e-04,  7.7462e-05, -4.8168e-04,  9.3770e-04,  1.1982e-03,
         7.6177e-04, -1.2655e-03, -2.6982e-04, -1.1972e-03, -5.0954e-04,
         5.6904e-04,  1.4263e-03,  2.1984e-03,  3.4273e-04,  3.8207e-05,
        -2.0383e-03,  7.3153e-04,  1.1399e-03, -2.0109e-04,  5.9803e-04,
        -5.7089e-04,  7.6219e-04, -5.7048e-04,  1.0353e-04, -7.8670e-05,
         3.0757e-04, -1.2390e-03, -6.5241e-04,  4.7764e-05])
weight : tensor([[-0.2162,  0.3492, -0.3289,  ..., -0.1695,  0.3022,  0.1748],
        [-0.1654, -0.1417, -0.0260,  ...,  0.0576, -0.3306,  0.0935],
        [-0.1284, -0.4218, -0.1417,  ...,  0.1918,  0.1345,  0.0137],
        ...,
        [ 0.2267,  0.1357, -0.2861,  ..., -0.0853,  0.0166, -0.0870],
        [-0.2398, -0.1290,  0.1510,  ...,  0.0460,  0.3100,  0.0835],
        [ 0.2041, -0.2009, -0.0126,  ..., -0.0752,  0.0362, -0.1208]])
bias : tensor([-1.3023e-05,  1.3647e-03,  7.9382e-04, -6.3790e-04, -1.5709e-03,
        -3.1592e-04, -6.0375e-04, -2.5460e-04, -5.0186e-04, -3.2155e-04,
        -1.0283e-03,  1.5018e-03,  9.0837e-04,  3.8855e-04,  4.9452e-04,
         3.0844e-04,  1.4189e-03, -3.5339e-04,  9.6068e-05, -2.8573e-04,
        -4.8557e-04, -6.2844e-04,  6.5789e-04,  1.7398e-04,  8.6126e-04,
        -2.9733e-04,  4.7934e-04,  3.9566e-04,  3.9866e-05,  8.2166e-04,
        -6.7151e-04,  9.7809e-04, -4.3352e-04, -9.4407e-04, -1.6116e-03,
         4.7034e-05,  4.4507e-04, -1.8395e-04,  9.3594e-04,  3.0209e-05,
        -4.2264e-04,  2.3544e-04,  2.6412e-04, -4.4074e-05,  8.3013e-05,
         1.0190e-03, -6.0366e-04, -8.5435e-04,  5.0705e-04,  7.2625e-04,
        -5.3652e-04, -1.1645e-03,  2.4668e-04,  1.0863e-03, -2.5829e-04,
         8.2543e-04,  1.2294e-03, -3.2739e-04,  1.6288e-04,  1.4645e-03,
         6.6486e-04, -7.8466e-04, -1.1593e-03, -6.1641e-04])
policy_loss: 1.3783574104309082e-07
entropy_loss: -2.8621976375579834
value_loss: 220.4889373779297
loss: 110.24446868896484
policy_loss: 1.631118357181549e-05
entropy_loss: -2.862596273422241
value_loss: 232.3187255859375
loss: 116.15937805175781
policy_loss: -0.0002897139638662338
entropy_loss: -2.862962245941162
value_loss: 219.36048889160156
loss: 109.6799545288086
policy_loss: -0.0004189135506749153
entropy_loss: -2.863250970840454
value_loss: 219.75039672851562
loss: 109.8747787475586
policy_loss: -0.0010722661390900612
entropy_loss: -2.863492488861084
value_loss: 207.7774658203125
loss: 103.88765716552734
policy_loss: -0.0002172328531742096
entropy_loss: -2.863731622695923
value_loss: 228.57882690429688
loss: 114.28919982910156
policy_loss: -0.002901235595345497
entropy_loss: -2.8639180660247803
value_loss: 225.74127197265625
loss: 112.86773681640625
policy_loss: -0.0018248003907501698
entropy_loss: -2.8641419410705566
value_loss: 225.40420532226562
loss: 112.70027923583984
policy_loss: -0.003119558095932007
entropy_loss: -2.8642730712890625
value_loss: 216.01156616210938
loss: 108.0026626586914
policy_loss: -0.0013309475034475327
entropy_loss: -2.8644485473632812
value_loss: 215.9873046875
loss: 107.99232482910156
policy_loss: -0.003744928166270256
entropy_loss: -2.8646199703216553
value_loss: 218.75640869140625
loss: 109.37445831298828
policy_loss: -0.006038747727870941
entropy_loss: -2.864762783050537
value_loss: 230.807373046875
loss: 115.39764404296875
policy_loss: -0.007493241690099239
entropy_loss: -2.864823818206787
value_loss: 213.5593719482422
loss: 106.7721939086914
policy_loss: -0.004269097000360489
entropy_loss: -2.8649230003356934
value_loss: 227.51634216308594
loss: 113.75389862060547
policy_loss: -0.004475918598473072
entropy_loss: -2.8649637699127197
value_loss: 218.94549560546875
loss: 109.46826934814453
policy_loss: -0.0053161680698394775
entropy_loss: -2.8650078773498535
value_loss: 214.7059326171875
loss: 107.34764862060547
policy_loss: 0.00035091256722807884
entropy_loss: -2.8650472164154053
value_loss: 229.09715270996094
loss: 114.5489273071289
policy_loss: -0.009026742540299892
entropy_loss: -2.864968776702881
value_loss: 214.82774353027344
loss: 107.40484619140625
policy_loss: -0.005707051604986191
entropy_loss: -2.8649725914001465
value_loss: 210.60546875
loss: 105.29702758789062
policy_loss: -0.01389238890260458
entropy_loss: -2.8649632930755615
value_loss: 212.85678100585938
loss: 106.41449737548828
policy_loss: -0.009869723580777645
entropy_loss: -2.8649773597717285
value_loss: 214.9356231689453
loss: 107.45793914794922
policy_loss: -0.010688125155866146
entropy_loss: -2.8650450706481934
value_loss: 217.75360107421875
loss: 108.8661117553711
policy_loss: -0.0022153016179800034
entropy_loss: -2.8651235103607178
value_loss: 210.0347137451172
loss: 105.01514434814453
policy_loss: -0.0056684501469135284
entropy_loss: -2.8651680946350098
value_loss: 216.804931640625
loss: 108.39679718017578
policy_loss: -0.010388139635324478
entropy_loss: -2.8651883602142334
value_loss: 219.0709686279297
loss: 109.52509307861328
policy_loss: -0.008593244478106499
entropy_loss: -2.8651845455169678
value_loss: 212.48370361328125
loss: 106.23326110839844
policy_loss: -0.007115399464964867
entropy_loss: -2.8652193546295166
value_loss: 210.81973266601562
loss: 105.40274810791016
policy_loss: -0.004184314981102943
entropy_loss: -2.865251064300537
value_loss: 209.31588745117188
loss: 104.65376281738281
policy_loss: -0.01716756820678711
entropy_loss: -2.86529541015625
value_loss: 208.77291870117188
loss: 104.36929321289062
policy_loss: -0.004255514591932297
entropy_loss: -2.8653414249420166
value_loss: 210.09161376953125
loss: 105.04154968261719
policy_loss: -0.0009397659450769424
entropy_loss: -2.8654215335845947
value_loss: 213.78775024414062
loss: 106.89293670654297
policy_loss: -0.009506067261099815
entropy_loss: -2.865466833114624
value_loss: 210.99514770507812
loss: 105.48806762695312
policy_loss: -0.007326805964112282
entropy_loss: -2.8654749393463135
value_loss: 204.44552612304688
loss: 102.21543884277344
policy_loss: -0.012727337889373302
entropy_loss: -2.865447998046875
value_loss: 208.999267578125
loss: 104.48690795898438
policy_loss: -0.004724340513348579
entropy_loss: -2.865457057952881
value_loss: 212.45782470703125
loss: 106.22418975830078
policy_loss: -0.008899637497961521
entropy_loss: -2.8654801845550537
value_loss: 209.52040100097656
loss: 104.75130462646484
policy_loss: -0.009100109338760376
entropy_loss: -2.865455389022827
value_loss: 214.5775146484375
loss: 107.27965545654297
policy_loss: -0.010453425347805023
entropy_loss: -2.865440607070923
value_loss: 206.76588439941406
loss: 103.37248992919922
policy_loss: -0.0077132731676101685
entropy_loss: -2.8653414249420166
value_loss: 203.27545166015625
loss: 101.63001251220703
policy_loss: -0.007489567622542381
entropy_loss: -2.865314245223999
value_loss: 202.59385681152344
loss: 101.28943634033203
-----------------------------------------
| avg_speed               | 0.969       |
| is_success              | 0           |
| max_speed               | 0.969       |
| reward                  | -0.5301246  |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.32e+03   |
| time/                   |             |
|    fps                  | 120         |
|    iterations           | 4           |
|    time_elapsed         | 67          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.006086668 |
|    clip_fraction        | 0.0436      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.0701      |
|    learning_rate        | 0.0003      |
|    loss                 | 101         |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00574    |
|    std                  | 1.01        |
|    value_loss           | 216         |
-----------------------------------------
TRAINING:
weight : tensor([[ 0.2375, -0.2994,  0.1523,  ...,  0.0421,  0.3540, -0.0146],
        [-0.1641,  0.1169, -0.0391,  ..., -0.1568, -0.1298,  0.2507],
        [-0.0622, -0.2327,  0.3669,  ...,  0.1784,  0.0254,  0.0541],
        ...,
        [-0.1338, -0.0475,  0.0665,  ...,  0.0495,  0.3749,  0.0622],
        [-0.2557, -0.3574,  0.2091,  ...,  0.0682, -0.1436,  0.0517],
        [-0.1702, -0.1503,  0.1254,  ...,  0.2094, -0.3275,  0.0176]])
bias : tensor([-8.2867e-05,  2.6364e-05,  6.3131e-04,  2.6473e-04,  3.1406e-04,
        -1.8783e-04,  2.8369e-04, -2.4980e-05,  1.6861e-04,  2.8864e-04,
         4.3544e-04,  3.8972e-04,  2.4837e-04, -3.6500e-04,  2.2922e-05,
        -7.5757e-04,  4.0922e-04,  5.6613e-04,  3.2957e-04, -8.5063e-04,
        -6.6973e-05,  3.8246e-04, -9.2053e-04,  2.5698e-06,  7.6073e-06,
         2.2254e-04,  1.2232e-05,  4.6589e-04,  3.7385e-04, -1.5710e-05,
        -4.8075e-04,  2.1130e-05,  4.5498e-04,  2.7786e-04, -2.8501e-04,
         3.1332e-04,  3.2204e-04,  1.3570e-04,  5.0435e-04,  3.4205e-04,
        -3.5933e-04,  5.5994e-05, -1.5130e-03,  9.0732e-04, -8.2750e-05,
         5.2779e-05,  5.4078e-04,  2.9451e-05, -4.9244e-04, -3.3633e-04,
         3.8070e-04,  2.3108e-04,  6.9126e-04,  4.5648e-04,  2.1502e-04,
         1.1132e-03, -4.1395e-04,  4.7922e-05,  2.1949e-04, -3.8774e-04,
        -1.9706e-04,  5.8430e-04,  2.5627e-04,  1.1598e-04])
weight : tensor([[-0.3352, -0.1554, -0.0158,  ..., -0.2044,  0.1390,  0.0007],
        [ 0.2540,  0.0903, -0.1825,  ...,  0.1370, -0.2468,  0.2414],
        [ 0.0859, -0.1896, -0.1909,  ...,  0.0361, -0.0212,  0.2582],
        ...,
        [ 0.0673, -0.0694, -0.2761,  ...,  0.1749, -0.0246, -0.3440],
        [ 0.2612,  0.0601, -0.0187,  ..., -0.0885, -0.2104, -0.1096],
        [-0.2264,  0.0097,  0.0473,  ...,  0.0743,  0.0294, -0.0111]])
bias : tensor([ 3.1157e-04, -7.9038e-05, -2.7267e-04, -2.2971e-04,  4.1906e-04,
        -4.5000e-04, -5.5121e-04,  7.4915e-04,  6.5782e-05, -3.5942e-04,
         1.0115e-03, -1.3251e-04,  1.5944e-04, -1.7986e-04,  6.6658e-04,
         6.7105e-04, -1.2427e-04,  2.2524e-04,  1.6189e-06,  1.8692e-04,
         1.2709e-05, -2.2391e-05, -1.4731e-04, -2.5685e-04,  7.8717e-05,
        -3.1523e-04,  6.0875e-04,  4.4390e-05, -4.7743e-04, -1.4843e-04,
         1.1277e-04,  5.2637e-04,  1.1851e-05, -1.6972e-04, -8.3809e-04,
        -3.9476e-05, -2.5205e-04, -4.9637e-04,  1.1140e-04,  1.0384e-03,
         2.4898e-04,  4.2973e-04, -1.2220e-05, -2.1296e-06, -1.4111e-04,
         4.0279e-04,  1.9055e-05, -1.6131e-04,  1.8626e-04, -4.4576e-04,
        -1.8437e-04, -1.6379e-04,  4.2915e-04,  1.8943e-04, -2.1320e-04,
         2.4482e-04, -2.8745e-04, -1.2257e-03,  6.9997e-04,  4.0278e-04,
         9.3473e-04,  1.9234e-04,  9.4962e-05, -2.2029e-04])
policy_loss: 1.2665987014770508e-07
entropy_loss: -2.8571295738220215
value_loss: 323.0413513183594
loss: 161.5206756591797
policy_loss: 5.177222192287445e-06
entropy_loss: -2.857269525527954
value_loss: 357.3936767578125
loss: 178.69683837890625
policy_loss: 7.432559505105019e-05
entropy_loss: -2.857393741607666
value_loss: 312.123779296875
loss: 156.0619659423828
policy_loss: 6.831996142864227e-05
entropy_loss: -2.8575210571289062
value_loss: 337.01544189453125
loss: 168.50778198242188
policy_loss: 0.00012132525444030762
entropy_loss: -2.8576695919036865
value_loss: 327.5009765625
loss: 163.7506103515625
policy_loss: -6.601959466934204e-05
entropy_loss: -2.8578569889068604
value_loss: 313.7441101074219
loss: 156.8719940185547
policy_loss: -0.00019317399710416794
entropy_loss: -2.858095645904541
value_loss: 340.7137451171875
loss: 170.35667419433594
policy_loss: 0.0003296388313174248
entropy_loss: -2.8582892417907715
value_loss: 342.2005615234375
loss: 171.10061645507812
policy_loss: -9.07164067029953e-05
entropy_loss: -2.858450174331665
value_loss: 316.52783203125
loss: 158.26382446289062
policy_loss: -0.00029702112078666687
entropy_loss: -2.8585944175720215
value_loss: 331.1856994628906
loss: 165.59255981445312
policy_loss: -0.00016857311129570007
entropy_loss: -2.858794927597046
value_loss: 346.92633056640625
loss: 173.46299743652344
policy_loss: 0.00017556268721818924
entropy_loss: -2.859006404876709
value_loss: 316.1378479003906
loss: 158.06910705566406
policy_loss: 8.913222700357437e-05
entropy_loss: -2.859182596206665
value_loss: 328.180419921875
loss: 164.09030151367188
policy_loss: -0.0004718061536550522
entropy_loss: -2.859355926513672
value_loss: 318.7693176269531
loss: 159.38418579101562
policy_loss: -0.0006329230964183807
entropy_loss: -2.8595006465911865
value_loss: 337.8772888183594
loss: 168.93801879882812
policy_loss: -9.637698531150818e-05
entropy_loss: -2.8596837520599365
value_loss: 307.63177490234375
loss: 153.8157958984375
policy_loss: -8.949730545282364e-05
entropy_loss: -2.859882354736328
value_loss: 330.23809814453125
loss: 165.11895751953125
policy_loss: -0.00019055232405662537
entropy_loss: -2.860048770904541
value_loss: 321.0806579589844
loss: 160.54014587402344
policy_loss: -0.0005365246906876564
entropy_loss: -2.8602678775787354
value_loss: 316.3601379394531
loss: 158.17953491210938
policy_loss: -0.0014924108982086182
entropy_loss: -2.860460042953491
value_loss: 303.5191650390625
loss: 151.75808715820312
policy_loss: -0.0003316928632557392
entropy_loss: -2.8606717586517334
value_loss: 326.75372314453125
loss: 163.37652587890625
policy_loss: -0.0009833984076976776
entropy_loss: -2.8608956336975098
value_loss: 301.03900146484375
loss: 150.51852416992188
policy_loss: -0.0011985870078206062
entropy_loss: -2.8610994815826416
value_loss: 304.7962341308594
loss: 152.39691162109375
policy_loss: -0.0007299128919839859
entropy_loss: -2.861297369003296
value_loss: 315.3832092285156
loss: 157.6908721923828
policy_loss: -0.0008283546194434166
entropy_loss: -2.8615148067474365
value_loss: 303.8178405761719
loss: 151.90809631347656
policy_loss: -0.0016763629391789436
entropy_loss: -2.8617348670959473
value_loss: 303.94293212890625
loss: 151.96978759765625
policy_loss: -0.0012352676130831242
entropy_loss: -2.8619818687438965
value_loss: 299.04132080078125
loss: 149.51942443847656
policy_loss: -0.0008734622970223427
entropy_loss: -2.862220525741577
value_loss: 317.0191650390625
loss: 158.5087127685547
policy_loss: -0.0024169767275452614
entropy_loss: -2.8624396324157715
value_loss: 305.8690185546875
loss: 152.93209838867188
policy_loss: -0.0011600013822317123
entropy_loss: -2.8626768589019775
value_loss: 300.17010498046875
loss: 150.08389282226562
policy_loss: -0.0004718545824289322
entropy_loss: -2.8629112243652344
value_loss: 298.95635986328125
loss: 149.4777069091797
policy_loss: -0.0016085137613117695
entropy_loss: -2.863151788711548
value_loss: 294.72332763671875
loss: 147.3600616455078
policy_loss: -0.0017597805708646774
entropy_loss: -2.8633713722229004
value_loss: 307.4705810546875
loss: 153.73353576660156
policy_loss: -0.0018666218966245651
entropy_loss: -2.8635916709899902
value_loss: 288.25738525390625
loss: 144.1268310546875
policy_loss: 0.0003667231649160385
entropy_loss: -2.8638253211975098
value_loss: 284.9103088378906
loss: 142.4555206298828
policy_loss: -0.0042077163234353065
entropy_loss: -2.864006280899048
value_loss: 294.61083984375
loss: 147.30120849609375
policy_loss: -0.001910880208015442
entropy_loss: -2.864234685897827
value_loss: 275.7868957519531
loss: 137.89154052734375
policy_loss: -0.0019656242802739143
entropy_loss: -2.8644585609436035
value_loss: 301.0368347167969
loss: 150.51644897460938
policy_loss: -0.0016580168157815933
entropy_loss: -2.864701986312866
value_loss: 286.4266052246094
loss: 143.21163940429688
policy_loss: -0.003438402432948351
entropy_loss: -2.8649544715881348
value_loss: 287.49139404296875
loss: 143.7422637939453
------------------------------------------
| avg_speed               | 0.407        |
| is_success              | 0            |
| max_speed               | 0.407        |
| reward                  | -0.6468722   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.03e+03    |
| time/                   |              |
|    fps                  | 114          |
|    iterations           | 4            |
|    time_elapsed         | 71           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0005803289 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | -0.281       |
|    learning_rate        | 0.0003       |
|    loss                 | 144          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.000835    |
|    std                  | 1.01         |
|    value_loss           | 313          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.0797,  0.4124,  0.2369,  ..., -0.0441,  0.0343,  0.3007],
        [ 0.1218,  0.3296,  0.1106,  ..., -0.1005, -0.3113, -0.1934],
        [ 0.1153,  0.1781,  0.0246,  ...,  0.4175, -0.1214,  0.4005],
        ...,
        [ 0.0279,  0.1482, -0.2625,  ..., -0.3853, -0.0781, -0.1393],
        [-0.2694,  0.0040,  0.0757,  ..., -0.0088,  0.0140, -0.1106],
        [ 0.1476,  0.1595,  0.3138,  ..., -0.1198,  0.1927,  0.2706]])
bias : tensor([-8.0736e-05,  1.2838e-03,  2.9062e-04,  3.8759e-04,  5.4934e-04,
        -6.0462e-04,  3.9413e-04, -2.7434e-04, -8.3669e-04, -3.3338e-04,
        -3.4281e-04,  1.8904e-04,  2.0884e-04,  3.7082e-04, -3.2066e-05,
        -1.6743e-04, -3.1656e-04, -7.2344e-05, -5.8070e-04, -8.4157e-04,
        -1.9959e-04,  9.5238e-05, -5.7048e-04,  1.1217e-04,  6.4629e-04,
         5.5173e-04, -6.0623e-04,  2.8909e-04,  9.6852e-04, -2.4759e-04,
        -1.0524e-03, -8.7411e-04,  7.7525e-04,  1.1798e-03,  4.3089e-04,
        -6.3925e-04, -7.0415e-05, -3.4601e-04, -4.4013e-04,  3.1855e-04,
        -1.7316e-04,  3.8971e-04, -5.4890e-05,  6.0203e-04, -7.3082e-04,
        -2.1459e-04,  1.0870e-04,  4.3014e-04, -6.5488e-04,  2.7358e-05,
        -4.9516e-04,  9.5014e-04,  2.0828e-05, -1.4080e-04,  1.1734e-03,
        -3.9388e-04,  8.3565e-04, -5.0499e-05, -6.0687e-04,  2.0814e-04,
         2.9386e-04,  3.3868e-04,  1.9498e-04, -1.4473e-04])
weight : tensor([[-0.1733,  0.0857,  0.1616,  ..., -0.2979,  0.0028, -0.0793],
        [ 0.0456, -0.2652,  0.0881,  ...,  0.1013,  0.0815,  0.3122],
        [-0.0708,  0.2354, -0.1154,  ..., -0.1613, -0.2248,  0.1526],
        ...,
        [ 0.2285,  0.3863,  0.1879,  ..., -0.0478,  0.4152,  0.2052],
        [-0.0495,  0.2789,  0.1176,  ..., -0.2082,  0.1528, -0.2256],
        [ 0.0447, -0.0549,  0.3604,  ...,  0.0104,  0.0276, -0.2451]])
bias : tensor([ 6.1026e-04,  4.9679e-04,  1.2226e-05,  5.3818e-05, -4.6869e-04,
         2.3640e-04,  5.0637e-04, -6.6683e-05,  1.1581e-03, -1.1310e-03,
        -2.6010e-04,  1.3581e-04, -3.4066e-05,  1.7364e-04,  2.5609e-04,
        -1.7418e-04, -5.6955e-05,  3.2876e-05,  8.5279e-04,  4.2396e-04,
         2.0745e-04,  1.9437e-04,  3.5297e-05, -5.8932e-04,  3.9612e-04,
         5.5436e-04, -1.0747e-04,  1.9294e-04, -1.0785e-04, -4.9704e-04,
         4.1370e-04, -6.9152e-04,  3.5354e-06, -1.9537e-05,  8.0085e-04,
        -1.6946e-04, -2.6142e-05,  4.7876e-04, -6.2840e-04, -5.3680e-04,
         6.9168e-04,  5.0042e-04, -2.5184e-04,  1.9605e-04,  1.0119e-04,
        -5.3817e-04,  3.5876e-04, -5.0552e-04,  1.3048e-04, -9.5488e-04,
         1.0431e-03,  5.7003e-04,  5.5292e-04,  1.2073e-03,  1.0776e-03,
        -9.4755e-04,  3.0330e-04, -9.8812e-04,  4.8913e-05,  9.3448e-04,
         9.9166e-04,  1.3285e-04,  5.8984e-04,  2.3542e-04])
policy_loss: -2.2351741790771484e-08
entropy_loss: -2.8448805809020996
value_loss: 645.77783203125
loss: 322.888916015625
policy_loss: 0.0001648319885134697
entropy_loss: -2.8450636863708496
value_loss: 650.4413452148438
loss: 325.2208251953125
policy_loss: -0.00026313867419958115
entropy_loss: -2.8452184200286865
value_loss: 635.2125244140625
loss: 317.6059875488281
policy_loss: 1.628836616873741e-05
entropy_loss: -2.8453938961029053
value_loss: 657.3905029296875
loss: 328.6952819824219
policy_loss: -0.0004527457058429718
entropy_loss: -2.845588445663452
value_loss: 683.4031982421875
loss: 341.7011413574219
policy_loss: -0.0003934483975172043
entropy_loss: -2.845781087875366
value_loss: 655.9146728515625
loss: 327.9569396972656
policy_loss: -0.00047782622277736664
entropy_loss: -2.8459928035736084
value_loss: 579.071533203125
loss: 289.5352783203125
policy_loss: -0.0007135258056223392
entropy_loss: -2.8462202548980713
value_loss: 637.4456787109375
loss: 318.7221374511719
policy_loss: -0.002470649778842926
entropy_loss: -2.846405267715454
value_loss: 643.545654296875
loss: 321.7703552246094
policy_loss: -0.0012700483202934265
entropy_loss: -2.8465940952301025
value_loss: 615.4395751953125
loss: 307.718505859375
policy_loss: -0.0007417346350848675
entropy_loss: -2.8468286991119385
value_loss: 636.859130859375
loss: 318.4288330078125
policy_loss: 9.762495756149292e-05
entropy_loss: -2.847028970718384
value_loss: 626.0067138671875
loss: 313.0034484863281
policy_loss: -0.0017627710476517677
entropy_loss: -2.847200870513916
value_loss: 574.2698364257812
loss: 287.1331481933594
policy_loss: -0.0027461107820272446
entropy_loss: -2.8473799228668213
value_loss: 613.1604614257812
loss: 306.5774841308594
policy_loss: -0.002448409330099821
entropy_loss: -2.847581624984741
value_loss: 675.0094604492188
loss: 337.5022888183594
policy_loss: -0.001558590680360794
entropy_loss: -2.8477671146392822
value_loss: 625.1495361328125
loss: 312.5732116699219
policy_loss: -0.003021134063601494
entropy_loss: -2.847938299179077
value_loss: 598.7950439453125
loss: 299.3945007324219
policy_loss: -0.0017813919112086296
entropy_loss: -2.848174810409546
value_loss: 652.4594116210938
loss: 326.2279357910156
policy_loss: -0.004804497584700584
entropy_loss: -2.8483808040618896
value_loss: 568.8544311523438
loss: 284.42242431640625
policy_loss: -0.0033031124621629715
entropy_loss: -2.8485121726989746
value_loss: 633.8782348632812
loss: 316.9358215332031
policy_loss: -0.0030325613915920258
entropy_loss: -2.848655939102173
value_loss: 581.6681518554688
loss: 290.8310546875
policy_loss: -0.0004290761426091194
entropy_loss: -2.848813533782959
value_loss: 620.534423828125
loss: 310.26678466796875
policy_loss: -0.0039670951664447784
entropy_loss: -2.8489301204681396
value_loss: 614.6680297851562
loss: 307.3300476074219
policy_loss: -0.009503927081823349
entropy_loss: -2.8490638732910156
value_loss: 603.7750854492188
loss: 301.8780517578125
policy_loss: -0.006505000405013561
entropy_loss: -2.8492090702056885
value_loss: 619.2442626953125
loss: 309.6156311035156
policy_loss: -0.0057568978518247604
entropy_loss: -2.849351406097412
value_loss: 574.7271728515625
loss: 287.3578186035156
policy_loss: -0.0028700483962893486
entropy_loss: -2.8495161533355713
value_loss: 607.8012084960938
loss: 303.8977355957031
policy_loss: -0.00402214378118515
entropy_loss: -2.8496363162994385
value_loss: 586.19140625
loss: 293.0916748046875
policy_loss: -0.004367025103420019
entropy_loss: -2.8497812747955322
value_loss: 561.4940795898438
loss: 280.74267578125
policy_loss: -0.0055504292249679565
entropy_loss: -2.849933385848999
value_loss: 579.4987182617188
loss: 289.7438049316406
policy_loss: -0.004982328973710537
entropy_loss: -2.850097417831421
value_loss: 613.7064208984375
loss: 306.8482360839844
policy_loss: -0.006819352973252535
entropy_loss: -2.8502373695373535
value_loss: 600.6163940429688
loss: 300.3013916015625
policy_loss: -0.0022700210101902485
entropy_loss: -2.850391387939453
value_loss: 518.5524291992188
loss: 259.2739562988281
policy_loss: -0.003927365876734257
entropy_loss: -2.8505709171295166
value_loss: 659.2601318359375
loss: 329.6261291503906
policy_loss: -0.013197122141718864
entropy_loss: -2.8507537841796875
value_loss: 569.4751586914062
loss: 284.7243957519531
policy_loss: -0.005098042078316212
entropy_loss: -2.8509294986724854
value_loss: 576.4132080078125
loss: 288.2015075683594
policy_loss: -0.011893178336322308
entropy_loss: -2.8510892391204834
value_loss: 539.4931640625
loss: 269.73468017578125
policy_loss: -0.014940636232495308
entropy_loss: -2.8513054847717285
value_loss: 574.1992797851562
loss: 287.0846862792969
policy_loss: 0.0009601470082998276
entropy_loss: -2.851494073867798
value_loss: 560.8176879882812
loss: 280.4097900390625
policy_loss: 0.002059241756796837
entropy_loss: -2.8516640663146973
value_loss: 617.70068359375
loss: 308.8523864746094
-----------------------------------------
| avg_speed               | 0.353       |
| is_success              | 0           |
| max_speed               | 0.353       |
| reward                  | -0.34633332 |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.42e+03   |
| time/                   |             |
|    fps                  | 124         |
|    iterations           | 5           |
|    time_elapsed         | 82          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.004294691 |
|    clip_fraction        | 0.0157      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.85       |
|    explained_variance   | 0.0634      |
|    learning_rate        | 0.0003      |
|    loss                 | 309         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00335    |
|    std                  | 1.01        |
|    value_loss           | 610         |
-----------------------------------------
TRAINING:
weight : tensor([[ 0.1840, -0.3625, -0.0660,  ..., -0.0128, -0.2192, -0.3063],
        [ 0.0239,  0.1504, -0.0072,  ..., -0.0745, -0.0070, -0.0495],
        [-0.0708,  0.0526,  0.0282,  ..., -0.1717, -0.1298,  0.2242],
        ...,
        [ 0.2470, -0.0852,  0.2185,  ...,  0.1993, -0.2106,  0.3181],
        [-0.0448, -0.2570, -0.0557,  ..., -0.1355, -0.2733,  0.3106],
        [-0.0029,  0.1034, -0.1744,  ..., -0.0743,  0.0880,  0.0951]])
bias : tensor([ 2.1731e-03,  4.7866e-04,  1.7464e-05, -2.9491e-04, -5.1736e-05,
         4.0665e-03,  1.3626e-03, -3.2557e-03,  8.3585e-04,  1.1308e-03,
         1.7941e-03, -7.9230e-04, -2.5664e-03,  1.1149e-03, -3.7824e-05,
         2.7963e-03,  2.5513e-05,  1.6786e-04, -1.0264e-03, -1.3475e-03,
        -7.9015e-04, -8.0842e-07, -6.7938e-04, -2.5640e-03,  9.0961e-04,
         4.0117e-05,  7.8560e-04,  2.3666e-03,  2.0826e-03,  8.2303e-05,
        -1.1998e-03,  3.2935e-04, -8.4791e-04,  1.2179e-03, -1.0211e-03,
        -1.0436e-03, -1.0542e-04, -9.0934e-04,  4.5068e-03,  2.0701e-05,
         3.0501e-03, -2.2969e-03,  1.0429e-03,  2.2241e-04,  4.4768e-04,
        -6.2512e-04,  2.3978e-03,  1.8318e-03, -8.5391e-04,  1.0875e-04,
        -2.2495e-03, -1.5697e-04, -2.0376e-04, -3.7096e-04,  5.0917e-04,
         2.9643e-03,  7.4676e-04,  1.0856e-04, -6.5024e-05, -1.0388e-03,
        -2.0903e-04, -1.8217e-03,  1.3857e-03, -3.1396e-03])
weight : tensor([[-0.2179,  0.3488, -0.3287,  ..., -0.1705,  0.3018,  0.1744],
        [-0.1656, -0.1413, -0.0243,  ...,  0.0542, -0.3294,  0.0932],
        [-0.1285, -0.4217, -0.1406,  ...,  0.1899,  0.1352,  0.0132],
        ...,
        [ 0.2279,  0.1367, -0.2867,  ..., -0.0843,  0.0164, -0.0877],
        [-0.2403, -0.1292,  0.1503,  ...,  0.0465,  0.3095,  0.0835],
        [ 0.2044, -0.1990, -0.0128,  ..., -0.0742,  0.0373, -0.1210]])
bias : tensor([-8.9608e-04,  2.7966e-04,  4.3086e-04,  5.5253e-05,  5.6819e-04,
        -2.6683e-03,  3.1690e-04, -5.6571e-04,  1.4021e-03, -3.8441e-04,
        -8.1268e-04,  1.5982e-03, -3.5370e-04,  9.6264e-06,  9.8513e-04,
        -3.4931e-04, -3.9482e-04,  2.3864e-03, -9.6279e-04, -5.1784e-04,
        -9.6396e-04, -7.1137e-04,  7.2380e-04, -5.9436e-04,  3.2800e-04,
        -6.8835e-04,  9.0457e-04,  1.8397e-03,  2.8679e-04,  3.0294e-04,
         4.1382e-04,  1.8372e-03, -5.3923e-05, -3.2628e-04,  4.5407e-05,
         8.7099e-04, -6.1698e-04, -7.4536e-04,  1.1676e-03, -1.9892e-03,
        -4.2507e-04,  1.1073e-03, -1.6087e-04, -2.0970e-04,  9.7637e-04,
        -8.5100e-04, -7.2782e-04,  2.2117e-03, -3.8218e-04,  2.1172e-04,
         4.3052e-04, -2.2065e-03,  2.8747e-04,  1.2115e-05,  9.1072e-04,
         1.5008e-04,  2.8014e-03,  3.4044e-04,  5.0849e-04,  1.2917e-03,
         2.3611e-03,  1.1811e-04, -1.5258e-03,  2.1950e-04])
policy_loss: 1.203734427690506e-07
entropy_loss: -2.8652472496032715
value_loss: 748.7171020507812
loss: 374.3585510253906
policy_loss: 9.377487003803253e-06
entropy_loss: -2.8651976585388184
value_loss: 729.1870727539062
loss: 364.5935363769531
policy_loss: -5.0235074013471603e-05
entropy_loss: -2.8651769161224365
value_loss: 742.050537109375
loss: 371.02520751953125
policy_loss: 0.0002614874392747879
entropy_loss: -2.8651959896087646
value_loss: 753.9617919921875
loss: 376.9811706542969
policy_loss: -0.0004248502664268017
entropy_loss: -2.8651747703552246
value_loss: 741.9921875
loss: 370.99566650390625
policy_loss: 0.00033207982778549194
entropy_loss: -2.8651633262634277
value_loss: 735.77197265625
loss: 367.8863220214844
policy_loss: 0.0004717647098004818
entropy_loss: -2.865164279937744
value_loss: 743.3055419921875
loss: 371.6532287597656
policy_loss: -0.00018464564345777035
entropy_loss: -2.8651695251464844
value_loss: 730.6408081054688
loss: 365.3202209472656
policy_loss: -6.454437971115112e-05
entropy_loss: -2.865185022354126
value_loss: 746.09521484375
loss: 373.04754638671875
policy_loss: 0.00012339348904788494
entropy_loss: -2.8652307987213135
value_loss: 745.8859252929688
loss: 372.9430847167969
policy_loss: -0.00033126864582300186
entropy_loss: -2.865251064300537
value_loss: 724.2539672851562
loss: 362.12664794921875
policy_loss: -0.0003252420574426651
entropy_loss: -2.8652455806732178
value_loss: 701.7039184570312
loss: 350.85162353515625
policy_loss: -6.507430225610733e-05
entropy_loss: -2.8652877807617188
value_loss: 723.2407836914062
loss: 361.6203308105469
policy_loss: -0.0013216855004429817
entropy_loss: -2.8653371334075928
value_loss: 720.495361328125
loss: 360.2463684082031
policy_loss: -0.0001479554921388626
entropy_loss: -2.8654024600982666
value_loss: 716.209228515625
loss: 358.1044616699219
policy_loss: -0.00019430415704846382
entropy_loss: -2.865455389022827
value_loss: 717.4440307617188
loss: 358.7218322753906
policy_loss: -0.0012952047400176525
entropy_loss: -2.8655142784118652
value_loss: 718.630126953125
loss: 359.31378173828125
policy_loss: -0.0007297312840819359
entropy_loss: -2.865570306777954
value_loss: 726.5711059570312
loss: 363.2848205566406
policy_loss: -0.0005152560770511627
entropy_loss: -2.865607976913452
value_loss: 684.8573608398438
loss: 342.42816162109375
policy_loss: -0.000463021919131279
entropy_loss: -2.8656580448150635
value_loss: 704.3251953125
loss: 352.1621398925781
policy_loss: -0.0013054925948381424
entropy_loss: -2.8657355308532715
value_loss: 718.0269775390625
loss: 359.0121765136719
policy_loss: -0.0012904340401291847
entropy_loss: -2.8658101558685303
value_loss: 705.0865478515625
loss: 352.5419921875
policy_loss: -0.0007651913911104202
entropy_loss: -2.8658957481384277
value_loss: 663.9015502929688
loss: 331.95001220703125
policy_loss: -0.0011602435261011124
entropy_loss: -2.865966558456421
value_loss: 703.2960205078125
loss: 351.6468505859375
policy_loss: -0.0012618359178304672
entropy_loss: -2.8660504817962646
value_loss: 689.7083740234375
loss: 344.8529357910156
policy_loss: -0.0014506729785352945
entropy_loss: -2.8661463260650635
value_loss: 667.4362182617188
loss: 333.7166442871094
policy_loss: -0.0029981564730405807
entropy_loss: -2.8662450313568115
value_loss: 708.176025390625
loss: 354.08502197265625
policy_loss: -0.0005986869800835848
entropy_loss: -2.8663382530212402
value_loss: 680.2887573242188
loss: 340.1437683105469
policy_loss: -0.0029945357237011194
entropy_loss: -2.866424798965454
value_loss: 671.5195922851562
loss: 335.7568054199219
policy_loss: -0.0024264417588710785
entropy_loss: -2.866497278213501
value_loss: 666.882080078125
loss: 333.4385986328125
policy_loss: -0.0004976466298103333
entropy_loss: -2.8665730953216553
value_loss: 683.0201416015625
loss: 341.50958251953125
policy_loss: -0.0022976696491241455
entropy_loss: -2.8666434288024902
value_loss: 679.9791870117188
loss: 339.9873046875
policy_loss: -0.00023790821433067322
entropy_loss: -2.866738796234131
value_loss: 654.8768310546875
loss: 327.43817138671875
policy_loss: -0.0012734096962958574
entropy_loss: -2.866844415664673
value_loss: 679.6397705078125
loss: 339.818603515625
policy_loss: -0.005728618241846561
entropy_loss: -2.8669321537017822
value_loss: 664.8179931640625
loss: 332.40325927734375
policy_loss: -0.0032319538295269012
entropy_loss: -2.8670384883880615
value_loss: 658.546630859375
loss: 329.27008056640625
policy_loss: -0.004028733354061842
entropy_loss: -2.8671364784240723
value_loss: 671.9594116210938
loss: 335.9756774902344
policy_loss: -0.0016613071784377098
entropy_loss: -2.867255926132202
value_loss: 634.7398681640625
loss: 317.3682861328125
policy_loss: -0.0024323351681232452
entropy_loss: -2.867342472076416
value_loss: 650.6607666015625
loss: 325.32794189453125
policy_loss: -0.004318529739975929
entropy_loss: -2.8674604892730713
value_loss: 657.4168701171875
loss: 328.7041015625
-------------------------------------------
| avg_speed               | 1.62          |
| is_success              | 0             |
| max_speed               | 1.62          |
| reward                  | -1.4672099    |
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -1.3e+03      |
| time/                   |               |
|    fps                  | 120           |
|    iterations           | 5             |
|    time_elapsed         | 84            |
|    total_timesteps      | 10240         |
| train/                  |               |
|    approx_kl            | 0.00090677274 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.87         |
|    explained_variance   | -0.173        |
|    learning_rate        | 0.0003        |
|    loss                 | 329           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00117      |
|    std                  | 1.01          |
|    value_loss           | 702           |
-------------------------------------------
TRAINING:
weight : tensor([[ 0.2374, -0.2992,  0.1530,  ...,  0.0421,  0.3542, -0.0149],
        [-0.1644,  0.1175, -0.0401,  ..., -0.1572, -0.1303,  0.2509],
        [-0.0632, -0.2316,  0.3680,  ...,  0.1790,  0.0252,  0.0541],
        ...,
        [-0.1343, -0.0470,  0.0676,  ...,  0.0499,  0.3750,  0.0617],
        [-0.2556, -0.3574,  0.2092,  ...,  0.0683, -0.1435,  0.0517],
        [-0.1695, -0.1509,  0.1255,  ...,  0.2096, -0.3272,  0.0174]])
bias : tensor([-1.0239e-04, -2.8474e-04,  1.2783e-04,  5.1637e-04,  7.0362e-04,
        -5.5233e-04,  4.5774e-04,  1.9242e-04,  2.0283e-04,  3.7911e-04,
         9.7150e-04,  4.2728e-04,  1.9964e-04, -5.6065e-04, -3.2458e-05,
        -7.9262e-04,  8.0856e-04,  8.6280e-04,  2.6622e-04, -1.0658e-03,
        -2.2957e-04,  8.3273e-04, -9.6513e-04, -2.4726e-04,  2.4141e-04,
         1.8586e-04, -3.2729e-04,  4.0983e-04,  7.4086e-04,  3.2774e-04,
        -3.9576e-04, -4.4519e-04,  9.1748e-04,  2.6720e-04,  2.6700e-05,
         4.2245e-04,  4.1250e-04,  3.1705e-04,  3.0306e-04, -1.8869e-04,
        -3.8996e-04,  1.6672e-04, -1.8692e-03,  4.3333e-04, -2.3782e-04,
         4.6998e-05,  8.8637e-04, -1.8283e-05, -4.9000e-04, -7.4920e-04,
         2.8996e-04, -3.3952e-04,  1.0618e-03, -5.8516e-04,  4.9564e-05,
         1.7254e-03, -2.8518e-04, -1.3537e-04,  1.6614e-05, -6.8838e-04,
        -9.9313e-06,  1.0474e-03,  1.8604e-04,  4.0428e-04])
weight : tensor([[-3.3513e-01, -1.5506e-01, -1.5615e-02,  ..., -2.0458e-01,
          1.3932e-01,  1.9106e-04],
        [ 2.5402e-01,  9.0409e-02, -1.8252e-01,  ...,  1.3689e-01,
         -2.4671e-01,  2.4122e-01],
        [ 8.5867e-02, -1.8998e-01, -1.9088e-01,  ...,  3.5831e-02,
         -2.1210e-02,  2.5876e-01],
        ...,
        [ 6.7295e-02, -6.9260e-02, -2.7607e-01,  ...,  1.7486e-01,
         -2.4594e-02, -3.4415e-01],
        [ 2.6076e-01,  5.9728e-02, -1.9263e-02,  ..., -8.8525e-02,
         -2.1076e-01, -1.0923e-01],
        [-2.2658e-01,  9.4606e-03,  4.7000e-02,  ...,  7.4325e-02,
          2.9160e-02, -1.0987e-02]])
bias : tensor([ 6.6966e-04,  3.6978e-05,  1.6445e-04,  6.2641e-05,  6.1477e-05,
        -5.8600e-04, -1.3844e-03,  7.2710e-04,  4.9541e-05, -6.2726e-04,
         1.0361e-03, -1.7562e-04, -1.4412e-04, -1.9967e-04,  7.0595e-04,
         6.9175e-04, -2.4199e-04,  2.5205e-04, -2.2286e-04,  4.4754e-04,
         5.6207e-05,  1.0116e-04, -2.8971e-04, -6.4505e-04,  1.8856e-04,
        -3.6653e-04,  7.6400e-04,  2.6252e-05, -1.3368e-03, -3.0161e-04,
         3.7590e-05,  6.5353e-04, -1.1854e-04, -2.7508e-04, -5.3866e-04,
        -1.9956e-04, -4.0680e-06, -5.2326e-04,  2.5709e-04,  1.5913e-03,
         2.2964e-04,  4.9305e-04,  4.5974e-05, -4.8674e-04,  2.8260e-04,
         6.0457e-04, -1.3960e-04, -1.9863e-04,  2.2205e-04, -7.4475e-04,
         2.3146e-04, -3.3668e-04,  6.2080e-04,  3.1131e-04, -3.0158e-04,
         2.6582e-04, -8.7969e-04, -2.0573e-03,  7.8350e-04,  5.5256e-04,
         1.0742e-03,  1.3474e-04, -3.1750e-04, -4.1312e-04])
policy_loss: -6.05359673500061e-08
entropy_loss: -2.865184783935547
value_loss: 274.52130126953125
loss: 137.26065063476562
policy_loss: -0.00013623014092445374
entropy_loss: -2.8652570247650146
value_loss: 269.06378173828125
loss: 134.53175354003906
policy_loss: 7.657520473003387e-05
entropy_loss: -2.865272283554077
value_loss: 288.4212646484375
loss: 144.21070861816406
policy_loss: -0.0003078179433941841
entropy_loss: -2.8653810024261475
value_loss: 281.19940185546875
loss: 140.59939575195312
policy_loss: -0.00011317804455757141
entropy_loss: -2.8655030727386475
value_loss: 283.906494140625
loss: 141.95314025878906
policy_loss: -0.0005714814178645611
entropy_loss: -2.865607976913452
value_loss: 273.12884521484375
loss: 136.56385803222656
policy_loss: -0.0025587715208530426
entropy_loss: -2.8656160831451416
value_loss: 277.12799072265625
loss: 138.56143188476562
policy_loss: -0.0012206579558551311
entropy_loss: -2.8658127784729004
value_loss: 276.4239196777344
loss: 138.2107391357422
policy_loss: -0.001042477786540985
entropy_loss: -2.86586594581604
value_loss: 290.2115783691406
loss: 145.10475158691406
policy_loss: -0.0038550696335732937
entropy_loss: -2.865844488143921
value_loss: 264.19775390625
loss: 132.0950164794922
policy_loss: -0.0005574468523263931
entropy_loss: -2.8657877445220947
value_loss: 285.482177734375
loss: 142.7405242919922
policy_loss: -0.004021836444735527
entropy_loss: -2.8657875061035156
value_loss: 266.8174743652344
loss: 133.4047088623047
policy_loss: -0.003127878997474909
entropy_loss: -2.865816593170166
value_loss: 275.23480224609375
loss: 137.61427307128906
policy_loss: -0.002668650820851326
entropy_loss: -2.8658559322357178
value_loss: 270.0331726074219
loss: 135.013916015625
policy_loss: -0.007387234829366207
entropy_loss: -2.865797281265259
value_loss: 273.6129455566406
loss: 136.79908752441406
policy_loss: -0.002400382421910763
entropy_loss: -2.865882635116577
value_loss: 282.96746826171875
loss: 141.48133850097656
policy_loss: -0.007269677706062794
entropy_loss: -2.865875005722046
value_loss: 284.7515869140625
loss: 142.3685302734375
policy_loss: -0.004258140921592712
entropy_loss: -2.8658738136291504
value_loss: 276.6260681152344
loss: 138.30877685546875
policy_loss: -0.00734346266835928
entropy_loss: -2.865835666656494
value_loss: 268.4638671875
loss: 134.22459411621094
policy_loss: -0.002064201980829239
entropy_loss: -2.86582350730896
value_loss: 266.7227478027344
loss: 133.35931396484375
policy_loss: -0.005940333008766174
entropy_loss: -2.865764856338501
value_loss: 263.2577819824219
loss: 131.62295532226562
policy_loss: -0.003931076731532812
entropy_loss: -2.8657495975494385
value_loss: 274.49517822265625
loss: 137.24365234375
policy_loss: -0.005322704557329416
entropy_loss: -2.865701198577881
value_loss: 267.4102783203125
loss: 133.69981384277344
policy_loss: -0.009271491318941116
entropy_loss: -2.8656461238861084
value_loss: 285.687744140625
loss: 142.8345947265625
policy_loss: -0.00013128062710165977
entropy_loss: -2.8656046390533447
value_loss: 264.6955261230469
loss: 132.34762573242188
policy_loss: -0.0028100586496293545
entropy_loss: -2.8655622005462646
value_loss: 276.86224365234375
loss: 138.42831420898438
policy_loss: -0.009995708242058754
entropy_loss: -2.865520715713501
value_loss: 266.567626953125
loss: 133.27381896972656
policy_loss: -0.01341150887310505
entropy_loss: -2.865478515625
value_loss: 276.66961669921875
loss: 138.32139587402344
policy_loss: -0.003773184958845377
entropy_loss: -2.8654673099517822
value_loss: 273.3357849121094
loss: 136.66412353515625
policy_loss: -0.00298120453953743
entropy_loss: -2.865339756011963
value_loss: 269.8537292480469
loss: 134.92388916015625
policy_loss: -0.013432573527097702
entropy_loss: -2.8653504848480225
value_loss: 265.0885009765625
loss: 132.53082275390625
policy_loss: -0.00841414276510477
entropy_loss: -2.8653299808502197
value_loss: 270.4752197265625
loss: 135.2292022705078
policy_loss: -0.003848481923341751
entropy_loss: -2.8653223514556885
value_loss: 270.9144592285156
loss: 135.45338439941406
policy_loss: -0.007455507759004831
entropy_loss: -2.8652760982513428
value_loss: 260.3748779296875
loss: 130.1799774169922
policy_loss: -0.014798158779740334
entropy_loss: -2.8651976585388184
value_loss: 269.7623291015625
loss: 134.86636352539062
policy_loss: -0.004074604716151953
entropy_loss: -2.865182399749756
value_loss: 271.4990539550781
loss: 135.74545288085938
policy_loss: -0.0029129041358828545
entropy_loss: -2.8650994300842285
value_loss: 257.25018310546875
loss: 128.62217712402344
policy_loss: -0.01304221898317337
entropy_loss: -2.864948034286499
value_loss: 265.0970458984375
loss: 132.5354766845703
policy_loss: -0.007877185940742493
entropy_loss: -2.8648035526275635
value_loss: 271.163818359375
loss: 135.57403564453125
policy_loss: -0.006605563685297966
entropy_loss: -2.8646621704101562
value_loss: 272.6966552734375
loss: 136.3417205810547
------------------------------------------
| avg_speed               | 0.0928       |
| is_success              | 0            |
| max_speed               | 0.0928       |
| reward                  | -0.5651007   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.01e+03    |
| time/                   |              |
|    fps                  | 115          |
|    iterations           | 5            |
|    time_elapsed         | 88           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.0057934066 |
|    clip_fraction        | 0.0324       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.87        |
|    explained_variance   | 0.0876       |
|    learning_rate        | 0.0003       |
|    loss                 | 136          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00477     |
|    std                  | 1.01         |
|    value_loss           | 273          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.0784,  0.4112,  0.2385,  ..., -0.0445,  0.0341,  0.3005],
        [ 0.1246,  0.3324,  0.1108,  ..., -0.0980, -0.3111, -0.1931],
        [ 0.1157,  0.1786,  0.0252,  ...,  0.4164, -0.1212,  0.4007],
        ...,
        [ 0.0295,  0.1497, -0.2622,  ..., -0.3831, -0.0778, -0.1392],
        [-0.2673,  0.0059,  0.0762,  ..., -0.0106,  0.0142, -0.1109],
        [ 0.1483,  0.1597,  0.3136,  ..., -0.1186,  0.1919,  0.2705]])
bias : tensor([-3.0122e-04,  2.0069e-03,  3.1051e-04,  1.9682e-04,  5.0247e-04,
        -1.0265e-03, -6.5760e-05, -4.5103e-04, -1.0312e-03, -6.4370e-04,
        -5.7250e-04,  3.2217e-04,  2.6882e-06,  1.1450e-03, -1.3924e-04,
        -8.1923e-04, -3.4703e-04, -9.6654e-05, -6.7565e-04, -1.0720e-03,
        -4.3774e-04, -1.0612e-03, -9.3025e-04,  7.8136e-04,  9.1709e-04,
        -2.9072e-04, -7.7753e-04, -2.5174e-04,  1.4911e-03,  8.9603e-04,
        -1.4686e-03, -8.0374e-04,  1.4971e-03,  1.4061e-03,  4.5188e-04,
        -5.9200e-04,  5.3963e-05, -3.4791e-04, -1.0093e-03,  1.0192e-03,
        -2.9423e-04,  1.3969e-03, -6.9274e-04,  7.7826e-04, -1.0513e-03,
         9.4219e-05, -4.2544e-05,  7.9969e-04, -1.0076e-03,  5.2686e-04,
        -5.1388e-04,  1.5227e-03,  2.3023e-04, -1.1112e-05,  1.2951e-03,
        -6.1756e-04,  1.0211e-03, -9.4574e-05, -1.5382e-03, -3.5339e-05,
         7.0014e-04,  4.8032e-04,  5.7943e-04, -1.2247e-04])
weight : tensor([[-0.1730,  0.0848,  0.1622,  ..., -0.2985,  0.0026, -0.0791],
        [ 0.0458, -0.2648,  0.0883,  ...,  0.1016,  0.0818,  0.3124],
        [-0.0707,  0.2346, -0.1153,  ..., -0.1620, -0.2250,  0.1526],
        ...,
        [ 0.2286,  0.3861,  0.1881,  ..., -0.0480,  0.4151,  0.2052],
        [-0.0494,  0.2780,  0.1178,  ..., -0.2088,  0.1524, -0.2257],
        [ 0.0448, -0.0554,  0.3605,  ...,  0.0096,  0.0277, -0.2450]])
bias : tensor([ 1.0547e-03,  4.9822e-04,  1.4875e-04,  4.9752e-05, -6.5034e-04,
         1.0687e-03,  5.9296e-04, -8.5501e-05,  1.9420e-03, -1.4162e-03,
        -4.8733e-04,  9.5491e-05,  1.6441e-05,  2.3367e-04,  4.7330e-04,
         1.2249e-04,  4.7232e-05,  4.8592e-04,  1.2939e-03,  6.1759e-04,
        -5.8584e-05,  3.1555e-04, -2.0744e-04, -1.3224e-03,  7.0816e-04,
         1.3456e-03, -2.6893e-04,  2.4994e-04,  7.6291e-05, -1.0109e-03,
         6.7108e-04, -9.4443e-04,  9.5644e-05, -1.9757e-05,  1.4541e-03,
         3.1750e-04, -4.1559e-04,  5.0665e-04, -1.4941e-03, -7.8938e-04,
         1.3972e-03,  1.0487e-03, -2.9080e-04,  4.1725e-04,  1.6295e-04,
        -6.9284e-04,  5.5840e-04, -8.3015e-04,  4.2485e-04, -1.1908e-03,
         1.6335e-03,  7.0246e-04,  8.2941e-04,  1.6277e-03,  1.8232e-03,
        -1.1243e-03,  6.3627e-04, -1.4305e-03,  4.9573e-04,  1.4221e-03,
         1.8036e-03,  3.5470e-04,  7.7318e-04,  4.6840e-04])
policy_loss: -9.313225746154785e-10
entropy_loss: -2.8518385887145996
value_loss: 311.96923828125
loss: 155.984619140625
policy_loss: 3.220513463020325e-05
entropy_loss: -2.8518853187561035
value_loss: 311.89801025390625
loss: 155.94903564453125
policy_loss: -1.5961937606334686e-05
entropy_loss: -2.8520798683166504
value_loss: 322.93780517578125
loss: 161.46888732910156
policy_loss: -6.381259299814701e-05
entropy_loss: -2.8523879051208496
value_loss: 322.6318054199219
loss: 161.3158416748047
policy_loss: -0.00046342192217707634
entropy_loss: -2.8526456356048584
value_loss: 307.29620361328125
loss: 153.64764404296875
policy_loss: -0.0005178097635507584
entropy_loss: -2.8530220985412598
value_loss: 322.289306640625
loss: 161.14413452148438
policy_loss: -0.001121237874031067
entropy_loss: -2.853402614593506
value_loss: 315.1982421875
loss: 157.59800720214844
policy_loss: -6.356090307235718e-05
entropy_loss: -2.8537747859954834
value_loss: 317.0990905761719
loss: 158.5494842529297
policy_loss: -0.0019819000735878944
entropy_loss: -2.8540685176849365
value_loss: 305.41485595703125
loss: 152.7054443359375
policy_loss: -0.002606775611639023
entropy_loss: -2.854280948638916
value_loss: 313.1316833496094
loss: 156.563232421875
policy_loss: -0.0006400654092431068
entropy_loss: -2.8545267581939697
value_loss: 317.4579162597656
loss: 158.7283172607422
policy_loss: -0.0007547633722424507
entropy_loss: -2.854907751083374
value_loss: 313.53717041015625
loss: 156.76783752441406
policy_loss: -0.002463553100824356
entropy_loss: -2.8552398681640625
value_loss: 300.9307556152344
loss: 150.46292114257812
policy_loss: -0.0018753246404230595
entropy_loss: -2.855499267578125
value_loss: 312.41845703125
loss: 156.2073516845703
policy_loss: -0.003011602908372879
entropy_loss: -2.8558695316314697
value_loss: 315.47515869140625
loss: 157.7345733642578
policy_loss: -0.00453109759837389
entropy_loss: -2.8561782836914062
value_loss: 305.6556701660156
loss: 152.82330322265625
policy_loss: -0.008445652201771736
entropy_loss: -2.856534481048584
value_loss: 306.7593078613281
loss: 153.3712158203125
policy_loss: -0.003659677691757679
entropy_loss: -2.856914758682251
value_loss: 300.393310546875
loss: 150.1929931640625
policy_loss: 0.0006950846873223782
entropy_loss: -2.857260227203369
value_loss: 292.8532409667969
loss: 146.4273223876953
policy_loss: -0.004185710102319717
entropy_loss: -2.8577475547790527
value_loss: 317.92376708984375
loss: 158.95770263671875
policy_loss: -0.00856027752161026
entropy_loss: -2.8581161499023438
value_loss: 303.84912109375
loss: 151.91600036621094
policy_loss: -0.005181877873837948
entropy_loss: -2.858466863632202
value_loss: 305.6861572265625
loss: 152.837890625
policy_loss: -0.001453734003007412
entropy_loss: -2.8588128089904785
value_loss: 298.9744873046875
loss: 149.4857940673828
policy_loss: -0.003704383969306946
entropy_loss: -2.85917067527771
value_loss: 291.98321533203125
loss: 145.98789978027344
policy_loss: -0.007289852946996689
entropy_loss: -2.859577178955078
value_loss: 299.065185546875
loss: 149.52529907226562
policy_loss: -0.0036498531699180603
entropy_loss: -2.8600003719329834
value_loss: 287.52728271484375
loss: 143.75999450683594
policy_loss: -0.005915641784667969
entropy_loss: -2.8603804111480713
value_loss: 291.8062744140625
loss: 145.897216796875
policy_loss: -0.003916272893548012
entropy_loss: -2.8607289791107178
value_loss: 304.24737548828125
loss: 152.11976623535156
policy_loss: -0.011295046657323837
entropy_loss: -2.861133337020874
value_loss: 286.175537109375
loss: 143.07647705078125
policy_loss: -0.008111480623483658
entropy_loss: -2.861544132232666
value_loss: 299.2564392089844
loss: 149.62010192871094
policy_loss: 0.0035546589642763138
entropy_loss: -2.861931085586548
value_loss: 275.10968017578125
loss: 137.5583953857422
policy_loss: -0.003924280405044556
entropy_loss: -2.8622994422912598
value_loss: 304.18115234375
loss: 152.08665466308594
policy_loss: -0.0018411856144666672
entropy_loss: -2.8626580238342285
value_loss: 285.8428955078125
loss: 142.9196014404297
policy_loss: -0.0002739052288234234
entropy_loss: -2.863006353378296
value_loss: 290.1062316894531
loss: 145.05284118652344
policy_loss: -0.008724537678062916
entropy_loss: -2.863334894180298
value_loss: 284.8150634765625
loss: 142.3988037109375
policy_loss: -0.011775081977248192
entropy_loss: -2.8636248111724854
value_loss: 286.3667907714844
loss: 143.17161560058594
policy_loss: -0.00044490210711956024
entropy_loss: -2.86397385597229
value_loss: 275.9745788574219
loss: 137.98684692382812
policy_loss: -0.01927095465362072
entropy_loss: -2.864307165145874
value_loss: 280.94464111328125
loss: 140.4530487060547
policy_loss: -0.006222031079232693
entropy_loss: -2.8648340702056885
value_loss: 284.2198791503906
loss: 142.1037139892578
policy_loss: 0.0017724186182022095
entropy_loss: -2.8652853965759277
value_loss: 288.58819580078125
loss: 144.29586791992188
Directory created: PPO/models/QUALITATIVE-TEST/6t248l2y/model_epoch(0)
------------------------------------
| avg_speed          | 0.915       |
| is_success         | 0           |
| max_speed          | 0.915       |
| reward             | -0.46153295 |
| rollout/           |             |
|    ep_len_mean     | 941         |
|    ep_rew_mean     | -1.26e+03   |
| time/              |             |
|    fps             | 125         |
|    iterations      | 1           |
|    time_elapsed    | 16          |
|    total_timesteps | 12288       |
------------------------------------
TRAINING:
weight : tensor([[ 0.1834, -0.3639, -0.0651,  ..., -0.0132, -0.2192, -0.3086],
        [ 0.0236,  0.1507, -0.0065,  ..., -0.0746, -0.0066, -0.0493],
        [-0.0709,  0.0525,  0.0287,  ..., -0.1718, -0.1294,  0.2236],
        ...,
        [ 0.2469, -0.0843,  0.2195,  ...,  0.1994, -0.2108,  0.3188],
        [-0.0465, -0.2567, -0.0545,  ..., -0.1347, -0.2739,  0.3101],
        [-0.0029,  0.1044, -0.1745,  ..., -0.0746,  0.0881,  0.0959]])
bias : tensor([ 3.6204e-03,  7.8050e-04,  7.1499e-04, -9.0337e-04, -8.0643e-04,
         4.5215e-03,  2.1675e-03, -5.0622e-03,  7.8672e-04,  2.1641e-04,
         2.6597e-03, -7.5389e-04, -3.4157e-03,  1.9330e-03, -8.3866e-04,
         3.6237e-03, -7.6647e-04, -2.0495e-03, -1.1348e-03, -1.2677e-03,
        -1.5850e-03,  3.9422e-04, -1.3288e-03, -4.0817e-03,  1.6260e-03,
        -8.9223e-04,  1.0928e-03,  2.7293e-03,  3.4725e-03,  6.9260e-04,
        -2.2387e-03,  5.0889e-04, -1.8349e-05,  2.0732e-03, -7.2222e-04,
        -6.8548e-04,  1.3034e-03, -1.3473e-03,  6.4422e-03, -5.4096e-04,
         4.0100e-03, -3.1893e-03,  2.3395e-03,  7.2317e-04,  2.9006e-04,
        -5.2184e-04,  2.6971e-03,  1.7667e-03, -1.2675e-03, -3.7557e-05,
        -2.7532e-03, -1.1743e-03, -9.7309e-04,  2.7445e-04,  3.8371e-04,
         4.2486e-03,  2.7918e-04,  2.3900e-04, -4.9237e-05, -1.5008e-03,
         4.7526e-04, -2.2421e-03,  2.5982e-03, -4.4141e-03])
weight : tensor([[-0.2182,  0.3496, -0.3285,  ..., -0.1701,  0.3016,  0.1748],
        [-0.1656, -0.1422, -0.0248,  ...,  0.0534, -0.3295,  0.0936],
        [-0.1284, -0.4222, -0.1407,  ...,  0.1894,  0.1352,  0.0133],
        ...,
        [ 0.2281,  0.1360, -0.2869,  ..., -0.0849,  0.0163, -0.0878],
        [-0.2399, -0.1299,  0.1500,  ...,  0.0459,  0.3092,  0.0841],
        [ 0.2041, -0.1983, -0.0125,  ..., -0.0737,  0.0377, -0.1218]])
bias : tensor([-1.6118e-03,  8.3927e-06,  5.3055e-04,  9.4261e-04,  1.2299e-03,
        -3.9195e-03,  7.6914e-04, -5.2343e-04,  2.3446e-03,  2.7008e-04,
        -9.3551e-04,  1.2695e-03, -1.5928e-03, -4.2580e-04,  1.0014e-03,
        -7.3294e-04, -1.1557e-03,  3.8307e-03, -1.4863e-03, -6.1596e-04,
        -1.6642e-03, -4.9764e-04,  6.5098e-04, -6.2561e-05, -7.6428e-04,
        -9.4304e-04,  5.1618e-04,  2.3812e-03,  5.7868e-04,  8.4236e-06,
         1.4355e-03,  3.1191e-03, -2.9211e-04, -3.3697e-04, -3.0557e-04,
         7.8786e-04, -1.2177e-03, -7.2481e-04,  1.0317e-03, -2.8430e-03,
        -5.5634e-04,  1.9524e-03,  6.5633e-04,  3.7977e-04,  1.4892e-03,
        -9.8192e-04, -1.1932e-03,  3.9398e-03, -3.9364e-04, -6.0434e-04,
         3.5685e-04, -2.9669e-03, -3.5909e-04, -7.2133e-04,  1.2610e-03,
        -2.6525e-05,  3.9568e-03,  1.1706e-03, -3.5131e-05,  1.5053e-03,
         2.9542e-03,  5.0464e-04, -1.9537e-03,  7.1000e-04])
policy_loss: -1.4901161193847656e-07
entropy_loss: -2.8675577640533447
value_loss: 526.33740234375
loss: 263.168701171875
policy_loss: -3.032572567462921e-05
entropy_loss: -2.8676581382751465
value_loss: 526.1604614257812
loss: 263.0802001953125
policy_loss: -0.0001305900514125824
entropy_loss: -2.867767333984375
value_loss: 530.2860107421875
loss: 265.14288330078125
policy_loss: 0.00020589912310242653
entropy_loss: -2.867896795272827
value_loss: 520.5534057617188
loss: 260.27691650390625
policy_loss: -6.706826388835907e-05
entropy_loss: -2.867994785308838
value_loss: 518.8092651367188
loss: 259.4045715332031
policy_loss: -6.772484630346298e-05
entropy_loss: -2.868083953857422
value_loss: 510.27325439453125
loss: 255.13656616210938
policy_loss: -0.0004535391926765442
entropy_loss: -2.868182897567749
value_loss: 502.68402099609375
loss: 251.341552734375
policy_loss: -0.0004984289407730103
entropy_loss: -2.8682618141174316
value_loss: 540.060791015625
loss: 270.0299072265625
policy_loss: -0.0009097810834646225
entropy_loss: -2.868364095687866
value_loss: 513.3993530273438
loss: 256.6987609863281
policy_loss: -0.0008285548537969589
entropy_loss: -2.8684515953063965
value_loss: 498.5362243652344
loss: 249.2672882080078
policy_loss: -0.0005833432078361511
entropy_loss: -2.8685355186462402
value_loss: 530.3375854492188
loss: 265.168212890625
policy_loss: 0.00010924041271209717
entropy_loss: -2.8686482906341553
value_loss: 496.6971435546875
loss: 248.3486785888672
policy_loss: -0.00104538444429636
entropy_loss: -2.8687517642974854
value_loss: 485.12969970703125
loss: 242.5637969970703
policy_loss: -0.0003843400627374649
entropy_loss: -2.868849039077759
value_loss: 531.6810302734375
loss: 265.8401184082031
policy_loss: -0.001956770196557045
entropy_loss: -2.8689959049224854
value_loss: 474.3597412109375
loss: 237.17791748046875
policy_loss: -0.0008263364434242249
entropy_loss: -2.8691084384918213
value_loss: 514.04541015625
loss: 257.0218811035156
policy_loss: -0.003249727189540863
entropy_loss: -2.869204044342041
value_loss: 472.0198059082031
loss: 236.00665283203125
policy_loss: -0.0004343157634139061
entropy_loss: -2.8692972660064697
value_loss: 497.1816101074219
loss: 248.5903778076172
policy_loss: -0.002254677936434746
entropy_loss: -2.8693997859954834
value_loss: 494.58428955078125
loss: 247.28988647460938
policy_loss: -0.0004065660759806633
entropy_loss: -2.869504451751709
value_loss: 507.6283874511719
loss: 253.81378173828125
policy_loss: -0.0033200401812791824
entropy_loss: -2.8696019649505615
value_loss: 500.826416015625
loss: 250.40988159179688
policy_loss: 0.00025935471057891846
entropy_loss: -2.869697332382202
value_loss: 472.10491943359375
loss: 236.05271911621094
policy_loss: -0.0033926889300346375
entropy_loss: -2.8697354793548584
value_loss: 473.1881408691406
loss: 236.59068298339844
policy_loss: -0.002379830926656723
entropy_loss: -2.8697967529296875
value_loss: 492.0670166015625
loss: 246.0311279296875
policy_loss: -0.0015184208750724792
entropy_loss: -2.8699071407318115
value_loss: 479.2540283203125
loss: 239.62548828125
policy_loss: -0.0037448853254318237
entropy_loss: -2.8700103759765625
value_loss: 476.8366394042969
loss: 238.41458129882812
policy_loss: -0.0037549342960119247
entropy_loss: -2.8701131343841553
value_loss: 462.3433837890625
loss: 231.16793823242188
policy_loss: -0.0024651847779750824
entropy_loss: -2.870222330093384
value_loss: 486.21771240234375
loss: 243.10638427734375
policy_loss: -0.003617212176322937
entropy_loss: -2.870330572128296
value_loss: 467.7855529785156
loss: 233.88916015625
policy_loss: -0.002768043428659439
entropy_loss: -2.8704640865325928
value_loss: 462.9759826660156
loss: 231.4852294921875
policy_loss: -0.004438238218426704
entropy_loss: -2.8705461025238037
value_loss: 484.9041748046875
loss: 242.44764709472656
policy_loss: -0.003181452862918377
entropy_loss: -2.870624542236328
value_loss: 456.7537841796875
loss: 228.37371826171875
policy_loss: -0.0022553447633981705
entropy_loss: -2.870739221572876
value_loss: 446.1493835449219
loss: 223.0724334716797
policy_loss: -0.0036913957446813583
entropy_loss: -2.8708646297454834
value_loss: 468.86212158203125
loss: 234.4273681640625
policy_loss: -0.007913424633443356
entropy_loss: -2.871015787124634
value_loss: 484.6842041015625
loss: 242.3341827392578
policy_loss: -0.0025188373401761055
entropy_loss: -2.8711302280426025
value_loss: 440.5665588378906
loss: 220.28076171875
policy_loss: -0.004088979214429855
entropy_loss: -2.871246576309204
value_loss: 461.87109375
loss: 230.93145751953125
policy_loss: -0.003420492634177208
entropy_loss: -2.8713278770446777
value_loss: 419.76812744140625
loss: 209.88064575195312
policy_loss: -0.0047505805268883705
entropy_loss: -2.8714330196380615
value_loss: 466.41943359375
loss: 233.20497131347656
policy_loss: -0.0062038227915763855
entropy_loss: -2.871542453765869
value_loss: 461.23974609375
loss: 230.61366271972656
Directory created: PPO/models/QUALITATIVE-TEST/hq0uahmd/model_epoch(0)
-----------------------------------
| avg_speed          | 3.26       |
| is_success         | 0          |
| max_speed          | 3.26       |
| reward             | -1.1034448 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.27e+03  |
| time/              |            |
|    fps             | 124        |
|    iterations      | 1          |
|    time_elapsed    | 16         |
|    total_timesteps | 12288      |
-----------------------------------
TRAINING:
weight : tensor([[ 0.2373, -0.2985,  0.1536,  ...,  0.0423,  0.3536, -0.0161],
        [-0.1640,  0.1189, -0.0411,  ..., -0.1575, -0.1283,  0.2516],
        [-0.0634, -0.2308,  0.3692,  ...,  0.1800,  0.0233,  0.0538],
        ...,
        [-0.1341, -0.0474,  0.0675,  ...,  0.0502,  0.3758,  0.0605],
        [-0.2555, -0.3566,  0.2094,  ...,  0.0694, -0.1445,  0.0517],
        [-0.1698, -0.1496,  0.1270,  ...,  0.2108, -0.3287,  0.0168]])
bias : tensor([-9.0536e-04,  6.0061e-05, -1.1190e-03,  8.0918e-04,  4.7861e-04,
         1.2674e-03,  2.0442e-03, -4.1811e-04, -1.4693e-03, -1.9985e-04,
        -3.2316e-04, -9.4732e-04, -1.7263e-03, -9.0710e-04,  3.7095e-04,
         2.4253e-04,  3.3946e-03,  4.3996e-04,  7.2100e-04,  8.9728e-04,
        -3.2804e-04,  2.6551e-03, -5.7159e-04,  1.0788e-03, -6.9802e-04,
        -5.1541e-05, -4.5226e-04, -5.5175e-04, -2.1433e-03, -1.8984e-03,
        -1.6405e-03,  7.3419e-04, -6.1836e-04, -1.1019e-04, -5.0916e-04,
        -1.7116e-04,  4.6987e-04, -5.9810e-04,  1.3210e-03, -3.1426e-04,
        -1.1846e-03, -1.1388e-03, -2.1577e-04,  1.9255e-03,  4.6438e-04,
         3.8727e-04,  6.4553e-05,  6.5940e-04, -1.5013e-03,  5.7638e-04,
         1.3850e-04,  1.0243e-03,  1.0500e-04,  7.0881e-04, -1.6959e-03,
        -9.0178e-04,  7.9882e-04, -7.1978e-04,  1.3628e-03, -1.1910e-03,
         1.2374e-03,  1.1616e-03, -5.4966e-04, -8.5181e-04])
weight : tensor([[-0.3352, -0.1549, -0.0148,  ..., -0.2071,  0.1410,  0.0020],
        [ 0.2539,  0.0905, -0.1824,  ...,  0.1362, -0.2466,  0.2414],
        [ 0.0874, -0.1904, -0.1901,  ...,  0.0379, -0.0211,  0.2589],
        ...,
        [ 0.0675, -0.0693, -0.2758,  ...,  0.1751, -0.0243, -0.3440],
        [ 0.2617,  0.0593, -0.0191,  ..., -0.0858, -0.2106, -0.1100],
        [-0.2266,  0.0093,  0.0469,  ...,  0.0748,  0.0291, -0.0110]])
bias : tensor([-1.6052e-03, -1.4743e-04,  1.2337e-03, -7.5274e-04,  6.8761e-04,
         5.7948e-04,  1.9507e-04,  1.3218e-04, -6.2508e-04, -8.3623e-05,
        -1.8021e-05,  1.0269e-03,  2.9485e-05, -1.5909e-04,  8.1682e-04,
         1.3127e-03,  1.0503e-03,  2.5582e-04, -4.4966e-04, -1.2021e-03,
         6.1849e-04,  8.0558e-04, -3.4922e-04,  1.0799e-03, -4.6415e-05,
         5.2518e-04, -7.4878e-04,  3.9969e-05, -2.7490e-04, -5.8713e-04,
         8.1079e-04, -6.9445e-04,  2.7176e-04,  9.2252e-04, -1.7037e-03,
         6.8138e-04, -7.9778e-04,  1.1117e-03,  4.4039e-04,  1.0546e-03,
         6.1575e-05,  4.8652e-04, -5.4062e-04,  2.3745e-04, -2.7129e-04,
         1.5992e-03,  6.3654e-04,  9.9483e-04, -7.5876e-05,  7.9064e-04,
        -5.0711e-04,  6.4511e-04, -2.8645e-04, -2.8039e-04, -1.1410e-03,
        -3.3681e-04,  1.3796e-04, -6.7054e-04, -1.1260e-03,  2.5996e-03,
         2.0681e-03, -5.4671e-04,  4.2239e-04, -4.9943e-04])
policy_loss: -3.725290298461914e-09
entropy_loss: -2.864494562149048
value_loss: 235.32452392578125
loss: 117.66226196289062
policy_loss: -6.449595093727112e-05
entropy_loss: -2.864377498626709
value_loss: 237.60888671875
loss: 118.80438232421875
policy_loss: 5.310773849487305e-05
entropy_loss: -2.864288091659546
value_loss: 238.73318481445312
loss: 119.36664581298828
policy_loss: -0.0003205556422472
entropy_loss: -2.8641698360443115
value_loss: 249.6335906982422
loss: 124.81647491455078
policy_loss: 3.2199546694755554e-05
entropy_loss: -2.8640520572662354
value_loss: 237.9628143310547
loss: 118.98143768310547
policy_loss: -0.00044892728328704834
entropy_loss: -2.8638968467712402
value_loss: 235.36688232421875
loss: 117.68299102783203
policy_loss: -0.00040208548307418823
entropy_loss: -2.863727569580078
value_loss: 245.05657958984375
loss: 122.52788543701172
policy_loss: -0.0009835236705839634
entropy_loss: -2.8635826110839844
value_loss: 234.6438751220703
loss: 117.32095336914062
policy_loss: -0.0008722092024981976
entropy_loss: -2.8635175228118896
value_loss: 243.02560424804688
loss: 121.51193237304688
policy_loss: -0.0017442069947719574
entropy_loss: -2.8634886741638184
value_loss: 231.6290740966797
loss: 115.81278991699219
policy_loss: -0.0015689381398260593
entropy_loss: -2.8634376525878906
value_loss: 232.70510864257812
loss: 116.35098266601562
policy_loss: 0.0007769707590341568
entropy_loss: -2.863403558731079
value_loss: 233.36227416992188
loss: 116.68191528320312
policy_loss: -0.0024227146059274673
entropy_loss: -2.8633534908294678
value_loss: 238.89993286132812
loss: 119.44754028320312
policy_loss: -0.00035097822546958923
entropy_loss: -2.8632776737213135
value_loss: 228.90380859375
loss: 114.45155334472656
policy_loss: -0.0021028658375144005
entropy_loss: -2.8632025718688965
value_loss: 232.80728149414062
loss: 116.40153503417969
policy_loss: -0.002717919647693634
entropy_loss: -2.8631856441497803
value_loss: 225.07846069335938
loss: 112.53651428222656
policy_loss: -0.0033123940229415894
entropy_loss: -2.8631556034088135
value_loss: 230.6931915283203
loss: 115.3432846069336
policy_loss: -0.006247836165130138
entropy_loss: -2.863131046295166
value_loss: 224.60406494140625
loss: 112.29578399658203
policy_loss: -0.0004966799169778824
entropy_loss: -2.863121271133423
value_loss: 225.52545166015625
loss: 112.7622299194336
policy_loss: -0.0006930269300937653
entropy_loss: -2.863098382949829
value_loss: 228.17227172851562
loss: 114.08544158935547
policy_loss: -0.0028060171753168106
entropy_loss: -2.8630831241607666
value_loss: 223.69039916992188
loss: 111.84239196777344
policy_loss: -0.00826115533709526
entropy_loss: -2.863086462020874
value_loss: 214.8584747314453
loss: 107.42097473144531
policy_loss: -0.0012775566428899765
entropy_loss: -2.8630659580230713
value_loss: 230.02871704101562
loss: 115.0130844116211
policy_loss: -0.002390434965491295
entropy_loss: -2.8630409240722656
value_loss: 222.75125122070312
loss: 111.37323760986328
policy_loss: -0.005476068705320358
entropy_loss: -2.863050937652588
value_loss: 224.32423400878906
loss: 112.1566390991211
policy_loss: -0.006990233901888132
entropy_loss: -2.863070011138916
value_loss: 220.628173828125
loss: 110.30709838867188
policy_loss: -0.0019286572933197021
entropy_loss: -2.8631110191345215
value_loss: 214.8057861328125
loss: 107.40096282958984
policy_loss: -0.002648870460689068
entropy_loss: -2.8631210327148438
value_loss: 213.8857879638672
loss: 106.94024658203125
policy_loss: -0.0030622039921581745
entropy_loss: -2.863136053085327
value_loss: 206.86550903320312
loss: 103.42969512939453
policy_loss: -0.012876907363533974
entropy_loss: -2.863158941268921
value_loss: 213.66651916503906
loss: 106.82038116455078
policy_loss: -0.0021314341574907303
entropy_loss: -2.8631720542907715
value_loss: 224.90065002441406
loss: 112.44819641113281
policy_loss: -0.0007517579942941666
entropy_loss: -2.8631670475006104
value_loss: 209.94520568847656
loss: 104.97184753417969
policy_loss: -0.007862932980060577
entropy_loss: -2.8631937503814697
value_loss: 209.34779357910156
loss: 104.66603088378906
policy_loss: -0.0030668294057250023
entropy_loss: -2.863290309906006
value_loss: 210.31285095214844
loss: 105.15335845947266
policy_loss: -0.00949090626090765
entropy_loss: -2.863358974456787
value_loss: 204.42047119140625
loss: 102.20074462890625
policy_loss: -3.664824180305004e-05
entropy_loss: -2.8633882999420166
value_loss: 213.37176513671875
loss: 106.68584442138672
policy_loss: -0.00914204865694046
entropy_loss: -2.8633971214294434
value_loss: 212.364501953125
loss: 106.17311096191406
policy_loss: -0.009551098570227623
entropy_loss: -2.8633882999420166
value_loss: 205.39410400390625
loss: 102.6875
policy_loss: 0.002228332683444023
entropy_loss: -2.8634085655212402
value_loss: 206.9687042236328
loss: 103.48657989501953
policy_loss: -0.005506481043994427
entropy_loss: -2.8634564876556396
value_loss: 194.577392578125
loss: 97.28318786621094
Directory created: PPO/models/QUALITATIVE-TEST/pz9fksqe/model_epoch(0)
----------------------------------
| avg_speed          | 2.97      |
| is_success         | 0         |
| max_speed          | 2.97      |
| reward             | -0.928582 |
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | -1.06e+03 |
| time/              |           |
|    fps             | 118       |
|    iterations      | 1         |
|    time_elapsed    | 17        |
|    total_timesteps | 12288     |
----------------------------------
TRAINING:
weight : tensor([[ 0.0781,  0.4097,  0.2380,  ..., -0.0436,  0.0334,  0.2997],
        [ 0.1253,  0.3332,  0.1118,  ..., -0.0975, -0.3113, -0.1928],
        [ 0.1162,  0.1797,  0.0251,  ...,  0.4163, -0.1214,  0.4010],
        ...,
        [ 0.0304,  0.1493, -0.2602,  ..., -0.3830, -0.0778, -0.1389],
        [-0.2682,  0.0054,  0.0765,  ..., -0.0114,  0.0158, -0.1104],
        [ 0.1490,  0.1607,  0.3120,  ..., -0.1178,  0.1900,  0.2679]])
bias : tensor([-7.4660e-04,  1.8765e-03,  4.4573e-04, -5.2395e-04,  1.9226e-04,
        -1.8964e-03, -1.5986e-03, -2.0890e-03, -2.1114e-03,  2.3805e-04,
        -1.9270e-03,  8.0432e-04, -5.4860e-04,  2.2021e-03, -1.4659e-03,
        -8.0647e-04, -2.7156e-03,  2.0630e-03, -2.3318e-03,  5.3490e-04,
         2.0977e-03, -3.8860e-03, -2.2678e-03,  1.6792e-03,  3.0897e-04,
        -2.3107e-03, -4.1748e-05, -7.5483e-05,  1.2082e-03,  2.6148e-03,
        -3.2721e-03, -7.3436e-04, -2.0541e-04,  2.1139e-03,  2.1936e-03,
        -2.2217e-03,  8.7487e-04, -4.2081e-04, -2.9632e-04,  3.4383e-03,
        -1.7832e-03,  4.2472e-03, -3.5333e-03,  9.5652e-04, -3.2462e-03,
         8.9002e-04, -9.1158e-04,  9.6663e-04,  1.0645e-03,  1.7434e-03,
         9.5910e-04,  1.2372e-03,  5.3698e-04,  1.5442e-03,  2.4377e-03,
        -1.6205e-04,  1.8074e-03,  2.3880e-05, -2.9228e-03, -1.4539e-03,
         4.4749e-04, -1.2449e-03,  2.7210e-03,  1.0982e-03])
weight : tensor([[-0.1732,  0.0847,  0.1624,  ..., -0.2986,  0.0025, -0.0790],
        [ 0.0459, -0.2647,  0.0886,  ...,  0.1015,  0.0821,  0.3126],
        [-0.0712,  0.2343, -0.1151,  ..., -0.1625, -0.2255,  0.1524],
        ...,
        [ 0.2286,  0.3860,  0.1879,  ..., -0.0479,  0.4150,  0.2049],
        [-0.0502,  0.2779,  0.1182,  ..., -0.2093,  0.1515, -0.2262],
        [ 0.0443, -0.0555,  0.3602,  ...,  0.0099,  0.0267, -0.2457]])
bias : tensor([ 3.3359e-04,  6.4552e-04, -1.1003e-03, -1.3510e-03,  1.0226e-03,
         4.7658e-04,  1.3259e-03, -2.8126e-04,  2.1556e-03, -2.9029e-03,
         1.1524e-03, -1.4918e-03,  1.2209e-03,  1.7705e-03,  1.6379e-03,
         2.4270e-03,  1.4241e-03,  1.5871e-03,  1.6365e-03, -9.3753e-04,
        -2.6760e-03,  7.1260e-04, -1.3148e-03, -9.0511e-04,  1.4745e-03,
         1.6810e-03,  9.3713e-04, -6.0965e-04,  1.4858e-03, -1.4529e-03,
         1.9328e-03, -2.3639e-03,  9.5751e-05,  1.1464e-03,  2.8327e-04,
         8.8656e-04, -1.8923e-04,  3.7769e-04, -3.8241e-03, -1.9072e-04,
         6.0602e-04,  2.3869e-03, -1.1467e-03,  1.0878e-03,  2.0521e-03,
        -3.0770e-04,  2.5451e-03, -1.6416e-03,  2.9696e-03, -2.3843e-03,
         1.6462e-03,  3.2017e-03,  2.9768e-03,  2.9412e-04,  2.1173e-03,
        -2.1099e-03,  1.0442e-03, -8.2162e-04, -3.4005e-04, -1.8746e-04,
         1.7142e-03,  9.3106e-04, -8.6694e-04,  8.3042e-04])
policy_loss: -1.1734664440155029e-07
entropy_loss: -2.865561008453369
value_loss: 292.7900085449219
loss: 146.39500427246094
policy_loss: 1.2120231986045837e-05
entropy_loss: -2.8657736778259277
value_loss: 291.62689208984375
loss: 145.81346130371094
policy_loss: -1.794286072254181e-05
entropy_loss: -2.8659322261810303
value_loss: 286.27838134765625
loss: 143.13917541503906
policy_loss: 1.323595643043518e-05
entropy_loss: -2.866028070449829
value_loss: 292.5403137207031
loss: 146.27017211914062
policy_loss: -4.225596785545349e-05
entropy_loss: -2.866102457046509
value_loss: 295.31951904296875
loss: 147.6597137451172
policy_loss: -6.563682109117508e-05
entropy_loss: -2.866203546524048
value_loss: 282.3022155761719
loss: 141.1510467529297
policy_loss: -0.000373154878616333
entropy_loss: -2.8662989139556885
value_loss: 279.84417724609375
loss: 139.92172241210938
policy_loss: -0.0004327632486820221
entropy_loss: -2.8663103580474854
value_loss: 295.1804504394531
loss: 147.5897979736328
policy_loss: 6.760470569133759e-05
entropy_loss: -2.86623215675354
value_loss: 286.1601867675781
loss: 143.0801544189453
policy_loss: -0.001548759639263153
entropy_loss: -2.8660924434661865
value_loss: 281.8406982421875
loss: 140.91880798339844
policy_loss: 0.00020260177552700043
entropy_loss: -2.8659110069274902
value_loss: 281.1434326171875
loss: 140.57191467285156
policy_loss: -0.0007669609040021896
entropy_loss: -2.865691900253296
value_loss: 286.1569519042969
loss: 143.0777130126953
policy_loss: -0.0006142575293779373
entropy_loss: -2.8655471801757812
value_loss: 279.2395324707031
loss: 139.61915588378906
policy_loss: -0.0001903653610497713
entropy_loss: -2.8654062747955322
value_loss: 277.87646484375
loss: 138.93804931640625
policy_loss: -0.0027222605422139168
entropy_loss: -2.865251064300537
value_loss: 270.91290283203125
loss: 135.4537353515625
policy_loss: -0.00033493712544441223
entropy_loss: -2.865060329437256
value_loss: 286.13568115234375
loss: 143.0675048828125
policy_loss: -0.0017171762883663177
entropy_loss: -2.8648531436920166
value_loss: 269.03118896484375
loss: 134.5138702392578
policy_loss: -0.001088954508304596
entropy_loss: -2.8646433353424072
value_loss: 287.4200134277344
loss: 143.70892333984375
policy_loss: -0.0006221961230039597
entropy_loss: -2.8644144535064697
value_loss: 273.1924743652344
loss: 136.59561157226562
policy_loss: -0.0025682132691144943
entropy_loss: -2.8641889095306396
value_loss: 261.4128723144531
loss: 130.70387268066406
policy_loss: -0.0019415076822042465
entropy_loss: -2.8639485836029053
value_loss: 272.3991394042969
loss: 136.1976318359375
policy_loss: -0.0033899256959557533
entropy_loss: -2.8637261390686035
value_loss: 267.57635498046875
loss: 133.7847900390625
policy_loss: -0.002055500168353319
entropy_loss: -2.863525152206421
value_loss: 262.2642822265625
loss: 131.1300811767578
policy_loss: -0.0004461752250790596
entropy_loss: -2.863292932510376
value_loss: 264.1994934082031
loss: 132.09930419921875
policy_loss: -0.0022293305955827236
entropy_loss: -2.8630242347717285
value_loss: 252.81326293945312
loss: 126.40440368652344
policy_loss: -9.960215538740158e-05
entropy_loss: -2.8627965450286865
value_loss: 267.56524658203125
loss: 133.7825164794922
policy_loss: -0.004614412784576416
entropy_loss: -2.8625295162200928
value_loss: 271.7240295410156
loss: 135.85740661621094
policy_loss: -0.0032122982665896416
entropy_loss: -2.8622782230377197
value_loss: 249.29576110839844
loss: 124.64466857910156
policy_loss: -0.0021708253771066666
entropy_loss: -2.8620123863220215
value_loss: 260.06298828125
loss: 130.02932739257812
policy_loss: -0.003799108788371086
entropy_loss: -2.8617823123931885
value_loss: 244.87374877929688
loss: 122.43307495117188
policy_loss: -0.004439288750290871
entropy_loss: -2.861564874649048
value_loss: 252.2562255859375
loss: 126.12367248535156
policy_loss: -0.0015631942078471184
entropy_loss: -2.8613202571868896
value_loss: 259.4572448730469
loss: 129.72706604003906
policy_loss: -0.0038326657377183437
entropy_loss: -2.8610880374908447
value_loss: 240.73458862304688
loss: 120.36346435546875
policy_loss: -0.005137821659445763
entropy_loss: -2.8608739376068115
value_loss: 254.13026428222656
loss: 127.05999755859375
policy_loss: 0.0021112877875566483
entropy_loss: -2.860642910003662
value_loss: 246.1431427001953
loss: 123.07368469238281
policy_loss: -0.006360319443047047
entropy_loss: -2.860419988632202
value_loss: 250.9508056640625
loss: 125.46903991699219
policy_loss: -0.005805302411317825
entropy_loss: -2.8602335453033447
value_loss: 235.81759643554688
loss: 117.90299224853516
policy_loss: -0.00023911241441965103
entropy_loss: -2.860016107559204
value_loss: 244.4225616455078
loss: 122.21104431152344
policy_loss: -0.0026460238732397556
entropy_loss: -2.859846353530884
value_loss: 244.44192504882812
loss: 122.21831512451172
policy_loss: -0.00541217066347599
entropy_loss: -2.8597066402435303
value_loss: 243.1214599609375
loss: 121.5553207397461
------------------------------------------
| avg_speed               | 0.807        |
| is_success              | 0            |
| max_speed               | 0.807        |
| reward                  | -0.6863019   |
| rollout/                |              |
|    ep_len_mean          | 949          |
|    ep_rew_mean          | -1.26e+03    |
| time/                   |              |
|    fps                  | 123          |
|    iterations           | 2            |
|    time_elapsed         | 33           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0031567642 |
|    clip_fraction        | 0.00464      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | -0.0112      |
|    learning_rate        | 0.0003       |
|    loss                 | 122          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00175     |
|    std                  | 1.01         |
|    value_loss           | 269          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.1806, -0.3642, -0.0674,  ..., -0.0156, -0.2207, -0.3077],
        [ 0.0247,  0.1493, -0.0053,  ..., -0.0759, -0.0062, -0.0502],
        [-0.0710,  0.0531,  0.0302,  ..., -0.1721, -0.1292,  0.2232],
        ...,
        [ 0.2478, -0.0848,  0.2202,  ...,  0.1979, -0.2103,  0.3187],
        [-0.0456, -0.2564, -0.0549,  ..., -0.1342, -0.2740,  0.3107],
        [-0.0015,  0.1030, -0.1731,  ..., -0.0744,  0.0879,  0.0950]])
bias : tensor([ 2.0635e-03,  9.4751e-04,  6.7254e-04, -1.2329e-03, -4.6683e-04,
         3.4107e-03,  2.0501e-03, -5.3479e-03,  8.5204e-04,  1.0023e-03,
         1.9905e-03, -6.3989e-04, -3.5119e-03,  6.8825e-04, -9.3789e-04,
         3.5079e-03,  1.7537e-04, -2.6193e-03, -1.2537e-03, -1.7999e-03,
        -1.3759e-03,  1.5811e-04, -1.2966e-03, -5.2415e-03,  1.3510e-03,
         4.1799e-04,  1.2619e-03,  2.7684e-03,  2.8522e-03,  4.5269e-05,
        -1.9674e-03, -4.1706e-04, -1.1264e-03,  1.3955e-03, -1.1033e-03,
        -7.1744e-04,  2.5312e-03, -9.3774e-04,  5.9147e-03, -3.6126e-04,
         4.7173e-03, -3.2107e-03,  2.2106e-03,  3.1955e-04,  1.2419e-03,
         5.8250e-05,  2.8351e-03,  1.6792e-03, -1.1085e-03, -3.3792e-04,
        -2.0307e-03, -1.4851e-03, -2.0666e-04, -5.2427e-04,  4.3815e-04,
         4.3286e-03,  4.2354e-04, -3.1421e-04, -1.1655e-03, -1.4450e-03,
        -6.6094e-04, -1.0638e-03,  2.1626e-03, -4.3775e-03])
weight : tensor([[-0.2184,  0.3498, -0.3304,  ..., -0.1691,  0.3010,  0.1748],
        [-0.1651, -0.1415, -0.0241,  ...,  0.0532, -0.3292,  0.0934],
        [-0.1285, -0.4219, -0.1403,  ...,  0.1894,  0.1354,  0.0130],
        ...,
        [ 0.2279,  0.1367, -0.2849,  ..., -0.0862,  0.0170, -0.0877],
        [-0.2392, -0.1299,  0.1503,  ...,  0.0462,  0.3092,  0.0841],
        [ 0.2030, -0.1981, -0.0117,  ..., -0.0741,  0.0372, -0.1220]])
bias : tensor([-2.4961e-03,  2.0499e-04,  6.7414e-04,  5.8909e-04,  7.7464e-04,
        -4.1379e-03,  8.1199e-04,  7.1158e-05,  2.2768e-03,  6.9989e-04,
        -1.4180e-03,  1.0552e-03, -2.2414e-03, -2.0882e-04,  1.3082e-03,
        -8.3381e-04, -1.6107e-03,  3.3054e-03, -1.4599e-03, -4.9885e-04,
        -2.1017e-03, -5.6656e-04,  6.7123e-04,  6.0658e-04, -1.1634e-03,
        -8.6213e-04,  1.6948e-04,  2.6573e-03,  6.5289e-04, -5.8230e-04,
         1.6680e-03,  4.1005e-03, -6.6523e-04, -6.4467e-04, -4.4579e-04,
         5.2030e-04, -1.8504e-03, -3.6601e-04,  3.6710e-04, -2.7933e-03,
        -4.2772e-04,  2.3386e-03,  1.1002e-03,  6.2105e-04,  1.2705e-03,
        -3.5797e-04, -1.4486e-03,  4.2992e-03, -2.8196e-04, -1.3413e-03,
         6.7500e-05, -3.2880e-03, -2.9587e-04, -5.3532e-04,  1.1667e-03,
        -1.6048e-04,  4.2530e-03,  1.5864e-03,  3.1701e-04,  9.0612e-04,
         3.0748e-03,  1.1694e-03, -2.0620e-03,  9.4627e-04])
policy_loss: -7.82310962677002e-08
entropy_loss: -2.8716776371002197
value_loss: 344.85162353515625
loss: 172.42581176757812
policy_loss: 3.437395207583904e-05
entropy_loss: -2.871793270111084
value_loss: 331.6374816894531
loss: 165.8187713623047
policy_loss: 3.078114241361618e-05
entropy_loss: -2.871833562850952
value_loss: 337.71990966796875
loss: 168.8599853515625
policy_loss: -0.0004628170281648636
entropy_loss: -2.871908664703369
value_loss: 352.5594482421875
loss: 176.27926635742188
policy_loss: -0.00011180900037288666
entropy_loss: -2.871999979019165
value_loss: 332.192626953125
loss: 166.09620666503906
policy_loss: -0.0007065534591674805
entropy_loss: -2.872112512588501
value_loss: 343.8643493652344
loss: 171.9314727783203
policy_loss: -0.0006302343681454659
entropy_loss: -2.872220516204834
value_loss: 342.56951904296875
loss: 171.2841339111328
policy_loss: 0.00022655632346868515
entropy_loss: -2.8722951412200928
value_loss: 323.3827819824219
loss: 161.69161987304688
policy_loss: -0.0009765811264514923
entropy_loss: -2.8723337650299072
value_loss: 322.62158203125
loss: 161.309814453125
policy_loss: -0.00033898837864398956
entropy_loss: -2.8723273277282715
value_loss: 334.2811279296875
loss: 167.14022827148438
policy_loss: -0.0006555570289492607
entropy_loss: -2.8722825050354004
value_loss: 329.45648193359375
loss: 164.7275848388672
policy_loss: -0.0013786163181066513
entropy_loss: -2.8722879886627197
value_loss: 329.6058044433594
loss: 164.80152893066406
policy_loss: -0.0017853714525699615
entropy_loss: -2.872312068939209
value_loss: 329.03948974609375
loss: 164.51795959472656
policy_loss: -0.0021905815228819847
entropy_loss: -2.8723373413085938
value_loss: 311.7190856933594
loss: 155.8573455810547
policy_loss: -0.00095400121062994
entropy_loss: -2.8723909854888916
value_loss: 333.35528564453125
loss: 166.6766815185547
policy_loss: -0.0002915165387094021
entropy_loss: -2.8724405765533447
value_loss: 315.31439208984375
loss: 157.6569061279297
policy_loss: -0.003652503713965416
entropy_loss: -2.8724312782287598
value_loss: 308.8465881347656
loss: 154.41964721679688
policy_loss: -0.0014490520115941763
entropy_loss: -2.8724172115325928
value_loss: 317.2357482910156
loss: 158.61642456054688
policy_loss: -0.0015170462429523468
entropy_loss: -2.87239670753479
value_loss: 317.6275329589844
loss: 158.812255859375
policy_loss: -0.0014161309227347374
entropy_loss: -2.872394561767578
value_loss: 318.635986328125
loss: 159.3165740966797
policy_loss: -0.0024493271484971046
entropy_loss: -2.8723771572113037
value_loss: 326.5527648925781
loss: 163.27392578125
policy_loss: -0.0034145936369895935
entropy_loss: -2.8723435401916504
value_loss: 300.1161193847656
loss: 150.0546417236328
policy_loss: -0.0023655961267650127
entropy_loss: -2.8723373413085938
value_loss: 307.1290283203125
loss: 153.56214904785156
policy_loss: -0.001952754333615303
entropy_loss: -2.8723299503326416
value_loss: 302.2475891113281
loss: 151.12184143066406
policy_loss: -0.002790587954223156
entropy_loss: -2.8723104000091553
value_loss: 303.1104736328125
loss: 151.5524444580078
policy_loss: -0.002024168148636818
entropy_loss: -2.8722853660583496
value_loss: 296.6950988769531
loss: 148.34552001953125
policy_loss: -0.004986034706234932
entropy_loss: -2.8722357749938965
value_loss: 307.24420166015625
loss: 153.6171112060547
policy_loss: -0.0023383721709251404
entropy_loss: -2.8722379207611084
value_loss: 302.82110595703125
loss: 151.40821838378906
policy_loss: -0.002292156219482422
entropy_loss: -2.8722167015075684
value_loss: 293.3834533691406
loss: 146.68943786621094
policy_loss: -0.0033472515642642975
entropy_loss: -2.872199773788452
value_loss: 299.87664794921875
loss: 149.9349822998047
policy_loss: -0.005297025665640831
entropy_loss: -2.8721871376037598
value_loss: 297.172607421875
loss: 148.5810089111328
policy_loss: -0.0036938204430043697
entropy_loss: -2.8721885681152344
value_loss: 293.9339599609375
loss: 146.96328735351562
policy_loss: -0.0028618029318749905
entropy_loss: -2.872152805328369
value_loss: 289.10906982421875
loss: 144.55166625976562
policy_loss: -0.0026128538884222507
entropy_loss: -2.8720855712890625
value_loss: 287.52734375
loss: 143.7610626220703
policy_loss: -0.004602974280714989
entropy_loss: -2.872025966644287
value_loss: 294.13482666015625
loss: 147.06280517578125
policy_loss: -0.006836053915321827
entropy_loss: -2.8719823360443115
value_loss: 288.3568115234375
loss: 144.17156982421875
policy_loss: -0.0055817291140556335
entropy_loss: -2.8719496726989746
value_loss: 282.6891174316406
loss: 141.33897399902344
policy_loss: -0.0032892776653170586
entropy_loss: -2.8719370365142822
value_loss: 281.14935302734375
loss: 140.57138061523438
policy_loss: -0.0026590642519295216
entropy_loss: -2.8719236850738525
value_loss: 281.8359069824219
loss: 140.91529846191406
policy_loss: -0.006921065971255302
entropy_loss: -2.8718934059143066
value_loss: 289.09613037109375
loss: 144.5411376953125
------------------------------------------
| avg_speed               | 1.74         |
| is_success              | 0            |
| max_speed               | 1.74         |
| reward                  | -0.9550836   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.27e+03    |
| time/                   |              |
|    fps                  | 122          |
|    iterations           | 2            |
|    time_elapsed         | 33           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0024403045 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.87        |
|    explained_variance   | 0.206        |
|    learning_rate        | 0.0003       |
|    loss                 | 145          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00226     |
|    std                  | 1.02         |
|    value_loss           | 313          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.2375, -0.2986,  0.1537,  ...,  0.0419,  0.3535, -0.0165],
        [-0.1632,  0.1187, -0.0417,  ..., -0.1567, -0.1276,  0.2517],
        [-0.0637, -0.2309,  0.3693,  ...,  0.1802,  0.0232,  0.0538],
        ...,
        [-0.1313, -0.0514,  0.0681,  ...,  0.0494,  0.3763,  0.0607],
        [-0.2558, -0.3556,  0.2085,  ...,  0.0699, -0.1444,  0.0524],
        [-0.1711, -0.1482,  0.1270,  ...,  0.2108, -0.3293,  0.0167]])
bias : tensor([-4.9424e-04,  5.7295e-04, -1.2085e-03,  7.9261e-04,  1.1677e-03,
         3.8805e-03,  2.4344e-03, -9.2654e-04, -1.5495e-03, -2.0992e-04,
        -1.1653e-03, -5.1159e-04, -3.9240e-03, -9.9700e-04, -8.7744e-04,
         2.0400e-03,  4.2753e-03, -2.4838e-03,  2.7979e-03,  1.8530e-03,
        -1.1228e-03,  3.9130e-03,  4.5115e-04,  2.9155e-04,  3.0687e-04,
        -5.1436e-04, -1.6936e-03,  9.7434e-04, -4.1157e-03, -3.7914e-03,
        -2.7127e-03,  1.3896e-03, -1.8583e-03, -1.1846e-03, -1.7151e-03,
         5.6280e-05,  2.0151e-04, -9.1677e-05,  3.3054e-03, -5.6941e-04,
        -2.5037e-03, -1.7989e-03,  5.9549e-04,  3.1146e-03,  1.7883e-04,
        -2.7622e-04, -2.3766e-04,  9.0924e-04, -2.4837e-03,  4.5502e-03,
         6.8697e-04,  2.0171e-03, -2.2349e-04,  2.6168e-03, -1.9286e-03,
        -2.9584e-03, -1.2460e-05,  1.3119e-04,  1.9959e-03, -1.6351e-03,
         1.3668e-03,  3.7040e-03, -1.4315e-03, -2.3913e-03])
weight : tensor([[-0.3365, -0.1553, -0.0166,  ..., -0.2077,  0.1394,  0.0018],
        [ 0.2538,  0.0908, -0.1823,  ...,  0.1355, -0.2465,  0.2416],
        [ 0.0883, -0.1897, -0.1888,  ...,  0.0383, -0.0199,  0.2587],
        ...,
        [ 0.0680, -0.0692, -0.2752,  ...,  0.1755, -0.0238, -0.3442],
        [ 0.2632,  0.0598, -0.0172,  ..., -0.0852, -0.2087, -0.1105],
        [-0.2266,  0.0091,  0.0466,  ...,  0.0751,  0.0289, -0.0112]])
bias : tensor([-3.6011e-03, -1.6656e-04,  2.9791e-03, -2.3118e-03,  3.0221e-03,
        -3.7674e-04,  2.0142e-03,  1.2135e-03,  5.9096e-04,  2.0183e-03,
        -2.0786e-04,  1.0981e-03,  7.7800e-04, -4.9257e-04,  1.5709e-03,
         2.2725e-03,  2.1580e-03,  1.1351e-03, -3.0089e-04, -1.6349e-03,
         1.3846e-03,  9.1000e-04, -7.3321e-04,  2.0437e-03, -3.9025e-04,
         2.4320e-03, -1.0406e-03,  1.0095e-03,  1.2645e-03, -1.9682e-03,
         6.8541e-04, -3.7427e-04,  9.1275e-04,  4.1904e-04, -3.5724e-03,
         7.8940e-04, -3.0722e-04,  2.1261e-03,  1.0261e-03,  2.0471e-03,
         5.7385e-04, -8.9148e-04, -9.8203e-04,  1.3903e-04,  4.3319e-04,
         5.0915e-04,  5.8048e-04,  1.8765e-03, -5.5836e-04,  1.7905e-03,
        -2.2963e-03,  1.3288e-03, -1.5932e-03,  1.8769e-04, -1.3085e-03,
         5.4438e-05,  1.5979e-03,  4.7701e-04, -4.0068e-03,  3.0118e-03,
         3.3253e-03, -1.4648e-04,  2.9848e-03, -9.7694e-04])
policy_loss: -3.166496753692627e-08
entropy_loss: -2.863456964492798
value_loss: 673.5338745117188
loss: 336.7669372558594
policy_loss: 4.26657497882843e-05
entropy_loss: -2.863452672958374
value_loss: 660.0762939453125
loss: 330.0381774902344
policy_loss: 0.0001529497094452381
entropy_loss: -2.8634450435638428
value_loss: 648.41064453125
loss: 324.2054748535156
policy_loss: -5.2723102271556854e-05
entropy_loss: -2.8634376525878906
value_loss: 634.990234375
loss: 317.49505615234375
policy_loss: -7.48438760638237e-05
entropy_loss: -2.863410711288452
value_loss: 625.5449829101562
loss: 312.7724304199219
policy_loss: 2.893153578042984e-05
entropy_loss: -2.8633878231048584
value_loss: 630.9341430664062
loss: 315.46710205078125
policy_loss: 2.3114262148737907e-05
entropy_loss: -2.863344669342041
value_loss: 684.8399658203125
loss: 342.4200134277344
policy_loss: -1.0376796126365662e-05
entropy_loss: -2.863290548324585
value_loss: 664.9151611328125
loss: 332.45758056640625
policy_loss: 0.00012766942381858826
entropy_loss: -2.8632469177246094
value_loss: 655.6429443359375
loss: 327.82159423828125
policy_loss: -0.0003606639802455902
entropy_loss: -2.863189458847046
value_loss: 691.9434814453125
loss: 345.97137451171875
policy_loss: -0.0003026966005563736
entropy_loss: -2.8631386756896973
value_loss: 627.8012084960938
loss: 313.9002990722656
policy_loss: -0.0001506200060248375
entropy_loss: -2.8630640506744385
value_loss: 605.5111694335938
loss: 302.75543212890625
policy_loss: 0.0005875639617443085
entropy_loss: -2.8630106449127197
value_loss: 649.2536010742188
loss: 324.62738037109375
policy_loss: -0.0006937552243471146
entropy_loss: -2.8629660606384277
value_loss: 664.7962036132812
loss: 332.39739990234375
policy_loss: -0.0006600674241781235
entropy_loss: -2.862914800643921
value_loss: 648.9157104492188
loss: 324.4571838378906
policy_loss: -0.0007135383784770966
entropy_loss: -2.8628618717193604
value_loss: 583.716064453125
loss: 291.8573303222656
policy_loss: -0.00076346006244421
entropy_loss: -2.8627965450286865
value_loss: 662.8934936523438
loss: 331.44598388671875
policy_loss: -0.0004578419029712677
entropy_loss: -2.862729549407959
value_loss: 583.2708740234375
loss: 291.6349792480469
policy_loss: -0.0007406957447528839
entropy_loss: -2.8626558780670166
value_loss: 669.1980590820312
loss: 334.5982971191406
policy_loss: -0.0003940947353839874
entropy_loss: -2.8625779151916504
value_loss: 591.9275512695312
loss: 295.96337890625
policy_loss: -0.0011608172208070755
entropy_loss: -2.862509250640869
value_loss: 588.5846557617188
loss: 294.2911682128906
policy_loss: -0.0003586485981941223
entropy_loss: -2.8624346256256104
value_loss: 602.3585815429688
loss: 301.1789245605469
policy_loss: -0.000856669619679451
entropy_loss: -2.8623621463775635
value_loss: 634.4649658203125
loss: 317.23162841796875
policy_loss: -0.0012728367000818253
entropy_loss: -2.862285852432251
value_loss: 638.9414672851562
loss: 319.4694519042969
policy_loss: -0.0027272403240203857
entropy_loss: -2.862210750579834
value_loss: 603.100341796875
loss: 301.5474548339844
policy_loss: -0.0013520307838916779
entropy_loss: -2.862138509750366
value_loss: 617.1473999023438
loss: 308.5723571777344
policy_loss: -0.0014640837907791138
entropy_loss: -2.862060546875
value_loss: 584.6756591796875
loss: 292.33636474609375
policy_loss: 0.000902276486158371
entropy_loss: -2.8619768619537354
value_loss: 616.916015625
loss: 308.45892333984375
policy_loss: -0.00349805923178792
entropy_loss: -2.8618967533111572
value_loss: 575.2415771484375
loss: 287.6172790527344
policy_loss: -3.955606371164322e-05
entropy_loss: -2.8618357181549072
value_loss: 594.6959838867188
loss: 297.34796142578125
policy_loss: 0.0003190853167325258
entropy_loss: -2.8617818355560303
value_loss: 623.8868408203125
loss: 311.9437255859375
policy_loss: -0.003240220481529832
entropy_loss: -2.86171555519104
value_loss: 584.694091796875
loss: 292.34381103515625
policy_loss: -0.0006557181477546692
entropy_loss: -2.8616280555725098
value_loss: 596.96240234375
loss: 298.4805603027344
policy_loss: -0.001323566772043705
entropy_loss: -2.8615670204162598
value_loss: 580.8538208007812
loss: 290.42559814453125
policy_loss: -0.0005086427554488182
entropy_loss: -2.861503839492798
value_loss: 583.6294555664062
loss: 291.814208984375
policy_loss: -0.005441352725028992
entropy_loss: -2.861447811126709
value_loss: 574.2183227539062
loss: 287.1037292480469
policy_loss: 0.0006530769169330597
entropy_loss: -2.861358404159546
value_loss: 566.384521484375
loss: 283.1929016113281
policy_loss: -0.004916387610137463
entropy_loss: -2.8612711429595947
value_loss: 596.3060302734375
loss: 298.1481018066406
policy_loss: -0.003860021010041237
entropy_loss: -2.8611998558044434
value_loss: 561.1396484375
loss: 280.56597900390625
policy_loss: -0.000806199386715889
entropy_loss: -2.861114740371704
value_loss: 569.3504028320312
loss: 284.6744079589844
------------------------------------------
| avg_speed               | 5.6          |
| is_success              | 0            |
| max_speed               | 5.6          |
| reward                  | -1.2794266   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.08e+03    |
| time/                   |              |
|    fps                  | 116          |
|    iterations           | 2            |
|    time_elapsed         | 35           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0008520081 |
|    clip_fraction        | 9.77e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | -0.315       |
|    learning_rate        | 0.0003       |
|    loss                 | 285          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.000901    |
|    std                  | 1.01         |
|    value_loss           | 619          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.0786,  0.4098,  0.2380,  ..., -0.0419,  0.0326,  0.2987],
        [ 0.1253,  0.3332,  0.1127,  ..., -0.0981, -0.3113, -0.1923],
        [ 0.1158,  0.1800,  0.0256,  ...,  0.4151, -0.1214,  0.4019],
        ...,
        [ 0.0305,  0.1491, -0.2605,  ..., -0.3823, -0.0772, -0.1393],
        [-0.2694,  0.0059,  0.0748,  ..., -0.0106,  0.0174, -0.1108],
        [ 0.1507,  0.1601,  0.3122,  ..., -0.1152,  0.1890,  0.2664]])
bias : tensor([-5.1867e-04,  2.0735e-03, -3.0342e-04,  1.4984e-04, -8.7919e-04,
        -1.1569e-03, -2.4218e-03, -1.3447e-03, -7.2907e-04, -7.3326e-04,
        -1.9760e-03,  3.2914e-03, -2.2321e-03,  4.9889e-03,  4.3965e-04,
        -1.7612e-03, -1.8726e-03,  3.4135e-03, -4.0494e-03, -5.3230e-04,
         2.1337e-03, -5.0052e-03, -1.2113e-03,  3.8336e-03,  2.6900e-03,
        -4.5867e-03,  6.6634e-04, -1.8423e-03,  6.9171e-04,  4.9814e-03,
        -5.2615e-03, -1.5136e-03,  3.0004e-03,  2.8336e-03,  2.5986e-03,
        -1.8931e-03, -1.6685e-03,  1.8625e-03, -1.3485e-03,  4.9314e-03,
        -3.6959e-03,  5.7937e-03, -3.8814e-03,  2.5222e-03, -4.7905e-03,
         2.0545e-03, -2.1502e-03,  2.6888e-03, -3.7934e-05,  3.9532e-03,
        -2.6615e-05,  1.4551e-03, -1.5529e-04,  3.1386e-03,  4.2264e-03,
        -7.2264e-04,  2.3994e-03,  1.8842e-05, -3.8661e-03, -3.1589e-03,
         1.6078e-03, -1.8024e-03,  2.5386e-04,  3.3806e-03])
weight : tensor([[-0.1731,  0.0848,  0.1625,  ..., -0.2987,  0.0026, -0.0788],
        [ 0.0458, -0.2648,  0.0885,  ...,  0.1016,  0.0824,  0.3123],
        [-0.0703,  0.2347, -0.1148,  ..., -0.1625, -0.2261,  0.1533],
        ...,
        [ 0.2287,  0.3862,  0.1880,  ..., -0.0479,  0.4153,  0.2051],
        [-0.0489,  0.2787,  0.1188,  ..., -0.2094,  0.1508, -0.2245],
        [ 0.0449, -0.0554,  0.3603,  ...,  0.0100,  0.0255, -0.2451]])
bias : tensor([ 3.0062e-04, -2.8433e-04,  4.3725e-04, -1.8352e-03,  7.7639e-04,
         1.8939e-03,  4.1993e-03,  6.6323e-04,  3.3966e-03, -3.7459e-03,
        -1.9089e-04, -1.8470e-03,  2.1532e-03,  4.8065e-05,  2.4125e-03,
         1.5213e-03,  2.5778e-03,  4.1602e-03,  3.2890e-03,  8.8689e-04,
        -3.5471e-03,  1.8375e-03, -2.0879e-03, -1.7256e-03,  2.8197e-03,
         3.9915e-03, -5.4998e-05, -2.9217e-03,  7.2853e-04, -3.3275e-03,
         2.7852e-03, -2.0800e-03,  1.1947e-03,  4.5764e-05,  2.5805e-03,
         2.3457e-03, -2.2796e-04,  2.7250e-03, -3.9291e-03, -7.1187e-04,
         2.2193e-03,  4.4529e-03,  3.5901e-04,  1.9809e-03,  2.0651e-03,
        -2.5557e-03,  5.6453e-03, -4.1324e-03,  4.0248e-03, -4.8601e-03,
         3.1919e-03,  2.2269e-03,  3.8492e-03,  8.7608e-04,  3.3896e-03,
        -2.3940e-03,  8.3475e-04, -2.3605e-03, -3.9909e-04,  1.4914e-03,
         3.1308e-03,  8.1397e-04,  1.0673e-03,  2.8656e-03])
policy_loss: -1.816079020500183e-07
entropy_loss: -2.8595659732818604
value_loss: 508.3091735839844
loss: 254.1545867919922
policy_loss: -5.093403160572052e-06
entropy_loss: -2.859388589859009
value_loss: 524.769775390625
loss: 262.3848876953125
policy_loss: -0.00017256848514080048
entropy_loss: -2.8592681884765625
value_loss: 514.7786254882812
loss: 257.3891296386719
policy_loss: -0.00010265689343214035
entropy_loss: -2.859100341796875
value_loss: 504.2268981933594
loss: 252.11334228515625
policy_loss: 0.0001727510243654251
entropy_loss: -2.8589425086975098
value_loss: 492.5919494628906
loss: 246.296142578125
policy_loss: -0.001386847347021103
entropy_loss: -2.8588294982910156
value_loss: 528.552734375
loss: 264.2749938964844
policy_loss: -0.000829670112580061
entropy_loss: -2.8586885929107666
value_loss: 504.70556640625
loss: 252.35195922851562
policy_loss: -0.001215582713484764
entropy_loss: -2.858551263809204
value_loss: 492.2404479980469
loss: 246.11900329589844
policy_loss: -0.0012284666299819946
entropy_loss: -2.8583731651306152
value_loss: 497.2882080078125
loss: 248.6428680419922
policy_loss: -0.0033823102712631226
entropy_loss: -2.8582215309143066
value_loss: 458.7137145996094
loss: 229.3534698486328
policy_loss: -0.0015544388443231583
entropy_loss: -2.858093500137329
value_loss: 511.5213317871094
loss: 255.7591094970703
policy_loss: -0.0015327073633670807
entropy_loss: -2.8579466342926025
value_loss: 511.6015625
loss: 255.79925537109375
policy_loss: -0.004769410938024521
entropy_loss: -2.8577561378479004
value_loss: 487.4715270996094
loss: 243.73098754882812
policy_loss: -0.0019053532741963863
entropy_loss: -2.8576033115386963
value_loss: 504.1840515136719
loss: 252.09011840820312
policy_loss: -0.00238869059830904
entropy_loss: -2.8574204444885254
value_loss: 451.0887145996094
loss: 225.54196166992188
policy_loss: -0.004043440334498882
entropy_loss: -2.8572347164154053
value_loss: 495.7310485839844
loss: 247.86148071289062
policy_loss: -0.00680722389370203
entropy_loss: -2.857038736343384
value_loss: 481.6231689453125
loss: 240.80477905273438
policy_loss: -0.0030021071434020996
entropy_loss: -2.8568227291107178
value_loss: 474.2926025390625
loss: 237.14329528808594
policy_loss: -0.002758963033556938
entropy_loss: -2.8566224575042725
value_loss: 491.2780456542969
loss: 245.63626098632812
policy_loss: -0.006848221644759178
entropy_loss: -2.856414556503296
value_loss: 450.4415283203125
loss: 225.2139129638672
policy_loss: -0.0033746184781193733
entropy_loss: -2.856231927871704
value_loss: 493.7232360839844
loss: 246.85824584960938
policy_loss: -0.005852125585079193
entropy_loss: -2.8560636043548584
value_loss: 458.10675048828125
loss: 229.04751586914062
policy_loss: -0.009591675363481045
entropy_loss: -2.855914831161499
value_loss: 467.8740539550781
loss: 233.92742919921875
policy_loss: -0.005910040345042944
entropy_loss: -2.8557372093200684
value_loss: 438.4090576171875
loss: 219.19862365722656
policy_loss: -0.005580605007708073
entropy_loss: -2.8555586338043213
value_loss: 446.98626708984375
loss: 223.487548828125
policy_loss: -0.008891713805496693
entropy_loss: -2.855374813079834
value_loss: 437.90545654296875
loss: 218.94383239746094
policy_loss: -0.003300807438790798
entropy_loss: -2.8552231788635254
value_loss: 476.7638244628906
loss: 238.3786163330078
policy_loss: -0.010549245402216911
entropy_loss: -2.855091094970703
value_loss: 457.16412353515625
loss: 228.57151794433594
policy_loss: -0.008075907826423645
entropy_loss: -2.8549439907073975
value_loss: 441.2039794921875
loss: 220.5939178466797
policy_loss: -0.00877237319946289
entropy_loss: -2.8548624515533447
value_loss: 467.818115234375
loss: 233.90028381347656
policy_loss: -0.007662072777748108
entropy_loss: -2.8547556400299072
value_loss: 421.14202880859375
loss: 210.5633544921875
policy_loss: -0.006418406963348389
entropy_loss: -2.854625940322876
value_loss: 451.4378967285156
loss: 225.7125244140625
policy_loss: -0.011749984696507454
entropy_loss: -2.854492425918579
value_loss: 437.6670837402344
loss: 218.82179260253906
policy_loss: -0.007583548314869404
entropy_loss: -2.8543546199798584
value_loss: 424.3182067871094
loss: 212.15151977539062
policy_loss: -0.005875612609088421
entropy_loss: -2.854238986968994
value_loss: 452.85052490234375
loss: 226.4193878173828
policy_loss: -0.007378981448709965
entropy_loss: -2.854112148284912
value_loss: 430.7083435058594
loss: 215.34678649902344
policy_loss: -0.012371338903903961
entropy_loss: -2.8540215492248535
value_loss: 447.87152099609375
loss: 223.9233856201172
policy_loss: -0.018418092280626297
entropy_loss: -2.8539376258850098
value_loss: 430.2391052246094
loss: 215.10113525390625
policy_loss: -0.004908673465251923
entropy_loss: -2.853868007659912
value_loss: 414.08258056640625
loss: 207.036376953125
policy_loss: 0.0027401461265981197
entropy_loss: -2.8538286685943604
value_loss: 418.6441955566406
loss: 209.32484436035156
-----------------------------------------
| avg_speed               | 0.175       |
| is_success              | 0           |
| max_speed               | 0.175       |
| reward                  | -0.53654426 |
| rollout/                |             |
|    ep_len_mean          | 955         |
|    ep_rew_mean          | -1.25e+03   |
| time/                   |             |
|    fps                  | 122         |
|    iterations           | 3           |
|    time_elapsed         | 50          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.00625555  |
|    clip_fraction        | 0.0232      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | -0.0795     |
|    learning_rate        | 0.0003      |
|    loss                 | 209         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00483    |
|    std                  | 1.01        |
|    value_loss           | 470         |
-----------------------------------------
TRAINING:
weight : tensor([[ 0.1775, -0.3628, -0.0658,  ..., -0.0151, -0.2210, -0.3075],
        [ 0.0259,  0.1486, -0.0062,  ..., -0.0771, -0.0062, -0.0502],
        [-0.0720,  0.0533,  0.0305,  ..., -0.1729, -0.1292,  0.2231],
        ...,
        [ 0.2495, -0.0870,  0.2196,  ...,  0.1985, -0.2102,  0.3191],
        [-0.0439, -0.2579, -0.0558,  ..., -0.1338, -0.2743,  0.3109],
        [-0.0016,  0.1004, -0.1737,  ..., -0.0749,  0.0881,  0.0954]])
bias : tensor([ 4.7776e-03, -5.4489e-04,  1.2126e-03, -2.2362e-03, -3.2181e-03,
         6.1527e-03,  3.1495e-03, -6.6861e-03,  1.7672e-04, -1.3503e-03,
         2.8062e-03,  3.2786e-05, -3.5884e-03,  2.9057e-03, -1.2082e-03,
         3.6888e-03, -4.0557e-03, -7.0034e-03, -2.1930e-04,  2.6542e-04,
        -2.1159e-03,  5.1371e-04, -2.4881e-03, -4.7834e-03,  5.0498e-03,
        -1.0975e-03, -6.4136e-04,  1.0190e-03,  4.1217e-03, -4.3937e-04,
        -3.4996e-03,  8.6949e-04,  2.3761e-03,  6.3068e-03, -1.5591e-04,
        -1.5780e-03,  6.0729e-03, -1.6769e-03,  6.9253e-03,  1.7633e-03,
         1.8042e-03, -5.1275e-03,  5.7800e-03,  2.0342e-03, -9.6305e-04,
        -2.2724e-03,  2.5335e-03,  1.8185e-03, -3.9215e-03,  1.6717e-03,
        -3.9430e-03, -2.1058e-03, -8.8156e-04,  1.3796e-03,  1.7443e-03,
         4.1556e-03, -2.2185e-03, -2.5556e-03,  1.4927e-03, -3.9538e-03,
         8.6183e-04, -2.5752e-03,  1.2977e-03, -5.8232e-03])
weight : tensor([[-0.2173,  0.3489, -0.3313,  ..., -0.1694,  0.3019,  0.1760],
        [-0.1664, -0.1404, -0.0229,  ...,  0.0524, -0.3296,  0.0926],
        [-0.1294, -0.4213, -0.1398,  ...,  0.1891,  0.1351,  0.0122],
        ...,
        [ 0.2259,  0.1384, -0.2842,  ..., -0.0858,  0.0158, -0.0900],
        [-0.2399, -0.1293,  0.1510,  ...,  0.0461,  0.3090,  0.0831],
        [ 0.2026, -0.1979, -0.0116,  ..., -0.0732,  0.0365, -0.1227]])
bias : tensor([-5.3403e-03,  2.6392e-03,  2.2890e-03, -9.2170e-04, -1.4732e-03,
        -4.9889e-03,  2.6850e-04,  3.2300e-03,  3.0961e-03,  2.2879e-03,
        -4.7325e-03, -1.3299e-03, -4.2464e-03, -3.0357e-03,  2.2105e-03,
        -6.9975e-04, -1.7937e-03,  1.4027e-03, -9.5573e-04, -3.6579e-04,
        -4.6749e-03,  1.5009e-03, -2.1438e-03,  2.8905e-03, -3.8987e-03,
         4.4405e-04, -3.3913e-03,  4.3898e-03, -1.9045e-03, -1.9129e-03,
         1.6716e-03,  6.3908e-03,  1.9481e-03, -7.8411e-04, -2.4589e-03,
        -1.9584e-03, -6.1322e-04,  5.3118e-04, -2.0006e-03, -3.0768e-03,
         3.5106e-03,  3.4658e-03,  4.3590e-03,  8.3614e-04, -1.1781e-03,
         3.6155e-03, -2.7688e-03,  6.1579e-03, -3.3031e-05, -2.4534e-03,
        -1.5862e-04, -5.6698e-03, -9.7371e-04, -3.0549e-03,  5.2471e-04,
         3.5520e-04,  4.5469e-03,  3.0001e-03, -9.1004e-04, -1.3466e-03,
         6.5855e-03,  4.4004e-03, -6.7218e-04,  2.8531e-03])
policy_loss: -1.5459954738616943e-07
entropy_loss: -2.871849298477173
value_loss: 470.9486083984375
loss: 235.47430419921875
policy_loss: -4.3122097849845886e-05
entropy_loss: -2.8717916011810303
value_loss: 455.7022399902344
loss: 227.85107421875
policy_loss: 0.00018676184117794037
entropy_loss: -2.871704339981079
value_loss: 475.7232971191406
loss: 237.86183166503906
policy_loss: -0.000330580398440361
entropy_loss: -2.8716166019439697
value_loss: 468.21881103515625
loss: 234.10906982421875
policy_loss: -0.0001016426831483841
entropy_loss: -2.8715364933013916
value_loss: 442.8282775878906
loss: 221.41403198242188
policy_loss: -0.0004426259547472
entropy_loss: -2.871443271636963
value_loss: 485.0270080566406
loss: 242.5130615234375
policy_loss: -8.510425686836243e-05
entropy_loss: -2.871354818344116
value_loss: 445.4364013671875
loss: 222.71810913085938
policy_loss: -0.0001251567155122757
entropy_loss: -2.8712613582611084
value_loss: 454.4445495605469
loss: 227.22215270996094
policy_loss: -0.0006574103608727455
entropy_loss: -2.8711512088775635
value_loss: 450.57318115234375
loss: 225.2859344482422
policy_loss: -0.0003460897132754326
entropy_loss: -2.8710596561431885
value_loss: 454.5367431640625
loss: 227.2680206298828
policy_loss: -0.0004232432693243027
entropy_loss: -2.8709490299224854
value_loss: 414.9852294921875
loss: 207.4921875
policy_loss: -0.0008157957345247269
entropy_loss: -2.87082839012146
value_loss: 459.7568054199219
loss: 229.87759399414062
policy_loss: -0.00045833364129066467
entropy_loss: -2.870697259902954
value_loss: 445.3939208984375
loss: 222.69650268554688
policy_loss: -0.0009187322575598955
entropy_loss: -2.8705544471740723
value_loss: 437.6064758300781
loss: 218.8023223876953
policy_loss: -0.0016319472342729568
entropy_loss: -2.8704111576080322
value_loss: 430.75482177734375
loss: 215.3757781982422
policy_loss: -0.0008185345213860273
entropy_loss: -2.8702428340911865
value_loss: 415.9906005859375
loss: 207.99447631835938
policy_loss: -0.002179548144340515
entropy_loss: -2.870103359222412
value_loss: 434.245361328125
loss: 217.12049865722656
policy_loss: -0.0008131950162351131
entropy_loss: -2.869964838027954
value_loss: 413.6429748535156
loss: 206.8206787109375
policy_loss: -0.0012159356847405434
entropy_loss: -2.8698537349700928
value_loss: 424.58746337890625
loss: 212.29251098632812
policy_loss: -0.0016559436917304993
entropy_loss: -2.869739294052124
value_loss: 406.5643615722656
loss: 203.280517578125
policy_loss: -0.002022458240389824
entropy_loss: -2.869579315185547
value_loss: 432.8048095703125
loss: 216.40037536621094
policy_loss: -0.0023139650002121925
entropy_loss: -2.8694443702697754
value_loss: 399.6650390625
loss: 199.8302001953125
policy_loss: -0.002581704407930374
entropy_loss: -2.8692853450775146
value_loss: 425.30682373046875
loss: 212.6508331298828
policy_loss: -0.0011962000280618668
entropy_loss: -2.869110345840454
value_loss: 371.8716125488281
loss: 185.9346160888672
policy_loss: -0.00290745310485363
entropy_loss: -2.8689424991607666
value_loss: 400.3200378417969
loss: 200.1571044921875
policy_loss: -0.002071312628686428
entropy_loss: -2.8687758445739746
value_loss: 375.2605895996094
loss: 187.6282196044922
policy_loss: -0.003015302587300539
entropy_loss: -2.868629217147827
value_loss: 414.9393005371094
loss: 207.4666290283203
policy_loss: -0.002406924497336149
entropy_loss: -2.868450403213501
value_loss: 390.57366943359375
loss: 195.284423828125
policy_loss: -0.002053908770903945
entropy_loss: -2.8682785034179688
value_loss: 398.5138244628906
loss: 199.25485229492188
policy_loss: -0.005115995183587074
entropy_loss: -2.8681082725524902
value_loss: 388.8118591308594
loss: 194.40081787109375
policy_loss: -0.0015247464179992676
entropy_loss: -2.867943048477173
value_loss: 372.43536376953125
loss: 186.21615600585938
policy_loss: -0.00422506220638752
entropy_loss: -2.8677635192871094
value_loss: 375.4415283203125
loss: 187.71653747558594
policy_loss: -0.003162149339914322
entropy_loss: -2.867584228515625
value_loss: 389.52581787109375
loss: 194.75975036621094
policy_loss: -0.0006305873394012451
entropy_loss: -2.867384433746338
value_loss: 374.9824523925781
loss: 187.4906005859375
policy_loss: -0.007456440478563309
entropy_loss: -2.8672118186950684
value_loss: 367.9603271484375
loss: 183.9727020263672
policy_loss: -0.0043459730222821236
entropy_loss: -2.8670270442962646
value_loss: 358.70703125
loss: 179.3491668701172
policy_loss: -0.005040372721850872
entropy_loss: -2.8668503761291504
value_loss: 370.6629333496094
loss: 185.32643127441406
policy_loss: -0.0060877129435539246
entropy_loss: -2.8666510581970215
value_loss: 363.4877014160156
loss: 181.73776245117188
policy_loss: -0.002102917991578579
entropy_loss: -2.8664777278900146
value_loss: 345.6809387207031
loss: 172.83836364746094
policy_loss: -0.0037896912544965744
entropy_loss: -2.8663136959075928
value_loss: 368.9918212890625
loss: 184.49212646484375
------------------------------------------
| avg_speed               | 2.79         |
| is_success              | 0            |
| max_speed               | 2.79         |
| reward                  | -1.0765396   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.24e+03    |
| time/                   |              |
|    fps                  | 121          |
|    iterations           | 3            |
|    time_elapsed         | 50           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0020555626 |
|    clip_fraction        | 0.00112      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.87        |
|    explained_variance   | -0.246       |
|    learning_rate        | 0.0003       |
|    loss                 | 184          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00192     |
|    std                  | 1.01         |
|    value_loss           | 414          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.2375, -0.2986,  0.1534,  ...,  0.0418,  0.3538, -0.0166],
        [-0.1653,  0.1194, -0.0420,  ..., -0.1563, -0.1275,  0.2518],
        [-0.0629, -0.2312,  0.3688,  ...,  0.1802,  0.0232,  0.0541],
        ...,
        [-0.1317, -0.0518,  0.0670,  ...,  0.0496,  0.3767,  0.0606],
        [-0.2549, -0.3560,  0.2086,  ...,  0.0697, -0.1443,  0.0526],
        [-0.1702, -0.1489,  0.1293,  ...,  0.2105, -0.3292,  0.0168]])
bias : tensor([-6.3204e-05,  1.4464e-03, -1.5109e-03,  1.2652e-03,  7.8696e-04,
         5.1135e-03,  1.8297e-03, -1.4956e-03, -1.7637e-03, -1.9219e-03,
        -2.5691e-03, -3.9314e-04, -5.9345e-03, -2.1521e-03, -2.3345e-04,
         3.5133e-03,  3.6982e-03, -1.6849e-03,  3.0551e-03,  1.7985e-03,
        -1.6534e-03,  4.8852e-03,  8.0502e-04,  2.6932e-04,  8.2273e-04,
        -6.1191e-04, -1.5115e-03,  2.9499e-04, -5.6972e-03, -4.5185e-03,
        -2.7297e-03,  2.0639e-03, -1.8247e-03, -2.0926e-03, -2.7569e-03,
        -2.5724e-04,  1.1129e-03,  9.9164e-04,  4.1669e-03, -1.0233e-03,
        -3.2774e-03, -1.2753e-03,  1.6216e-03,  3.3181e-03, -1.8681e-03,
        -2.8653e-04, -1.4161e-04,  1.1950e-03, -3.1081e-03,  5.9447e-03,
         2.0081e-03,  2.6766e-03, -3.6878e-04,  3.4899e-03, -1.6285e-03,
        -3.8016e-03, -3.2256e-04,  1.4925e-03,  1.7024e-04, -2.1894e-03,
         4.6251e-04,  4.9004e-03, -1.9004e-03, -3.5814e-03])
weight : tensor([[-0.3370, -0.1553, -0.0171,  ..., -0.2077,  0.1393,  0.0019],
        [ 0.2538,  0.0909, -0.1819,  ...,  0.1358, -0.2461,  0.2418],
        [ 0.0885, -0.1896, -0.1888,  ...,  0.0382, -0.0199,  0.2584],
        ...,
        [ 0.0678, -0.0691, -0.2753,  ...,  0.1755, -0.0241, -0.3443],
        [ 0.2636,  0.0597, -0.0169,  ..., -0.0853, -0.2087, -0.1104],
        [-0.2267,  0.0092,  0.0465,  ...,  0.0749,  0.0287, -0.0113]])
bias : tensor([-4.1097e-03, -8.4928e-04,  3.2241e-03, -2.3770e-03,  4.0040e-03,
         7.7738e-04,  2.5936e-03,  1.0270e-03,  2.4612e-03,  3.8267e-03,
         2.1924e-04,  7.3151e-04,  3.3706e-04, -1.6153e-03,  1.9103e-03,
         3.4724e-03,  2.3235e-03,  6.7247e-04, -1.2395e-04, -8.0662e-04,
         1.0502e-03,  5.6648e-04, -1.8924e-03,  2.5137e-03,  9.9834e-05,
         2.9509e-03, -1.1564e-03,  9.5142e-04,  1.6314e-03, -2.4681e-03,
         9.9310e-04, -9.6835e-04,  1.9374e-03,  2.0067e-04, -3.7137e-03,
        -2.9571e-04, -6.4599e-04,  3.5577e-03,  1.1328e-03,  2.2785e-03,
         1.4111e-03,  3.2930e-04, -1.1127e-03,  1.8822e-04,  1.6827e-04,
        -7.1781e-04,  7.7743e-04,  2.4458e-03, -9.7316e-04,  1.8125e-03,
        -3.6263e-03,  1.2533e-03, -3.0644e-03,  2.0064e-03, -1.9371e-03,
        -5.6300e-05,  2.0204e-03,  1.1898e-03, -4.5289e-03,  2.8374e-03,
         2.6662e-03,  4.2482e-04,  4.0363e-03, -6.6737e-04])
policy_loss: -1.9755680114030838e-07
entropy_loss: -2.8610308170318604
value_loss: 404.6136779785156
loss: 202.3068389892578
policy_loss: -1.7682090401649475e-05
entropy_loss: -2.8609468936920166
value_loss: 391.9619140625
loss: 195.98094177246094
policy_loss: -0.00011878693476319313
entropy_loss: -2.8608782291412354
value_loss: 406.0461120605469
loss: 203.02293395996094
policy_loss: 0.00014118477702140808
entropy_loss: -2.8608171939849854
value_loss: 407.2069396972656
loss: 203.60360717773438
policy_loss: -0.0006251386366784573
entropy_loss: -2.8607749938964844
value_loss: 396.89996337890625
loss: 198.44935607910156
policy_loss: 0.0001611672341823578
entropy_loss: -2.8607466220855713
value_loss: 403.59405517578125
loss: 201.7971954345703
policy_loss: -0.0010213330388069153
entropy_loss: -2.8607277870178223
value_loss: 398.9120788574219
loss: 199.45501708984375
policy_loss: -0.0003008497878909111
entropy_loss: -2.8607141971588135
value_loss: 399.36480712890625
loss: 199.68209838867188
policy_loss: -0.0012418106198310852
entropy_loss: -2.860694646835327
value_loss: 389.3641662597656
loss: 194.68084716796875
policy_loss: -0.0004887823015451431
entropy_loss: -2.8606832027435303
value_loss: 400.2853088378906
loss: 200.1421661376953
policy_loss: -0.0016969479620456696
entropy_loss: -2.860679864883423
value_loss: 393.5381164550781
loss: 196.76736450195312
policy_loss: -0.00200831750407815
entropy_loss: -2.8606619834899902
value_loss: 394.5544128417969
loss: 197.2751922607422
policy_loss: -0.001894854474812746
entropy_loss: -2.8606581687927246
value_loss: 399.7450866699219
loss: 199.8706512451172
policy_loss: -0.0009360508993268013
entropy_loss: -2.860654354095459
value_loss: 382.8818664550781
loss: 191.44000244140625
policy_loss: -0.0038956948556005955
entropy_loss: -2.860637903213501
value_loss: 383.2525939941406
loss: 191.62240600585938
policy_loss: -0.003097381442785263
entropy_loss: -2.8606491088867188
value_loss: 385.5557861328125
loss: 192.77479553222656
policy_loss: -0.003912289626896381
entropy_loss: -2.860656976699829
value_loss: 374.37677001953125
loss: 187.18447875976562
policy_loss: -0.0044354405254125595
entropy_loss: -2.8606550693511963
value_loss: 391.4737548828125
loss: 195.73243713378906
policy_loss: -0.00321919284760952
entropy_loss: -2.8606505393981934
value_loss: 383.30224609375
loss: 191.6479034423828
policy_loss: -0.003013867884874344
entropy_loss: -2.860647678375244
value_loss: 372.67901611328125
loss: 186.33648681640625
policy_loss: -0.007727417163550854
entropy_loss: -2.8606696128845215
value_loss: 376.5898742675781
loss: 188.28721618652344
policy_loss: -0.003176826983690262
entropy_loss: -2.8606581687927246
value_loss: 377.27081298828125
loss: 188.63223266601562
policy_loss: -0.0007559922523796558
entropy_loss: -2.860687017440796
value_loss: 367.2787780761719
loss: 183.6386260986328
policy_loss: -0.008773761801421642
entropy_loss: -2.8607327938079834
value_loss: 369.46246337890625
loss: 184.7224578857422
policy_loss: -0.006359420251101255
entropy_loss: -2.8607633113861084
value_loss: 372.82659912109375
loss: 186.4069366455078
policy_loss: -0.009405763819813728
entropy_loss: -2.8608014583587646
value_loss: 377.03076171875
loss: 188.5059814453125
policy_loss: -0.0018508387729525566
entropy_loss: -2.8608016967773438
value_loss: 341.745361328125
loss: 170.87083435058594
policy_loss: -0.007457162253558636
entropy_loss: -2.8608286380767822
value_loss: 367.4850158691406
loss: 183.73504638671875
policy_loss: -0.00674794614315033
entropy_loss: -2.8608853816986084
value_loss: 365.6868896484375
loss: 182.83670043945312
policy_loss: -0.007505936548113823
entropy_loss: -2.8609237670898438
value_loss: 354.1350402832031
loss: 177.0600128173828
policy_loss: -0.005303454585373402
entropy_loss: -2.860994815826416
value_loss: 362.6077880859375
loss: 181.298583984375
policy_loss: -0.011106950230896473
entropy_loss: -2.8610663414001465
value_loss: 344.39453125
loss: 172.1861572265625
policy_loss: -0.006812922656536102
entropy_loss: -2.861156463623047
value_loss: 347.6649169921875
loss: 173.82565307617188
policy_loss: -0.008005108684301376
entropy_loss: -2.8612630367279053
value_loss: 353.30560302734375
loss: 176.64479064941406
policy_loss: -0.007126768585294485
entropy_loss: -2.8613624572753906
value_loss: 349.25177001953125
loss: 174.61875915527344
policy_loss: -0.012442775070667267
entropy_loss: -2.8614842891693115
value_loss: 345.2391357421875
loss: 172.6071319580078
policy_loss: -0.010012991726398468
entropy_loss: -2.861619710922241
value_loss: 333.3241271972656
loss: 166.6520538330078
policy_loss: -0.0077692619524896145
entropy_loss: -2.8617959022521973
value_loss: 339.78277587890625
loss: 169.8836212158203
policy_loss: -0.006524012424051762
entropy_loss: -2.8619673252105713
value_loss: 351.8640441894531
loss: 175.9254913330078
policy_loss: -0.012251035310328007
entropy_loss: -2.8621480464935303
value_loss: 339.1436767578125
loss: 169.55958557128906
----------------------------------------
| avg_speed               | 0.295      |
| is_success              | 0          |
| max_speed               | 0.295      |
| reward                  | -0.4687631 |
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | -1.1e+03   |
| time/                   |            |
|    fps                  | 116        |
|    iterations           | 3          |
|    time_elapsed         | 52         |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.00580082 |
|    clip_fraction        | 0.0172     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.86      |
|    explained_variance   | -0.178     |
|    learning_rate        | 0.0003     |
|    loss                 | 170        |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.00447   |
|    std                  | 1.01       |
|    value_loss           | 375        |
----------------------------------------
TRAINING:
weight : tensor([[ 0.0767,  0.4119,  0.2423,  ..., -0.0435,  0.0316,  0.2988],
        [ 0.1248,  0.3348,  0.1126,  ..., -0.0970, -0.3115, -0.1925],
        [ 0.1145,  0.1815,  0.0248,  ...,  0.4153, -0.1214,  0.4018],
        ...,
        [ 0.0311,  0.1478, -0.2610,  ..., -0.3818, -0.0768, -0.1395],
        [-0.2712,  0.0086,  0.0702,  ..., -0.0081,  0.0188, -0.1111],
        [ 0.1515,  0.1597,  0.3133,  ..., -0.1156,  0.1884,  0.2657]])
bias : tensor([-4.3018e-04,  1.4246e-03, -9.5235e-04,  1.5896e-04, -1.5550e-03,
        -5.6668e-04, -2.4895e-03, -7.1116e-04, -3.2227e-04, -9.7990e-04,
        -1.6595e-03,  4.8018e-03, -2.9038e-03,  6.2621e-03,  1.7565e-03,
        -1.5119e-03, -1.6278e-03,  4.1512e-03, -4.8049e-03, -4.2743e-04,
         2.8296e-03, -5.5219e-03, -6.2839e-04,  5.0678e-03,  1.8342e-03,
        -6.6181e-03,  1.1288e-03, -2.7043e-03,  2.2035e-04,  5.5747e-03,
        -6.6124e-03, -1.4000e-04,  4.0203e-03,  3.2655e-03,  3.0743e-03,
        -1.4243e-03, -2.7489e-03,  2.7434e-03, -2.5275e-04,  5.9157e-03,
        -4.6655e-03,  6.7686e-03, -3.8805e-03,  3.2230e-03, -5.8899e-03,
         2.8126e-03, -2.9887e-03,  3.6186e-03, -1.7529e-04,  5.1887e-03,
        -1.0427e-04,  8.7472e-04,  1.6709e-04,  3.7840e-03,  5.3349e-03,
        -9.4878e-04,  3.0929e-03,  4.7520e-05, -3.6835e-03, -4.7530e-03,
         1.8149e-03, -1.6393e-03, -1.6113e-03,  4.4577e-03])
weight : tensor([[-0.1732,  0.0852,  0.1625,  ..., -0.2986,  0.0029, -0.0787],
        [ 0.0454, -0.2650,  0.0884,  ...,  0.1017,  0.0821,  0.3116],
        [-0.0695,  0.2359, -0.1148,  ..., -0.1624, -0.2258,  0.1552],
        ...,
        [ 0.2287,  0.3873,  0.1873,  ..., -0.0471,  0.4154,  0.2059],
        [-0.0476,  0.2808,  0.1191,  ..., -0.2095,  0.1516, -0.2214],
        [ 0.0458, -0.0543,  0.3605,  ...,  0.0100,  0.0258, -0.2429]])
bias : tensor([-2.5372e-04, -1.1145e-03,  3.6608e-04, -2.3331e-03,  8.3725e-04,
         1.7208e-03,  5.4092e-03,  1.3024e-03,  3.1324e-03, -4.5233e-03,
        -6.5305e-04, -1.9972e-03,  2.4624e-03, -7.3407e-05,  3.5361e-03,
         1.1431e-03,  2.8682e-03,  5.1579e-03,  3.0503e-03,  1.6504e-03,
        -5.7544e-03,  2.2646e-03, -2.3078e-03, -8.6538e-04,  4.0233e-03,
         3.5194e-03, -4.8976e-04, -3.9429e-03,  1.5457e-03, -4.2689e-03,
         3.7208e-03, -3.0059e-03,  1.3394e-03, -1.2366e-04,  2.3931e-03,
         4.5703e-03, -4.7736e-04,  4.0190e-03, -3.7631e-03, -7.7359e-04,
         1.9418e-03,  5.0756e-03,  1.0701e-03,  1.7706e-03,  2.5032e-03,
        -3.6003e-03,  8.2405e-03, -5.1740e-03,  5.5202e-03, -5.5367e-03,
         3.3188e-03,  2.6466e-03,  4.6129e-03,  6.7192e-04,  2.3861e-03,
        -3.3651e-03,  3.4894e-04, -1.8523e-03, -1.0873e-03,  6.5633e-04,
         2.6532e-03, -1.8171e-04,  1.2148e-03,  3.2124e-03])
policy_loss: -3.632158041000366e-08
entropy_loss: -2.853759527206421
value_loss: 484.80755615234375
loss: 242.40377807617188
policy_loss: -3.1054019927978516e-05
entropy_loss: -2.8536810874938965
value_loss: 515.1839599609375
loss: 257.5919494628906
policy_loss: 5.698390305042267e-05
entropy_loss: -2.853598117828369
value_loss: 492.59368896484375
loss: 246.29690551757812
policy_loss: 8.888076990842819e-05
entropy_loss: -2.8535194396972656
value_loss: 470.6330261230469
loss: 235.3166046142578
policy_loss: -0.00020541809499263763
entropy_loss: -2.8534510135650635
value_loss: 530.556640625
loss: 265.2781066894531
policy_loss: -0.0003458671271800995
entropy_loss: -2.8534178733825684
value_loss: 467.0844421386719
loss: 233.5418701171875
policy_loss: -0.0003352649509906769
entropy_loss: -2.853309392929077
value_loss: 488.58197021484375
loss: 244.2906494140625
policy_loss: -9.993149433284998e-05
entropy_loss: -2.8531858921051025
value_loss: 458.7936096191406
loss: 229.39669799804688
policy_loss: -0.00010077375918626785
entropy_loss: -2.8531229496002197
value_loss: 442.5895690917969
loss: 221.294677734375
policy_loss: -0.0013932501897215843
entropy_loss: -2.8530614376068115
value_loss: 496.1495666503906
loss: 248.07339477539062
policy_loss: -0.0005738595500588417
entropy_loss: -2.852996587753296
value_loss: 491.8507995605469
loss: 245.92481994628906
policy_loss: -0.0009181825444102287
entropy_loss: -2.8529229164123535
value_loss: 490.1703186035156
loss: 245.08424377441406
policy_loss: -0.0002744179219007492
entropy_loss: -2.852857828140259
value_loss: 482.6734619140625
loss: 241.33645629882812
policy_loss: -0.0020014832261949778
entropy_loss: -2.852790594100952
value_loss: 501.1073913574219
loss: 250.55169677734375
policy_loss: -0.002789537888020277
entropy_loss: -2.8527543544769287
value_loss: 460.74517822265625
loss: 230.3697967529297
policy_loss: -0.0005783848464488983
entropy_loss: -2.8526647090911865
value_loss: 448.91650390625
loss: 224.45767211914062
policy_loss: -0.002682245336472988
entropy_loss: -2.85260009765625
value_loss: 465.62139892578125
loss: 232.80801391601562
policy_loss: -0.0019490066915750504
entropy_loss: -2.852522134780884
value_loss: 471.8368835449219
loss: 235.91648864746094
policy_loss: -0.0020052138715982437
entropy_loss: -2.8524515628814697
value_loss: 469.69512939453125
loss: 234.84556579589844
policy_loss: -0.001978803426027298
entropy_loss: -2.852403163909912
value_loss: 456.51153564453125
loss: 228.2537841796875
policy_loss: -0.0034164227545261383
entropy_loss: -2.852339267730713
value_loss: 443.7460632324219
loss: 221.86961364746094
policy_loss: -0.0038002245128154755
entropy_loss: -2.8522744178771973
value_loss: 469.29888916015625
loss: 234.64564514160156
policy_loss: -0.004538265988230705
entropy_loss: -2.852175235748291
value_loss: 468.37481689453125
loss: 234.18287658691406
policy_loss: -0.00017623277381062508
entropy_loss: -2.8520891666412354
value_loss: 451.9400329589844
loss: 225.96983337402344
policy_loss: -0.0022651096805930138
entropy_loss: -2.8520278930664062
value_loss: 440.678466796875
loss: 220.33697509765625
policy_loss: -0.004518719390034676
entropy_loss: -2.8519785404205322
value_loss: 459.63958740234375
loss: 229.81527709960938
policy_loss: -0.003492266871035099
entropy_loss: -2.8519227504730225
value_loss: 435.9210205078125
loss: 217.95701599121094
policy_loss: -0.00509252492338419
entropy_loss: -2.851884365081787
value_loss: 466.61590576171875
loss: 233.3028564453125
policy_loss: -0.0076648639515042305
entropy_loss: -2.8518450260162354
value_loss: 449.3533935546875
loss: 224.66903686523438
policy_loss: -0.0009792689234018326
entropy_loss: -2.851797580718994
value_loss: 427.746826171875
loss: 213.8724365234375
policy_loss: -0.002853596583008766
entropy_loss: -2.8517775535583496
value_loss: 439.9878845214844
loss: 219.9910888671875
policy_loss: -0.006377419922500849
entropy_loss: -2.8517720699310303
value_loss: 455.64453125
loss: 227.81588745117188
policy_loss: -0.00377042219042778
entropy_loss: -2.8517606258392334
value_loss: 432.42755126953125
loss: 216.2100067138672
policy_loss: -0.006013743579387665
entropy_loss: -2.851701259613037
value_loss: 452.0164489746094
loss: 226.00221252441406
policy_loss: -0.006426304578781128
entropy_loss: -2.8516793251037598
value_loss: 429.6953430175781
loss: 214.84124755859375
policy_loss: -0.0033918777480721474
entropy_loss: -2.851670980453491
value_loss: 429.0167236328125
loss: 214.50497436523438
policy_loss: -0.009534389711916447
entropy_loss: -2.8517072200775146
value_loss: 451.20196533203125
loss: 225.59144592285156
policy_loss: -0.005377611611038446
entropy_loss: -2.851768732070923
value_loss: 420.9696350097656
loss: 210.4794464111328
policy_loss: -0.0036012642085552216
entropy_loss: -2.8518548011779785
value_loss: 409.31842041015625
loss: 204.65560913085938
policy_loss: -0.002464024815708399
entropy_loss: -2.8519210815429688
value_loss: 432.63922119140625
loss: 216.31715393066406
-----------------------------------------
| avg_speed               | 0.162       |
| is_success              | 0           |
| max_speed               | 0.162       |
| reward                  | -0.49787402 |
| rollout/                |             |
|    ep_len_mean          | 960         |
|    ep_rew_mean          | -1.28e+03   |
| time/                   |             |
|    fps                  | 122         |
|    iterations           | 4           |
|    time_elapsed         | 66          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.003536987 |
|    clip_fraction        | 0.00942     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.85       |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 216         |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0026     |
|    std                  | 1.01        |
|    value_loss           | 461         |
-----------------------------------------
TRAINING:
weight : tensor([[ 1.7695e-01, -3.6110e-01, -6.7121e-02,  ..., -1.4220e-02,
         -2.2002e-01, -3.0763e-01],
        [ 2.5197e-02,  1.4626e-01, -3.8578e-03,  ..., -7.8628e-02,
         -6.8913e-03, -4.9855e-02],
        [-7.1968e-02,  5.4186e-02,  3.1084e-02,  ..., -1.7304e-01,
         -1.2859e-01,  2.2306e-01],
        ...,
        [ 2.4864e-01, -8.9366e-02,  2.1944e-01,  ...,  1.9863e-01,
         -2.1088e-01,  3.1955e-01],
        [-4.3675e-02, -2.5876e-01, -5.5624e-02,  ..., -1.3286e-01,
         -2.7499e-01,  3.1079e-01],
        [-1.3249e-04,  1.0094e-01, -1.7269e-01,  ..., -7.3912e-02,
          8.7064e-02,  9.5744e-02]])
bias : tensor([ 6.5505e-03, -1.9907e-03,  1.5397e-03, -2.0819e-03, -4.6497e-03,
         8.0386e-03,  3.8835e-03, -7.2275e-03,  1.1609e-04, -1.8328e-03,
         3.4332e-03,  1.4267e-04, -3.8598e-03,  4.3883e-03, -1.0127e-03,
         3.3124e-03, -5.4482e-03, -8.8549e-03,  8.8531e-05,  1.7151e-03,
        -2.6514e-03,  1.0037e-03, -3.4886e-03, -4.6962e-03,  7.6067e-03,
        -2.3860e-03, -2.1616e-03,  3.8925e-05,  5.1120e-03, -5.4597e-04,
        -4.5112e-03,  1.6890e-03,  3.5573e-03,  8.3848e-03, -2.8048e-05,
        -2.2660e-03,  7.6867e-03, -1.5756e-03,  7.0745e-03,  2.9193e-03,
         1.1064e-04, -5.7847e-03,  7.8488e-03,  3.4686e-03, -2.5388e-03,
        -3.6787e-03,  2.4277e-03,  1.9367e-03, -5.5174e-03,  2.2909e-03,
        -4.9783e-03, -2.2746e-03, -1.5500e-03,  2.3102e-03,  2.7048e-03,
         4.3447e-03, -4.4348e-03, -3.4076e-03,  2.9134e-03, -5.6680e-03,
         1.5795e-03, -3.4450e-03,  1.1972e-03, -6.6418e-03])
weight : tensor([[-0.2188,  0.3491, -0.3330,  ..., -0.1681,  0.3033,  0.1754],
        [-0.1662, -0.1400, -0.0219,  ...,  0.0513, -0.3305,  0.0928],
        [-0.1291, -0.4212, -0.1393,  ...,  0.1885,  0.1345,  0.0122],
        ...,
        [ 0.2274,  0.1381, -0.2824,  ..., -0.0872,  0.0148, -0.0893],
        [-0.2403, -0.1289,  0.1517,  ...,  0.0458,  0.3082,  0.0835],
        [ 0.2033, -0.1982, -0.0115,  ..., -0.0731,  0.0363, -0.1229]])
bias : tensor([-7.6858e-03,  4.1855e-03,  3.5180e-03, -2.4157e-03, -2.6218e-03,
        -5.6928e-03, -2.7153e-04,  5.0355e-03,  3.6425e-03,  3.0681e-03,
        -5.7506e-03, -2.9861e-03, -5.1498e-03, -4.1228e-03,  2.4985e-03,
        -5.1861e-04, -1.7999e-03,  1.6066e-04, -6.7096e-04, -4.9440e-04,
        -6.1781e-03,  2.7922e-03, -3.4509e-03,  3.8138e-03, -4.6550e-03,
         1.1971e-03, -5.2862e-03,  5.3589e-03, -3.4515e-03, -2.0807e-03,
         9.2565e-04,  7.4933e-03,  3.3703e-03, -5.8902e-04, -3.3481e-03,
        -3.0454e-03,  1.8063e-04,  1.3551e-03, -3.0534e-03, -3.0422e-03,
         6.2197e-03,  3.8729e-03,  5.6361e-03,  6.7413e-04, -2.2670e-03,
         5.3397e-03, -3.4735e-03,  7.0951e-03, -2.7021e-04, -2.9546e-03,
         1.0065e-04, -7.1062e-03, -2.3147e-03, -3.8089e-03,  7.4515e-05,
         1.0549e-03,  4.6538e-03,  3.7551e-03, -1.5105e-03, -2.3852e-03,
         8.4032e-03,  6.5923e-03,  4.3265e-04,  3.6056e-03])
policy_loss: 2.086162567138672e-07
entropy_loss: -2.8661439418792725
value_loss: 372.5672302246094
loss: 186.2836151123047
policy_loss: 4.031741991639137e-05
entropy_loss: -2.8660085201263428
value_loss: 370.0458679199219
loss: 185.02297973632812
policy_loss: -0.00013410113751888275
entropy_loss: -2.8658978939056396
value_loss: 347.9609375
loss: 173.98033142089844
policy_loss: 0.00039157201535999775
entropy_loss: -2.8657898902893066
value_loss: 373.8616943359375
loss: 186.93124389648438
policy_loss: -5.491357296705246e-05
entropy_loss: -2.8656983375549316
value_loss: 361.36138916015625
loss: 180.68063354492188
policy_loss: 4.8502348363399506e-05
entropy_loss: -2.8656156063079834
value_loss: 366.0955505371094
loss: 183.04782104492188
policy_loss: 0.00023842975497245789
entropy_loss: -2.8656296730041504
value_loss: 362.1084289550781
loss: 181.05445861816406
policy_loss: -0.0005980981513857841
entropy_loss: -2.8655717372894287
value_loss: 371.38507080078125
loss: 185.6919403076172
policy_loss: -0.0002595963887870312
entropy_loss: -2.8655335903167725
value_loss: 355.6141662597656
loss: 177.80682373046875
policy_loss: -0.000531855970621109
entropy_loss: -2.865527868270874
value_loss: 351.5419006347656
loss: 175.77041625976562
policy_loss: -0.0002217486035078764
entropy_loss: -2.865583896636963
value_loss: 364.5557861328125
loss: 182.2776641845703
policy_loss: -0.0007404247298836708
entropy_loss: -2.8656294345855713
value_loss: 379.76239013671875
loss: 189.8804473876953
policy_loss: -0.00030476879328489304
entropy_loss: -2.865617275238037
value_loss: 362.1340637207031
loss: 181.0667266845703
policy_loss: -0.0008137570694088936
entropy_loss: -2.8656084537506104
value_loss: 367.5848388671875
loss: 183.79161071777344
policy_loss: -0.0004132259637117386
entropy_loss: -2.8655991554260254
value_loss: 344.85430908203125
loss: 172.42674255371094
policy_loss: -0.0021682260558009148
entropy_loss: -2.865586996078491
value_loss: 363.9889221191406
loss: 181.99229431152344
policy_loss: -0.0017768959514796734
entropy_loss: -2.865600824356079
value_loss: 361.68768310546875
loss: 180.84207153320312
policy_loss: -0.0015408433973789215
entropy_loss: -2.865609645843506
value_loss: 355.80615234375
loss: 177.9015350341797
policy_loss: -0.001568295992910862
entropy_loss: -2.865654230117798
value_loss: 355.9988098144531
loss: 177.99783325195312
policy_loss: -0.0006081331521272659
entropy_loss: -2.865670919418335
value_loss: 349.61346435546875
loss: 174.80612182617188
policy_loss: -0.002591619035229087
entropy_loss: -2.865699529647827
value_loss: 367.47943115234375
loss: 183.73712158203125
policy_loss: -0.002039383165538311
entropy_loss: -2.865755558013916
value_loss: 349.7539978027344
loss: 174.8749542236328
policy_loss: -0.0018779945094138384
entropy_loss: -2.8658676147460938
value_loss: 346.13037109375
loss: 173.0633087158203
policy_loss: -0.0012958487495779991
entropy_loss: -2.8659591674804688
value_loss: 342.72442626953125
loss: 171.3609161376953
policy_loss: -0.0007376223802566528
entropy_loss: -2.865983724594116
value_loss: 350.84051513671875
loss: 175.41952514648438
policy_loss: -0.0055993953719735146
entropy_loss: -2.865980386734009
value_loss: 354.1114501953125
loss: 177.0501251220703
policy_loss: -0.0016981344670057297
entropy_loss: -2.8659682273864746
value_loss: 352.5665588378906
loss: 176.28158569335938
policy_loss: -0.0025294963270425797
entropy_loss: -2.8659920692443848
value_loss: 331.0933532714844
loss: 165.5441436767578
policy_loss: -0.0019291974604129791
entropy_loss: -2.866039276123047
value_loss: 330.1285400390625
loss: 165.06234741210938
policy_loss: -0.0031768479384481907
entropy_loss: -2.86602783203125
value_loss: 342.354248046875
loss: 171.1739501953125
policy_loss: -0.005301002413034439
entropy_loss: -2.866058588027954
value_loss: 363.2464294433594
loss: 181.617919921875
policy_loss: -0.0025337953120470047
entropy_loss: -2.8661134243011475
value_loss: 335.11419677734375
loss: 167.5545654296875
policy_loss: -0.0030141398310661316
entropy_loss: -2.866163730621338
value_loss: 333.908203125
loss: 166.95108032226562
policy_loss: -0.004698579199612141
entropy_loss: -2.8662736415863037
value_loss: 349.6921081542969
loss: 174.8413543701172
policy_loss: -0.006698861718177795
entropy_loss: -2.866351842880249
value_loss: 327.7606201171875
loss: 163.8736114501953
policy_loss: -3.474066033959389e-05
entropy_loss: -2.8663899898529053
value_loss: 341.43756103515625
loss: 170.71875
policy_loss: -0.004490711726248264
entropy_loss: -2.866436004638672
value_loss: 323.1296691894531
loss: 161.5603485107422
policy_loss: -0.0063554830849170685
entropy_loss: -2.8664803504943848
value_loss: 337.3406982421875
loss: 168.6639862060547
policy_loss: -0.0018914416432380676
entropy_loss: -2.8665528297424316
value_loss: 325.4152526855469
loss: 162.7057342529297
policy_loss: -0.0040274616330862045
entropy_loss: -2.866640567779541
value_loss: 349.104248046875
loss: 174.548095703125
-----------------------------------------
| avg_speed               | 0.79        |
| is_success              | 0           |
| max_speed               | 0.79        |
| reward                  | -1.2931846  |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.22e+03   |
| time/                   |             |
|    fps                  | 121         |
|    iterations           | 4           |
|    time_elapsed         | 67          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.002391065 |
|    clip_fraction        | 0.00337     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.87       |
|    explained_variance   | -0.0139     |
|    learning_rate        | 0.0003      |
|    loss                 | 175         |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00184    |
|    std                  | 1.01        |
|    value_loss           | 352         |
-----------------------------------------
TRAINING:
weight : tensor([[ 0.2354, -0.3004,  0.1527,  ...,  0.0401,  0.3533, -0.0179],
        [-0.1663,  0.1199, -0.0417,  ..., -0.1557, -0.1273,  0.2525],
        [-0.0648, -0.2324,  0.3663,  ...,  0.1812,  0.0228,  0.0531],
        ...,
        [-0.1360, -0.0570,  0.0659,  ...,  0.0502,  0.3751,  0.0593],
        [-0.2558, -0.3566,  0.2081,  ...,  0.0704, -0.1445,  0.0518],
        [-0.1675, -0.1470,  0.1314,  ...,  0.2097, -0.3287,  0.0167]])
bias : tensor([ 0.0022,  0.0009, -0.0004,  0.0015,  0.0008,  0.0066,  0.0007,  0.0003,
        -0.0020, -0.0025, -0.0037, -0.0001, -0.0083, -0.0017, -0.0017,  0.0070,
         0.0043, -0.0042,  0.0051,  0.0024, -0.0023,  0.0058,  0.0013, -0.0014,
         0.0015,  0.0003, -0.0027,  0.0017, -0.0060, -0.0042, -0.0034,  0.0031,
        -0.0028, -0.0024, -0.0038, -0.0003,  0.0025,  0.0020,  0.0044, -0.0020,
        -0.0052, -0.0008,  0.0012,  0.0029, -0.0019,  0.0007,  0.0009,  0.0008,
        -0.0039,  0.0092,  0.0035,  0.0032, -0.0002,  0.0046, -0.0010, -0.0043,
        -0.0015,  0.0038,  0.0004, -0.0032, -0.0003,  0.0090, -0.0011, -0.0050])
weight : tensor([[-3.3786e-01, -1.5535e-01, -1.8745e-02,  ..., -2.0801e-01,
          1.3753e-01,  2.7848e-04],
        [ 2.5360e-01,  9.1271e-02, -1.8272e-01,  ...,  1.3584e-01,
         -2.4720e-01,  2.4037e-01],
        [ 8.8586e-02, -1.8935e-01, -1.8814e-01,  ...,  3.8258e-02,
         -1.9103e-02,  2.5917e-01],
        ...,
        [ 6.8115e-02, -6.9149e-02, -2.7460e-01,  ...,  1.7553e-01,
         -2.3109e-02, -3.4341e-01],
        [ 2.6418e-01,  5.9741e-02, -1.5307e-02,  ..., -8.4786e-02,
         -2.0691e-01, -1.0857e-01],
        [-2.2665e-01,  9.0102e-03,  4.6743e-02,  ...,  7.4920e-02,
          2.9292e-02, -1.0676e-02]])
bias : tensor([-0.0069, -0.0025,  0.0049, -0.0034,  0.0058,  0.0007,  0.0038,  0.0009,
         0.0045,  0.0068,  0.0008, -0.0004,  0.0015, -0.0016,  0.0023,  0.0051,
         0.0027,  0.0008,  0.0002, -0.0009,  0.0010, -0.0011, -0.0036,  0.0023,
         0.0008,  0.0050,  0.0002,  0.0029,  0.0032, -0.0036, -0.0003, -0.0007,
         0.0044, -0.0018, -0.0045, -0.0006,  0.0011,  0.0037,  0.0010,  0.0040,
         0.0008, -0.0008, -0.0030, -0.0011,  0.0009, -0.0025, -0.0008,  0.0018,
        -0.0022,  0.0019, -0.0048,  0.0011, -0.0050,  0.0031, -0.0012,  0.0011,
         0.0036,  0.0027, -0.0069,  0.0028,  0.0029,  0.0014,  0.0064, -0.0009])
policy_loss: -1.2479722499847412e-07
entropy_loss: -2.862321376800537
value_loss: 966.87255859375
loss: 483.436279296875
policy_loss: 5.126139149069786e-05
entropy_loss: -2.8624396324157715
value_loss: 991.605224609375
loss: 495.80267333984375
policy_loss: 5.893595516681671e-05
entropy_loss: -2.862598180770874
value_loss: 1017.8185424804688
loss: 508.9093322753906
policy_loss: -9.292946197092533e-05
entropy_loss: -2.8627431392669678
value_loss: 972.641357421875
loss: 486.3205871582031
policy_loss: -0.00014810264110565186
entropy_loss: -2.862851619720459
value_loss: 1014.7493286132812
loss: 507.37451171875
policy_loss: -9.463727474212646e-05
entropy_loss: -2.8629724979400635
value_loss: 957.5790405273438
loss: 478.7894287109375
policy_loss: -0.0003088824450969696
entropy_loss: -2.863079309463501
value_loss: 1027.14208984375
loss: 513.5707397460938
policy_loss: -9.761075489223003e-05
entropy_loss: -2.8631463050842285
value_loss: 928.2761840820312
loss: 464.13800048828125
policy_loss: -0.0007217195816338062
entropy_loss: -2.863210916519165
value_loss: 1038.87548828125
loss: 519.43701171875
policy_loss: -0.0004788096994161606
entropy_loss: -2.8632493019104004
value_loss: 1006.9992065429688
loss: 503.4991149902344
policy_loss: -0.0003610048443078995
entropy_loss: -2.863297939300537
value_loss: 913.5184936523438
loss: 456.7588806152344
policy_loss: -0.00042143650352954865
entropy_loss: -2.863342523574829
value_loss: 940.3176879882812
loss: 470.1584167480469
policy_loss: -0.0005022091791033745
entropy_loss: -2.8633880615234375
value_loss: 1001.172607421875
loss: 500.5858154296875
policy_loss: -0.0002251695841550827
entropy_loss: -2.863412380218506
value_loss: 936.3604736328125
loss: 468.1800231933594
policy_loss: -0.0024858610704541206
entropy_loss: -2.8634188175201416
value_loss: 972.07275390625
loss: 486.0339050292969
policy_loss: -0.0008539315313100815
entropy_loss: -2.863471746444702
value_loss: 958.4932250976562
loss: 479.2457580566406
policy_loss: -0.0006010755896568298
entropy_loss: -2.8635001182556152
value_loss: 950.1806640625
loss: 475.0897216796875
policy_loss: -0.0020944615826010704
entropy_loss: -2.8635365962982178
value_loss: 956.2925415039062
loss: 478.1441650390625
policy_loss: -0.0011822618544101715
entropy_loss: -2.8635785579681396
value_loss: 966.4329223632812
loss: 483.21527099609375
policy_loss: -0.0020199837163090706
entropy_loss: -2.863595485687256
value_loss: 961.181640625
loss: 480.58880615234375
policy_loss: -0.0026296377182006836
entropy_loss: -2.8636090755462646
value_loss: 937.4031372070312
loss: 468.6989440917969
policy_loss: -0.0012072473764419556
entropy_loss: -2.8636701107025146
value_loss: 985.5125122070312
loss: 492.7550354003906
policy_loss: -0.0014740917831659317
entropy_loss: -2.863710880279541
value_loss: 921.4473266601562
loss: 460.7221984863281
policy_loss: -0.0030058603733778
entropy_loss: -2.863689661026001
value_loss: 954.787109375
loss: 477.39056396484375
policy_loss: -0.0011294297873973846
entropy_loss: -2.8636934757232666
value_loss: 937.4054565429688
loss: 468.70159912109375
policy_loss: -0.0032453248277306557
entropy_loss: -2.8637235164642334
value_loss: 944.7619018554688
loss: 472.3777160644531
policy_loss: -0.005046317353844643
entropy_loss: -2.8637518882751465
value_loss: 960.1058959960938
loss: 480.04791259765625
policy_loss: -0.0010608830489218235
entropy_loss: -2.8637468814849854
value_loss: 921.4972534179688
loss: 460.74755859375
policy_loss: -0.001647859811782837
entropy_loss: -2.863746404647827
value_loss: 972.7603149414062
loss: 486.3785095214844
policy_loss: -0.006460278294980526
entropy_loss: -2.863727331161499
value_loss: 828.7661743164062
loss: 414.3766174316406
policy_loss: 0.0007811554241925478
entropy_loss: -2.8637049198150635
value_loss: 937.4164428710938
loss: 468.7090148925781
policy_loss: -0.005627218633890152
entropy_loss: -2.8636574745178223
value_loss: 989.9796142578125
loss: 494.98419189453125
policy_loss: -0.0004451107233762741
entropy_loss: -2.863666296005249
value_loss: 941.7992553710938
loss: 470.899169921875
policy_loss: -0.005493789911270142
entropy_loss: -2.863677740097046
value_loss: 965.1179809570312
loss: 482.5534973144531
policy_loss: -0.006550753954797983
entropy_loss: -2.863696813583374
value_loss: 844.4803466796875
loss: 422.2336120605469
policy_loss: -0.0027019567787647247
entropy_loss: -2.863685369491577
value_loss: 942.7665405273438
loss: 471.38055419921875
policy_loss: -0.0039007810410112143
entropy_loss: -2.863701105117798
value_loss: 884.87109375
loss: 442.431640625
policy_loss: -0.004894282668828964
entropy_loss: -2.8637235164642334
value_loss: 919.130126953125
loss: 459.5601806640625
policy_loss: -0.006170663982629776
entropy_loss: -2.8637337684631348
value_loss: 941.5865478515625
loss: 470.787109375
policy_loss: -0.00099964439868927
entropy_loss: -2.863755941390991
value_loss: 914.5174560546875
loss: 457.2577209472656
------------------------------------------
| avg_speed               | 2.26         |
| is_success              | 0            |
| max_speed               | 2.26         |
| reward                  | -0.3084484   |
| rollout/                |              |
|    ep_len_mean          | 965          |
|    ep_rew_mean          | -1.1e+03     |
| time/                   |              |
|    fps                  | 116          |
|    iterations           | 4            |
|    time_elapsed         | 70           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0024230785 |
|    clip_fraction        | 0.00283      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0409       |
|    learning_rate        | 0.0003       |
|    loss                 | 457          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00189     |
|    std                  | 1.01         |
|    value_loss           | 953          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.0741,  0.4094,  0.2426,  ..., -0.0395,  0.0310,  0.3004],
        [ 0.1254,  0.3363,  0.1139,  ..., -0.0959, -0.3114, -0.1924],
        [ 0.1139,  0.1834,  0.0229,  ...,  0.4154, -0.1219,  0.4017],
        ...,
        [ 0.0303,  0.1467, -0.2618,  ..., -0.3820, -0.0767, -0.1398],
        [-0.2716,  0.0094,  0.0687,  ..., -0.0096,  0.0191, -0.1126],
        [ 0.1521,  0.1592,  0.3143,  ..., -0.1147,  0.1879,  0.2670]])
bias : tensor([-2.1925e-03,  7.7011e-04, -1.4192e-03, -9.3782e-04, -2.3512e-03,
        -5.1568e-04, -2.1773e-03, -9.0087e-04, -5.1665e-04, -5.4645e-04,
        -1.5385e-03,  4.1262e-03, -3.3512e-03,  6.5401e-03,  7.8802e-04,
        -1.6557e-03, -2.0654e-03,  4.3514e-03, -4.6638e-03,  1.1788e-05,
         4.1696e-03, -5.6916e-03, -1.0408e-03,  5.2412e-03, -4.2449e-05,
        -6.9572e-03,  5.8710e-04, -1.9395e-03,  6.5548e-04,  5.4061e-03,
        -7.5717e-03,  1.8103e-03,  3.0493e-03,  2.5858e-03,  3.7335e-03,
        -1.5519e-03, -1.9392e-03,  2.5286e-03,  3.8541e-04,  6.0014e-03,
        -3.9596e-03,  6.7058e-03, -4.0507e-03,  3.0898e-03, -6.8361e-03,
         2.4097e-03, -3.4610e-03,  4.3930e-03, -2.2977e-04,  4.9367e-03,
         1.7823e-03,  1.0123e-03,  7.0927e-04,  4.2197e-03,  5.6547e-03,
        -1.0552e-04,  3.6332e-03, -5.7160e-04, -3.3994e-03, -5.1395e-03,
         9.1351e-04, -1.6710e-03, -1.1887e-03,  3.1848e-03])
weight : tensor([[-0.1731,  0.0852,  0.1626,  ..., -0.2986,  0.0029, -0.0786],
        [ 0.0451, -0.2649,  0.0880,  ...,  0.1020,  0.0820,  0.3117],
        [-0.0687,  0.2350, -0.1130,  ..., -0.1636, -0.2258,  0.1561],
        ...,
        [ 0.2292,  0.3867,  0.1888,  ..., -0.0477,  0.4147,  0.2067],
        [-0.0469,  0.2801,  0.1208,  ..., -0.2105,  0.1512, -0.2209],
        [ 0.0466, -0.0551,  0.3621,  ...,  0.0090,  0.0256, -0.2422]])
bias : tensor([-3.4320e-04, -1.1931e-03,  5.9685e-05, -2.7006e-03,  7.1034e-04,
         1.2248e-03,  5.0215e-03,  1.0388e-03,  2.6112e-03, -4.4261e-03,
         2.2911e-04, -2.1144e-03,  2.3056e-03,  4.4288e-04,  3.4765e-03,
         1.1060e-03,  2.1585e-03,  5.4201e-03,  2.9417e-03,  3.6607e-04,
        -6.4543e-03,  8.7741e-04, -2.6098e-03, -5.8858e-04,  3.9429e-03,
         2.6962e-03, -4.6271e-04, -3.3171e-03,  2.4017e-03, -4.5832e-03,
         4.3704e-03, -3.7009e-03,  9.2646e-04, -1.0933e-05,  2.0672e-03,
         4.8804e-03, -6.0175e-04,  3.6581e-03, -3.8863e-03, -9.4192e-04,
         1.6380e-03,  5.1774e-03,  9.7426e-04,  1.6145e-03,  2.8330e-03,
        -3.3816e-03,  9.1842e-03, -6.1528e-03,  6.4698e-03, -5.4529e-03,
         2.9014e-03,  3.9345e-03,  5.0739e-03,  6.6127e-04,  2.4525e-03,
        -4.0179e-03,  2.8851e-04, -8.1404e-04, -1.1151e-03, -1.7929e-04,
         2.5198e-03, -1.0765e-03,  2.1347e-05,  2.2456e-03])
policy_loss: 9.033828973770142e-08
entropy_loss: -2.8519747257232666
value_loss: 686.7734375
loss: 343.38671875
policy_loss: -7.109157741069794e-05
entropy_loss: -2.852020502090454
value_loss: 750.5950927734375
loss: 375.2974853515625
policy_loss: 3.220885992050171e-05
entropy_loss: -2.852048397064209
value_loss: 746.4990844726562
loss: 373.24957275390625
policy_loss: -5.855783820152283e-05
entropy_loss: -2.8520636558532715
value_loss: 706.363525390625
loss: 353.18170166015625
policy_loss: -4.5709311962127686e-06
entropy_loss: -2.8520543575286865
value_loss: 744.9923706054688
loss: 372.4961853027344
policy_loss: 0.00010097958147525787
entropy_loss: -2.8520467281341553
value_loss: 723.0213623046875
loss: 361.5107727050781
policy_loss: -0.0005079368129372597
entropy_loss: -2.8520238399505615
value_loss: 677.6419677734375
loss: 338.8204650878906
policy_loss: -0.0003109271638095379
entropy_loss: -2.8519818782806396
value_loss: 712.8170166015625
loss: 356.408203125
policy_loss: 6.613926962018013e-05
entropy_loss: -2.851928949356079
value_loss: 702.2459106445312
loss: 351.1230163574219
policy_loss: -0.0007608970627188683
entropy_loss: -2.8518755435943604
value_loss: 724.4482421875
loss: 362.2233581542969
policy_loss: -0.000491805374622345
entropy_loss: -2.8518106937408447
value_loss: 696.9951782226562
loss: 348.4971008300781
policy_loss: -0.00022525759413838387
entropy_loss: -2.8517377376556396
value_loss: 688.5987548828125
loss: 344.2991638183594
policy_loss: -0.00041490141302347183
entropy_loss: -2.851654291152954
value_loss: 718.8389282226562
loss: 359.4190368652344
policy_loss: -0.000525391660630703
entropy_loss: -2.851593255996704
value_loss: 693.7686157226562
loss: 346.8837890625
policy_loss: -0.0001442958600819111
entropy_loss: -2.851529598236084
value_loss: 676.3885498046875
loss: 338.1941223144531
policy_loss: -0.0012199776247143745
entropy_loss: -2.8514254093170166
value_loss: 670.6861572265625
loss: 335.34185791015625
policy_loss: -0.0012747608125209808
entropy_loss: -2.8513131141662598
value_loss: 688.8570556640625
loss: 344.42724609375
policy_loss: -0.001066449098289013
entropy_loss: -2.8512041568756104
value_loss: 675.2328491210938
loss: 337.6153564453125
policy_loss: -0.00021956302225589752
entropy_loss: -2.8510947227478027
value_loss: 671.471923828125
loss: 335.7357482910156
policy_loss: -0.0005582273006439209
entropy_loss: -2.85097336769104
value_loss: 669.0938110351562
loss: 334.5463562011719
policy_loss: -0.0015747875440865755
entropy_loss: -2.850841760635376
value_loss: 691.4322509765625
loss: 345.71453857421875
policy_loss: -0.0008255839347839355
entropy_loss: -2.8507044315338135
value_loss: 649.2984008789062
loss: 324.64837646484375
policy_loss: 0.0001020822674036026
entropy_loss: -2.8505709171295166
value_loss: 646.2848510742188
loss: 323.14251708984375
policy_loss: -0.0017738924361765385
entropy_loss: -2.8504433631896973
value_loss: 663.3907470703125
loss: 331.693603515625
policy_loss: -0.0016396441496908665
entropy_loss: -2.8503034114837646
value_loss: 646.9949340820312
loss: 323.4958190917969
policy_loss: -0.00019549205899238586
entropy_loss: -2.8501436710357666
value_loss: 640.6266479492188
loss: 320.3131408691406
policy_loss: -0.002060176804661751
entropy_loss: -2.849998712539673
value_loss: 616.8551025390625
loss: 308.42547607421875
policy_loss: -0.0015163496136665344
entropy_loss: -2.8498330116271973
value_loss: 692.5159301757812
loss: 346.2564392089844
policy_loss: -0.0018649427220225334
entropy_loss: -2.849684238433838
value_loss: 656.2034912109375
loss: 328.0998840332031
policy_loss: -0.002225782722234726
entropy_loss: -2.849515438079834
value_loss: 648.3479614257812
loss: 324.1717529296875
policy_loss: -0.0008256193250417709
entropy_loss: -2.849364995956421
value_loss: 600.5179443359375
loss: 300.2581481933594
policy_loss: -0.0016222009435296059
entropy_loss: -2.8492469787597656
value_loss: 641.6799926757812
loss: 320.83837890625
policy_loss: -0.002997288480401039
entropy_loss: -2.8490843772888184
value_loss: 611.01513671875
loss: 305.50457763671875
policy_loss: 2.22744420170784e-05
entropy_loss: -2.848928689956665
value_loss: 610.365478515625
loss: 305.1827697753906
policy_loss: -0.001933615654706955
entropy_loss: -2.8487610816955566
value_loss: 633.3848876953125
loss: 316.6905212402344
policy_loss: -0.002949555404484272
entropy_loss: -2.848593235015869
value_loss: 643.1018676757812
loss: 321.5479736328125
policy_loss: 0.00044257380068302155
entropy_loss: -2.8484206199645996
value_loss: 630.744140625
loss: 315.3725280761719
policy_loss: -0.0027583828195929527
entropy_loss: -2.848257541656494
value_loss: 591.14306640625
loss: 295.56878662109375
policy_loss: -0.004347685724496841
entropy_loss: -2.8480565547943115
value_loss: 628.2373657226562
loss: 314.1143493652344
policy_loss: -0.00246405228972435
entropy_loss: -2.847881555557251
value_loss: 601.7673950195312
loss: 300.8812255859375
-------------------------------------------
| avg_speed               | 4.54          |
| is_success              | 0             |
| max_speed               | 4.54          |
| reward                  | -1.3691396    |
| rollout/                |               |
|    ep_len_mean          | 964           |
|    ep_rew_mean          | -1.26e+03     |
| time/                   |               |
|    fps                  | 122           |
|    iterations           | 5             |
|    time_elapsed         | 83            |
|    total_timesteps      | 20480         |
| train/                  |               |
|    approx_kl            | 0.00062255526 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.85         |
|    explained_variance   | 0.143         |
|    learning_rate        | 0.0003        |
|    loss                 | 301           |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.00102      |
|    std                  | 1             |
|    value_loss           | 669           |
-------------------------------------------
TRAINING:
weight : tensor([[ 0.1765, -0.3633, -0.0665,  ..., -0.0140, -0.2192, -0.3072],
        [ 0.0246,  0.1449, -0.0034,  ..., -0.0813, -0.0067, -0.0508],
        [-0.0723,  0.0541,  0.0340,  ..., -0.1734, -0.1276,  0.2230],
        ...,
        [ 0.2494, -0.0870,  0.2169,  ...,  0.2018, -0.2127,  0.3197],
        [-0.0420, -0.2575, -0.0568,  ..., -0.1332, -0.2779,  0.3094],
        [-0.0005,  0.1007, -0.1750,  ..., -0.0729,  0.0861,  0.0955]])
bias : tensor([ 0.0115, -0.0041,  0.0031, -0.0015, -0.0086,  0.0123,  0.0039, -0.0100,
        -0.0015, -0.0041,  0.0052,  0.0003, -0.0039,  0.0059, -0.0006,  0.0022,
        -0.0087, -0.0134, -0.0002,  0.0045, -0.0027,  0.0012, -0.0055, -0.0042,
         0.0139, -0.0048, -0.0061, -0.0023,  0.0071, -0.0003, -0.0060,  0.0028,
         0.0059,  0.0134,  0.0014, -0.0045,  0.0116, -0.0026,  0.0101,  0.0059,
        -0.0034, -0.0065,  0.0138,  0.0069, -0.0056, -0.0073,  0.0031,  0.0016,
        -0.0097,  0.0040, -0.0079, -0.0021, -0.0020,  0.0048,  0.0041,  0.0052,
        -0.0085, -0.0052,  0.0087, -0.0102,  0.0023, -0.0057,  0.0007, -0.0089])
weight : tensor([[-0.2181,  0.3496, -0.3318,  ..., -0.1712,  0.3041,  0.1762],
        [-0.1659, -0.1420, -0.0241,  ...,  0.0518, -0.3302,  0.0911],
        [-0.1287, -0.4225, -0.1410,  ...,  0.1894,  0.1344,  0.0110],
        ...,
        [ 0.2259,  0.1385, -0.2834,  ..., -0.0834,  0.0126, -0.0895],
        [-0.2405, -0.1294,  0.1514,  ...,  0.0455,  0.3082,  0.0831],
        [ 0.2035, -0.1979, -0.0115,  ..., -0.0708,  0.0362, -0.1224]])
bias : tensor([-0.0122,  0.0080,  0.0065, -0.0043, -0.0036, -0.0078, -0.0020,  0.0095,
         0.0058,  0.0052, -0.0089, -0.0073, -0.0079, -0.0071,  0.0027, -0.0012,
        -0.0013, -0.0022, -0.0002, -0.0024, -0.0093,  0.0054, -0.0063,  0.0062,
        -0.0076,  0.0010, -0.0086,  0.0087, -0.0068, -0.0024,  0.0012,  0.0107,
         0.0080,  0.0002, -0.0048, -0.0057,  0.0007,  0.0023, -0.0051, -0.0032,
         0.0118,  0.0053,  0.0092, -0.0003, -0.0048,  0.0105, -0.0040,  0.0099,
        -0.0017, -0.0051,  0.0011, -0.0093, -0.0045, -0.0066, -0.0007,  0.0017,
         0.0072,  0.0049, -0.0027, -0.0040,  0.0142,  0.0104,  0.0022,  0.0063])
policy_loss: 2.3888424038887024e-07
entropy_loss: -2.866706609725952
value_loss: 283.9570007324219
loss: 141.97850036621094
policy_loss: 4.848465323448181e-05
entropy_loss: -2.8667356967926025
value_loss: 281.6200866699219
loss: 140.81008911132812
policy_loss: -0.00014629866927862167
entropy_loss: -2.8667871952056885
value_loss: 302.703125
loss: 151.35140991210938
policy_loss: -5.222950130701065e-05
entropy_loss: -2.8668859004974365
value_loss: 286.1055603027344
loss: 143.052734375
policy_loss: -0.0003847777843475342
entropy_loss: -2.8668859004974365
value_loss: 286.2525634765625
loss: 143.1259002685547
policy_loss: -0.0003605671226978302
entropy_loss: -2.8668673038482666
value_loss: 292.127685546875
loss: 146.0634765625
policy_loss: -0.000753769651055336
entropy_loss: -2.866781711578369
value_loss: 286.0731201171875
loss: 143.0358123779297
policy_loss: -0.000992882065474987
entropy_loss: -2.8668177127838135
value_loss: 274.77105712890625
loss: 137.38453674316406
policy_loss: -0.000367563683539629
entropy_loss: -2.8667893409729004
value_loss: 278.40728759765625
loss: 139.20327758789062
policy_loss: -0.0011729374527931213
entropy_loss: -2.8667564392089844
value_loss: 279.18389892578125
loss: 139.5907745361328
policy_loss: -0.0019735898822546005
entropy_loss: -2.866729497909546
value_loss: 285.68853759765625
loss: 142.84230041503906
policy_loss: -0.002116287127137184
entropy_loss: -2.8666913509368896
value_loss: 278.70550537109375
loss: 139.3506317138672
policy_loss: -0.0027690520510077477
entropy_loss: -2.8666398525238037
value_loss: 271.54302978515625
loss: 135.7687530517578
policy_loss: -0.0032066525891423225
entropy_loss: -2.8666269779205322
value_loss: 283.3165588378906
loss: 141.6550750732422
policy_loss: -0.001446552574634552
entropy_loss: -2.8665719032287598
value_loss: 278.28631591796875
loss: 139.14170837402344
policy_loss: -0.0015873871743679047
entropy_loss: -2.86651611328125
value_loss: 270.17657470703125
loss: 135.08670043945312
policy_loss: -0.0025765737518668175
entropy_loss: -2.8664515018463135
value_loss: 275.2669372558594
loss: 137.63088989257812
policy_loss: -0.0029651764780282974
entropy_loss: -2.86641526222229
value_loss: 266.9953918457031
loss: 133.49473571777344
policy_loss: -0.0024670474231243134
entropy_loss: -2.866407871246338
value_loss: 273.7442626953125
loss: 136.86965942382812
policy_loss: -0.00565681979060173
entropy_loss: -2.8663599491119385
value_loss: 267.95751953125
loss: 133.9730987548828
policy_loss: -0.0040467469953000546
entropy_loss: -2.8662798404693604
value_loss: 276.0851745605469
loss: 138.03854370117188
policy_loss: -0.006932983174920082
entropy_loss: -2.86618971824646
value_loss: 263.7105407714844
loss: 131.8483428955078
policy_loss: -0.0024162447080016136
entropy_loss: -2.8660852909088135
value_loss: 257.79595947265625
loss: 128.89556884765625
policy_loss: -0.004324723966419697
entropy_loss: -2.866004705429077
value_loss: 267.0876159667969
loss: 133.53948974609375
policy_loss: -0.004751622676849365
entropy_loss: -2.865924596786499
value_loss: 256.0653381347656
loss: 128.02792358398438
policy_loss: -0.0066737160086631775
entropy_loss: -2.865852117538452
value_loss: 266.9877624511719
loss: 133.48721313476562
policy_loss: -0.005352901294827461
entropy_loss: -2.8658063411712646
value_loss: 260.3685302734375
loss: 130.1789093017578
policy_loss: -0.0046911220997571945
entropy_loss: -2.8657684326171875
value_loss: 261.5851745605469
loss: 130.78790283203125
policy_loss: -0.008246582001447678
entropy_loss: -2.865673065185547
value_loss: 261.98504638671875
loss: 130.98428344726562
policy_loss: -0.005513735115528107
entropy_loss: -2.8656258583068848
value_loss: 261.165283203125
loss: 130.57713317871094
policy_loss: -0.005455298349261284
entropy_loss: -2.8656041622161865
value_loss: 249.0422821044922
loss: 124.51568603515625
policy_loss: -0.0046384818851947784
entropy_loss: -2.865518093109131
value_loss: 253.58279418945312
loss: 126.78675842285156
policy_loss: -0.0071615856140851974
entropy_loss: -2.8654227256774902
value_loss: 252.0252685546875
loss: 126.0054702758789
policy_loss: -0.004548192024230957
entropy_loss: -2.8653199672698975
value_loss: 258.82916259765625
loss: 129.4100341796875
policy_loss: -0.008120924234390259
entropy_loss: -2.8651959896087646
value_loss: 252.04141235351562
loss: 126.01258850097656
policy_loss: -0.006438246928155422
entropy_loss: -2.865065097808838
value_loss: 243.60189819335938
loss: 121.79450988769531
policy_loss: -0.006496939808130264
entropy_loss: -2.8650031089782715
value_loss: 240.03846740722656
loss: 120.01273345947266
policy_loss: -0.007650407496839762
entropy_loss: -2.8649277687072754
value_loss: 251.11663818359375
loss: 125.55066680908203
policy_loss: -0.008446864783763885
entropy_loss: -2.864868402481079
value_loss: 241.486328125
loss: 120.7347183227539
policy_loss: -0.004983081482350826
entropy_loss: -2.864809513092041
value_loss: 254.92489624023438
loss: 127.45746612548828
------------------------------------------
| avg_speed               | 2.22         |
| is_success              | 0            |
| max_speed               | 2.22         |
| reward                  | -1.2430177   |
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -1.19e+03    |
| time/                   |              |
|    fps                  | 121          |
|    iterations           | 5            |
|    time_elapsed         | 84           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0038213972 |
|    clip_fraction        | 0.00977      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.87        |
|    explained_variance   | 0.159        |
|    learning_rate        | 0.0003       |
|    loss                 | 127          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0037      |
|    std                  | 1.01         |
|    value_loss           | 268          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.2373, -0.3017,  0.1517,  ...,  0.0399,  0.3521, -0.0180],
        [-0.1640,  0.1189, -0.0434,  ..., -0.1569, -0.1264,  0.2529],
        [-0.0627, -0.2338,  0.3639,  ...,  0.1832,  0.0216,  0.0530],
        ...,
        [-0.1313, -0.0595,  0.0647,  ...,  0.0536,  0.3734,  0.0592],
        [-0.2504, -0.3594,  0.2081,  ...,  0.0712, -0.1457,  0.0514],
        [-0.1721, -0.1452,  0.1296,  ...,  0.2089, -0.3281,  0.0164]])
bias : tensor([ 2.2317e-03,  6.9435e-04, -7.2914e-04,  1.9284e-03,  1.2600e-03,
         5.1778e-03,  1.8770e-03,  1.7545e-03, -1.4625e-03, -1.0268e-03,
         8.4088e-06,  4.9577e-04, -5.5377e-03,  2.7390e-04, -2.8487e-03,
         7.5583e-03,  4.2945e-03, -5.2504e-03,  5.1265e-03,  2.1976e-03,
        -3.2946e-03,  5.7079e-03,  1.7606e-03, -2.4049e-03,  1.4231e-03,
         3.2444e-04, -3.9529e-03,  2.6928e-03, -3.2761e-03, -2.9994e-03,
        -3.0067e-03,  2.8875e-03, -2.1442e-03, -2.0484e-03, -3.2516e-03,
         1.3975e-04,  1.8497e-03,  1.9537e-03,  2.5367e-03, -1.7251e-03,
        -5.8279e-03, -1.0782e-03, -6.7311e-04,  1.9707e-03,  2.6464e-04,
         1.2132e-03,  1.1083e-03,  5.5600e-04, -3.7130e-03,  8.8641e-03,
         2.7867e-03,  2.5131e-03, -2.3361e-04,  3.1051e-03, -6.8379e-04,
        -2.6772e-03, -2.9186e-03,  4.3892e-03,  1.5291e-03, -2.8097e-03,
        -2.1267e-04,  8.6278e-03, -1.1596e-03, -5.3323e-03])
weight : tensor([[-0.3384, -0.1544, -0.0192,  ..., -0.2078,  0.1366, -0.0010],
        [ 0.2527,  0.0919, -0.1836,  ...,  0.1356, -0.2484,  0.2395],
        [ 0.0891, -0.1901, -0.1880,  ...,  0.0378, -0.0181,  0.2600],
        ...,
        [ 0.0690, -0.0703, -0.2742,  ...,  0.1751, -0.0219, -0.3427],
        [ 0.2642,  0.0593, -0.0155,  ..., -0.0855, -0.2065, -0.1078],
        [-0.2264,  0.0085,  0.0469,  ...,  0.0748,  0.0296, -0.0100]])
bias : tensor([-0.0068, -0.0028,  0.0043, -0.0027,  0.0047, -0.0011,  0.0041,  0.0024,
         0.0035,  0.0067, -0.0004, -0.0006,  0.0012, -0.0002,  0.0020,  0.0028,
         0.0029,  0.0016, -0.0003, -0.0013,  0.0018, -0.0007, -0.0038,  0.0006,
         0.0008,  0.0042,  0.0011,  0.0038,  0.0024, -0.0037, -0.0009,  0.0006,
         0.0035, -0.0026, -0.0048,  0.0002,  0.0018,  0.0016,  0.0012,  0.0044,
         0.0002, -0.0030, -0.0034, -0.0013,  0.0019, -0.0026, -0.0018,  0.0006,
        -0.0007,  0.0016, -0.0036,  0.0013, -0.0043,  0.0023, -0.0007,  0.0014,
         0.0032,  0.0015, -0.0055,  0.0025,  0.0041,  0.0008,  0.0056, -0.0021])
policy_loss: 1.5692785382270813e-07
entropy_loss: -2.8637962341308594
value_loss: 405.0851135253906
loss: 202.5425567626953
policy_loss: -2.6555266231298447e-05
entropy_loss: -2.8638193607330322
value_loss: 397.7847900390625
loss: 198.89236450195312
policy_loss: -0.00021618790924549103
entropy_loss: -2.8638672828674316
value_loss: 385.5547790527344
loss: 192.7771759033203
policy_loss: 0.00018304027616977692
entropy_loss: -2.863910436630249
value_loss: 369.005859375
loss: 184.50311279296875
policy_loss: -0.00011387653648853302
entropy_loss: -2.8639092445373535
value_loss: 405.50189208984375
loss: 202.75083923339844
policy_loss: -1.8490944057703018e-05
entropy_loss: -2.8639066219329834
value_loss: 377.7614440917969
loss: 188.88070678710938
policy_loss: -0.001125231385231018
entropy_loss: -2.86393141746521
value_loss: 368.37506103515625
loss: 184.1864013671875
policy_loss: -2.7357134968042374e-05
entropy_loss: -2.8639371395111084
value_loss: 392.5376892089844
loss: 196.26881408691406
policy_loss: -0.0009618820622563362
entropy_loss: -2.8639159202575684
value_loss: 374.65228271484375
loss: 187.32518005371094
policy_loss: 9.788107126951218e-05
entropy_loss: -2.8638837337493896
value_loss: 374.7510986328125
loss: 187.37564086914062
policy_loss: -0.000289110466837883
entropy_loss: -2.8638901710510254
value_loss: 398.23272705078125
loss: 199.11607360839844
policy_loss: -0.0015910621732473373
entropy_loss: -2.8638572692871094
value_loss: 378.3885192871094
loss: 189.1926727294922
policy_loss: 0.00024786219000816345
entropy_loss: -2.863821506500244
value_loss: 364.2914733886719
loss: 182.14598083496094
policy_loss: -0.0013047903776168823
entropy_loss: -2.8637619018554688
value_loss: 392.2529602050781
loss: 196.1251678466797
policy_loss: -0.0004988545551896095
entropy_loss: -2.863710880279541
value_loss: 380.0345458984375
loss: 190.0167694091797
policy_loss: -0.0032287826761603355
entropy_loss: -2.863645076751709
value_loss: 368.2190856933594
loss: 184.10630798339844
policy_loss: -0.003487495705485344
entropy_loss: -2.8636057376861572
value_loss: 379.2220458984375
loss: 189.60752868652344
policy_loss: -0.0018402226269245148
entropy_loss: -2.8635687828063965
value_loss: 354.842041015625
loss: 177.41917419433594
policy_loss: 0.0017170379869639874
entropy_loss: -2.863584041595459
value_loss: 385.2088623046875
loss: 192.6061553955078
policy_loss: -0.0024478863924741745
entropy_loss: -2.863569736480713
value_loss: 363.44415283203125
loss: 181.71963500976562
policy_loss: -0.0036713071167469025
entropy_loss: -2.8635101318359375
value_loss: 367.95428466796875
loss: 183.9734649658203
policy_loss: -0.00048593804240226746
entropy_loss: -2.8634133338928223
value_loss: 368.02764892578125
loss: 184.01333618164062
policy_loss: 0.0010475963354110718
entropy_loss: -2.8633322715759277
value_loss: 363.6410827636719
loss: 181.82159423828125
policy_loss: -0.005152381956577301
entropy_loss: -2.8632428646087646
value_loss: 359.2674255371094
loss: 179.62855529785156
policy_loss: -0.0034136297181248665
entropy_loss: -2.863198757171631
value_loss: 370.9345397949219
loss: 185.46385192871094
policy_loss: 0.0016517050098627806
entropy_loss: -2.8630940914154053
value_loss: 332.52789306640625
loss: 166.26559448242188
policy_loss: -0.0015127873048186302
entropy_loss: -2.8630311489105225
value_loss: 346.5439758300781
loss: 173.27047729492188
policy_loss: -0.006113468669354916
entropy_loss: -2.863008975982666
value_loss: 385.36614990234375
loss: 192.6769561767578
policy_loss: -0.002833048813045025
entropy_loss: -2.8629910945892334
value_loss: 334.09307861328125
loss: 167.043701171875
policy_loss: -0.003458874300122261
entropy_loss: -2.863020420074463
value_loss: 366.48016357421875
loss: 183.2366180419922
policy_loss: -0.003241535509005189
entropy_loss: -2.8630259037017822
value_loss: 375.73681640625
loss: 187.86517333984375
policy_loss: -0.000996394082903862
entropy_loss: -2.863025426864624
value_loss: 335.91864013671875
loss: 167.9583282470703
policy_loss: -0.0017171204090118408
entropy_loss: -2.863029718399048
value_loss: 352.1395263671875
loss: 176.0680389404297
policy_loss: -0.0033758017234504223
entropy_loss: -2.8630292415618896
value_loss: 343.0838928222656
loss: 171.53857421875
policy_loss: -0.0034151803702116013
entropy_loss: -2.863067865371704
value_loss: 347.6434631347656
loss: 173.8183135986328
policy_loss: -0.003384376410394907
entropy_loss: -2.8630623817443848
value_loss: 346.77203369140625
loss: 173.38262939453125
policy_loss: -0.0073892767541110516
entropy_loss: -2.8630928993225098
value_loss: 323.0279846191406
loss: 161.50660705566406
policy_loss: -0.002279287204146385
entropy_loss: -2.8631081581115723
value_loss: 349.3202209472656
loss: 174.6578369140625
policy_loss: 0.0007325764745473862
entropy_loss: -2.8631186485290527
value_loss: 335.21435546875
loss: 167.60791015625
policy_loss: -0.0030586186330765486
entropy_loss: -2.8631551265716553
value_loss: 359.8382568359375
loss: 179.91607666015625
------------------------------------------
| avg_speed               | 1.95         |
| is_success              | 0            |
| max_speed               | 1.95         |
| reward                  | -1.27663     |
| rollout/                |              |
|    ep_len_mean          | 969          |
|    ep_rew_mean          | -1.11e+03    |
| time/                   |              |
|    fps                  | 116          |
|    iterations           | 5            |
|    time_elapsed         | 88           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0023586722 |
|    clip_fraction        | 0.0061       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | 180          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00167     |
|    std                  | 1.01         |
|    value_loss           | 367          |
------------------------------------------
TRAINING:
weight : tensor([[ 0.0721,  0.4057,  0.2395,  ..., -0.0382,  0.0314,  0.3012],
        [ 0.1256,  0.3354,  0.1160,  ..., -0.0966, -0.3118, -0.1922],
        [ 0.1144,  0.1851,  0.0227,  ...,  0.4146, -0.1225,  0.4016],
        ...,
        [ 0.0301,  0.1466, -0.2615,  ..., -0.3825, -0.0767, -0.1399],
        [-0.2718,  0.0089,  0.0692,  ..., -0.0111,  0.0189, -0.1132],
        [ 0.1541,  0.1630,  0.3127,  ..., -0.1115,  0.1881,  0.2674]])
bias : tensor([-3.0020e-03,  6.9454e-04, -1.7061e-03, -1.5058e-03, -2.4365e-03,
        -5.7612e-04, -1.7462e-03, -1.1811e-03, -3.8655e-04, -3.4050e-04,
        -1.8121e-03,  2.8641e-03, -3.2152e-03,  6.2383e-03,  8.9763e-05,
        -1.8012e-03, -2.6921e-03,  4.0474e-03, -4.5607e-03,  2.6771e-04,
         4.7889e-03, -4.6863e-03, -1.3772e-03,  4.4910e-03, -1.6466e-03,
        -6.1435e-03,  3.8111e-05, -8.7637e-04,  1.2061e-03,  4.5782e-03,
        -7.6294e-03,  2.0536e-03,  2.7024e-03,  2.3424e-03,  3.6633e-03,
        -1.5516e-03, -1.2329e-03,  2.0188e-03,  9.9583e-04,  5.9889e-03,
        -3.3907e-03,  6.2104e-03, -3.9099e-03,  2.8223e-03, -6.8154e-03,
         1.9985e-03, -3.2819e-03,  4.5030e-03,  1.0295e-04,  3.9585e-03,
         2.3156e-03,  7.4607e-04,  1.0975e-03,  4.1081e-03,  5.3734e-03,
         4.3362e-04,  3.8388e-03, -4.0730e-04, -2.6096e-03, -5.2089e-03,
         2.9625e-04, -1.3453e-03, -6.3162e-04,  1.3292e-03])
weight : tensor([[-0.1730,  0.0851,  0.1626,  ..., -0.2987,  0.0030, -0.0786],
        [ 0.0448, -0.2647,  0.0877,  ...,  0.1021,  0.0819,  0.3118],
        [-0.0688,  0.2345, -0.1129,  ..., -0.1642, -0.2262,  0.1558],
        ...,
        [ 0.2288,  0.3867,  0.1890,  ..., -0.0480,  0.4145,  0.2071],
        [-0.0467,  0.2798,  0.1213,  ..., -0.2109,  0.1508, -0.2208],
        [ 0.0466, -0.0552,  0.3628,  ...,  0.0091,  0.0253, -0.2421]])
bias : tensor([-2.8056e-04, -1.1528e-03,  3.2878e-05, -2.7173e-03,  6.7832e-04,
         1.0303e-03,  4.3325e-03,  7.6280e-04,  2.2681e-03, -4.2415e-03,
         8.7306e-04, -2.1760e-03,  2.1096e-03,  6.2071e-04,  3.5153e-03,
         1.1250e-03,  1.0987e-03,  4.9307e-03,  3.0317e-03, -3.5229e-04,
        -6.7514e-03, -1.8209e-04, -2.5065e-03, -4.4998e-04,  3.2258e-03,
         1.9172e-03, -4.0643e-04, -2.5658e-03,  3.0119e-03, -4.4523e-03,
         4.4527e-03, -4.0301e-03,  6.1615e-04,  1.5946e-04,  1.7733e-03,
         5.1207e-03, -4.9941e-04,  3.3821e-03, -3.7275e-03, -1.1027e-03,
         1.3010e-03,  4.8117e-03,  8.7415e-04,  1.4362e-03,  2.9089e-03,
        -2.6168e-03,  9.6681e-03, -6.4917e-03,  6.3498e-03, -5.5786e-03,
         2.7463e-03,  4.3907e-03,  5.3332e-03,  6.5429e-04,  2.2064e-03,
        -4.2302e-03,  2.7670e-04, -2.7761e-04, -1.1330e-03, -2.8806e-04,
         2.0501e-03, -1.7699e-03, -4.1819e-04,  1.3445e-03])
policy_loss: 7.636845111846924e-08
entropy_loss: -2.847703456878662
value_loss: 410.3718566894531
loss: 205.18592834472656
policy_loss: 4.6454835683107376e-05
entropy_loss: -2.847503423690796
value_loss: 398.15863037109375
loss: 199.07936096191406
policy_loss: 1.4720484614372253e-05
entropy_loss: -2.847282648086548
value_loss: 406.8811950683594
loss: 203.44061279296875
policy_loss: -0.00020753033459186554
entropy_loss: -2.847078800201416
value_loss: 380.1273193359375
loss: 190.06344604492188
policy_loss: -0.00013389065861701965
entropy_loss: -2.8468363285064697
value_loss: 394.61090087890625
loss: 197.30531311035156
policy_loss: -7.845088839530945e-05
entropy_loss: -2.8465845584869385
value_loss: 419.6995544433594
loss: 209.84970092773438
policy_loss: -0.0004397425800561905
entropy_loss: -2.8463704586029053
value_loss: 386.92987060546875
loss: 193.46449279785156
policy_loss: -0.001774805597960949
entropy_loss: -2.8461976051330566
value_loss: 369.9663391113281
loss: 184.9813995361328
policy_loss: -0.0008036904036998749
entropy_loss: -2.8458902835845947
value_loss: 376.259765625
loss: 188.1290740966797
policy_loss: -0.0010602790862321854
entropy_loss: -2.8455758094787598
value_loss: 374.58258056640625
loss: 187.2902374267578
policy_loss: -0.002375621348619461
entropy_loss: -2.8453049659729004
value_loss: 388.2506103515625
loss: 194.1229248046875
policy_loss: -0.0005694588180631399
entropy_loss: -2.8450090885162354
value_loss: 407.7048034667969
loss: 203.85183715820312
policy_loss: -0.0018569286912679672
entropy_loss: -2.8446810245513916
value_loss: 389.7408752441406
loss: 194.8685760498047
policy_loss: -0.0011563580483198166
entropy_loss: -2.844308376312256
value_loss: 388.459228515625
loss: 194.22845458984375
policy_loss: -0.0021118514705449343
entropy_loss: -2.843994379043579
value_loss: 367.4832458496094
loss: 183.73951721191406
policy_loss: -0.0034330151975154877
entropy_loss: -2.8436777591705322
value_loss: 377.6743469238281
loss: 188.833740234375
policy_loss: -0.003895131405442953
entropy_loss: -2.843334436416626
value_loss: 382.8135986328125
loss: 191.4029083251953
policy_loss: -0.0007694456726312637
entropy_loss: -2.842949151992798
value_loss: 335.1454162597656
loss: 167.5719451904297
policy_loss: -0.005261393263936043
entropy_loss: -2.8426129817962646
value_loss: 397.6394958496094
loss: 198.81448364257812
policy_loss: -0.002096114680171013
entropy_loss: -2.84226393699646
value_loss: 384.41607666015625
loss: 192.20594787597656
policy_loss: -0.006629683077335358
entropy_loss: -2.8419265747070312
value_loss: 349.0563659667969
loss: 174.5215606689453
policy_loss: -0.0024861209094524384
entropy_loss: -2.8415894508361816
value_loss: 370.33074951171875
loss: 185.1628875732422
policy_loss: -0.0015231389552354813
entropy_loss: -2.8412461280822754
value_loss: 361.88482666015625
loss: 180.94088745117188
policy_loss: -0.005157750099897385
entropy_loss: -2.840949773788452
value_loss: 396.30059814453125
loss: 198.1451416015625
policy_loss: -0.00838400423526764
entropy_loss: -2.840623378753662
value_loss: 358.24560546875
loss: 179.1144256591797
policy_loss: 0.000695754773914814
entropy_loss: -2.8403472900390625
value_loss: 360.36456298828125
loss: 180.1829833984375
policy_loss: -0.0021296292543411255
entropy_loss: -2.840076208114624
value_loss: 381.712646484375
loss: 190.85418701171875
policy_loss: -0.01051964983344078
entropy_loss: -2.8398118019104004
value_loss: 355.4375305175781
loss: 177.708251953125
policy_loss: -0.0018221326172351837
entropy_loss: -2.8394968509674072
value_loss: 369.21722412109375
loss: 184.60679626464844
policy_loss: -0.00698714517056942
entropy_loss: -2.8392179012298584
value_loss: 365.90582275390625
loss: 182.9459228515625
policy_loss: -0.006965518929064274
entropy_loss: -2.838961124420166
value_loss: 342.8308410644531
loss: 171.40846252441406
policy_loss: -0.006837301887571812
entropy_loss: -2.838695764541626
value_loss: 356.45306396484375
loss: 178.21969604492188
policy_loss: -0.004972616210579872
entropy_loss: -2.838409662246704
value_loss: 353.1776123046875
loss: 176.58383178710938
policy_loss: -0.009544332511723042
entropy_loss: -2.8381409645080566
value_loss: 347.7403259277344
loss: 173.86062622070312
policy_loss: -0.004550592042505741
entropy_loss: -2.8379018306732178
value_loss: 354.79620361328125
loss: 177.3935546875
policy_loss: -0.004451886750757694
entropy_loss: -2.8376657962799072
value_loss: 357.87811279296875
loss: 178.93460083007812
policy_loss: -0.007793571799993515
entropy_loss: -2.8374364376068115
value_loss: 351.0128479003906
loss: 175.49862670898438
policy_loss: -0.00472482992336154
entropy_loss: -2.837188959121704
value_loss: 336.55963134765625
loss: 168.27508544921875
policy_loss: -0.007081455085426569
entropy_loss: -2.8369791507720947
value_loss: 353.36981201171875
loss: 176.67782592773438
policy_loss: -0.004583943635225296
entropy_loss: -2.8367841243743896
value_loss: 352.36480712890625
loss: 176.17782592773438
-----------------------------------
| avg_speed          | 1.87       |
| is_success         | 0          |
| max_speed          | 1.87       |
| reward             | -0.9487894 |
| rollout/           |            |
|    ep_len_mean     | 967        |
|    ep_rew_mean     | -1.26e+03  |
| time/              |            |
|    fps             | 124        |
|    iterations      | 1          |
|    time_elapsed    | 16         |
|    total_timesteps | 22528      |
-----------------------------------
TRAINING:
weight : tensor([[ 0.1771, -0.3641, -0.0648,  ..., -0.0152, -0.2192, -0.3063],
        [ 0.0239,  0.1428, -0.0048,  ..., -0.0807, -0.0077, -0.0516],
        [-0.0716,  0.0565,  0.0357,  ..., -0.1769, -0.1269,  0.2227],
        ...,
        [ 0.2493, -0.0848,  0.2166,  ...,  0.2050, -0.2116,  0.3212],
        [-0.0412, -0.2569, -0.0578,  ..., -0.1303, -0.2782,  0.3101],
        [-0.0026,  0.0990, -0.1780,  ..., -0.0697,  0.0865,  0.0949]])
bias : tensor([ 0.0133, -0.0069,  0.0042,  0.0005, -0.0110,  0.0139,  0.0040, -0.0124,
        -0.0022, -0.0064,  0.0078, -0.0019, -0.0056,  0.0063, -0.0024,  0.0012,
        -0.0101, -0.0156, -0.0011,  0.0060, -0.0026,  0.0031, -0.0075, -0.0060,
         0.0177, -0.0064, -0.0092, -0.0021,  0.0100,  0.0018, -0.0071,  0.0032,
         0.0069,  0.0158,  0.0038, -0.0052,  0.0132, -0.0055,  0.0132,  0.0070,
        -0.0048, -0.0066,  0.0170,  0.0105, -0.0069, -0.0100,  0.0037,  0.0016,
        -0.0126,  0.0039, -0.0095, -0.0024, -0.0039,  0.0071,  0.0047,  0.0068,
        -0.0127, -0.0063,  0.0128, -0.0145,  0.0015, -0.0036,  0.0013, -0.0104])
weight : tensor([[-0.2137,  0.3465, -0.3335,  ..., -0.1707,  0.3047,  0.1770],
        [-0.1682, -0.1413, -0.0233,  ...,  0.0501, -0.3292,  0.0903],
        [-0.1308, -0.4219, -0.1410,  ...,  0.1896,  0.1337,  0.0106],
        ...,
        [ 0.2222,  0.1407, -0.2833,  ..., -0.0818,  0.0112, -0.0905],
        [-0.2407, -0.1293,  0.1514,  ...,  0.0451,  0.3086,  0.0828],
        [ 0.2027, -0.1973, -0.0108,  ..., -0.0704,  0.0358, -0.1219]])
bias : tensor([-0.0162,  0.0099,  0.0095, -0.0030, -0.0018, -0.0102, -0.0034,  0.0122,
         0.0088,  0.0069, -0.0106, -0.0111, -0.0105, -0.0085,  0.0035, -0.0028,
        -0.0030, -0.0018, -0.0003, -0.0032, -0.0108,  0.0071, -0.0084,  0.0073,
        -0.0089, -0.0005, -0.0101,  0.0112, -0.0089, -0.0026,  0.0024,  0.0127,
         0.0104,  0.0014, -0.0049, -0.0071, -0.0003,  0.0031, -0.0076, -0.0053,
         0.0152,  0.0068,  0.0109,  0.0002, -0.0050,  0.0134, -0.0043,  0.0121,
        -0.0036, -0.0080,  0.0015, -0.0101, -0.0073, -0.0089, -0.0014,  0.0014,
         0.0102,  0.0061, -0.0028, -0.0048,  0.0181,  0.0145,  0.0022,  0.0084])
policy_loss: -1.1641532182693481e-07
entropy_loss: -2.864767551422119
value_loss: 314.23040771484375
loss: 157.11520385742188
policy_loss: -6.262119859457016e-05
entropy_loss: -2.8647654056549072
value_loss: 305.72491455078125
loss: 152.86239624023438
policy_loss: -0.0001370287500321865
entropy_loss: -2.8647425174713135
value_loss: 310.6666259765625
loss: 155.3331756591797
policy_loss: -1.4334917068481445e-05
entropy_loss: -2.864759922027588
value_loss: 313.1998291015625
loss: 156.5998992919922
policy_loss: -0.0005130632780492306
entropy_loss: -2.8647806644439697
value_loss: 307.2681579589844
loss: 153.63356018066406
policy_loss: 0.00016687344759702682
entropy_loss: -2.864845037460327
value_loss: 298.64141845703125
loss: 149.3208770751953
policy_loss: 0.00010632304474711418
entropy_loss: -2.8649063110351562
value_loss: 308.4266662597656
loss: 154.21343994140625
policy_loss: -0.00100712850689888
entropy_loss: -2.8649747371673584
value_loss: 311.29925537109375
loss: 155.64862060546875
policy_loss: -0.0003637373447418213
entropy_loss: -2.865034580230713
value_loss: 306.4991455078125
loss: 153.24920654296875
policy_loss: -0.0009036143310368061
entropy_loss: -2.8651082515716553
value_loss: 308.3911437988281
loss: 154.19467163085938
policy_loss: -0.0007990635931491852
entropy_loss: -2.8652002811431885
value_loss: 299.8229064941406
loss: 149.91065979003906
policy_loss: -0.00024261511862277985
entropy_loss: -2.86531662940979
value_loss: 282.5148010253906
loss: 141.2571563720703
policy_loss: -0.0010631927289068699
entropy_loss: -2.8654019832611084
value_loss: 302.18450927734375
loss: 151.0911865234375
policy_loss: -0.0008689053356647491
entropy_loss: -2.8654913902282715
value_loss: 300.6793518066406
loss: 150.33880615234375
policy_loss: 0.00013620639219880104
entropy_loss: -2.865598201751709
value_loss: 287.41864013671875
loss: 143.70945739746094
policy_loss: -0.002016207203269005
entropy_loss: -2.8657071590423584
value_loss: 272.1345520019531
loss: 136.0652618408203
policy_loss: -0.0014897454530000687
entropy_loss: -2.8658158779144287
value_loss: 278.9836730957031
loss: 139.49034118652344
policy_loss: -0.0006601028144359589
entropy_loss: -2.8659403324127197
value_loss: 283.18621826171875
loss: 141.5924530029297
policy_loss: -0.0017945985309779644
entropy_loss: -2.866028070449829
value_loss: 289.93865966796875
loss: 144.967529296875
policy_loss: -0.0013468693941831589
entropy_loss: -2.8661558628082275
value_loss: 272.6873779296875
loss: 136.34234619140625
policy_loss: 0.0002860724925994873
entropy_loss: -2.866281032562256
value_loss: 278.1882019042969
loss: 139.09439086914062
policy_loss: -0.003732757642865181
entropy_loss: -2.866407871246338
value_loss: 269.206298828125
loss: 134.5994110107422
policy_loss: -0.002509966492652893
entropy_loss: -2.8665428161621094
value_loss: 269.02496337890625
loss: 134.50997924804688
policy_loss: -0.0010116510093212128
entropy_loss: -2.8666739463806152
value_loss: 269.6599426269531
loss: 134.82896423339844
policy_loss: -0.0026223319582641125
entropy_loss: -2.8668150901794434
value_loss: 272.8709716796875
loss: 136.432861328125
policy_loss: -0.000766318291425705
entropy_loss: -2.8669354915618896
value_loss: 278.2841491699219
loss: 139.1413116455078
policy_loss: -0.0026825638487935066
entropy_loss: -2.8670499324798584
value_loss: 249.2158966064453
loss: 124.60526275634766
policy_loss: -0.0027037393301725388
entropy_loss: -2.86716628074646
value_loss: 248.03504943847656
loss: 124.01482391357422
policy_loss: -0.0014106985181570053
entropy_loss: -2.8673195838928223
value_loss: 256.2830505371094
loss: 128.14012145996094
policy_loss: -0.00586935319006443
entropy_loss: -2.8674545288085938
value_loss: 254.71177673339844
loss: 127.35002136230469
policy_loss: 0.0008697062730789185
entropy_loss: -2.8675730228424072
value_loss: 247.83641052246094
loss: 123.91907501220703
policy_loss: -0.0038864053785800934
entropy_loss: -2.867717981338501
value_loss: 252.4327850341797
loss: 126.21250915527344
policy_loss: -0.006838850677013397
entropy_loss: -2.8678793907165527
value_loss: 246.61404418945312
loss: 123.30018615722656
policy_loss: -0.0031436700373888016
entropy_loss: -2.867999792098999
value_loss: 246.43470764160156
loss: 123.2142105102539
policy_loss: -0.002231529913842678
entropy_loss: -2.8681414127349854
value_loss: 237.71261596679688
loss: 118.85408020019531
policy_loss: 0.0004911292344331741
entropy_loss: -2.8682825565338135
value_loss: 244.4446563720703
loss: 122.22281646728516
policy_loss: -0.0005046511068940163
entropy_loss: -2.868436336517334
value_loss: 244.05938720703125
loss: 122.02919006347656
policy_loss: -0.0002070646733045578
entropy_loss: -2.868600606918335
value_loss: 234.23507690429688
loss: 117.1173324584961
policy_loss: -0.008015966042876244
entropy_loss: -2.868751287460327
value_loss: 229.28640747070312
loss: 114.63518524169922
policy_loss: -0.005050869658589363
entropy_loss: -2.868879795074463
value_loss: 233.34121704101562
loss: 116.66555786132812
-----------------------------------
| avg_speed          | 3.34       |
| is_success         | 0          |
| max_speed          | 3.34       |
| reward             | -1.1520541 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.19e+03  |
| time/              |            |
|    fps             | 124        |
|    iterations      | 1          |
|    time_elapsed    | 16         |
|    total_timesteps | 22528      |
-----------------------------------
TRAINING:
weight : tensor([[ 0.2383, -0.3027,  0.1488,  ...,  0.0393,  0.3504, -0.0184],
        [-0.1632,  0.1188, -0.0431,  ..., -0.1582, -0.1262,  0.2532],
        [-0.0616, -0.2355,  0.3627,  ...,  0.1830,  0.0209,  0.0525],
        ...,
        [-0.1293, -0.0612,  0.0636,  ...,  0.0561,  0.3719,  0.0587],
        [-0.2455, -0.3638,  0.2058,  ...,  0.0712, -0.1460,  0.0504],
        [-0.1728, -0.1446,  0.1289,  ...,  0.2088, -0.3279,  0.0170]])
bias : tensor([ 0.0004,  0.0023, -0.0034,  0.0013,  0.0028,  0.0025,  0.0019,  0.0009,
        -0.0011, -0.0017,  0.0025,  0.0004, -0.0034,  0.0009,  0.0006,  0.0051,
         0.0048, -0.0034,  0.0015,  0.0015, -0.0012,  0.0045,  0.0037, -0.0010,
        -0.0014, -0.0026, -0.0035,  0.0008, -0.0024, -0.0029, -0.0020,  0.0002,
        -0.0011,  0.0010, -0.0024,  0.0018, -0.0017,  0.0004,  0.0023,  0.0004,
        -0.0026, -0.0027, -0.0012,  0.0001,  0.0016, -0.0019,  0.0002,  0.0018,
        -0.0009,  0.0064,  0.0005,  0.0020, -0.0007, -0.0017, -0.0011, -0.0020,
        -0.0038,  0.0019,  0.0032,  0.0002,  0.0017,  0.0059, -0.0041, -0.0056])
weight : tensor([[-0.3387, -0.1540, -0.0197,  ..., -0.2076,  0.1360, -0.0019],
        [ 0.2517,  0.0922, -0.1850,  ...,  0.1362, -0.2505,  0.2389],
        [ 0.0901, -0.1904, -0.1868,  ...,  0.0371, -0.0161,  0.2607],
        ...,
        [ 0.0696, -0.0706, -0.2738,  ...,  0.1745, -0.0209, -0.3423],
        [ 0.2644,  0.0591, -0.0153,  ..., -0.0858, -0.2061, -0.1075],
        [-0.2265,  0.0086,  0.0471,  ...,  0.0746,  0.0299, -0.0092]])
bias : tensor([-5.3672e-03,  1.9595e-04, -4.7824e-04,  1.7313e-04,  4.2001e-03,
        -1.2355e-03,  2.7524e-03,  2.1858e-03,  3.1451e-04,  5.4723e-03,
        -1.3809e-03,  1.5595e-03, -2.2560e-03, -1.1783e-03,  1.5607e-03,
         1.4215e-03,  1.5608e-03,  1.7689e-03, -1.5492e-03, -2.0755e-03,
         3.2860e-03,  1.0314e-03, -9.5076e-04,  1.3513e-03, -1.1078e-03,
         2.2241e-03, -2.9793e-04,  1.2477e-03, -1.6074e-04, -4.3464e-03,
         1.4733e-03, -4.2613e-04,  1.1534e-03, -5.0445e-04, -3.8924e-03,
        -1.7221e-03,  4.6117e-04,  1.5727e-03,  2.2729e-03,  3.4678e-03,
         1.3762e-03, -1.8869e-03, -6.1000e-04,  4.6733e-05,  1.4447e-03,
        -1.9262e-03, -7.8608e-05,  2.0119e-03,  2.4763e-03,  1.0922e-03,
        -1.8008e-03,  2.9977e-03, -3.9825e-03,  4.3405e-04, -1.4814e-03,
         6.3122e-04,  1.5904e-03,  1.0216e-03, -2.8769e-03,  2.9210e-03,
         2.4421e-03, -2.7237e-04,  4.2762e-03, -2.1740e-03])
policy_loss: -1.30385160446167e-08
entropy_loss: -2.8632142543792725
value_loss: 482.25128173828125
loss: 241.12564086914062
policy_loss: 5.166791379451752e-05
entropy_loss: -2.863258123397827
value_loss: 463.9981689453125
loss: 231.99913024902344
policy_loss: 0.00015053339302539825
entropy_loss: -2.8632891178131104
value_loss: 477.6834411621094
loss: 238.8418731689453
policy_loss: 0.00011569634079933167
entropy_loss: -2.863320827484131
value_loss: 478.7406311035156
loss: 239.3704376220703
policy_loss: 0.00017918972298502922
entropy_loss: -2.8633484840393066
value_loss: 501.2082214355469
loss: 250.6042938232422
policy_loss: -3.3404678106307983e-05
entropy_loss: -2.8633692264556885
value_loss: 469.84539794921875
loss: 234.92266845703125
policy_loss: -0.00020879553630948067
entropy_loss: -2.8633687496185303
value_loss: 466.3990783691406
loss: 233.19932556152344
policy_loss: -0.0001056501641869545
entropy_loss: -2.8633744716644287
value_loss: 430.736328125
loss: 215.36805725097656
policy_loss: -0.0008323965594172478
entropy_loss: -2.8633840084075928
value_loss: 501.4534912109375
loss: 250.7259063720703
policy_loss: -0.0002168598584830761
entropy_loss: -2.863415002822876
value_loss: 446.63470458984375
loss: 223.317138671875
policy_loss: -0.0005059279501438141
entropy_loss: -2.8634111881256104
value_loss: 430.19390869140625
loss: 215.09645080566406
policy_loss: 0.00036718323826789856
entropy_loss: -2.8633954524993896
value_loss: 449.02093505859375
loss: 224.51083374023438
policy_loss: -0.0005155950784683228
entropy_loss: -2.863386392593384
value_loss: 449.635498046875
loss: 224.81723022460938
policy_loss: -0.0016533918678760529
entropy_loss: -2.8633651733398438
value_loss: 446.37274169921875
loss: 223.18472290039062
policy_loss: -0.0007077241316437721
entropy_loss: -2.8633463382720947
value_loss: 438.0436096191406
loss: 219.02110290527344
policy_loss: -0.00046226149424910545
entropy_loss: -2.8633193969726562
value_loss: 449.6341857910156
loss: 224.81663513183594
policy_loss: -0.00043582357466220856
entropy_loss: -2.8633017539978027
value_loss: 406.4280090332031
loss: 203.21356201171875
policy_loss: -0.0026006773114204407
entropy_loss: -2.8632607460021973
value_loss: 465.5118713378906
loss: 232.7533416748047
policy_loss: -0.0014904243871569633
entropy_loss: -2.8632354736328125
value_loss: 432.6758728027344
loss: 216.33644104003906
policy_loss: -0.0009462665766477585
entropy_loss: -2.8632073402404785
value_loss: 435.3794250488281
loss: 217.6887664794922
policy_loss: -0.00011285394430160522
entropy_loss: -2.8631818294525146
value_loss: 445.60870361328125
loss: 222.8042449951172
policy_loss: -0.003329552710056305
entropy_loss: -2.8631720542907715
value_loss: 415.89398193359375
loss: 207.94366455078125
policy_loss: -0.003517521545290947
entropy_loss: -2.863140344619751
value_loss: 414.0045166015625
loss: 206.9987335205078
policy_loss: -0.0015516653656959534
entropy_loss: -2.863100528717041
value_loss: 421.8603820800781
loss: 210.9286346435547
policy_loss: -0.002226353157311678
entropy_loss: -2.8630661964416504
value_loss: 439.7721252441406
loss: 219.8838348388672
policy_loss: -0.002321625128388405
entropy_loss: -2.863028049468994
value_loss: 419.2290344238281
loss: 209.61219787597656
policy_loss: -0.004697734490036964
entropy_loss: -2.863006353378296
value_loss: 400.6542053222656
loss: 200.32240295410156
policy_loss: -0.0019999113865196705
entropy_loss: -2.862983465194702
value_loss: 396.37677001953125
loss: 198.18638610839844
policy_loss: -0.003536118194460869
entropy_loss: -2.8629415035247803
value_loss: 398.4278259277344
loss: 199.2103729248047
policy_loss: -0.0022194376215338707
entropy_loss: -2.862903356552124
value_loss: 431.18719482421875
loss: 215.5913848876953
policy_loss: -0.004250703379511833
entropy_loss: -2.862853765487671
value_loss: 403.5391540527344
loss: 201.76531982421875
policy_loss: -0.004555396735668182
entropy_loss: -2.862823247909546
value_loss: 382.44122314453125
loss: 191.21604919433594
policy_loss: -0.002390674315392971
entropy_loss: -2.8627753257751465
value_loss: 403.7394104003906
loss: 201.8673095703125
policy_loss: -0.004491181578487158
entropy_loss: -2.862722873687744
value_loss: 373.1309814453125
loss: 186.56100463867188
policy_loss: -0.004048721864819527
entropy_loss: -2.862670660018921
value_loss: 393.09869384765625
loss: 196.54530334472656
policy_loss: -0.0064658173359930515
entropy_loss: -2.862640142440796
value_loss: 407.19775390625
loss: 203.5924072265625
policy_loss: -0.001276679802685976
entropy_loss: -2.8625893592834473
value_loss: 364.4534606933594
loss: 182.22544860839844
policy_loss: -0.004915894940495491
entropy_loss: -2.8625261783599854
value_loss: 377.95928955078125
loss: 188.9747314453125
policy_loss: -0.007193973287940025
entropy_loss: -2.8624701499938965
value_loss: 387.6921081542969
loss: 193.8388671875
policy_loss: -0.006811292842030525
entropy_loss: -2.862443685531616
value_loss: 409.9256286621094
loss: 204.9560089111328
------------------------------------
| avg_speed          | 2.54        |
| is_success         | 0           |
| max_speed          | 2.54        |
| reward             | -0.51083124 |
| rollout/           |             |
|    ep_len_mean     | 972         |
|    ep_rew_mean     | -1.1e+03    |
| time/              |             |
|    fps             | 118         |
|    iterations      | 1           |
|    time_elapsed    | 17          |
|    total_timesteps | 22528       |
------------------------------------
TRAINING:
weight : tensor([[ 0.0741,  0.3986,  0.2329,  ..., -0.0355,  0.0323,  0.2997],
        [ 0.1258,  0.3334,  0.1159,  ..., -0.0992, -0.3118, -0.1917],
        [ 0.1145,  0.1853,  0.0187,  ...,  0.4174, -0.1220,  0.4010],
        ...,
        [ 0.0300,  0.1455, -0.2599,  ..., -0.3851, -0.0764, -0.1391],
        [-0.2716,  0.0072,  0.0714,  ..., -0.0125,  0.0185, -0.1118],
        [ 0.1566,  0.1575,  0.3118,  ..., -0.1180,  0.1883,  0.2671]])
bias : tensor([-2.3798e-03,  1.5836e-03, -1.3026e-03, -1.7460e-03, -8.1949e-04,
        -2.6554e-04, -1.3574e-03, -1.3536e-03, -1.0515e-03, -5.9341e-04,
        -1.4870e-03,  3.5503e-03, -1.9100e-03,  4.9367e-03, -7.6069e-04,
        -1.6419e-03, -1.6091e-03,  3.4226e-03, -3.5513e-03,  3.3021e-04,
         3.8185e-03, -3.8970e-03, -8.2745e-04,  3.1867e-03, -1.0279e-03,
        -3.9960e-03, -1.2483e-04, -1.0968e-03,  1.1727e-03,  4.7731e-03,
        -6.4650e-03,  1.0626e-03,  4.0527e-03,  3.1152e-03,  2.4697e-03,
        -1.1816e-03, -2.3677e-04,  8.2505e-04, -1.4881e-03,  4.7557e-03,
        -2.5037e-03,  5.5071e-03, -3.1384e-03,  2.6960e-03, -4.6821e-03,
         1.6260e-03, -2.1337e-03,  3.6964e-03, -5.5190e-04,  2.9956e-03,
         1.7876e-03,  9.4518e-04,  9.9810e-05,  3.4346e-03,  4.7313e-03,
         4.9760e-04,  2.0775e-03,  1.7004e-04, -2.8758e-03, -4.5566e-03,
        -5.1565e-05, -6.6691e-04,  1.5539e-04,  1.7777e-03])
weight : tensor([[-0.1730,  0.0851,  0.1627,  ..., -0.2987,  0.0030, -0.0787],
        [ 0.0450, -0.2649,  0.0877,  ...,  0.1019,  0.0818,  0.3119],
        [-0.0682,  0.2346, -0.1143,  ..., -0.1638, -0.2279,  0.1556],
        ...,
        [ 0.2298,  0.3879,  0.1870,  ..., -0.0467,  0.4126,  0.2075],
        [-0.0472,  0.2799,  0.1212,  ..., -0.2105,  0.1503, -0.2212],
        [ 0.0462, -0.0553,  0.3618,  ...,  0.0095,  0.0244, -0.2422]])
bias : tensor([-3.5013e-04, -4.4216e-04,  2.1508e-03, -1.3655e-03,  4.0898e-04,
         7.6696e-04,  4.7046e-03,  4.1293e-04,  2.1482e-03, -3.6651e-03,
         3.7905e-04, -1.0864e-03,  1.7739e-03, -1.4508e-04,  3.2539e-03,
         2.5505e-04,  9.3042e-04,  3.9485e-03,  3.2274e-03,  9.3512e-04,
        -5.4182e-03, -3.0874e-04, -2.1340e-03, -1.3351e-03,  2.5530e-03,
         2.6940e-03, -5.7983e-04, -2.1881e-03,  2.2480e-03, -3.1346e-03,
         3.7415e-03, -3.1855e-03,  2.4621e-04,  1.9654e-04,  3.0694e-03,
         2.5806e-03,  1.5152e-04,  2.9537e-03, -2.5790e-03, -5.5304e-05,
         2.4352e-03,  5.0655e-03,  1.5160e-03,  1.9528e-03,  1.3046e-03,
        -2.4943e-03,  6.5139e-03, -5.8265e-03,  4.7953e-03, -4.8121e-03,
         2.7047e-03,  3.0275e-03,  2.2619e-03,  2.7290e-04,  3.7514e-03,
        -2.4622e-03,  4.0497e-04, -9.7460e-04,  1.0517e-03,  1.5419e-03,
         2.4562e-03,  1.6156e-03, -2.2402e-04,  1.2205e-03])
policy_loss: -9.12696123123169e-08
entropy_loss: -2.8366150856018066
value_loss: 537.0841674804688
loss: 268.5420837402344
policy_loss: 3.0396506190299988e-05
entropy_loss: -2.836477756500244
value_loss: 529.72607421875
loss: 264.8630676269531
policy_loss: -6.806105375289917e-06
entropy_loss: -2.836303949356079
value_loss: 562.487548828125
loss: 281.2437744140625
policy_loss: 4.7516077756881714e-05
entropy_loss: -2.8361854553222656
value_loss: 538.9468994140625
loss: 269.4735107421875
policy_loss: -8.550472557544708e-05
entropy_loss: -2.836045742034912
value_loss: 547.6221923828125
loss: 273.8110046386719
policy_loss: -0.0002568233758211136
entropy_loss: -2.8359410762786865
value_loss: 537.7297973632812
loss: 268.8646545410156
policy_loss: -0.00030598975718021393
entropy_loss: -2.835853338241577
value_loss: 524.1143798828125
loss: 262.056884765625
policy_loss: -0.0004257066175341606
entropy_loss: -2.8357274532318115
value_loss: 543.1478881835938
loss: 271.5735168457031
policy_loss: -6.0968101024627686e-05
entropy_loss: -2.835609197616577
value_loss: 519.5266723632812
loss: 259.7632751464844
policy_loss: -0.0011206381022930145
entropy_loss: -2.8354990482330322
value_loss: 521.5274047851562
loss: 260.7625732421875
policy_loss: -0.0006794799119234085
entropy_loss: -2.835409641265869
value_loss: 543.3536376953125
loss: 271.6761474609375
policy_loss: -0.0013201371766626835
entropy_loss: -2.8352904319763184
value_loss: 537.0117797851562
loss: 268.50457763671875
policy_loss: -0.0013317102566361427
entropy_loss: -2.835196018218994
value_loss: 516.2154541015625
loss: 258.10638427734375
policy_loss: -0.0008445787243545055
entropy_loss: -2.8351287841796875
value_loss: 534.7562255859375
loss: 267.37725830078125
policy_loss: -0.0016804058104753494
entropy_loss: -2.835085391998291
value_loss: 527.331787109375
loss: 263.6642150878906
policy_loss: -0.001458614133298397
entropy_loss: -2.8350279331207275
value_loss: 503.9974365234375
loss: 251.99725341796875
policy_loss: -0.0016047153621912003
entropy_loss: -2.83493971824646
value_loss: 500.28582763671875
loss: 250.1413116455078
policy_loss: -0.0019656382501125336
entropy_loss: -2.8348939418792725
value_loss: 525.0119018554688
loss: 262.5039978027344
policy_loss: -0.001480553299188614
entropy_loss: -2.834827184677124
value_loss: 508.76385498046875
loss: 254.3804473876953
policy_loss: -0.0030439281836152077
entropy_loss: -2.8347432613372803
value_loss: 504.2173156738281
loss: 252.10562133789062
policy_loss: -0.0026434622704982758
entropy_loss: -2.834665060043335
value_loss: 475.1992492675781
loss: 237.59698486328125
policy_loss: -0.0014931149780750275
entropy_loss: -2.834578037261963
value_loss: 498.00372314453125
loss: 249.0003662109375
policy_loss: -0.0032785581424832344
entropy_loss: -2.8344991207122803
value_loss: 513.74169921875
loss: 256.8675842285156
policy_loss: -0.0035643400624394417
entropy_loss: -2.8344321250915527
value_loss: 504.98260498046875
loss: 252.48773193359375
policy_loss: -0.0032436642795801163
entropy_loss: -2.8343634605407715
value_loss: 495.7467346191406
loss: 247.8701171875
policy_loss: -0.0032013924792408943
entropy_loss: -2.8342955112457275
value_loss: 486.68145751953125
loss: 243.3375244140625
policy_loss: -0.005745380185544491
entropy_loss: -2.8342490196228027
value_loss: 485.9091796875
loss: 242.94883728027344
policy_loss: -0.00157143734395504
entropy_loss: -2.8341753482818604
value_loss: 478.771484375
loss: 239.38417053222656
policy_loss: -0.007856071926653385
entropy_loss: -2.834106206893921
value_loss: 471.399169921875
loss: 235.6917266845703
policy_loss: -0.0030779121443629265
entropy_loss: -2.8340260982513428
value_loss: 484.80859375
loss: 242.40121459960938
policy_loss: -0.0044643753208220005
entropy_loss: -2.8339006900787354
value_loss: 485.503173828125
loss: 242.7471160888672
policy_loss: -0.0012577944435179234
entropy_loss: -2.8338189125061035
value_loss: 461.09027099609375
loss: 230.54388427734375
policy_loss: -0.0037177158519625664
entropy_loss: -2.8337647914886475
value_loss: 449.1018371582031
loss: 224.5471954345703
policy_loss: -0.005095962435007095
entropy_loss: -2.8336424827575684
value_loss: 469.2374267578125
loss: 234.61361694335938
policy_loss: -0.006554413586854935
entropy_loss: -2.833557367324829
value_loss: 482.3306884765625
loss: 241.15878295898438
policy_loss: -0.004662822932004929
entropy_loss: -2.8334808349609375
value_loss: 458.2960510253906
loss: 229.1433563232422
policy_loss: -0.006310896947979927
entropy_loss: -2.8334310054779053
value_loss: 430.3166198730469
loss: 215.15199279785156
policy_loss: -0.004085489548742771
entropy_loss: -2.833402156829834
value_loss: 459.71026611328125
loss: 229.85104370117188
policy_loss: -0.006609736010432243
entropy_loss: -2.833360195159912
value_loss: 462.63177490234375
loss: 231.3092803955078
policy_loss: -0.006492519285529852
entropy_loss: -2.833329916000366
value_loss: 465.5364074707031
loss: 232.76171875
-----------------------------------------
| avg_speed               | 2.23        |
| is_success              | 0           |
| max_speed               | 2.23        |
| reward                  | -0.367062   |
| rollout/                |             |
|    ep_len_mean          | 970         |
|    ep_rew_mean          | -1.27e+03   |
| time/                   |             |
|    fps                  | 122         |
|    iterations           | 2           |
|    time_elapsed         | 33          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.002501697 |
|    clip_fraction        | 0.00239     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.83       |
|    explained_variance   | -0.0742     |
|    learning_rate        | 0.0003      |
|    loss                 | 233         |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00256    |
|    std                  | 0.998       |
|    value_loss           | 502         |
-----------------------------------------
TRAINING:
weight : tensor([[ 0.1775, -0.3636, -0.0648,  ..., -0.0146, -0.2193, -0.3069],
        [ 0.0233,  0.1418, -0.0049,  ..., -0.0800, -0.0077, -0.0514],
        [-0.0717,  0.0567,  0.0360,  ..., -0.1787, -0.1268,  0.2226],
        ...,
        [ 0.2464, -0.0874,  0.2161,  ...,  0.2065, -0.2114,  0.3219],
        [-0.0421, -0.2582, -0.0575,  ..., -0.1289, -0.2784,  0.3103],
        [-0.0026,  0.0988, -0.1778,  ..., -0.0677,  0.0867,  0.0957]])
bias : tensor([ 0.0135, -0.0075,  0.0051,  0.0018, -0.0124,  0.0146,  0.0041, -0.0131,
        -0.0026, -0.0077,  0.0088, -0.0039, -0.0066,  0.0064, -0.0036,  0.0010,
        -0.0102, -0.0162, -0.0012,  0.0058, -0.0026,  0.0044, -0.0079, -0.0070,
         0.0179, -0.0071, -0.0093, -0.0011,  0.0113,  0.0029, -0.0070,  0.0028,
         0.0070,  0.0158,  0.0050, -0.0047,  0.0131, -0.0068,  0.0141,  0.0073,
        -0.0048, -0.0062,  0.0178,  0.0119, -0.0064, -0.0110,  0.0038,  0.0015,
        -0.0132,  0.0037, -0.0100, -0.0031, -0.0046,  0.0079,  0.0045,  0.0078,
        -0.0134, -0.0062,  0.0135, -0.0156,  0.0006, -0.0015,  0.0020, -0.0105])
weight : tensor([[-0.2117,  0.3447, -0.3341,  ..., -0.1706,  0.3048,  0.1775],
        [-0.1704, -0.1399, -0.0223,  ...,  0.0495, -0.3299,  0.0910],
        [-0.1318, -0.4210, -0.1409,  ...,  0.1901,  0.1332,  0.0101],
        ...,
        [ 0.2210,  0.1419, -0.2829,  ..., -0.0814,  0.0109, -0.0912],
        [-0.2412, -0.1288,  0.1518,  ...,  0.0447,  0.3085,  0.0834],
        [ 0.2030, -0.1974, -0.0108,  ..., -0.0705,  0.0357, -0.1224]])
bias : tensor([-0.0171,  0.0094,  0.0101, -0.0015, -0.0002, -0.0110, -0.0038,  0.0128,
         0.0096,  0.0072, -0.0107, -0.0124, -0.0111, -0.0086,  0.0036, -0.0033,
        -0.0040, -0.0012, -0.0002, -0.0033, -0.0115,  0.0078, -0.0089,  0.0071,
        -0.0092, -0.0016, -0.0105,  0.0118, -0.0092, -0.0033,  0.0033,  0.0129,
         0.0112,  0.0015, -0.0042, -0.0070, -0.0011,  0.0033, -0.0083, -0.0064,
         0.0158,  0.0072,  0.0114,  0.0006, -0.0047,  0.0138, -0.0045,  0.0129,
        -0.0044, -0.0091,  0.0019, -0.0100, -0.0082, -0.0097, -0.0019,  0.0009,
         0.0112,  0.0065, -0.0022, -0.0047,  0.0191,  0.0157,  0.0019,  0.0096])
policy_loss: 7.916241884231567e-09
entropy_loss: -2.8690202236175537
value_loss: 398.46563720703125
loss: 199.23281860351562
policy_loss: 0.00012122467160224915
entropy_loss: -2.869148015975952
value_loss: 396.57373046875
loss: 198.2869873046875
policy_loss: -4.062056541442871e-05
entropy_loss: -2.869253635406494
value_loss: 410.93353271484375
loss: 205.4667205810547
policy_loss: -0.00025932490825653076
entropy_loss: -2.8693277835845947
value_loss: 410.0583801269531
loss: 205.0289306640625
policy_loss: -0.00048776157200336456
entropy_loss: -2.8694052696228027
value_loss: 400.4605407714844
loss: 200.2297821044922
policy_loss: -0.00019154930487275124
entropy_loss: -2.8694779872894287
value_loss: 413.9887390136719
loss: 206.99417114257812
policy_loss: -0.0001657828688621521
entropy_loss: -2.86952805519104
value_loss: 388.1844177246094
loss: 194.092041015625
policy_loss: -4.521757364273071e-05
entropy_loss: -2.869539737701416
value_loss: 394.2583312988281
loss: 197.12911987304688
policy_loss: -0.0011916514486074448
entropy_loss: -2.869575262069702
value_loss: 360.2606506347656
loss: 180.12913513183594
policy_loss: -0.0007778964936733246
entropy_loss: -2.8696274757385254
value_loss: 395.1028137207031
loss: 197.55062866210938
policy_loss: -0.0005561108700931072
entropy_loss: -2.869676351547241
value_loss: 403.0403747558594
loss: 201.51963806152344
policy_loss: -0.000359509140253067
entropy_loss: -2.8697142601013184
value_loss: 414.6050720214844
loss: 207.3021697998047
policy_loss: -0.0026938682422041893
entropy_loss: -2.869722843170166
value_loss: 381.28277587890625
loss: 190.63868713378906
policy_loss: -0.001927688717842102
entropy_loss: -2.869708776473999
value_loss: 410.2029724121094
loss: 205.0995635986328
policy_loss: -0.0005368604324758053
entropy_loss: -2.8697266578674316
value_loss: 401.00738525390625
loss: 200.50315856933594
policy_loss: -0.00037812627851963043
entropy_loss: -2.8697354793548584
value_loss: 354.88775634765625
loss: 177.44349670410156
policy_loss: -0.00369291752576828
entropy_loss: -2.869720697402954
value_loss: 375.1493835449219
loss: 187.5709991455078
policy_loss: -0.002440021373331547
entropy_loss: -2.8696951866149902
value_loss: 379.4048767089844
loss: 189.6999969482422
policy_loss: -0.0017472794279456139
entropy_loss: -2.8696885108947754
value_loss: 377.8010559082031
loss: 188.89877319335938
policy_loss: -0.0009810524061322212
entropy_loss: -2.869636297225952
value_loss: 387.8549499511719
loss: 193.92649841308594
policy_loss: -0.0023325057700276375
entropy_loss: -2.869605779647827
value_loss: 352.8614196777344
loss: 176.42837524414062
policy_loss: -0.0030665555968880653
entropy_loss: -2.8695738315582275
value_loss: 392.1579895019531
loss: 196.075927734375
policy_loss: -0.0016329828649759293
entropy_loss: -2.869556427001953
value_loss: 393.52435302734375
loss: 196.7605438232422
policy_loss: -0.005766851827502251
entropy_loss: -2.8695130348205566
value_loss: 354.5701599121094
loss: 177.27931213378906
policy_loss: -0.003452576696872711
entropy_loss: -2.8694558143615723
value_loss: 353.14495849609375
loss: 176.56903076171875
policy_loss: -0.005382094532251358
entropy_loss: -2.869401693344116
value_loss: 358.41015625
loss: 179.19969177246094
policy_loss: -0.002763381227850914
entropy_loss: -2.8692855834960938
value_loss: 385.03839111328125
loss: 192.5164337158203
policy_loss: -0.003757331520318985
entropy_loss: -2.8691697120666504
value_loss: 368.7628173828125
loss: 184.37765502929688
policy_loss: -0.007431909441947937
entropy_loss: -2.869098424911499
value_loss: 371.34368896484375
loss: 185.66441345214844
policy_loss: -0.0036145146004855633
entropy_loss: -2.8690619468688965
value_loss: 378.2537536621094
loss: 189.12326049804688
policy_loss: -0.0009074192494153976
entropy_loss: -2.868988037109375
value_loss: 340.0790100097656
loss: 170.03860473632812
policy_loss: -0.005634414032101631
entropy_loss: -2.8689157962799072
value_loss: 348.596923828125
loss: 174.29283142089844
policy_loss: -0.007753584533929825
entropy_loss: -2.86881422996521
value_loss: 363.79473876953125
loss: 181.88961791992188
policy_loss: -0.005588118452578783
entropy_loss: -2.868694543838501
value_loss: 343.7273864746094
loss: 171.8581085205078
policy_loss: -0.005764918401837349
entropy_loss: -2.868560552597046
value_loss: 335.2371520996094
loss: 167.61280822753906
policy_loss: -0.0004932265728712082
entropy_loss: -2.868422031402588
value_loss: 368.1204833984375
loss: 184.05975341796875
policy_loss: -0.0071554407477378845
entropy_loss: -2.868309259414673
value_loss: 317.43011474609375
loss: 158.70790100097656
policy_loss: -0.015050007030367851
entropy_loss: -2.868208169937134
value_loss: 342.0893859863281
loss: 171.02964782714844
policy_loss: 0.0015538930892944336
entropy_loss: -2.868083953857422
value_loss: 355.4124755859375
loss: 177.70779418945312
policy_loss: -0.0002096090465784073
entropy_loss: -2.8679392337799072
value_loss: 369.0821838378906
loss: 184.54087829589844
-----------------------------------------
| avg_speed               | 7.16        |
| is_success              | 0           |
| max_speed               | 7.16        |
| reward                  | -2.0363178  |
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.19e+03   |
| time/                   |             |
|    fps                  | 119         |
|    iterations           | 2           |
|    time_elapsed         | 34          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.004237687 |
|    clip_fraction        | 0.0104      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.87       |
|    explained_variance   | -0.469      |
|    learning_rate        | 0.0003      |
|    loss                 | 185         |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00261    |
|    std                  | 1.02        |
|    value_loss           | 376         |
-----------------------------------------
slurmstepd: error: *** JOB 118132 ON airl.ist.berkeley.edu CANCELLED AT 2024-01-18T07:03:40 ***
slurmstepd: error: *** STEP 118132.0 ON airl.ist.berkeley.edu CANCELLED AT 2024-01-18T07:03:40 ***
slurmstepd: error: *** STEP 118132.1 ON ppo.ist.berkeley.edu CANCELLED AT 2024-01-17T23:03:40 ***
slurmstepd: error: *** STEP 118132.2 ON sac.ist.berkeley.edu CANCELLED AT 2024-01-18T07:03:40 ***
