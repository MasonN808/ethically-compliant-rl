wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240112_064026-d1vqr1px
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-mountain-160
wandb: â­ï¸ View project at https://wandb.ai/ecrl/PPO%2BPPOL
wandb: ğŸš€ View run at https://wandb.ai/ecrl/PPO%2BPPOL/runs/d1vqr1px
Using cpu device
------------------------------------
| avg_speed          | 0.266       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.266       |
| reward             | -0.23268087 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.41e+03   |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2048        |
------------------------------------
Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/PPOL_New/train_ppol_high_limit.py", line 141, in <module>
    train()
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/PPOL_New/train_ppol_high_limit.py", line 118, in train
    agent.learn(total_timesteps=args.total_timesteps, callback=callback, reset_num_timesteps=False)
  File "/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppol/ppol.py", line 405, in learn
    result = super().learn(
  File "/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/on_policy_algorithm.py", line 594, in learn
    self.train()
  File "/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppol/ppol.py", line 255, in train
    lambdas = self.pid_controller(d=d, K_P=self.K_P, K_I=self.K_I, K_D=self.K_D, j_c=cost_values, j_c_prev=j_c_prev, integral=integral)
  File "/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppol/ppol.py", line 381, in pid_controller
    return lmbda.requires_grad_(False)
RuntimeError: you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach().
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 
wandb: Run history:
wandb:  avg_speed â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–„â–ƒâ–„â–„â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–„â–…â–†â–†â–ˆâ–‡â–ˆâ–‡â–
wandb:       cost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: is_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  max_speed â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–„â–ƒâ–„â–„â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–„â–…â–†â–†â–ˆâ–‡â–ˆâ–‡â–
wandb:     reward â–ˆâ–‡â–†â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–ˆâ–†â–†â–…â–…â–†â–†â–…â–†â–†â–…â–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:  avg_speed 0.26557
wandb:       cost 0
wandb: is_success 0
wandb:  max_speed 0.26557
wandb:     reward -0.23268
wandb: 
wandb: ğŸš€ View run generous-mountain-160 at: https://wandb.ai/ecrl/PPO%2BPPOL/runs/d1vqr1px
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240112_064026-d1vqr1px/logs
srun: error: airl.ist.berkeley.edu: task 0: Exited with exit code 1
