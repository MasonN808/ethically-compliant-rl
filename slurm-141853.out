wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240222_032630-cvnfd1ju
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run virtuous-wish-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/cvnfd1ju
Using cpu device
-----------------------------------
| avg_speed          | 2.06       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.06       |
| reward             | -0.5047797 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.55e+03  |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2048       |
-----------------------------------
------------------------------------------
| avg_speed                | 4.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.57        |
| reward                   | -0.90582424 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.49e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.004058154 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.817       |
|    cost_value_loss       | 4.71        |
|    cost_values           | -0.242      |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -0.000244   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 312         |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00109    |
|    std                   | 0.998       |
|    value_loss            | 664         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.43         |
| reward                   | -0.3386776   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 95           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0038798812 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.03        |
|    cost_value_loss       | 0.00467      |
|    cost_values           | -0.00873     |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 262          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.997        |
|    value_loss            | 568          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0352726   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 4            |
|    time_elapsed          | 130          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0060830805 |
|    clip_fraction         | 0.0484       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.233        |
|    cost_value_loss       | 1.05         |
|    cost_values           | 0.122        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 96.9         |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.994        |
|    value_loss            | 211          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.5731049   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0039018411 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.344        |
|    cost_value_loss       | 0.276        |
|    cost_values           | 0.323        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 144          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.987        |
|    value_loss            | 293          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.88         |
| reward                   | -1.1047593   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 199          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0053831646 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.52         |
|    cost_value_loss       | 0.707        |
|    cost_values           | 0.474        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84.7         |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.000996    |
|    std                   | 0.989        |
|    value_loss            | 186          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.95       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.95       |
| reward                   | -1.0681826 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -1.14e+03  |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 7          |
|    time_elapsed          | 234        |
|    total_timesteps       | 14336      |
| train/                   |            |
|    approx_kl             | 0.00439135 |
|    clip_fraction         | 0.0189     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.07       |
|    cost_value_loss       | 1.86       |
|    cost_values           | 0.827      |
|    entropy               | -2.81      |
|    entropy_loss          | -2.81      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 170        |
|    n_updates             | 60         |
|    policy_gradient_loss  | -0.000989  |
|    std                   | 0.987      |
|    value_loss            | 348        |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.91        |
| reward                   | -1.1146827  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 268         |
|    total_timesteps       | 16384       |
| train/                   |             |
|    approx_kl             | 0.003150839 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 1.99        |
|    cost_values           | 0.896       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 128         |
|    n_updates             | 70          |
|    policy_gradient_loss  | -0.000957   |
|    std                   | 0.985       |
|    value_loss            | 279         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3677261   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0039662407 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.821        |
|    cost_value_loss       | 0.086        |
|    cost_values           | 0.954        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 179          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.986        |
|    value_loss            | 371          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.75993     |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0033170348 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.11         |
|    cost_values           | 0.939        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 107          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.984        |
|    value_loss            | 228          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.7822887   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 372          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0034976348 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 1.92         |
|    cost_values           | 0.965        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 108          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.000678    |
|    std                   | 0.983        |
|    value_loss            | 219          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -0.68530357 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 407         |
|    total_timesteps       | 24576       |
| train/                   |             |
|    approx_kl             | 0.004178889 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.866       |
|    cost_value_loss       | 0.0301      |
|    cost_values           | 0.897       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 90.6        |
|    n_updates             | 110         |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 0.979       |
|    value_loss            | 192         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3888553  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 441         |
|    total_timesteps       | 26624       |
| train/                   |             |
|    approx_kl             | 0.005357722 |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 3.35        |
|    cost_values           | 0.939       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 120         |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.978       |
|    value_loss            | 275         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.411045    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0026006587 |
|    clip_fraction         | 0.00596      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.968        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.8         |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.000478    |
|    std                   | 0.981        |
|    value_loss            | 122          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.5758715   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 510          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0035305587 |
|    clip_fraction         | 0.0327       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 2.44         |
|    cost_values           | 0.973        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65.5         |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.981        |
|    value_loss            | 141          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.76         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.76         |
| reward                   | -0.5131786   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 544          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0031692898 |
|    clip_fraction         | 0.00767      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 2.06         |
|    cost_values           | 0.98         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 102          |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.000424    |
|    std                   | 0.98         |
|    value_loss            | 216          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.9          |
| reward                   | -0.46915057  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 579          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0053265095 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58         |
|    cost_value_loss       | 8.38         |
|    cost_values           | 1.01         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 61.2         |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.978        |
|    value_loss            | 118          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.05         |
| reward                   | -0.646361    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 613          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0051119253 |
|    clip_fraction         | 0.0573       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 0.94         |
|    cost_values           | 0.949        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 73.8         |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 0.977        |
|    value_loss            | 160          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -0.8467985   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -991         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 647          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0044608917 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 2.39         |
|    cost_values           | 0.989        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 89.2         |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.974        |
|    value_loss            | 179          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.77        |
| reward                   | -1.0750343  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -994        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 682         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.003858047 |
|    clip_fraction         | 0.0217      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 2.06        |
|    cost_values           | 0.992       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.3        |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.972       |
|    value_loss            | 105         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.35         |
| reward                   | -0.7206096   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -988         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 716          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0050678253 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.764        |
|    cost_values           | 0.969        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 123          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.971        |
|    value_loss            | 245          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.6          |
| reward                   | -1.1326547   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -982         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 750          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0025215533 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 4.63         |
|    cost_values           | 0.998        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 57.2         |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.000861    |
|    std                   | 0.97         |
|    value_loss            | 120          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.39         |
| reward                   | -0.38756683  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -973         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 784          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0050353617 |
|    clip_fraction         | 0.0399       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 2.34         |
|    cost_values           | 0.996        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 68.2         |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 0.965        |
|    value_loss            | 139          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.38         |
| reward                   | -1.1798205   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -952         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 820          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0032838343 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 0.987        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27           |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00039     |
|    std                   | 0.959        |
|    value_loss            | 60.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.66         |
| reward                   | -0.5481645   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -949         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 854          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0044454476 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 6.12         |
|    cost_values           | 0.999        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.6         |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.000682    |
|    std                   | 0.96         |
|    value_loss            | 82.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.77        |
| reward                   | -1.0187972  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -935        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 889         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.004502804 |
|    clip_fraction         | 0.0339      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 3.77        |
|    cost_values           | 0.999       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.3        |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.962       |
|    value_loss            | 71.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.18         |
| reward                   | -0.68174493  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -926         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 923          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0021522993 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.78         |
|    cost_value_loss       | 15.8         |
|    cost_values           | 1.02         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30           |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.963        |
|    value_loss            | 49.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.626       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.626       |
| reward                   | -0.38935465 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -911        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 957         |
|    total_timesteps       | 57344       |
| train/                   |             |
|    approx_kl             | 0.003922193 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.73        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 1.02        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.4        |
|    n_updates             | 270         |
|    policy_gradient_loss  | -0.00184    |
|    std                   | 0.97        |
|    value_loss            | 28.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.879        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.879        |
| reward                   | -0.36998415  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -898         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 992          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0007538981 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 11.4         |
|    cost_values           | 1.02         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.4         |
|    n_updates             | 280          |
|    policy_gradient_loss  | 4.88e-05     |
|    std                   | 0.969        |
|    value_loss            | 35.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.844        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.844        |
| reward                   | -0.5852053   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -888         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1026         |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0017139514 |
|    clip_fraction         | 0.00215      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 7.64         |
|    cost_values           | 1            |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -6.29e-05    |
|    std                   | 0.967        |
|    value_loss            | 45.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.94         |
| reward                   | -0.48066893  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -885         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1060         |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0052578747 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.91         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 1.01         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.2         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.962        |
|    value_loss            | 38.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.02         |
| reward                   | -0.38667277  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -892         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1094         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0035875805 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.306        |
|    cost_values           | 0.968        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.8         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.000731    |
|    std                   | 0.963        |
|    value_loss            | 78.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.217        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.217        |
| reward                   | -0.5323961   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -894         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1129         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0041311835 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.15         |
|    cost_values           | 0.962        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.000923    |
|    std                   | 0.965        |
|    value_loss            | 233          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.92         |
| reward                   | -0.40767846  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0032003217 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 1            |
|    cost_value_loss       | 0.785        |
|    cost_values           | 0.984        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.8         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.964        |
|    value_loss            | 137          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 6.29       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.29       |
| reward                   | -1.0772825 |
| rollout/                 |            |
|    ep_len_mean           | 991        |
|    ep_rew_mean           | -902       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 35         |
|    time_elapsed          | 1198       |
|    total_timesteps       | 71680      |
| train/                   |            |
|    approx_kl             | 0.00441717 |
|    clip_fraction         | 0.0194     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.33       |
|    cost_value_loss       | 1.79       |
|    cost_values           | 0.997      |
|    entropy               | -2.76      |
|    entropy_loss          | -2.76      |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 59.1       |
|    n_updates             | 340        |
|    policy_gradient_loss  | -0.00115   |
|    std                   | 0.961      |
|    value_loss            | 123        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -0.95106536  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -902         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1232         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0041100774 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.912        |
|    cost_value_loss       | 0.215        |
|    cost_values           | 0.981        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 121          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.959        |
|    value_loss            | 251          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.13         |
| reward                   | -0.60448986  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1267         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0026371279 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.889        |
|    cost_values           | 0.986        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.3         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.961        |
|    value_loss            | 99.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.74         |
| reward                   | -0.7297639   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1301         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0026460746 |
|    clip_fraction         | 0.0064       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 1.13         |
|    cost_values           | 0.997        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.6         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.000694    |
|    std                   | 0.956        |
|    value_loss            | 91.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.79        |
| reward                   | -0.72436017 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -881        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1335        |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.001908295 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 3.04        |
|    cost_values           | 1           |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.9        |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.959       |
|    value_loss            | 27.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.74         |
| reward                   | -0.8217616   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -877         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1370         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0058041844 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 4.22         |
|    cost_values           | 0.999        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.6         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.957        |
|    value_loss            | 57.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.85         |
| reward                   | -1.0718601   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1405         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0017483002 |
|    clip_fraction         | 0.00688      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 1.67         |
|    cost_values           | 0.997        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.8         |
|    n_updates             | 400          |
|    policy_gradient_loss  | 5.39e-05     |
|    std                   | 0.956        |
|    value_loss            | 36.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.65         |
| reward                   | -1.0449378   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -877         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1439         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0028421392 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 7.01         |
|    cost_values           | 1.01         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36           |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.000268    |
|    std                   | 0.958        |
|    value_loss            | 70.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.47897422  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -876         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1473         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0045090644 |
|    clip_fraction         | 0.0414       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.944        |
|    cost_value_loss       | 0.457        |
|    cost_values           | 0.979        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.1         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.959        |
|    value_loss            | 119          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.1384888   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1507         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0029242227 |
|    clip_fraction         | 0.0061       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 1.38         |
|    cost_values           | 0.99         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.5         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.000161    |
|    std                   | 0.959        |
|    value_loss            | 59.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1754633   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -873         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1542         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0040429747 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.968        |
|    cost_value_loss       | 0.457        |
|    cost_values           | 0.992        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.3         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.959        |
|    value_loss            | 64.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.2021614   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1576         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0062137786 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.449        |
|    cost_values           | 0.994        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.9         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.958        |
|    value_loss            | 73.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.76395476  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1610         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0047568735 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 2.12         |
|    cost_values           | 0.999        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.6         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.948        |
|    value_loss            | 88.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -1.0810398  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -877        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1644        |
|    total_timesteps       | 98304       |
| train/                   |             |
|    approx_kl             | 0.003158286 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 1.27        |
|    cost_values           | 0.995       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41          |
|    n_updates             | 470         |
|    policy_gradient_loss  | -0.000849   |
|    std                   | 0.942       |
|    value_loss            | 82.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.88132477  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -869         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1679         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0035394728 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 1.24         |
|    cost_values           | 0.99         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42           |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.000648    |
|    std                   | 0.947        |
|    value_loss            | 92.6         |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -1.1206363 |
| rollout/           |            |
|    ep_len_mean     | 987        |
|    ep_rew_mean     | -862       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 102400     |
-----------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7124067  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -856        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 104448      |
| train/                   |             |
|    approx_kl             | 0.003509072 |
|    clip_fraction         | 0.0275      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.903       |
|    cost_value_loss       | 0.187       |
|    cost_values           | 0.983       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 47.4        |
|    n_updates             | 500         |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.941       |
|    value_loss            | 99.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -0.66043013  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -854         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0036554963 |
|    clip_fraction         | 0.00791      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.704        |
|    cost_values           | 0.97         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.1         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.000497    |
|    std                   | 0.941        |
|    value_loss            | 51.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8513221   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0030918373 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 1.63         |
|    cost_values           | 0.993        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.3         |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.936        |
|    value_loss            | 56.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.4543347  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -842        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 110592      |
| train/                   |             |
|    approx_kl             | 0.003572505 |
|    clip_fraction         | 0.0112      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.938       |
|    cost_value_loss       | 0.468       |
|    cost_values           | 0.972       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.8        |
|    n_updates             | 530         |
|    policy_gradient_loss  | -0.000534   |
|    std                   | 0.938       |
|    value_loss            | 36.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.93         |
| reward                   | -0.7447011   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -843         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0057177455 |
|    clip_fraction         | 0.0634       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.918        |
|    cost_values           | 0.968        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.8         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00456     |
|    std                   | 0.937        |
|    value_loss            | 104          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.547        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.547        |
| reward                   | -0.6634313   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0024736926 |
|    clip_fraction         | 0.00557      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.83         |
|    cost_value_loss       | 0.0596       |
|    cost_values           | 0.963        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.4         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.000497    |
|    std                   | 0.934        |
|    value_loss            | 59.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.43        |
| reward                   | -0.53875744 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -836        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 267         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.003488588 |
|    clip_fraction         | 0.048       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.771       |
|    cost_value_loss       | 0.0402      |
|    cost_values           | 0.897       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.4        |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.936       |
|    value_loss            | 76.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.66559297  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0030448784 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.931        |
|    cost_value_loss       | 0.651        |
|    cost_values           | 0.87         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.3         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.000947    |
|    std                   | 0.937        |
|    value_loss            | 54           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.78183734  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 339          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0064784572 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 2.17         |
|    cost_values           | 0.986        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.939        |
|    value_loss            | 29.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.56         |
| reward                   | -1.0014086   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -819         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 374          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0053474098 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.953        |
|    cost_value_loss       | 0.366        |
|    cost_values           | 0.938        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.1         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.937        |
|    value_loss            | 55.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.17         |
| reward                   | -0.6353972   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -819         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 12           |
|    time_elapsed          | 410          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0063163345 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.734        |
|    cost_value_loss       | 0.0251       |
|    cost_values           | 0.86         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.4         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.935        |
|    value_loss            | 37.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.8135055  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -821        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 13          |
|    time_elapsed          | 445         |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.004026571 |
|    clip_fraction         | 0.0344      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 1.58        |
|    cost_values           | 0.879       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 0.94        |
|    value_loss            | 26.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.12         |
| reward                   | -0.78645486  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 14           |
|    time_elapsed          | 481          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0036210858 |
|    clip_fraction         | 0.0356       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 2.7          |
|    cost_values           | 1            |
|    entropy               | -2.69        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.931        |
|    value_loss            | 30.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.33        |
| reward                   | -0.7991149  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -808        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 15          |
|    time_elapsed          | 516         |
|    total_timesteps       | 131072      |
| train/                   |             |
|    approx_kl             | 0.005948276 |
|    clip_fraction         | 0.0434      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 6.42        |
|    cost_values           | 1.47        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.42        |
|    n_updates             | 630         |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.924       |
|    value_loss            | 6.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.61         |
| reward                   | -1.1777215   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 550          |
|    total_timesteps       | 133120       |
| train/                   |              |
|    approx_kl             | 0.0044148206 |
|    clip_fraction         | 0.0666       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 2.42         |
|    cost_values           | 2.33         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 640          |
|    policy_gradient_loss  | -0.000134    |
|    std                   | 0.928        |
|    value_loss            | 6.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.12         |
| reward                   | -0.46821132  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 585          |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0030525648 |
|    clip_fraction         | 0.0608       |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 0.159        |
|    cost_values           | 2.15         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.82         |
|    n_updates             | 650          |
|    policy_gradient_loss  | 0.000515     |
|    std                   | 0.927        |
|    value_loss            | 21.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0243      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0243      |
| reward                   | -0.5216283  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -795        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 619         |
|    total_timesteps       | 137216      |
| train/                   |             |
|    approx_kl             | 0.005198339 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.9         |
|    cost_value_loss       | 16.4        |
|    cost_values           | 2.08        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 660         |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.921       |
|    value_loss            | 6.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.601        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.601        |
| reward                   | -0.7577968   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 654          |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0012484461 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 1.92         |
|    cost_values           | 2.5          |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.8          |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.000659    |
|    std                   | 0.919        |
|    value_loss            | 6.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.8674439   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -789         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 688          |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0049825255 |
|    clip_fraction         | 0.0576       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 0.636        |
|    cost_values           | 2.02         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.9          |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.0044      |
|    std                   | 0.915        |
|    value_loss            | 9.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00775     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00775     |
| reward                   | -0.52470326 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -784        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 723         |
|    total_timesteps       | 143360      |
| train/                   |             |
|    approx_kl             | 0.004720519 |
|    clip_fraction         | 0.0192      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 1.52        |
|    cost_values           | 1.58        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.8        |
|    n_updates             | 690         |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.915       |
|    value_loss            | 64.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.39        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.39        |
| reward                   | -0.24079834 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -782        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 757         |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.003819006 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 18.9        |
|    cost_values           | 1.59        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.1        |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.913       |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.39         |
| reward                   | -0.8319372   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -787         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 792          |
|    total_timesteps       | 147456       |
| train/                   |              |
|    approx_kl             | 0.0048024654 |
|    clip_fraction         | 0.0501       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 1.79         |
|    cost_values           | 2            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 710          |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 0.908        |
|    value_loss            | 9.1          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.113         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.113         |
| reward                   | -0.77749705   |
| rollout/                 |               |
|    ep_len_mean           | 987           |
|    ep_rew_mean           | -781          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 24            |
|    time_elapsed          | 826           |
|    total_timesteps       | 149504        |
| train/                   |               |
|    approx_kl             | 0.00082431315 |
|    clip_fraction         | 0.0102        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.85          |
|    cost_value_loss       | 1.17          |
|    cost_values           | 1.73          |
|    entropy               | -2.64         |
|    entropy_loss          | -2.64         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.29          |
|    n_updates             | 720           |
|    policy_gradient_loss  | -0.00081      |
|    std                   | 0.907         |
|    value_loss            | 19.9          |
--------------------------------------------
------------------------------------------
| avg_speed                | 4.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.27        |
| reward                   | -0.70924884 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -785        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 861         |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.004170927 |
|    clip_fraction         | 0.0364      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 9.63        |
|    cost_values           | 1.71        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.3        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.91        |
|    value_loss            | 27.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.666       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.666       |
| reward                   | -0.73607546 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -790        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 896         |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.004265749 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 3.39        |
|    cost_values           | 2.06        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.85        |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00214    |
|    std                   | 0.912       |
|    value_loss            | 14          |
------------------------------------------
------------------------------------------
| avg_speed                | 4.44        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.44        |
| reward                   | -0.69603145 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -799        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 931         |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.004225791 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 0.119       |
|    cost_values           | 1.79        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.8        |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.913       |
|    value_loss            | 60.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.255        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.255        |
| reward                   | -0.28760827  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 966          |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0047412245 |
|    clip_fraction         | 0.0258       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 0.0686       |
|    cost_values           | 1.37         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.3         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.913        |
|    value_loss            | 67.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.76        |
| reward                   | -0.67049164 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -799        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 1000        |
|    total_timesteps       | 159744      |
| train/                   |             |
|    approx_kl             | 0.004172175 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 1.31        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 770         |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.909       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.204       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.204       |
| reward                   | -0.9517885  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -797        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1035        |
|    total_timesteps       | 161792      |
| train/                   |             |
|    approx_kl             | 0.009936132 |
|    clip_fraction         | 0.0589      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 8.83        |
|    cost_values           | 1.9         |
|    entropy               | -2.63       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.42        |
|    n_updates             | 780         |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 0.902       |
|    value_loss            | 8.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.923       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.923       |
| reward                   | -0.78571916 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -797        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1070        |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.005421835 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 0.121       |
|    cost_values           | 2.05        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.39        |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.899       |
|    value_loss            | 15.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.43         |
| reward                   | -0.53290105  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1105         |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0023806687 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 0.0468       |
|    cost_values           | 1.6          |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.897        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.16         |
| reward                   | -0.8898034   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1139         |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0055464096 |
|    clip_fraction         | 0.0506       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 6.27         |
|    cost_values           | 1.4          |
|    entropy               | -2.63        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.45         |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00361     |
|    std                   | 0.901        |
|    value_loss            | 6.82         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 3.78          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 3.78          |
| reward                   | -0.75745255   |
| rollout/                 |               |
|    ep_len_mean           | 987           |
|    ep_rew_mean           | -778          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 34            |
|    time_elapsed          | 1174          |
|    total_timesteps       | 169984        |
| train/                   |               |
|    approx_kl             | 0.00083703664 |
|    clip_fraction         | 0.0734        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.74          |
|    cost_value_loss       | 1.93          |
|    cost_values           | 1.57          |
|    entropy               | -2.62         |
|    entropy_loss          | -2.63         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.74          |
|    n_updates             | 820           |
|    policy_gradient_loss  | -0.00222      |
|    std                   | 0.896         |
|    value_loss            | 9.77          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.09         |
| reward                   | -0.7239533   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1208         |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0064623873 |
|    clip_fraction         | 0.203        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 1.07         |
|    cost_values           | 1.54         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 830          |
|    policy_gradient_loss  | 0.00786      |
|    std                   | 0.896        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.39        |
| reward                   | -0.7622093  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1242        |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.004840732 |
|    clip_fraction         | 0.0505      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 0.24        |
|    cost_values           | 1.22        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.807       |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 0.873       |
|    value_loss            | 1.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.476        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.476        |
| reward                   | -0.70250106  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1277         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0003798166 |
|    clip_fraction         | 0.239        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.124        |
|    cost_values           | 1.1          |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 850          |
|    policy_gradient_loss  | 0.011        |
|    std                   | 0.871        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.558        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.558        |
| reward                   | -0.7889937   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1312         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0041113403 |
|    clip_fraction         | 0.0348       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.885        |
|    cost_value_loss       | 0.419        |
|    cost_values           | 0.93         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.7          |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.87         |
|    value_loss            | 8.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.42         |
| reward                   | -0.63762945  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -775         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1346         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0030735522 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 3.68         |
|    cost_values           | 1            |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.000551    |
|    std                   | 0.869        |
|    value_loss            | 23.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.0193777   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -774         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1381         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0033274319 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 3.81         |
|    cost_values           | 1.17         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.16         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.000393    |
|    std                   | 0.868        |
|    value_loss            | 13.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.43         |
| reward                   | -0.94613135  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1415         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0044039907 |
|    clip_fraction         | 0.00615      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 1.34         |
|    cost_values           | 1.36         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.000574    |
|    std                   | 0.867        |
|    value_loss            | 7.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.9587768   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1450         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0023468607 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 0.797        |
|    cost_values           | 1.2          |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.83         |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.865        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.94544    |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1485        |
|    total_timesteps       | 188416      |
| train/                   |             |
|    approx_kl             | 0.004280311 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 2.4         |
|    cost_values           | 1.02        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 910         |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.866       |
|    value_loss            | 7.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.54         |
| reward                   | -1.3627571   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1520         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0023882585 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 2.08         |
|    cost_values           | 1.07         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.64         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.000561    |
|    std                   | 0.864        |
|    value_loss            | 6.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.75025654 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -762        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1555        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.0057164   |
|    clip_fraction         | 0.00874     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 2.39        |
|    cost_values           | 1.21        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38.1        |
|    n_updates             | 930         |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.863       |
|    value_loss            | 62.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.627       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.627       |
| reward                   | -0.5781421  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1589        |
|    total_timesteps       | 194560      |
| train/                   |             |
|    approx_kl             | 0.003021417 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 2.81        |
|    cost_values           | 1.22        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.36        |
|    n_updates             | 940         |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.862       |
|    value_loss            | 8.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.44        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.44        |
| reward                   | -0.7264991  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -763        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1624        |
|    total_timesteps       | 196608      |
| train/                   |             |
|    approx_kl             | 0.002721138 |
|    clip_fraction         | 0.00601     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 0.0655      |
|    cost_values           | 1.35        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.9        |
|    n_updates             | 950         |
|    policy_gradient_loss  | -0.000151   |
|    std                   | 0.862       |
|    value_loss            | 32.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.42         |
| reward                   | -0.8367124   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1658         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0017869918 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 2.61         |
|    cost_values           | 1.06         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.000598    |
|    std                   | 0.862        |
|    value_loss            | 36.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.12          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.12          |
| reward                   | -0.37589747   |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -759          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 49            |
|    time_elapsed          | 1694          |
|    total_timesteps       | 200704        |
| train/                   |               |
|    approx_kl             | 1.3762619e-06 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.916         |
|    cost_value_loss       | 0.197         |
|    cost_values           | 0.99          |
|    entropy               | -2.54         |
|    entropy_loss          | -2.54         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 22.9          |
|    n_updates             | 970           |
|    policy_gradient_loss  | 0.000169      |
|    std                   | 0.862         |
|    value_loss            | 46.8          |
--------------------------------------------
-----------------------------------
| avg_speed          | 7.95       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.95       |
| reward             | -0.9395509 |
| rollout/           |            |
|    ep_len_mean     | 989        |
|    ep_rew_mean     | -752       |
| time/              |            |
|    fps             | 81         |
|    iterations      | 1          |
|    time_elapsed    | 25         |
|    total_timesteps | 202752     |
-----------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.8479586    |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -749          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 2             |
|    time_elapsed          | 60            |
|    total_timesteps       | 204800        |
| train/                   |               |
|    approx_kl             | 0.00084304775 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.68          |
|    cost_value_loss       | 3.27          |
|    cost_values           | 1.01          |
|    entropy               | -2.54         |
|    entropy_loss          | -2.54         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.35          |
|    n_updates             | 990           |
|    policy_gradient_loss  | 0.000116      |
|    std                   | 0.863         |
|    value_loss            | 9             |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.48484606  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0049919365 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.756        |
|    cost_values           | 1.05         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.849        |
|    value_loss            | 7.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.53832483  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0013965705 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.459        |
|    cost_values           | 0.982        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 1010         |
|    policy_gradient_loss  | 0.000285     |
|    std                   | 0.848        |
|    value_loss            | 53.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7735925  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -743        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.004364528 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 3.33        |
|    cost_values           | 1.2         |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.846       |
|    value_loss            | 18.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8306714   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0040396536 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 2.37         |
|    cost_values           | 1.72         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.02         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.844        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8205835  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -740        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 232         |
|    total_timesteps       | 215040      |
| train/                   |             |
|    approx_kl             | 0.007097655 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.37        |
|    cost_value_loss       | 3.08        |
|    cost_values           | 2.04        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.12        |
|    n_updates             | 1040        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.843       |
|    value_loss            | 29.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0448351  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -743        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 217088      |
| train/                   |             |
|    approx_kl             | 0.007280687 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 0.086       |
|    cost_values           | 1.9         |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.06        |
|    n_updates             | 1050        |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 0.843       |
|    value_loss            | 17.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.55464387 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -746        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 301         |
|    total_timesteps       | 219136      |
| train/                   |             |
|    approx_kl             | 0.004356878 |
|    clip_fraction         | 0.012       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 0.0408      |
|    cost_values           | 1.48        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 1060        |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.842       |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -0.6902778   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 335          |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0045515993 |
|    clip_fraction         | 0.00645      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.0262       |
|    cost_values           | 1.1          |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.4          |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.842        |
|    value_loss            | 12.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.66194695  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0047060484 |
|    clip_fraction         | 0.0064       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 7.87         |
|    cost_values           | 1.1          |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.3          |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.843        |
|    value_loss            | 8.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -0.93262583  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0047033634 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 2.56         |
|    cost_values           | 1.45         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.000233    |
|    std                   | 0.843        |
|    value_loss            | 8.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.84999174  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0032543726 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.669        |
|    cost_values           | 1.6          |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.36         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.844        |
|    value_loss            | 4.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.33        |
| reward                   | -0.72547996 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -741        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 474         |
|    total_timesteps       | 229376      |
| train/                   |             |
|    approx_kl             | 0.004573658 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 0.911       |
|    cost_values           | 1.32        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.58        |
|    n_updates             | 1110        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.846       |
|    value_loss            | 6.72        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.7752174 |
| rollout/                 |            |
|    ep_len_mean           | 993        |
|    ep_rew_mean           | -744       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 15         |
|    time_elapsed          | 508        |
|    total_timesteps       | 231424     |
| train/                   |            |
|    approx_kl             | 0.00331702 |
|    clip_fraction         | 0.0183     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.48       |
|    cost_value_loss       | 2.47       |
|    cost_values           | 1.33       |
|    entropy               | -2.51      |
|    entropy_loss          | -2.51      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 3.14       |
|    n_updates             | 1120       |
|    policy_gradient_loss  | -0.000587  |
|    std                   | 0.848      |
|    value_loss            | 2.91       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.37614202  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0035358537 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 0.849        |
|    cost_values           | 1.42         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.51        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.23         |
|    n_updates             | 1130         |
|    policy_gradient_loss  | 3.22e-05     |
|    std                   | 0.847        |
|    value_loss            | 5.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.7          |
| reward                   | -0.8195254   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0062464224 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 0.244        |
|    cost_values           | 1.3          |
|    entropy               | -2.47        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.39         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.834        |
|    value_loss            | 14.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.68977994  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 611          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0042857006 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 4.37         |
|    cost_values           | 1.34         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.4         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.000817    |
|    std                   | 0.833        |
|    value_loss            | 36.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.22         |
| reward                   | -0.7322863   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 646          |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0011585129 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 4.58         |
|    cost_values           | 1.51         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.000243    |
|    std                   | 0.834        |
|    value_loss            | 30.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.58         |
| reward                   | -0.4046445   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 241664       |
| train/                   |              |
|    approx_kl             | 0.0026406925 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 6.99         |
|    cost_values           | 1.62         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.4         |
|    n_updates             | 1170         |
|    policy_gradient_loss  | -0.000662    |
|    std                   | 0.834        |
|    value_loss            | 34.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0978       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0978       |
| reward                   | -0.65824604  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0015374816 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 1.84         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.76         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.000321    |
|    std                   | 0.833        |
|    value_loss            | 6.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.58        |
| reward                   | -0.8153274  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 751         |
|    total_timesteps       | 245760      |
| train/                   |             |
|    approx_kl             | 0.004754077 |
|    clip_fraction         | 0.0223      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.37        |
|    cost_value_loss       | 2.23        |
|    cost_values           | 2.12        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 1190        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.832       |
|    value_loss            | 29.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.935        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.935        |
| reward                   | -0.71994555  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 785          |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0057078702 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.47         |
|    cost_value_loss       | 9.25         |
|    cost_values           | 2.23         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.831        |
|    value_loss            | 17           |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.75        |
| reward                   | -0.884827   |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -722        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 819         |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.006152562 |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.31        |
|    cost_value_loss       | 2.25        |
|    cost_values           | 2.28        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.73        |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.834       |
|    value_loss            | 4.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.65         |
| reward                   | -0.5748698   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 854          |
|    total_timesteps       | 251904       |
| train/                   |              |
|    approx_kl             | 0.0037182248 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 3.31         |
|    cost_values           | 2.22         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 1220         |
|    policy_gradient_loss  | -9.42e-05    |
|    std                   | 0.834        |
|    value_loss            | 5.69         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.14        |
| reward                   | -0.8817283  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 888         |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.003953879 |
|    clip_fraction         | 0.0102      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 6.04        |
|    cost_values           | 2.4         |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.2         |
|    n_updates             | 1230        |
|    policy_gradient_loss  | -0.000981   |
|    std                   | 0.832       |
|    value_loss            | 1.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.5          |
| reward                   | -0.6500524   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 922          |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0018864236 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 0.548        |
|    cost_values           | 2.62         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.3         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.000376    |
|    std                   | 0.831        |
|    value_loss            | 25.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.3          |
| reward                   | -0.53960514  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 957          |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0036678854 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 5.55         |
|    cost_values           | 2.49         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.5          |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.000226    |
|    std                   | 0.831        |
|    value_loss            | 2.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.578        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.578        |
| reward                   | -0.5356722   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 991          |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0072040013 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.83         |
|    cost_value_loss       | 20.4         |
|    cost_values           | 2.89         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00283      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.85         |
|    n_updates             | 1260         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.831        |
|    value_loss            | 6.58         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.578         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.578         |
| reward                   | -0.6816481    |
| rollout/                 |               |
|    ep_len_mean           | 968           |
|    ep_rew_mean           | -704          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 30            |
|    time_elapsed          | 1026          |
|    total_timesteps       | 262144        |
| train/                   |               |
|    approx_kl             | 0.00093537633 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.34          |
|    cost_value_loss       | 5.02          |
|    cost_values           | 2.94          |
|    entropy               | -2.47         |
|    entropy_loss          | -2.46         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.2          |
|    n_updates             | 1270          |
|    policy_gradient_loss  | -0.000315     |
|    std                   | 0.831         |
|    value_loss            | 17.5          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 4.31          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.31          |
| reward                   | -0.7604395    |
| rollout/                 |               |
|    ep_len_mean           | 968           |
|    ep_rew_mean           | -704          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 31            |
|    time_elapsed          | 1061          |
|    total_timesteps       | 264192        |
| train/                   |               |
|    approx_kl             | 0.00025818482 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.2           |
|    cost_value_loss       | 4.23          |
|    cost_values           | 2.8           |
|    entropy               | -2.47         |
|    entropy_loss          | -2.47         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21.2          |
|    n_updates             | 1280          |
|    policy_gradient_loss  | -2.84e-05     |
|    std                   | 0.831         |
|    value_loss            | 29.1          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.84         |
| reward                   | -0.7139035   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1096         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0045957393 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 0.119        |
|    cost_values           | 2.4          |
|    entropy               | -2.45        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.88         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.826        |
|    value_loss            | 3.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.25         |
| reward                   | -0.772846    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1130         |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0041454015 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 0.0952       |
|    cost_values           | 1.97         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.33         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.823        |
|    value_loss            | 7.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6105915  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1164        |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.001464753 |
|    clip_fraction         | 4.88e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 0.0471      |
|    cost_values           | 1.58        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.45        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.000269   |
|    std                   | 0.822       |
|    value_loss            | 6.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.53         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.53         |
| reward                   | -0.60819715  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1199         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0036819833 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 1.87         |
|    cost_values           | 1.3          |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.85         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.821        |
|    value_loss            | 6.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.67949826 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1233        |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.00448962  |
|    clip_fraction         | 0.00684     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.64        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 1.35        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 0.82        |
|    value_loss            | 9.01        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.98          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.98          |
| reward                   | -0.7669515    |
| rollout/                 |               |
|    ep_len_mean           | 968           |
|    ep_rew_mean           | -699          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 37            |
|    time_elapsed          | 1268          |
|    total_timesteps       | 276480        |
| train/                   |               |
|    approx_kl             | 0.00020784134 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.35          |
|    cost_value_loss       | 0.308         |
|    cost_values           | 1.44          |
|    entropy               | -2.44         |
|    entropy_loss          | -2.44         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 2.15          |
|    n_updates             | 1340          |
|    policy_gradient_loss  | 1.96e-05      |
|    std                   | 0.82          |
|    value_loss            | 4.46          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9743328   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1302         |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0017470706 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 6.67         |
|    cost_values           | 1.22         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.51         |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.000738    |
|    std                   | 0.821        |
|    value_loss            | 12.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.63          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.63          |
| reward                   | -0.67606485   |
| rollout/                 |               |
|    ep_len_mean           | 968           |
|    ep_rew_mean           | -702          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 39            |
|    time_elapsed          | 1338          |
|    total_timesteps       | 280576        |
| train/                   |               |
|    approx_kl             | 0.00019970289 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.01          |
|    cost_value_loss       | 0.0749        |
|    cost_values           | 1.07          |
|    entropy               | -2.44         |
|    entropy_loss          | -2.44         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.27          |
|    n_updates             | 1360          |
|    policy_gradient_loss  | 2.11e-05      |
|    std                   | 0.82          |
|    value_loss            | 9.53          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.5          |
| reward                   | -0.5467209   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1373         |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0033615902 |
|    clip_fraction         | 0.00186      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.898        |
|    cost_value_loss       | 0.21         |
|    cost_values           | 0.921        |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.69         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.000283    |
|    std                   | 0.82         |
|    value_loss            | 4.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.901        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.901        |
| reward                   | -0.6411323   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1408         |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0006113666 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 3.86         |
|    cost_values           | 0.983        |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.4         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -9.73e-05    |
|    std                   | 0.82         |
|    value_loss            | 52.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.29         |
| reward                   | -0.5497628   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1443         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0036921422 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 3.67         |
|    cost_values           | 1.05         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.79         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.82         |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.14         |
| reward                   | -0.5424437   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1477         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0026652263 |
|    clip_fraction         | 0.00767      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 2.61         |
|    cost_values           | 1.16         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.46         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00074     |
|    std                   | 0.821        |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.67         |
| reward                   | -0.5597885   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1512         |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0007076265 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.032        |
|    cost_values           | 1.14         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.879        |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -6.36e-05    |
|    std                   | 0.822        |
|    value_loss            | 2.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.78        |
| reward                   | -0.50100255 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1546        |
|    total_timesteps       | 292864      |
| train/                   |             |
|    approx_kl             | 0.00505015  |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.839       |
|    cost_value_loss       | 0.0848      |
|    cost_values           | 0.887       |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.57        |
|    n_updates             | 1420        |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 0.821       |
|    value_loss            | 3.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.04         |
| reward                   | -0.7189755   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1581         |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0029757263 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.906        |
|    cost_value_loss       | 0.509        |
|    cost_values           | 0.852        |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.82         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.000961    |
|    std                   | 0.82         |
|    value_loss            | 9.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.52575386  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1615         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0014743947 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.804        |
|    cost_value_loss       | 0.151        |
|    cost_values           | 0.853        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.09         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.000162    |
|    std                   | 0.816        |
|    value_loss            | 4.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.7218783   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1649         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0043799053 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.751        |
|    cost_value_loss       | 0.222        |
|    cost_values           | 0.778        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.13         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.000763    |
|    std                   | 0.815        |
|    value_loss            | 16.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.54        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.54        |
| reward                   | -0.5099856  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -678        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1684        |
|    total_timesteps       | 301056      |
| train/                   |             |
|    approx_kl             | 0.002731154 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.622       |
|    cost_value_loss       | 0.00927     |
|    cost_values           | 0.676       |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.86        |
|    n_updates             | 1460        |
|    policy_gradient_loss  | -0.000617   |
|    std                   | 0.815       |
|    value_loss            | 3.76        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
------------------------------------
| avg_speed          | 8.06        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.06        |
| reward             | -0.43197268 |
| rollout/           |             |
|    ep_len_mean     | 966         |
|    ep_rew_mean     | -671        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 303104      |
------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.39206326 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -672        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 305152      |
| train/                   |             |
|    approx_kl             | 0.002544966 |
|    clip_fraction         | 0.000635    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 2.6         |
|    cost_values           | 1.25        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.58        |
|    n_updates             | 1480        |
|    policy_gradient_loss  | -0.000287   |
|    std                   | 0.813       |
|    value_loss            | 4.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.632        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.632        |
| reward                   | -0.6857245   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0053484887 |
|    clip_fraction         | 0.0624       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.974        |
|    cost_value_loss       | 0.027        |
|    cost_values           | 0.997        |
|    entropy               | -2.41        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.84         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 0.808        |
|    value_loss            | 10.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 1             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1             |
| reward                   | -0.5611409    |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -670          |
| time/                    |               |
|    fps                   | 63            |
|    iterations            | 4             |
|    time_elapsed          | 129           |
|    total_timesteps       | 309248        |
| train/                   |               |
|    approx_kl             | 0.00060161285 |
|    clip_fraction         | 0.0238        |
|    clip_range            | 0.2           |
|    cost_returns          | 0.815         |
|    cost_value_loss       | 0.0244        |
|    cost_values           | 0.892         |
|    entropy               | -2.4          |
|    entropy_loss          | -2.4          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.426         |
|    n_updates             | 1500          |
|    policy_gradient_loss  | -0.000289     |
|    std                   | 0.802         |
|    value_loss            | 0.955         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 3.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.37         |
| reward                   | -0.68241376  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0023356695 |
|    clip_fraction         | 0.00474      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 2.38         |
|    cost_values           | 0.937        |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.9          |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -8.34e-05    |
|    std                   | 0.8          |
|    value_loss            | 6.6          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 3.05          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 3.05          |
| reward                   | -0.6051712    |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -664          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 6             |
|    time_elapsed          | 199           |
|    total_timesteps       | 313344        |
| train/                   |               |
|    approx_kl             | 0.00088974886 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.98          |
|    cost_value_loss       | 15.9          |
|    cost_values           | 1.17          |
|    entropy               | -2.39         |
|    entropy_loss          | -2.39         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.4          |
|    n_updates             | 1520          |
|    policy_gradient_loss  | -0.000271     |
|    std                   | 0.799         |
|    value_loss            | 8.19          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.50096184 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -660        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 234         |
|    total_timesteps       | 315392      |
| train/                   |             |
|    approx_kl             | 0.005492039 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 0.334       |
|    cost_values           | 1.34        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.55        |
|    n_updates             | 1530        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.798       |
|    value_loss            | 3.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.39418238 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -659        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 8           |
|    time_elapsed          | 268         |
|    total_timesteps       | 317440      |
| train/                   |             |
|    approx_kl             | 0.007669646 |
|    clip_fraction         | 0.0405      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 1.97        |
|    cost_values           | 1.29        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 1540        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.797       |
|    value_loss            | 2.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.95547694  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0014616122 |
|    clip_fraction         | 0.0769       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 5.15         |
|    cost_values           | 1.43         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.92         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | 0.00242      |
|    std                   | 0.796        |
|    value_loss            | 8.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.59153056 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -657        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 337         |
|    total_timesteps       | 321536      |
| train/                   |             |
|    approx_kl             | 0.00433217  |
|    clip_fraction         | 0.0158      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 5.21        |
|    cost_values           | 1.52        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 1560        |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.793       |
|    value_loss            | 4.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.33        |
| reward                   | -0.6528149  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -662        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 372         |
|    total_timesteps       | 323584      |
| train/                   |             |
|    approx_kl             | 0.004748972 |
|    clip_fraction         | 0.0574      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 0.111       |
|    cost_values           | 1.58        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.14        |
|    n_updates             | 1570        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.791       |
|    value_loss            | 4.48        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.9           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.9           |
| reward                   | -0.38807267   |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -663          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 12            |
|    time_elapsed          | 407           |
|    total_timesteps       | 325632        |
| train/                   |               |
|    approx_kl             | 0.00069204613 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.12          |
|    cost_value_loss       | 0.0362        |
|    cost_values           | 1.26          |
|    entropy               | -2.37         |
|    entropy_loss          | -2.37         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.8          |
|    n_updates             | 1580          |
|    policy_gradient_loss  | -0.000153     |
|    std                   | 0.791         |
|    value_loss            | 25.3          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -0.6825124  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -662        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 441         |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.004816032 |
|    clip_fraction         | 0.012       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.99        |
|    cost_value_loss       | 6.75        |
|    cost_values           | 1.15        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.792       |
|    value_loss            | 3.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.4064058  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -660        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 475         |
|    total_timesteps       | 329728      |
| train/                   |             |
|    approx_kl             | 0.004074225 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 0.519       |
|    cost_values           | 1.28        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.56        |
|    n_updates             | 1600        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.79        |
|    value_loss            | 6.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.341       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.341       |
| reward                   | -0.8408208  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -662        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 510         |
|    total_timesteps       | 331776      |
| train/                   |             |
|    approx_kl             | 0.003926962 |
|    clip_fraction         | 0.0263      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 0.981       |
|    cost_values           | 1.23        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 1610        |
|    policy_gradient_loss  | -0.000636   |
|    std                   | 0.788       |
|    value_loss            | 7.02        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.87         |
| reward                   | -0.7732884   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 544          |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0045662583 |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 8.56         |
|    cost_values           | 1.34         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.9         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -5.66e-05    |
|    std                   | 0.788        |
|    value_loss            | 36.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.73        |
| reward                   | -0.70639724 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 579         |
|    total_timesteps       | 335872      |
| train/                   |             |
|    approx_kl             | 0.001875791 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 1.71        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.7        |
|    n_updates             | 1630        |
|    policy_gradient_loss  | -0.000559   |
|    std                   | 0.788       |
|    value_loss            | 15.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.27         |
| reward                   | -0.64958525  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 613          |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0043570036 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 0.0673       |
|    cost_values           | 1.68         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.38         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.788        |
|    value_loss            | 2.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.83930844 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 647         |
|    total_timesteps       | 339968      |
| train/                   |             |
|    approx_kl             | 0.005197578 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 0.143       |
|    cost_values           | 1.31        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.914       |
|    n_updates             | 1650        |
|    policy_gradient_loss  | -0.000119   |
|    std                   | 0.788       |
|    value_loss            | 1.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.82609445  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0026981856 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.944        |
|    cost_value_loss       | 0.0223       |
|    cost_values           | 1.04         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | 0.000151     |
|    std                   | 0.787        |
|    value_loss            | 25.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.78          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.78          |
| reward                   | -1.2236748    |
| rollout/                 |               |
|    ep_len_mean           | 978           |
|    ep_rew_mean           | -690          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 21            |
|    time_elapsed          | 716           |
|    total_timesteps       | 344064        |
| train/                   |               |
|    approx_kl             | 0.00045345663 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.48          |
|    cost_value_loss       | 11.1          |
|    cost_values           | 1.14          |
|    entropy               | -2.36         |
|    entropy_loss          | -2.36         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 22.2          |
|    n_updates             | 1670          |
|    policy_gradient_loss  | -0.000157     |
|    std                   | 0.787         |
|    value_loss            | 33.8          |
--------------------------------------------
---------------------------------------------
| avg_speed                | 8.01           |
| cost                     | 0              |
| is_success               | 0              |
| max_speed                | 8.01           |
| reward                   | -0.6668481     |
| rollout/                 |                |
|    ep_len_mean           | 975            |
|    ep_rew_mean           | -691           |
| time/                    |                |
|    fps                   | 59             |
|    iterations            | 22             |
|    time_elapsed          | 751            |
|    total_timesteps       | 346112         |
| train/                   |                |
|    approx_kl             | 0.000120017154 |
|    clip_fraction         | 0              |
|    clip_range            | 0.2            |
|    cost_returns          | 1.27           |
|    cost_value_loss       | 0.77           |
|    cost_values           | 1.33           |
|    entropy               | -2.36          |
|    entropy_loss          | -2.36          |
|    explained_variance    | 0              |
|    lagrangian_multiplier | 0              |
|    learning_rate         | 0.0003         |
|    loss                  | 14.4           |
|    n_updates             | 1680           |
|    policy_gradient_loss  | -6.68e-05      |
|    std                   | 0.788          |
|    value_loss            | 30.4           |
---------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -1.246059    |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 786          |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0020972118 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 12.3         |
|    cost_values           | 1.29         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.4         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.000631    |
|    std                   | 0.788        |
|    value_loss            | 45.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4904331   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 820          |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0021308055 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 3.04         |
|    cost_values           | 1.65         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.82         |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.784        |
|    value_loss            | 17.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.13        |
| reward                   | -0.59005016 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 855         |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.002639036 |
|    clip_fraction         | 0.00586     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 0.988       |
|    cost_values           | 1.56        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.000128   |
|    std                   | 0.783       |
|    value_loss            | 27.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.83        |
| reward                   | -0.6424453  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 889         |
|    total_timesteps       | 354304      |
| train/                   |             |
|    approx_kl             | 0.003110839 |
|    clip_fraction         | 0.00142     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 1.44        |
|    cost_values           | 1.28        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 1720        |
|    policy_gradient_loss  | -0.000953   |
|    std                   | 0.783       |
|    value_loss            | 19.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.83         |
| reward                   | -0.54062945  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 923          |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0005175759 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 2.51         |
|    cost_values           | 1.07         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.000113    |
|    std                   | 0.783        |
|    value_loss            | 26           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.8014232   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0033495673 |
|    clip_fraction         | 0.00649      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.787        |
|    cost_values           | 1            |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.33         |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.000208    |
|    std                   | 0.779        |
|    value_loss            | 9.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.52166766  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 992          |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0034932229 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 5.21         |
|    cost_values           | 1            |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | 3.56e-05     |
|    std                   | 0.779        |
|    value_loss            | 38.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -1.1099783  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -721        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1027        |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.004139475 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.902       |
|    cost_value_loss       | 0.191       |
|    cost_values           | 0.923       |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.17        |
|    n_updates             | 1760        |
|    policy_gradient_loss  | -0.000359   |
|    std                   | 0.779       |
|    value_loss            | 13.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.152        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.152        |
| reward                   | -0.5176855   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1061         |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0038509308 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 3.53         |
|    cost_values           | 1.03         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22           |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.78         |
|    value_loss            | 41.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.26        |
| reward                   | -0.4492     |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -721        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1096        |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.004988117 |
|    clip_fraction         | 0.00723     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.901       |
|    cost_value_loss       | 0.0264      |
|    cost_values           | 1.01        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.95        |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.78        |
|    value_loss            | 7.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.133       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.133       |
| reward                   | -0.632882   |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1130        |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.004853826 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.26        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 1.13        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.779       |
|    value_loss            | 13.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.6          |
| reward                   | -0.7630353   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0042572343 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 0.432        |
|    cost_values           | 1.24         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.13         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.000552    |
|    std                   | 0.78         |
|    value_loss            | 7.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.41         |
| reward                   | -0.7610303   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1198         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0017955466 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.131        |
|    cost_values           | 1.09         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.5          |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.000109    |
|    std                   | 0.781        |
|    value_loss            | 5.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.62019694  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1233         |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0038371184 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.796        |
|    cost_value_loss       | 0.0184       |
|    cost_values           | 0.899        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.78         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.779        |
|    value_loss            | 7.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.31304878 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -722        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1268        |
|    total_timesteps       | 376832      |
| train/                   |             |
|    approx_kl             | 0.004634692 |
|    clip_fraction         | 0.0323      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 1.74        |
|    cost_values           | 0.943       |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.88        |
|    n_updates             | 1830        |
|    policy_gradient_loss  | -0.00243    |
|    std                   | 0.779       |
|    value_loss            | 2.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.31         |
| reward                   | -0.5663951   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1302         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0048702154 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.48         |
|    cost_values           | 1.07         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.777        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.66221803  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0051546087 |
|    clip_fraction         | 0.0724       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 7.24         |
|    cost_values           | 1.16         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.54         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.000896    |
|    std                   | 0.775        |
|    value_loss            | 9.45         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.96          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.96          |
| reward                   | -0.35775128   |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -718          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 40            |
|    time_elapsed          | 1371          |
|    total_timesteps       | 382976        |
| train/                   |               |
|    approx_kl             | 2.2925291e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.95          |
|    cost_value_loss       | 6.57          |
|    cost_values           | 1.25          |
|    entropy               | -2.33         |
|    entropy_loss          | -2.33         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.75          |
|    n_updates             | 1860          |
|    policy_gradient_loss  | 2.72e-05      |
|    std                   | 0.775         |
|    value_loss            | 6.96          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.61608344  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1405         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0044807317 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 0.9          |
|    cost_values           | 1.36         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.2         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00074     |
|    std                   | 0.775        |
|    value_loss            | 82.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.25         |
| reward                   | -0.63579535  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1441         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0039524017 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.207        |
|    cost_values           | 1.22         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.41         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.774        |
|    value_loss            | 7.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.834        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.834        |
| reward                   | -0.43243656  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1475         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0071759177 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 3.3          |
|    cost_values           | 1.04         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.1         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.774        |
|    value_loss            | 38.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.96         |
| reward                   | -0.75334114  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1510         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0050764866 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.89         |
|    cost_value_loss       | 0.0302       |
|    cost_values           | 0.925        |
|    entropy               | -2.31        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.54         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.77         |
|    value_loss            | 5.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5            |
| reward                   | -0.79938734  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1545         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0014696986 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.987        |
|    cost_value_loss       | 0.674        |
|    cost_values           | 0.96         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.79         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -1.95e-05    |
|    std                   | 0.768        |
|    value_loss            | 5.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.5861109  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1579        |
|    total_timesteps       | 395264      |
| train/                   |             |
|    approx_kl             | 0.005751067 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.9         |
|    cost_value_loss       | 0.142       |
|    cost_values           | 0.983       |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 1920        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.769       |
|    value_loss            | 6.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.6640632  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1614        |
|    total_timesteps       | 397312      |
| train/                   |             |
|    approx_kl             | 0.004174042 |
|    clip_fraction         | 0.0138      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.536       |
|    cost_values           | 0.983       |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 1930        |
|    policy_gradient_loss  | -0.000844   |
|    std                   | 0.769       |
|    value_loss            | 4.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.95         |
| reward                   | -0.64642084  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1649         |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0009914197 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 8.56         |
|    cost_values           | 1.14         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.72         |
|    n_updates             | 1940         |
|    policy_gradient_loss  | -0.000154    |
|    std                   | 0.77         |
|    value_loss            | 8.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.21         |
| reward                   | -0.57775897  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1683         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0003944886 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 1.64         |
|    cost_values           | 1.34         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.000263    |
|    std                   | 0.77         |
|    value_loss            | 49           |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.87       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.87       |
| reward             | -0.8159139 |
| rollout/           |            |
|    ep_len_mean     | 960        |
|    ep_rew_mean     | -715       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 403456     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.85990196  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0010315684 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.141        |
|    cost_values           | 1.14         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.08         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.772        |
|    value_loss            | 7.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.44953778 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 3           |
|    time_elapsed          | 95          |
|    total_timesteps       | 407552      |
| train/                   |             |
|    approx_kl             | 0.003533677 |
|    clip_fraction         | 0.037       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 0.934       |
|    cost_values           | 1.07        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.72        |
|    n_updates             | 1980        |
|    policy_gradient_loss  | -0.000562   |
|    std                   | 0.772       |
|    value_loss            | 7.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.77         |
| reward                   | -0.88114494  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 4            |
|    time_elapsed          | 131          |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0008015544 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 8.88         |
|    cost_values           | 1.1          |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.000508    |
|    std                   | 0.772        |
|    value_loss            | 8.13         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 2.22          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.22          |
| reward                   | -0.59627545   |
| rollout/                 |               |
|    ep_len_mean           | 954           |
|    ep_rew_mean           | -714          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 5             |
|    time_elapsed          | 166           |
|    total_timesteps       | 411648        |
| train/                   |               |
|    approx_kl             | 0.00012353313 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.7           |
|    cost_value_loss       | 14.5          |
|    cost_values           | 1.31          |
|    entropy               | -2.32         |
|    entropy_loss          | -2.32         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 26.4          |
|    n_updates             | 2000          |
|    policy_gradient_loss  | -6.3e-05      |
|    std                   | 0.772         |
|    value_loss            | 46            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 3.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.36         |
| reward                   | -0.53521717  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 6            |
|    time_elapsed          | 202          |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0002619807 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.84         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 1.43         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.000195    |
|    std                   | 0.773        |
|    value_loss            | 25.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.87         |
| reward                   | -0.70085365  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 7            |
|    time_elapsed          | 237          |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0013427283 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 2.16         |
|    cost_values           | 1.41         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.6          |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.000754    |
|    std                   | 0.773        |
|    value_loss            | 6.5          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 5.42          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.42          |
| reward                   | -0.812396     |
| rollout/                 |               |
|    ep_len_mean           | 954           |
|    ep_rew_mean           | -715          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 8             |
|    time_elapsed          | 273           |
|    total_timesteps       | 417792        |
| train/                   |               |
|    approx_kl             | 0.00024114863 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.18          |
|    cost_value_loss       | 0.329         |
|    cost_values           | 1.14          |
|    entropy               | -2.32         |
|    entropy_loss          | -2.32         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.78          |
|    n_updates             | 2030          |
|    policy_gradient_loss  | -9.03e-05     |
|    std                   | 0.771         |
|    value_loss            | 13.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 6.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.59         |
| reward                   | -0.65810275  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 9            |
|    time_elapsed          | 308          |
|    total_timesteps       | 419840       |
| train/                   |              |
|    approx_kl             | 0.0039039366 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 1.21         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.51         |
|    n_updates             | 2040         |
|    policy_gradient_loss  | -0.000714    |
|    std                   | 0.771        |
|    value_loss            | 8.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.9062143   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 10           |
|    time_elapsed          | 342          |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0027115976 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 5.14         |
|    cost_values           | 1.81         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.68         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.772        |
|    value_loss            | 5.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.27         |
| reward                   | -0.60680306  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 11           |
|    time_elapsed          | 376          |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0023900277 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 0.254        |
|    cost_values           | 2.06         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.64         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | 3.41e-05     |
|    std                   | 0.772        |
|    value_loss            | 8.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.40118778  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 12           |
|    time_elapsed          | 411          |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0028834008 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 0.0568       |
|    cost_values           | 1.69         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.23         |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.772        |
|    value_loss            | 13.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5909216   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 13           |
|    time_elapsed          | 446          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0026781033 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 0.932        |
|    cost_values           | 1.38         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.51         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.000214    |
|    std                   | 0.772        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.68498033  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 14           |
|    time_elapsed          | 480          |
|    total_timesteps       | 430080       |
| train/                   |              |
|    approx_kl             | 0.0007787962 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 4.3          |
|    cost_values           | 1.49         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 2090         |
|    policy_gradient_loss  | 2.97e-05     |
|    std                   | 0.772        |
|    value_loss            | 20.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.8147448   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 15           |
|    time_elapsed          | 515          |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0034303705 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 2.77         |
|    cost_values           | 1.71         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.16         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.000859    |
|    std                   | 0.773        |
|    value_loss            | 4.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9977364   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 549          |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0012811633 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 0.151        |
|    cost_values           | 1.58         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.2          |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.00061     |
|    std                   | 0.774        |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5468557   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 584          |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0049659642 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.0284       |
|    cost_values           | 1.23         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.773        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.2178593   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 619          |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0069822394 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 5.84         |
|    cost_values           | 1.08         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.89         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.773        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.83999765 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -722        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 653         |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.001968981 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 1.23        |
|    cost_values           | 1.14        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.83        |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -0.00055    |
|    std                   | 0.773       |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.93         |
| reward                   | -0.58635074  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 687          |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0045952783 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.888        |
|    cost_value_loss       | 0.0957       |
|    cost_values           | 0.91         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.000159    |
|    std                   | 0.773        |
|    value_loss            | 11.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.43        |
| reward                   | -0.7536572  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 722         |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.005240914 |
|    clip_fraction         | 0.0375      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 3.82        |
|    cost_values           | 1.18        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.772       |
|    value_loss            | 41.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.57        |
| reward                   | -0.7310663  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 756         |
|    total_timesteps       | 446464      |
| train/                   |             |
|    approx_kl             | 0.000691156 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 0.0481      |
|    cost_values           | 1.35        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15          |
|    n_updates             | 2170        |
|    policy_gradient_loss  | -4.14e-05   |
|    std                   | 0.771       |
|    value_loss            | 32.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.70378417  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 790          |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0021279438 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 1.26         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.771        |
|    value_loss            | 8.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7230464   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 825          |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0037197554 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 0.217        |
|    cost_values           | 1.34         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.77         |
|    value_loss            | 7.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -1.0037111   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 859          |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0017788829 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.22         |
|    cost_values           | 1.14         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.5          |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.000862    |
|    std                   | 0.769        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.85         |
| reward                   | -0.5111456   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 895          |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0039928923 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 1.38         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.000622    |
|    std                   | 0.769        |
|    value_loss            | 9.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.36        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.36        |
| reward                   | -0.3708041  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 929         |
|    total_timesteps       | 456704      |
| train/                   |             |
|    approx_kl             | 0.002670024 |
|    clip_fraction         | 0.00942     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 0.412       |
|    cost_values           | 1.49        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.38        |
|    n_updates             | 2220        |
|    policy_gradient_loss  | -0.0007     |
|    std                   | 0.769       |
|    value_loss            | 16.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.82         |
| reward                   | -0.79052293  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 964          |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0040683737 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 0.239        |
|    cost_values           | 1.21         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.49         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.768        |
|    value_loss            | 16.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.77         |
| reward                   | -0.7399909   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 998          |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0058799163 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 3.33         |
|    cost_values           | 1.01         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.75         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.768        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.24         |
| reward                   | -1.0909355   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1033         |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0047595794 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 4.21         |
|    cost_values           | 1.2          |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.02         |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.767        |
|    value_loss            | 9.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.44075072  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1068         |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0039318083 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 5.72         |
|    cost_values           | 1.57         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.57         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.765        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.34         |
| reward                   | -0.54378825  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1102         |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0037645074 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 9.24         |
|    cost_values           | 1.82         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.765        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.56         |
| reward                   | -0.7960874   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1137         |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0008796236 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.41         |
|    cost_value_loss       | 18.9         |
|    cost_values           | 2.22         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -0.000632    |
|    std                   | 0.765        |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.53         |
| reward                   | -0.7194074   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1171         |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0027069298 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 0.775        |
|    cost_values           | 2.24         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.13         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.766        |
|    value_loss            | 5.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.5763338   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1205         |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0038492512 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 2.11         |
|    cost_values           | 2.14         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.5          |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00057     |
|    std                   | 0.766        |
|    value_loss            | 1.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.41         |
| reward                   | -0.82816994  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1240         |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0053531034 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 0.352        |
|    cost_values           | 1.97         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.85         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.766        |
|    value_loss            | 6.32         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.48488203   |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -708          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 37            |
|    time_elapsed          | 1275          |
|    total_timesteps       | 477184        |
| train/                   |               |
|    approx_kl             | 0.00053319754 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.82          |
|    cost_value_loss       | 12.3          |
|    cost_values           | 1.89          |
|    entropy               | -2.3          |
|    entropy_loss          | -2.31         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.54          |
|    n_updates             | 2320          |
|    policy_gradient_loss  | -0.000203     |
|    std                   | 0.766         |
|    value_loss            | 5.34          |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.0876      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0876      |
| reward                   | -0.7493138  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1310        |
|    total_timesteps       | 479232      |
| train/                   |             |
|    approx_kl             | 0.005598531 |
|    clip_fraction         | 0.0113      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 0.266       |
|    cost_values           | 1.99        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.53        |
|    n_updates             | 2330        |
|    policy_gradient_loss  | -8.54e-06   |
|    std                   | 0.766       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.98         |
| reward                   | -0.65130836  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1345         |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0031675573 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 0.279        |
|    cost_values           | 1.59         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.06         |
|    n_updates             | 2340         |
|    policy_gradient_loss  | -0.000608    |
|    std                   | 0.764        |
|    value_loss            | 3.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.98621804  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1380         |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0034817357 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 0.488        |
|    cost_values           | 1.48         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.1          |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.000964    |
|    std                   | 0.762        |
|    value_loss            | 3.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.46010363  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1415         |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0029500714 |
|    clip_fraction         | 0.0021       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 5.63         |
|    cost_values           | 1.31         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28           |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.762        |
|    value_loss            | 37.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.9           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.9           |
| reward                   | -1.2085398    |
| rollout/                 |               |
|    ep_len_mean           | 979           |
|    ep_rew_mean           | -715          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 42            |
|    time_elapsed          | 1450          |
|    total_timesteps       | 487424        |
| train/                   |               |
|    approx_kl             | 1.8302148e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.39          |
|    cost_value_loss       | 10.1          |
|    cost_values           | 1.39          |
|    entropy               | -2.29         |
|    entropy_loss          | -2.29         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.3          |
|    n_updates             | 2370          |
|    policy_gradient_loss  | 4.95e-05      |
|    std                   | 0.762         |
|    value_loss            | 13.2          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -1.0005028  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1485        |
|    total_timesteps       | 489472      |
| train/                   |             |
|    approx_kl             | 0.004622966 |
|    clip_fraction         | 0.0209      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 0.88        |
|    cost_values           | 1.45        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.15        |
|    n_updates             | 2380        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.762       |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52759224  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1520         |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0024711774 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.0267       |
|    cost_values           | 1.17         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.13         |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.000258    |
|    std                   | 0.761        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.63         |
| reward                   | -0.7877432   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1555         |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0023654206 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 1.29         |
|    cost_values           | 1.09         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.87         |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.76         |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.58         |
| reward                   | -1.1072704   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1589         |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0060324403 |
|    clip_fraction         | 0.0526       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.965        |
|    cost_value_loss       | 0.0229       |
|    cost_values           | 1.05         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.35         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.761        |
|    value_loss            | 5.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.0671691   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1624         |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0038557705 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.767        |
|    cost_value_loss       | 0.0187       |
|    cost_values           | 0.847        |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.9          |
|    n_updates             | 2420         |
|    policy_gradient_loss  | -0.000775    |
|    std                   | 0.762        |
|    value_loss            | 6.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.891114    |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -732         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1658         |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0041110734 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.692        |
|    cost_value_loss       | 0.144        |
|    cost_values           | 0.734        |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.39         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.761        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72540236  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1692         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0034455145 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 3.83         |
|    cost_values           | 0.977        |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.761        |
|    value_loss            | 21.7         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
------------------------------------
| avg_speed          | 0.2         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.2         |
| reward             | -0.79231614 |
| rollout/           |             |
|    ep_len_mean     | 986         |
|    ep_rew_mean     | -725        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 2.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.23         |
| reward                   | -0.6891276   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0027894992 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.156        |
|    cost_values           | 1.25         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.23         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.761        |
|    value_loss            | 4.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3977557   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0038450332 |
|    clip_fraction         | 0.0083       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.887        |
|    cost_value_loss       | 0.0153       |
|    cost_values           | 0.954        |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.16         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.000625    |
|    std                   | 0.76         |
|    value_loss            | 4.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.42217445  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0044560935 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.43         |
|    cost_values           | 0.903        |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.759        |
|    value_loss            | 43.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.8324789   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0010594369 |
|    clip_fraction         | 0.00313      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 3.42         |
|    cost_values           | 1.19         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00017     |
|    std                   | 0.762        |
|    value_loss            | 5.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -0.89556694  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0038041305 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 1.21         |
|    cost_values           | 1.37         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.07         |
|    n_updates             | 2500         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.764        |
|    value_loss            | 11.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.18         |
| reward                   | -0.8285313   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0046823323 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 3.68         |
|    cost_values           | 1.38         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.79         |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.764        |
|    value_loss            | 4.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.86         |
| reward                   | -0.59682095  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0010801388 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.0956       |
|    cost_values           | 1.47         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00029     |
|    std                   | 0.763        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.5478732   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 299          |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0008633854 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 2.36         |
|    cost_values           | 1.25         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.18         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -3.98e-05    |
|    std                   | 0.763        |
|    value_loss            | 6.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8216146   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 333          |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0006778535 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 2.5          |
|    cost_values           | 1.19         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.81         |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -8.63e-05    |
|    std                   | 0.763        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.6404012   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0031579724 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.54         |
|    cost_values           | 1.16         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.762        |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5509247  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 12          |
|    time_elapsed          | 402         |
|    total_timesteps       | 526336      |
| train/                   |             |
|    approx_kl             | 0.005116003 |
|    clip_fraction         | 0.0341      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 2.33        |
|    cost_values           | 1.36        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.85        |
|    n_updates             | 2560        |
|    policy_gradient_loss  | -0.00184    |
|    std                   | 0.761       |
|    value_loss            | 5.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.35860902  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 436          |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0024751683 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 0.302        |
|    cost_values           | 1.3          |
|    entropy               | -2.28        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.08         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.000932    |
|    std                   | 0.757        |
|    value_loss            | 3.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.8150442   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 471          |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0024707438 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 4.62         |
|    cost_values           | 1.26         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.46         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | 0.00189      |
|    std                   | 0.754        |
|    value_loss            | 11.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.95          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.95          |
| reward                   | -0.7564761    |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -709          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 15            |
|    time_elapsed          | 505           |
|    total_timesteps       | 532480        |
| train/                   |               |
|    approx_kl             | 0.00014143006 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.88          |
|    cost_value_loss       | 8.43          |
|    cost_values           | 1.36          |
|    entropy               | -2.27         |
|    entropy_loss          | -2.27         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.13          |
|    n_updates             | 2590          |
|    policy_gradient_loss  | 0.000102      |
|    std                   | 0.754         |
|    value_loss            | 8.69          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.49167374  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 540          |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0054318644 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.0838       |
|    cost_values           | 1.42         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.2          |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.754        |
|    value_loss            | 8.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.36888272 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -703        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 574         |
|    total_timesteps       | 536576      |
| train/                   |             |
|    approx_kl             | 0.006336497 |
|    clip_fraction         | 0.0202      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 2.07        |
|    cost_values           | 1.13        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 2610        |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.753       |
|    value_loss            | 20.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.8094268   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 609          |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0019769487 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 4.5          |
|    cost_values           | 1.07         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.12         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.000632    |
|    std                   | 0.753        |
|    value_loss            | 8.4          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.06          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.06          |
| reward                   | -0.46391264   |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -700          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 19            |
|    time_elapsed          | 643           |
|    total_timesteps       | 540672        |
| train/                   |               |
|    approx_kl             | 0.00062153966 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.897         |
|    cost_value_loss       | 0.0227        |
|    cost_values           | 1.01          |
|    entropy               | -2.27         |
|    entropy_loss          | -2.27         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.2          |
|    n_updates             | 2630          |
|    policy_gradient_loss  | -0.000103     |
|    std                   | 0.753         |
|    value_loss            | 22.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.016174    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 677          |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0053527346 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.94         |
|    cost_values           | 1.05         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.99         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.756        |
|    value_loss            | 7.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4520913   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 712          |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0048138443 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 2.01         |
|    cost_values           | 1.24         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.43         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.756        |
|    value_loss            | 14.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6800362  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 746         |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.003360794 |
|    clip_fraction         | 0.0345      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.74        |
|    cost_value_loss       | 2.17        |
|    cost_values           | 1.48        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.7         |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.000101   |
|    std                   | 0.755       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.48401135 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 780         |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.004966977 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 1.57        |
|    cost_values           | 1.63        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 0.752       |
|    value_loss            | 2.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9469355   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 815          |
|    total_timesteps       | 550912       |
| train/                   |              |
|    approx_kl             | 0.0007657703 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 1.23         |
|    cost_values           | 1.72         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.02         |
|    n_updates             | 2680         |
|    policy_gradient_loss  | -0.000214    |
|    std                   | 0.75         |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6908055   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 849          |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0010859878 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 4.41         |
|    cost_values           | 1.59         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.08         |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.000371    |
|    std                   | 0.75         |
|    value_loss            | 13.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.53          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.53          |
| reward                   | -0.90106976   |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -700          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 26            |
|    time_elapsed          | 884           |
|    total_timesteps       | 555008        |
| train/                   |               |
|    approx_kl             | 0.00074819353 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 2.15          |
|    cost_value_loss       | 3.46          |
|    cost_values           | 1.8           |
|    entropy               | -2.27         |
|    entropy_loss          | -2.26         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.44          |
|    n_updates             | 2700          |
|    policy_gradient_loss  | -2.36e-05     |
|    std                   | 0.752         |
|    value_loss            | 3.87          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 6.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.75         |
| reward                   | -0.670935    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 918          |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0013498488 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 0.133        |
|    cost_values           | 2            |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.44         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | 0.000631     |
|    std                   | 0.752        |
|    value_loss            | 20.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0329       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0329       |
| reward                   | -0.687984    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 952          |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0013383717 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 0.0499       |
|    cost_values           | 1.63         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.17         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.000368    |
|    std                   | 0.753        |
|    value_loss            | 2.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.43        |
| reward                   | -0.67899257 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 986         |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.005317932 |
|    clip_fraction         | 0.0207      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 0.0359      |
|    cost_values           | 1.23        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.169       |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -0.0013     |
|    std                   | 0.754       |
|    value_loss            | 0.662       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.61         |
| reward                   | -0.62383306  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0016925837 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.869        |
|    cost_value_loss       | 0.0201       |
|    cost_values           | 0.953        |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.87         |
|    n_updates             | 2740         |
|    policy_gradient_loss  | 0.00027      |
|    std                   | 0.754        |
|    value_loss            | 4.97         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 3.79          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 3.79          |
| reward                   | -0.6924603    |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -705          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 31            |
|    time_elapsed          | 1055          |
|    total_timesteps       | 565248        |
| train/                   |               |
|    approx_kl             | 0.00043821245 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.758         |
|    cost_value_loss       | 0.0452        |
|    cost_values           | 0.871         |
|    entropy               | -2.27         |
|    entropy_loss          | -2.27         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.08          |
|    n_updates             | 2750          |
|    policy_gradient_loss  | -0.000101     |
|    std                   | 0.755         |
|    value_loss            | 14.8          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.1          |
| reward                   | -0.7407721   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0041755973 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 6.19         |
|    cost_values           | 1.11         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.67         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.000733    |
|    std                   | 0.753        |
|    value_loss            | 3.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.407       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.407       |
| reward                   | -0.77699643 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -706        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1124        |
|    total_timesteps       | 569344      |
| train/                   |             |
|    approx_kl             | 0.002996629 |
|    clip_fraction         | 0.00264     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 0.0751      |
|    cost_values           | 1.38        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 2770        |
|    policy_gradient_loss  | -0.000656   |
|    std                   | 0.751       |
|    value_loss            | 6.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.89         |
| reward                   | -0.8676425   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1158         |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0016411301 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 3.17         |
|    cost_values           | 1.13         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.000579    |
|    std                   | 0.751        |
|    value_loss            | 6.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.45         |
| reward                   | -0.8529458   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1192         |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0004816889 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.885        |
|    cost_value_loss       | 0.0156       |
|    cost_values           | 0.934        |
|    entropy               | -2.28        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.28         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.000343    |
|    std                   | 0.756        |
|    value_loss            | 2.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.28         |
| reward                   | -0.45333585  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1226         |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0034092148 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.727        |
|    cost_value_loss       | 0.0239       |
|    cost_values           | 0.863        |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.08         |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.000387    |
|    std                   | 0.758        |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.02         |
| reward                   | -0.8111666   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1261         |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0047424366 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 1.08         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.01         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.758        |
|    value_loss            | 6.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.56         |
| reward                   | -0.4238769   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1295         |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0067378064 |
|    clip_fraction         | 0.0507       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 3.11         |
|    cost_values           | 1.55         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.00358     |
|    std                   | 0.754        |
|    value_loss            | 3.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.6003174   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1330         |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0065320665 |
|    clip_fraction         | 0.0477       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 2.41         |
|    cost_values           | 1.77         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.9          |
|    n_updates             | 2830         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.754        |
|    value_loss            | 9.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5421326  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1366        |
|    total_timesteps       | 583680      |
| train/                   |             |
|    approx_kl             | 0.003302797 |
|    clip_fraction         | 0.0061      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 5.53        |
|    cost_values           | 2.13        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.84        |
|    n_updates             | 2840        |
|    policy_gradient_loss  | -0.000491   |
|    std                   | 0.754       |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.763324    |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1401         |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0069424007 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 3.72         |
|    cost_values           | 2.5          |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.97         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.753        |
|    value_loss            | 5.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.794        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.794        |
| reward                   | -0.7546537   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1436         |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0022382436 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 2.28         |
|    cost_values           | 2.6          |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.000164    |
|    std                   | 0.751        |
|    value_loss            | 8.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.21         |
| reward                   | -0.75663006  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1471         |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0013592452 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 5.52         |
|    cost_values           | 2.82         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00552      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.55         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.000198    |
|    std                   | 0.751        |
|    value_loss            | 4.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.73723793 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1506        |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.004515047 |
|    clip_fraction         | 0.00957     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.65        |
|    cost_value_loss       | 0.379       |
|    cost_values           | 2.73        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.26       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.69        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.000703   |
|    std                   | 0.744       |
|    value_loss            | 3.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.66         |
| reward                   | -0.87791866  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1540         |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0037444676 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 2.73         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7            |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.741        |
|    value_loss            | 3.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.22         |
| reward                   | -0.76194537  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1575         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0011221888 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 0.292        |
|    cost_values           | 2.92         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.82         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.000353    |
|    std                   | 0.741        |
|    value_loss            | 5.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.58         |
| reward                   | -0.5572016   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1610         |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0041952766 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 1.99         |
|    cost_values           | 2.58         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.000902    |
|    std                   | 0.736        |
|    value_loss            | 6.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.64         |
| reward                   | -0.70770276  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1644         |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0027007689 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.32         |
|    cost_value_loss       | 4.95         |
|    cost_values           | 2.59         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.73         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | 0.000368     |
|    std                   | 0.735        |
|    value_loss            | 7.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.7249541   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1679         |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0025872183 |
|    clip_fraction         | 0.0083       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 2.13         |
|    cost_values           | 2.47         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.32         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.000651    |
|    std                   | 0.733        |
|    value_loss            | 3.85         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.378      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.378      |
| reward             | -0.5576052 |
| rollout/           |            |
|    ep_len_mean     | 993        |
|    ep_rew_mean     | -677       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 604160     |
-----------------------------------
-------------------------------------------
| avg_speed                | 1.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.31         |
| reward                   | -0.8403547   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0019976469 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 0.137        |
|    cost_values           | 2.17         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.46         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | -0.000912    |
|    std                   | 0.732        |
|    value_loss            | 5.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.575       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.575       |
| reward                   | -0.7879619  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.004868428 |
|    clip_fraction         | 0.02        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.07        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.03        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.732       |
|    value_loss            | 3.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0626      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0626      |
| reward                   | -0.53060955 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.006028764 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 8.78        |
|    cost_values           | 2.57        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.34        |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.73        |
|    value_loss            | 3.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.32         |
| reward                   | -0.79103893  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0031001095 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 0.213        |
|    cost_values           | 2.71         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.71         |
|    n_updates             | 2980         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.728        |
|    value_loss            | 5.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.61         |
| reward                   | -0.43387052  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0031029661 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.39         |
|    cost_value_loss       | 8.44         |
|    cost_values           | 2.42         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.00081     |
|    std                   | 0.727        |
|    value_loss            | 14.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.62        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.62        |
| reward                   | -0.67365    |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 231         |
|    total_timesteps       | 616448      |
| train/                   |             |
|    approx_kl             | 0.005176937 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.52        |
|    cost_value_loss       | 1.86        |
|    cost_values           | 2.62        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.5         |
|    n_updates             | 3000        |
|    policy_gradient_loss  | -0.00191    |
|    std                   | 0.727       |
|    value_loss            | 9.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.8217123  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -689        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.004027342 |
|    clip_fraction         | 0.00425     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 1.36        |
|    cost_values           | 2.36        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.727       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.42047015  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0037111542 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 0.765        |
|    cost_values           | 2.05         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.48         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.726        |
|    value_loss            | 8.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.98721695 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 622592      |
| train/                   |             |
|    approx_kl             | 0.001975977 |
|    clip_fraction         | 0.000293    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.74        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 1.91        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 3030        |
|    policy_gradient_loss  | -0.000556   |
|    std                   | 0.725       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.6221912  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 370         |
|    total_timesteps       | 624640      |
| train/                   |             |
|    approx_kl             | 0.003901053 |
|    clip_fraction         | 0.00591     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 8.58        |
|    cost_values           | 2.25        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.35        |
|    n_updates             | 3040        |
|    policy_gradient_loss  | -0.000889   |
|    std                   | 0.725       |
|    value_loss            | 7.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.36         |
| reward                   | -0.72008365  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0047489665 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 3.23         |
|    cost_values           | 2.57         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.33         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.724        |
|    value_loss            | 3.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -1.0620668  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 439         |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.002593993 |
|    clip_fraction         | 0.00083     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.2         |
|    cost_value_loss       | 0.298       |
|    cost_values           | 2.44        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.000519   |
|    std                   | 0.724       |
|    value_loss            | 24          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.893418   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 473         |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.003782432 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 2.07        |
|    cost_values           | 2.22        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.722       |
|    value_loss            | 11.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.9382041  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 508         |
|    total_timesteps       | 632832      |
| train/                   |             |
|    approx_kl             | 0.004042295 |
|    clip_fraction         | 0.00337     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 0.124       |
|    cost_values           | 2.14        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.84        |
|    n_updates             | 3080        |
|    policy_gradient_loss  | 0.000443    |
|    std                   | 0.722       |
|    value_loss            | 7.96        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.84214675   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -703          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 16            |
|    time_elapsed          | 543           |
|    total_timesteps       | 634880        |
| train/                   |               |
|    approx_kl             | 0.00054666924 |
|    clip_fraction         | 0.000684      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.75          |
|    cost_value_loss       | 0.61          |
|    cost_values           | 1.73          |
|    entropy               | -2.19         |
|    entropy_loss          | -2.19         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.8          |
|    n_updates             | 3090          |
|    policy_gradient_loss  | 0.00111       |
|    std                   | 0.722         |
|    value_loss            | 22.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.6994168   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0035658241 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 0.698        |
|    cost_values           | 1.44         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.65         |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.000967    |
|    std                   | 0.722        |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.3109857   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 611          |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0036076545 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 2.75         |
|    cost_values           | 1.23         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.82         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.72         |
|    value_loss            | 3.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8472998   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 646          |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0055166627 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.0473       |
|    cost_values           | 1.15         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.72         |
|    value_loss            | 23.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.0733043   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0043563424 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 3.48         |
|    cost_values           | 0.999        |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.000555    |
|    std                   | 0.72         |
|    value_loss            | 26.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1622753   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 714          |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0032980004 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 1.01         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.8         |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.000778    |
|    std                   | 0.72         |
|    value_loss            | 37.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.73855305 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 749         |
|    total_timesteps       | 647168      |
| train/                   |             |
|    approx_kl             | 0.004859677 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.832       |
|    cost_value_loss       | 0.0196      |
|    cost_values           | 0.903       |
|    entropy               | -2.17       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.87        |
|    n_updates             | 3150        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.717       |
|    value_loss            | 13.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.65187883 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 783         |
|    total_timesteps       | 649216      |
| train/                   |             |
|    approx_kl             | 0.004054116 |
|    clip_fraction         | 0.0341      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 7.31        |
|    cost_values           | 1.05        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.6        |
|    n_updates             | 3160        |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 0.716       |
|    value_loss            | 36.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6483531   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 818          |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0037119745 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 5.97         |
|    cost_values           | 1.49         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.714        |
|    value_loss            | 18           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.5413844   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 852          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0002496728 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 2.32         |
|    cost_values           | 1.77         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.74         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | 0.000107     |
|    std                   | 0.715        |
|    value_loss            | 5.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.66803455  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0045629567 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 7.53         |
|    cost_values           | 1.94         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.92         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.716        |
|    value_loss            | 13.1         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.6576715 |
| rollout/                 |            |
|    ep_len_mean           | 995        |
|    ep_rew_mean           | -718       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 27         |
|    time_elapsed          | 921        |
|    total_timesteps       | 657408     |
| train/                   |            |
|    approx_kl             | 0.00439508 |
|    clip_fraction         | 0.0216     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.21       |
|    cost_value_loss       | 1.55       |
|    cost_values           | 2.14       |
|    entropy               | -2.16      |
|    entropy_loss          | -2.17      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.38       |
|    n_updates             | 3200       |
|    policy_gradient_loss  | -0.00106   |
|    std                   | 0.711      |
|    value_loss            | 16         |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0378174   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 956          |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0027559472 |
|    clip_fraction         | 0.0929       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.13         |
|    cost_value_loss       | 8.92         |
|    cost_values           | 2.12         |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.9         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.000898    |
|    std                   | 0.709        |
|    value_loss            | 43.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.86200416 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -718        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 990         |
|    total_timesteps       | 661504      |
| train/                   |             |
|    approx_kl             | 0.004464309 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 0.623       |
|    cost_values           | 2.04        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.15       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.24        |
|    n_updates             | 3220        |
|    policy_gradient_loss  | -0.0017     |
|    std                   | 0.707       |
|    value_loss            | 14.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2748236  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -721        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 663552      |
| train/                   |             |
|    approx_kl             | 0.006082886 |
|    clip_fraction         | 0.0172      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 3.91        |
|    cost_values           | 1.95        |
|    entropy               | -2.15       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.83        |
|    n_updates             | 3230        |
|    policy_gradient_loss  | -0.000799   |
|    std                   | 0.708       |
|    value_loss            | 14.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.52         |
| reward                   | -0.55945545  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1059         |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0005319793 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 1.79         |
|    cost_values           | 2.01         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.7          |
|    n_updates             | 3240         |
|    policy_gradient_loss  | 9.21e-05     |
|    std                   | 0.707        |
|    value_loss            | 4.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.34        |
| reward                   | -0.7101266  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1093        |
|    total_timesteps       | 667648      |
| train/                   |             |
|    approx_kl             | 0.004242651 |
|    clip_fraction         | 0.00835     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.82        |
|    cost_value_loss       | 1.31        |
|    cost_values           | 1.75        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.7        |
|    n_updates             | 3250        |
|    policy_gradient_loss  | -0.00086    |
|    std                   | 0.707       |
|    value_loss            | 32.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5461753  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -727        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1128        |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.005108428 |
|    clip_fraction         | 0.0114      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 0.0439      |
|    cost_values           | 1.47        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.89        |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.707       |
|    value_loss            | 17.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.62020797  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1162         |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0025777114 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 0.852        |
|    cost_values           | 1.17         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.4          |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.000319    |
|    std                   | 0.704        |
|    value_loss            | 6.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.88905084  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1197         |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0038997175 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 1.17         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.05         |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00267     |
|    std                   | 0.705        |
|    value_loss            | 8.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0316914   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1231         |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0050310306 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.409        |
|    cost_values           | 1.12         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.1         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.703        |
|    value_loss            | 70.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -1.0584686  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -727        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1265        |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.001725977 |
|    clip_fraction         | 0.0063      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 1.5         |
|    cost_values           | 1.09        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.31        |
|    n_updates             | 3300        |
|    policy_gradient_loss  | 1.31e-05    |
|    std                   | 0.704       |
|    value_loss            | 14.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.64332414 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1300        |
|    total_timesteps       | 679936      |
| train/                   |             |
|    approx_kl             | 0.004062559 |
|    clip_fraction         | 0.00317     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 3.26        |
|    cost_values           | 1.19        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.16        |
|    n_updates             | 3310        |
|    policy_gradient_loss  | -0.000726   |
|    std                   | 0.705       |
|    value_loss            | 9.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8855391  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -727        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1334        |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.004466054 |
|    clip_fraction         | 0.00518     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 0.133       |
|    cost_values           | 1.16        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17          |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.705       |
|    value_loss            | 40.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -1.2789247   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1369         |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0040044575 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 1.55         |
|    cost_values           | 1.04         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.704        |
|    value_loss            | 22.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.9716339   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1403         |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0015173682 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.999        |
|    cost_value_loss       | 0.168        |
|    cost_values           | 1.05         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.000128    |
|    std                   | 0.705        |
|    value_loss            | 31.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8327929   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1439         |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0063835997 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.807        |
|    cost_value_loss       | 0.0498       |
|    cost_values           | 0.919        |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.86         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.705        |
|    value_loss            | 19.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0992175   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1473         |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0029699893 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 5.81         |
|    cost_values           | 1            |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.3         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.705        |
|    value_loss            | 46.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.9551824   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1507         |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0017910243 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 2.02         |
|    cost_values           | 1.22         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.57         |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.000193    |
|    std                   | 0.704        |
|    value_loss            | 4.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.85188603  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1542         |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0017929728 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.555        |
|    cost_values           | 1.28         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.000564    |
|    std                   | 0.707        |
|    value_loss            | 21.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.2557249   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1576         |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 7.077487e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 5.54         |
|    cost_values           | 1.24         |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.82         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | 0.000236     |
|    std                   | 0.709        |
|    value_loss            | 15.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.042235    |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1610         |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0023886135 |
|    clip_fraction         | 0.00337      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 5.5          |
|    cost_values           | 1.4          |
|    entropy               | -2.14        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.000374    |
|    std                   | 0.707        |
|    value_loss            | 24.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.7159618  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -747        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1645        |
|    total_timesteps       | 700416      |
| train/                   |             |
|    approx_kl             | 0.003342155 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 0.21        |
|    cost_values           | 1.52        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.75        |
|    n_updates             | 3410        |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.706       |
|    value_loss            | 12.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.8807324   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1679         |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0046189697 |
|    clip_fraction         | 0.00713      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 4.03         |
|    cost_values           | 1.35         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.14         |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.000893    |
|    std                   | 0.707        |
|    value_loss            | 5.75         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
------------------------------------
| avg_speed          | 7.7         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.7         |
| reward             | -0.67074114 |
| rollout/           |             |
|    ep_len_mean     | 965         |
|    ep_rew_mean     | -757        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 704512      |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7990985   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0035133096 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.144        |
|    cost_values           | 1.1          |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.86         |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.705        |
|    value_loss            | 6.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9540617   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0041578393 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 6.69         |
|    cost_values           | 1.21         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.705        |
|    value_loss            | 15.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.58916944  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0055791875 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 2.56         |
|    cost_values           | 1.46         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.83         |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.705        |
|    value_loss            | 16.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.87130845  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0054741404 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 3.19         |
|    cost_values           | 1.32         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.7         |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.000797    |
|    std                   | 0.706        |
|    value_loss            | 47.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45302895  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 714752       |
| train/                   |              |
|    approx_kl             | 0.0025105318 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.0428       |
|    cost_values           | 1.14         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.87         |
|    n_updates             | 3480         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.7          |
|    value_loss            | 3.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0188072  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 231         |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.004929187 |
|    clip_fraction         | 0.00903     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.858       |
|    cost_value_loss       | 0.0696      |
|    cost_values           | 0.958       |
|    entropy               | -2.11       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.2        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.000352   |
|    std                   | 0.697       |
|    value_loss            | 26.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6188293   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 718848       |
| train/                   |              |
|    approx_kl             | 0.0018785251 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 11.1         |
|    cost_values           | 1.1          |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 3500         |
|    policy_gradient_loss  | -0.000236    |
|    std                   | 0.696        |
|    value_loss            | 15           |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -1.3239716 |
| rollout/                 |            |
|    ep_len_mean           | 960        |
|    ep_rew_mean           | -768       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 9          |
|    time_elapsed          | 300        |
|    total_timesteps       | 720896     |
| train/                   |            |
|    approx_kl             | 0.00563452 |
|    clip_fraction         | 0.0144     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.75       |
|    cost_value_loss       | 3.55       |
|    cost_values           | 1.36       |
|    entropy               | -2.11      |
|    entropy_loss          | -2.11      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.87       |
|    n_updates             | 3510       |
|    policy_gradient_loss  | -0.00191   |
|    std                   | 0.695      |
|    value_loss            | 10.4       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.8193475   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 335          |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0027329882 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.0284       |
|    cost_values           | 1.17         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.72         |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.696        |
|    value_loss            | 15.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.79862267 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -766        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 370         |
|    total_timesteps       | 724992      |
| train/                   |             |
|    approx_kl             | 0.004227749 |
|    clip_fraction         | 0.0523      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 5.1         |
|    cost_values           | 1.16        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.98        |
|    n_updates             | 3530        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.696       |
|    value_loss            | 9.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.80569375 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 404         |
|    total_timesteps       | 727040      |
| train/                   |             |
|    approx_kl             | 0.007875505 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 0.163       |
|    cost_values           | 1.27        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.18        |
|    n_updates             | 3540        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.698       |
|    value_loss            | 4           |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.88          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.88          |
| reward                   | -0.86527854   |
| rollout/                 |               |
|    ep_len_mean           | 953           |
|    ep_rew_mean           | -753          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 13            |
|    time_elapsed          | 439           |
|    total_timesteps       | 729088        |
| train/                   |               |
|    approx_kl             | 0.00091216946 |
|    clip_fraction         | 0.0958        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.01          |
|    cost_value_loss       | 0.207         |
|    cost_values           | 1.02          |
|    entropy               | -2.12         |
|    entropy_loss          | -2.12         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21.5          |
|    n_updates             | 3550          |
|    policy_gradient_loss  | 0.00483       |
|    std                   | 0.699         |
|    value_loss            | 39.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8189367   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 475          |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0022912929 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.785        |
|    cost_value_loss       | 0.0171       |
|    cost_values           | 0.874        |
|    entropy               | -2.11        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.98         |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.696        |
|    value_loss            | 4.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.2044177  |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 509         |
|    total_timesteps       | 733184      |
| train/                   |             |
|    approx_kl             | 0.003935997 |
|    clip_fraction         | 0.0083      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.982       |
|    cost_value_loss       | 1.08        |
|    cost_values           | 0.901       |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.69        |
|    n_updates             | 3570        |
|    policy_gradient_loss  | 3.37e-05    |
|    std                   | 0.693       |
|    value_loss            | 16.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7050361   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 545          |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0042098034 |
|    clip_fraction         | 0.0554       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.848        |
|    cost_value_loss       | 0.0849       |
|    cost_values           | 0.897        |
|    entropy               | -2.08        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.51         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.004       |
|    std                   | 0.683        |
|    value_loss            | 7.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23325635 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -743        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 580         |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.004242549 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.54        |
|    cost_value_loss       | 19.1        |
|    cost_values           | 1.15        |
|    entropy               | -2.06       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.7        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.679       |
|    value_loss            | 24          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.76693696  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 614          |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0010531207 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 0.276        |
|    cost_values           | 1.38         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.07         |
|    n_updates             | 3600         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.674        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0657889   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 650          |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0025691802 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.24         |
|    cost_values           | 1.19         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.17         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | -0.000475    |
|    std                   | 0.674        |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8852349  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 684         |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.001899533 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 8.48        |
|    cost_values           | 1.21        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.33        |
|    n_updates             | 3620        |
|    policy_gradient_loss  | 2.49e-05    |
|    std                   | 0.674       |
|    value_loss            | 5.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.67643857  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 719          |
|    total_timesteps       | 745472       |
| train/                   |              |
|    approx_kl             | 0.0015155886 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 0.362        |
|    cost_values           | 1.31         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.91         |
|    n_updates             | 3630         |
|    policy_gradient_loss  | -0.000587    |
|    std                   | 0.673        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7417579   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 753          |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0048014126 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 5.76         |
|    cost_values           | 1.2          |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.94         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.673        |
|    value_loss            | 13.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.88          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.88          |
| reward                   | -0.5663313    |
| rollout/                 |               |
|    ep_len_mean           | 956           |
|    ep_rew_mean           | -748          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 23            |
|    time_elapsed          | 788           |
|    total_timesteps       | 749568        |
| train/                   |               |
|    approx_kl             | 0.00011800401 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.84          |
|    cost_value_loss       | 3.25          |
|    cost_values           | 1.36          |
|    entropy               | -2.04         |
|    entropy_loss          | -2.05         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 31.1          |
|    n_updates             | 3650          |
|    policy_gradient_loss  | 4.17e-06      |
|    std                   | 0.673         |
|    value_loss            | 47            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.41971758  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 823          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0056352657 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.278        |
|    cost_values           | 1.23         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.22         |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.672        |
|    value_loss            | 2.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8962761   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 857          |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0027954269 |
|    clip_fraction         | 0.002        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 6.79         |
|    cost_values           | 1.1          |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.99         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.000865    |
|    std                   | 0.672        |
|    value_loss            | 11.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.13         |
| reward                   | -0.5902067   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 892          |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0034574326 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.194        |
|    cost_values           | 1.04         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.672        |
|    value_loss            | 37.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8532131   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 926          |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0053052492 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 2.66         |
|    cost_values           | 1.11         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.06         |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.000704    |
|    std                   | 0.672        |
|    value_loss            | 13.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40478417  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 961          |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0020403557 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 2.55         |
|    cost_values           | 1.21         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.58         |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.000599    |
|    std                   | 0.672        |
|    value_loss            | 7.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.78676623  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 995          |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0040618354 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 3.82         |
|    cost_values           | 1.16         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.36         |
|    n_updates             | 3710         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.672        |
|    value_loss            | 12.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.3157493  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -734        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1029        |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.001717985 |
|    clip_fraction         | 9.77e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 4.97        |
|    cost_values           | 1.15        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.7        |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.000551   |
|    std                   | 0.672       |
|    value_loss            | 38.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.35        |
| reward                   | -0.80133224 |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -727        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1064        |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.005817284 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 1.17        |
|    cost_values           | 1.11        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.15        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.0022     |
|    std                   | 0.672       |
|    value_loss            | 13.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.48         |
| reward                   | -0.66849     |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1098         |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0030881886 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 5.08         |
|    cost_values           | 1.07         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.671        |
|    value_loss            | 33.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5635767  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1133        |
|    total_timesteps       | 770048      |
| train/                   |             |
|    approx_kl             | 0.005267851 |
|    clip_fraction         | 0.0361      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.0569      |
|    cost_values           | 1.07        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 3750        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.671       |
|    value_loss            | 4.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.92409223 |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -725        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1168        |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.007874446 |
|    clip_fraction         | 0.0633      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 22.9        |
|    cost_values           | 1.12        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38.7        |
|    n_updates             | 3760        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.671       |
|    value_loss            | 43.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.54484606 |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1202        |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.002487846 |
|    clip_fraction         | 0.000781    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 1.39        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.63        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.000795   |
|    std                   | 0.671       |
|    value_loss            | 5.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6345885  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1237        |
|    total_timesteps       | 776192      |
| train/                   |             |
|    approx_kl             | 0.004216685 |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.3         |
|    cost_value_loss       | 6.3         |
|    cost_values           | 1.71        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 3780        |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 0.67        |
|    value_loss            | 15.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5584946   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0053371326 |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 3.25         |
|    cost_values           | 2.04         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 3790         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.671        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.68176144  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1307         |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0009578456 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.64         |
|    cost_value_loss       | 2.72         |
|    cost_values           | 2.14         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.000191    |
|    std                   | 0.672        |
|    value_loss            | 33.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.57003224 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -716        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1341        |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.006093763 |
|    clip_fraction         | 0.0502      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.15        |
|    cost_value_loss       | 2.83        |
|    cost_values           | 2.1         |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 3810        |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 0.672       |
|    value_loss            | 7.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -0.5360365   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1376         |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0029692461 |
|    clip_fraction         | 0.00864      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 1.29         |
|    cost_values           | 1.99         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | 8.31e-05     |
|    std                   | 0.67         |
|    value_loss            | 31.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.5104042  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -702        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1410        |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.009295608 |
|    clip_fraction         | 0.0544      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.46        |
|    cost_value_loss       | 5.91        |
|    cost_values           | 1.92        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.668       |
|    value_loss            | 29.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6746178   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1445         |
|    total_timesteps       | 788480       |
| train/                   |              |
|    approx_kl             | 0.0007234196 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.8          |
|    cost_value_loss       | 5.66         |
|    cost_values           | 2.05         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 3840         |
|    policy_gradient_loss  | -0.00022     |
|    std                   | 0.668        |
|    value_loss            | 53.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.39272588 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1479        |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.005504461 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 8.55        |
|    cost_values           | 2.11        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.16        |
|    n_updates             | 3850        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.669       |
|    value_loss            | 3.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.85825175 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1515        |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.004310448 |
|    clip_fraction         | 0.00566     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 9.26        |
|    cost_values           | 2.47        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.000866   |
|    std                   | 0.669       |
|    value_loss            | 18.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.87577444  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1550         |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0035203483 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.04         |
|    cost_value_loss       | 4.64         |
|    cost_values           | 2.77         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00153      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.56         |
|    n_updates             | 3870         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.665        |
|    value_loss            | 6.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6023641   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1586         |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0015255002 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 0.193        |
|    cost_values           | 2.78         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.3          |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.662        |
|    value_loss            | 12.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.99          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.99          |
| reward                   | -0.1826267    |
| rollout/                 |               |
|    ep_len_mean           | 943           |
|    ep_rew_mean           | -694          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 47            |
|    time_elapsed          | 1620          |
|    total_timesteps       | 798720        |
| train/                   |               |
|    approx_kl             | 0.00044229123 |
|    clip_fraction         | 0.0707        |
|    clip_range            | 0.2           |
|    cost_returns          | 2             |
|    cost_value_loss       | 0.0896        |
|    cost_values           | 2.19          |
|    entropy               | -2.01         |
|    entropy_loss          | -2.01         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.26          |
|    n_updates             | 3890          |
|    policy_gradient_loss  | 0.00202       |
|    std                   | 0.66          |
|    value_loss            | 12.2          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.58892083 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1655        |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.00351597  |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 4.46        |
|    cost_values           | 1.98        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.1        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.000634   |
|    std                   | 0.657       |
|    value_loss            | 26.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.05         |
| reward                   | -0.6985146   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1690         |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0037291918 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 4.31         |
|    cost_values           | 2.22         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.91         |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.00037     |
|    std                   | 0.657        |
|    value_loss            | 9.99         |
-------------------------------------------
----------------------------------
| avg_speed          | 6.39      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 6.39      |
| reward             | -0.535423 |
| rollout/           |           |
|    ep_len_mean     | 946       |
|    ep_rew_mean     | -683      |
| time/              |           |
|    fps             | 82        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 804864    |
----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.82903457  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0037962866 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.84         |
|    cost_value_loss       | 5.04         |
|    cost_values           | 2.06         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.27         |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.000363    |
|    std                   | 0.657        |
|    value_loss            | 6.78         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5667298    |
| rollout/                 |               |
|    ep_len_mean           | 946           |
|    ep_rew_mean           | -677          |
| time/                    |               |
|    fps                   | 64            |
|    iterations            | 3             |
|    time_elapsed          | 94            |
|    total_timesteps       | 808960        |
| train/                   |               |
|    approx_kl             | 0.00059303606 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.55          |
|    cost_value_loss       | 16            |
|    cost_values           | 2.44          |
|    entropy               | -2            |
|    entropy_loss          | -2            |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.4          |
|    n_updates             | 3940          |
|    policy_gradient_loss  | -0.000202     |
|    std                   | 0.657         |
|    value_loss            | 9.44          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.72694767 |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 129         |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.004157329 |
|    clip_fraction         | 0.00459     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 6.02        |
|    cost_values           | 2.69        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.76        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.657       |
|    value_loss            | 7.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.87396765  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 813056       |
| train/                   |              |
|    approx_kl             | 0.0022182357 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 1.75         |
|    cost_values           | 2.67         |
|    entropy               | -2.01        |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.85         |
|    n_updates             | 3960         |
|    policy_gradient_loss  | -0.000651    |
|    std                   | 0.66         |
|    value_loss            | 1.95         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.53168476 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -678        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 6           |
|    time_elapsed          | 198         |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.005787201 |
|    clip_fraction         | 0.0184      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 9.58        |
|    cost_values           | 2.85        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00945     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.3         |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.000538   |
|    std                   | 0.661       |
|    value_loss            | 36.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.8733051    |
| rollout/                 |               |
|    ep_len_mean           | 943           |
|    ep_rew_mean           | -671          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 7             |
|    time_elapsed          | 233           |
|    total_timesteps       | 817152        |
| train/                   |               |
|    approx_kl             | 0.00023826881 |
|    clip_fraction         | 0.00879       |
|    clip_range            | 0.2           |
|    cost_returns          | 2.6           |
|    cost_value_loss       | 0.491         |
|    cost_values           | 2.8           |
|    entropy               | -2.01         |
|    entropy_loss          | -2.01         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.69          |
|    n_updates             | 3980          |
|    policy_gradient_loss  | -0.000674     |
|    std                   | 0.66          |
|    value_loss            | 15.4          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.87788016 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -674        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 267         |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.006652537 |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 6.53        |
|    cost_values           | 2.48        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.04        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.658       |
|    value_loss            | 6.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8564284   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0042847423 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 0.45         |
|    cost_values           | 2.48         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.6          |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.658        |
|    value_loss            | 14.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.48480573  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0013571172 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.1          |
|    cost_value_loss       | 15.1         |
|    cost_values           | 2.41         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.000166    |
|    std                   | 0.658        |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.6062275   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0021685718 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.04         |
|    cost_value_loss       | 4.21         |
|    cost_values           | 2.67         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7            |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.658        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.95108724  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0055494756 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 0.734        |
|    cost_values           | 2.5          |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26           |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.658        |
|    value_loss            | 70.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.66        |
| reward                   | -0.99816203 |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 439         |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.004457552 |
|    clip_fraction         | 0.00815     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.32        |
|    cost_value_loss       | 8.43        |
|    cost_values           | 2.41        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.94        |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.000649   |
|    std                   | 0.658       |
|    value_loss            | 5.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.6478065  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -682        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 474         |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.004135816 |
|    clip_fraction         | 0.00493     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 0.277       |
|    cost_values           | 2.53        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.658       |
|    value_loss            | 13.5        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5250738    |
| rollout/                 |               |
|    ep_len_mean           | 946           |
|    ep_rew_mean           | -678          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 15            |
|    time_elapsed          | 508           |
|    total_timesteps       | 833536        |
| train/                   |               |
|    approx_kl             | 0.00034055504 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.95          |
|    cost_value_loss       | 0.109         |
|    cost_values           | 2.21          |
|    entropy               | -2            |
|    entropy_loss          | -2            |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.59          |
|    n_updates             | 4060          |
|    policy_gradient_loss  | -0.000189     |
|    std                   | 0.658         |
|    value_loss            | 28.9          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.57354665   |
| rollout/                 |               |
|    ep_len_mean           | 946           |
|    ep_rew_mean           | -675          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 16            |
|    time_elapsed          | 543           |
|    total_timesteps       | 835584        |
| train/                   |               |
|    approx_kl             | 0.00093013135 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.3           |
|    cost_value_loss       | 16.5          |
|    cost_values           | 2             |
|    entropy               | -2            |
|    entropy_loss          | -2            |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.3          |
|    n_updates             | 4070          |
|    policy_gradient_loss  | -0.000554     |
|    std                   | 0.658         |
|    value_loss            | 11.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4435825   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0037833224 |
|    clip_fraction         | 0.00884      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.65         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.22         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.000812    |
|    std                   | 0.659        |
|    value_loss            | 10           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6244584   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 612          |
|    total_timesteps       | 839680       |
| train/                   |              |
|    approx_kl             | 0.0037691197 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.45         |
|    cost_value_loss       | 9.29         |
|    cost_values           | 2.68         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.55         |
|    n_updates             | 4090         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.658        |
|    value_loss            | 4.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.63026357  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 646          |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0060733957 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 0.237        |
|    cost_values           | 2.74         |
|    entropy               | -1.99        |
|    entropy_loss          | -2           |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.18         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.655        |
|    value_loss            | 6.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42718506  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 681          |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0023190035 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 0.175        |
|    cost_values           | 2.18         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.92         |
|    n_updates             | 4110         |
|    policy_gradient_loss  | 0.000239     |
|    std                   | 0.654        |
|    value_loss            | 5.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7407785   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 716          |
|    total_timesteps       | 845824       |
| train/                   |              |
|    approx_kl             | 0.0034985873 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 4.88         |
|    cost_values           | 2.08         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 4120         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.654        |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.70257497  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 751          |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0037170094 |
|    clip_fraction         | 0.00664      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 2.43         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.000781    |
|    std                   | 0.654        |
|    value_loss            | 7.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9947927  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 787         |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.005642286 |
|    clip_fraction         | 0.0281      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 6.39        |
|    cost_values           | 2.76        |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.7         |
|    n_updates             | 4140        |
|    policy_gradient_loss  | -0.00203    |
|    std                   | 0.654       |
|    value_loss            | 5.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7696659   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 821          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0031201695 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 3            |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00878      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.6          |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.000116    |
|    std                   | 0.655        |
|    value_loss            | 16           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.81216234  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 856          |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 0.0041898885 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.71         |
|    cost_value_loss       | 1.28         |
|    cost_values           | 2.87         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.99         |
|    n_updates             | 4160         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.654        |
|    value_loss            | 9.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.2379249   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 890          |
|    total_timesteps       | 856064       |
| train/                   |              |
|    approx_kl             | 0.0031953263 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 0.15         |
|    cost_values           | 2.52         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.52         |
|    n_updates             | 4170         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.654        |
|    value_loss            | 12.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.72747403 |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -672        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 925         |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.001835783 |
|    clip_fraction         | 0.0485      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.64        |
|    cost_value_loss       | 2.74        |
|    cost_values           | 2.4         |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.3        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.654       |
|    value_loss            | 31.1        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.513474     |
| rollout/                 |               |
|    ep_len_mean           | 954           |
|    ep_rew_mean           | -676          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 28            |
|    time_elapsed          | 959           |
|    total_timesteps       | 860160        |
| train/                   |               |
|    approx_kl             | 0.00037336722 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.49          |
|    cost_value_loss       | 15.6          |
|    cost_values           | 2.75          |
|    entropy               | -1.99         |
|    entropy_loss          | -1.99         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00638       |
|    learning_rate         | 0.0003        |
|    loss                  | 5.75          |
|    n_updates             | 4190          |
|    policy_gradient_loss  | 9.49e-05      |
|    std                   | 0.654         |
|    value_loss            | 17.1          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.748243   |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -677        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 994         |
|    total_timesteps       | 862208      |
| train/                   |             |
|    approx_kl             | 0.008971674 |
|    clip_fraction         | 0.0757      |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 3.44        |
|    cost_values           | 2.96        |
|    entropy               | -1.98       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.5         |
|    n_updates             | 4200        |
|    policy_gradient_loss  | -0.00453    |
|    std                   | 0.651       |
|    value_loss            | 3.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4303507   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1029         |
|    total_timesteps       | 864256       |
| train/                   |              |
|    approx_kl             | 0.0003924218 |
|    clip_fraction         | 0.0356       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 3.74         |
|    cost_values           | 2.89         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.86         |
|    n_updates             | 4210         |
|    policy_gradient_loss  | 0.00313      |
|    std                   | 0.649        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0520627   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1064         |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0036543936 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.88         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0101       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.14         |
|    n_updates             | 4220         |
|    policy_gradient_loss  | -0.000984    |
|    std                   | 0.649        |
|    value_loss            | 7.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.8631113   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1099         |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0028009189 |
|    clip_fraction         | 0.002        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.41         |
|    cost_value_loss       | 11           |
|    cost_values           | 3            |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00658      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.000305    |
|    std                   | 0.649        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.83306897  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1135         |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0018477998 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.96         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 3            |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0.00581      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.22         |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.000235    |
|    std                   | 0.649        |
|    value_loss            | 31.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6504258   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1170         |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0043462412 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 0.224        |
|    cost_values           | 2.87         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.649        |
|    value_loss            | 24           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.46397653  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1205         |
|    total_timesteps       | 874496       |
| train/                   |              |
|    approx_kl             | 0.0048871003 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.45         |
|    cost_value_loss       | 8.37         |
|    cost_values           | 2.68         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.09         |
|    n_updates             | 4260         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.649        |
|    value_loss            | 7.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.86451775  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1240         |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0048599797 |
|    clip_fraction         | 0.00864      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 2.93         |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.67         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.65         |
|    value_loss            | 5.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8427405  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -688        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1276        |
|    total_timesteps       | 878592      |
| train/                   |             |
|    approx_kl             | 0.005183938 |
|    clip_fraction         | 0.0595      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 7.37        |
|    cost_values           | 3           |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0014      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.87        |
|    n_updates             | 4280        |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.65        |
|    value_loss            | 11.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40330753  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1310         |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0023996793 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.29         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 3            |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00202      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.000679    |
|    std                   | 0.649        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5283447   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1344         |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0037375202 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 0.673        |
|    cost_values           | 2.87         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.77         |
|    n_updates             | 4300         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.648        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7097811   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1379         |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0018676517 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 3.87         |
|    cost_values           | 2.58         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.24         |
|    n_updates             | 4310         |
|    policy_gradient_loss  | -0.0007      |
|    std                   | 0.649        |
|    value_loss            | 8.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7147436   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1414         |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 7.326159e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.18         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 2.57         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 4320         |
|    policy_gradient_loss  | 0.000207     |
|    std                   | 0.649        |
|    value_loss            | 6.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6145074   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1448         |
|    total_timesteps       | 888832       |
| train/                   |              |
|    approx_kl             | 0.0027856524 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 0.229        |
|    cost_values           | 2.56         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.33         |
|    n_updates             | 4330         |
|    policy_gradient_loss  | -0.000212    |
|    std                   | 0.648        |
|    value_loss            | 3.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8729863   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1483         |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0058031445 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 0.101        |
|    cost_values           | 2.04         |
|    entropy               | -1.96        |
|    entropy_loss          | -1.97        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.28         |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.000926    |
|    std                   | 0.643        |
|    value_loss            | 4.58         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.6420919  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1517        |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.005668334 |
|    clip_fraction         | 0.0532      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 7.11        |
|    cost_values           | 1.99        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.23        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.642       |
|    value_loss            | 9.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.7651777   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1552         |
|    total_timesteps       | 894976       |
| train/                   |              |
|    approx_kl             | 0.0024288185 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 1.75         |
|    cost_values           | 2.19         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 4360         |
|    policy_gradient_loss  | -0.000911    |
|    std                   | 0.642        |
|    value_loss            | 30.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5991911   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1587         |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0014171401 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 0.131        |
|    cost_values           | 1.95         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | -0.000777    |
|    std                   | 0.642        |
|    value_loss            | 29.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9044061   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1621         |
|    total_timesteps       | 899072       |
| train/                   |              |
|    approx_kl             | 0.0011648082 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 9.24         |
|    cost_values           | 1.83         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.9         |
|    n_updates             | 4380         |
|    policy_gradient_loss  | -0.000338    |
|    std                   | 0.641        |
|    value_loss            | 52.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.83173674   |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -691          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 48            |
|    time_elapsed          | 1656          |
|    total_timesteps       | 901120        |
| train/                   |               |
|    approx_kl             | 0.00027756445 |
|    clip_fraction         | 0.00732       |
|    clip_range            | 0.2           |
|    cost_returns          | 2.04          |
|    cost_value_loss       | 2.32          |
|    cost_values           | 1.97          |
|    entropy               | -1.94         |
|    entropy_loss          | -1.94         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3             |
|    n_updates             | 4390          |
|    policy_gradient_loss  | 3.3e-07       |
|    std                   | 0.637         |
|    value_loss            | 4.51          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.45289922 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1691        |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.005237371 |
|    clip_fraction         | 0.0371      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 0.0736      |
|    cost_values           | 1.75        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.47        |
|    n_updates             | 4400        |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.637       |
|    value_loss            | 2.67        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
------------------------------------
| avg_speed          | 8.02        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.42344162 |
| rollout/           |             |
|    ep_len_mean     | 962         |
|    ep_rew_mean     | -683        |
| time/              |             |
|    fps             | 81          |
|    iterations      | 1           |
|    time_elapsed    | 25          |
|    total_timesteps | 905216      |
------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.4711918 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -683       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 2          |
|    time_elapsed          | 60         |
|    total_timesteps       | 907264     |
| train/                   |            |
|    approx_kl             | 0.00299907 |
|    clip_fraction         | 0.0021     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.68       |
|    cost_value_loss       | 6.3        |
|    cost_values           | 1.82       |
|    entropy               | -1.93      |
|    entropy_loss          | -1.93      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.35       |
|    n_updates             | 4420       |
|    policy_gradient_loss  | -0.000994  |
|    std                   | 0.637      |
|    value_loss            | 11.3       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.48336643 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 94          |
|    total_timesteps       | 909312      |
| train/                   |             |
|    approx_kl             | 0.004699706 |
|    clip_fraction         | 0.00894     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 1.11        |
|    cost_values           | 1.76        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.2         |
|    n_updates             | 4430        |
|    policy_gradient_loss  | -0.000667   |
|    std                   | 0.636       |
|    value_loss            | 8.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9763826  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 129         |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.001608596 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 0.0572      |
|    cost_values           | 1.55        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.5        |
|    n_updates             | 4440        |
|    policy_gradient_loss  | 0.00527     |
|    std                   | 0.635       |
|    value_loss            | 30.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.62377053  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 913408       |
| train/                   |              |
|    approx_kl             | 0.0056398567 |
|    clip_fraction         | 0.0636       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 2.18         |
|    cost_values           | 1.41         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.12         |
|    n_updates             | 4450         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.638        |
|    value_loss            | 34           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.77315146  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 199          |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0040899673 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 3.71         |
|    cost_values           | 1.67         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.94        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.22         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.000525    |
|    std                   | 0.635        |
|    value_loss            | 9.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.5767043   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 234          |
|    total_timesteps       | 917504       |
| train/                   |              |
|    approx_kl             | 0.0042396667 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 8.82         |
|    cost_values           | 2.04         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.49         |
|    n_updates             | 4470         |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.634        |
|    value_loss            | 5.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31598592  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 8            |
|    time_elapsed          | 269          |
|    total_timesteps       | 919552       |
| train/                   |              |
|    approx_kl             | 0.0027509346 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 1.57         |
|    cost_values           | 2.19         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.02         |
|    n_updates             | 4480         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.634        |
|    value_loss            | 9.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.77778053  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 304          |
|    total_timesteps       | 921600       |
| train/                   |              |
|    approx_kl             | 0.0024551644 |
|    clip_fraction         | 0.00356      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.39         |
|    cost_value_loss       | 7.91         |
|    cost_values           | 2.19         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21           |
|    n_updates             | 4490         |
|    policy_gradient_loss  | -0.000303    |
|    std                   | 0.634        |
|    value_loss            | 34.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.8202138   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 339          |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0011110762 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.23         |
|    cost_value_loss       | 21.4         |
|    cost_values           | 2.4          |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.000634    |
|    std                   | 0.634        |
|    value_loss            | 8.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8724583   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 373          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0058203572 |
|    clip_fraction         | 0.06         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 2.15         |
|    cost_values           | 2.6          |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.43         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.00535     |
|    std                   | 0.633        |
|    value_loss            | 7.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6309117   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 408          |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0029268852 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 0.125        |
|    cost_values           | 2.31         |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.21         |
|    n_updates             | 4520         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.632        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38284436 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 442         |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.005831216 |
|    clip_fraction         | 0.0406      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 1.75        |
|    cost_values           | 2.01        |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.1        |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.633       |
|    value_loss            | 30.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.86543787 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -672        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 477         |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.004982261 |
|    clip_fraction         | 0.00977     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 0.0765      |
|    cost_values           | 1.8         |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.2         |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.634       |
|    value_loss            | 19.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.60753894  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0045031286 |
|    clip_fraction         | 0.01         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.71         |
|    cost_value_loss       | 9.83         |
|    cost_values           | 1.65         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.24         |
|    n_updates             | 4550         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.634        |
|    value_loss            | 7.7          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.7530208 |
| rollout/                 |            |
|    ep_len_mean           | 953        |
|    ep_rew_mean           | -675       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 16         |
|    time_elapsed          | 547        |
|    total_timesteps       | 935936     |
| train/                   |            |
|    approx_kl             | 0.00059828 |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 1.45       |
|    cost_value_loss       | 0.0875     |
|    cost_values           | 1.7        |
|    entropy               | -1.93      |
|    entropy_loss          | -1.93      |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 16.2       |
|    n_updates             | 4560       |
|    policy_gradient_loss  | -4.48e-05  |
|    std                   | 0.634      |
|    value_loss            | 36.5       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9472842   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 581          |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0008673738 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 2.55         |
|    cost_values           | 1.44         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.01         |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -1.8e-05     |
|    std                   | 0.634        |
|    value_loss            | 4.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5297973   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 616          |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0028167036 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 0.0344       |
|    cost_values           | 1.26         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.8          |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.634        |
|    value_loss            | 6.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.1442616   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 651          |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0043766154 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 1.04         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.636        |
|    value_loss            | 19.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.7838834   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 687          |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0046373405 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 5.67         |
|    cost_values           | 1.17         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.24         |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.637        |
|    value_loss            | 8.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.77068084  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 721          |
|    total_timesteps       | 946176       |
| train/                   |              |
|    approx_kl             | 0.0052045444 |
|    clip_fraction         | 0.0465       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 1.35         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.56         |
|    n_updates             | 4610         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.639        |
|    value_loss            | 8.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -1.0186695   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 756          |
|    total_timesteps       | 948224       |
| train/                   |              |
|    approx_kl             | 0.0041118828 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.0471       |
|    cost_values           | 1.26         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.28         |
|    n_updates             | 4620         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.639        |
|    value_loss            | 5.24         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.99          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.99          |
| reward                   | -0.75303155   |
| rollout/                 |               |
|    ep_len_mean           | 953           |
|    ep_rew_mean           | -684          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 23            |
|    time_elapsed          | 791           |
|    total_timesteps       | 950272        |
| train/                   |               |
|    approx_kl             | 0.00082806486 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.11          |
|    cost_value_loss       | 0.552         |
|    cost_values           | 0.992         |
|    entropy               | -1.94         |
|    entropy_loss          | -1.94         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.54          |
|    n_updates             | 4630          |
|    policy_gradient_loss  | -0.000312     |
|    std                   | 0.638         |
|    value_loss            | 22.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8460638   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 825          |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0048902584 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 7.95         |
|    cost_values           | 1.14         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.8          |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.638        |
|    value_loss            | 5.6          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0596659    |
| rollout/                 |               |
|    ep_len_mean           | 961           |
|    ep_rew_mean           | -688          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 25            |
|    time_elapsed          | 859           |
|    total_timesteps       | 954368        |
| train/                   |               |
|    approx_kl             | 0.00039322738 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.38          |
|    cost_value_loss       | 0.641         |
|    cost_values           | 1.35          |
|    entropy               | -1.94         |
|    entropy_loss          | -1.94         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.34          |
|    n_updates             | 4650          |
|    policy_gradient_loss  | -3.78e-05     |
|    std                   | 0.638         |
|    value_loss            | 9.57          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6689867   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 894          |
|    total_timesteps       | 956416       |
| train/                   |              |
|    approx_kl             | 0.0012144856 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 0.238        |
|    cost_values           | 1.12         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7            |
|    n_updates             | 4660         |
|    policy_gradient_loss  | 6.3e-05      |
|    std                   | 0.638        |
|    value_loss            | 16.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.68         |
| reward                   | -0.6426718   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 928          |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0038086092 |
|    clip_fraction         | 0.00356      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.744        |
|    cost_values           | 0.956        |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.03         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.000725    |
|    std                   | 0.638        |
|    value_loss            | 11.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -1.0142719 |
| rollout/                 |            |
|    ep_len_mean           | 954        |
|    ep_rew_mean           | -686       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 28         |
|    time_elapsed          | 962        |
|    total_timesteps       | 960512     |
| train/                   |            |
|    approx_kl             | 0.00322665 |
|    clip_fraction         | 0.0335     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.07       |
|    cost_value_loss       | 6.66       |
|    cost_values           | 1.18       |
|    entropy               | -1.94      |
|    entropy_loss          | -1.94      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.37       |
|    n_updates             | 4680       |
|    policy_gradient_loss  | -0.00248   |
|    std                   | 0.637      |
|    value_loss            | 4.15       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.544728    |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 998          |
|    total_timesteps       | 962560       |
| train/                   |              |
|    approx_kl             | 0.0019517324 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.486        |
|    cost_values           | 1.38         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 4690         |
|    policy_gradient_loss  | -0.000203    |
|    std                   | 0.637        |
|    value_loss            | 51.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.8500293  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1033        |
|    total_timesteps       | 964608      |
| train/                   |             |
|    approx_kl             | 0.006068568 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 1.31        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 4700        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.636       |
|    value_loss            | 15.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5469754   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1067         |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0027615048 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 1.65         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.93        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.637        |
|    value_loss            | 9.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.8223587   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1102         |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0037511596 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 4.99         |
|    cost_values           | 2.02         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.8         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00034     |
|    std                   | 0.637        |
|    value_loss            | 60.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.34427145  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1136         |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0004618052 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 4.72         |
|    cost_values           | 2.08         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.3         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | 5.98e-05     |
|    std                   | 0.637        |
|    value_loss            | 31.1         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.4322861 |
| rollout/                 |            |
|    ep_len_mean           | 948        |
|    ep_rew_mean           | -682       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 34         |
|    time_elapsed          | 1171       |
|    total_timesteps       | 972800     |
| train/                   |            |
|    approx_kl             | 0.0031369  |
|    clip_fraction         | 0.019      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.72       |
|    cost_value_loss       | 4.4        |
|    cost_values           | 2.12       |
|    entropy               | -1.94      |
|    entropy_loss          | -1.94      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.36       |
|    n_updates             | 4740       |
|    policy_gradient_loss  | -0.0016    |
|    std                   | 0.638      |
|    value_loss            | 13.1       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.7904206  |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -678        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1206        |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.001473637 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 5.45        |
|    cost_values           | 2.37        |
|    entropy               | -1.94       |
|    entropy_loss          | -1.94       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29          |
|    n_updates             | 4750        |
|    policy_gradient_loss  | -0.000598   |
|    std                   | 0.638       |
|    value_loss            | 60.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.74079657  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1240         |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0035428004 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 0.535        |
|    cost_values           | 2.17         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.34         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.638        |
|    value_loss            | 8.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.55292904  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1274         |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0022119202 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 0.55         |
|    cost_values           | 1.88         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.49         |
|    n_updates             | 4770         |
|    policy_gradient_loss  | -2.19e-05    |
|    std                   | 0.639        |
|    value_loss            | 6.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1403813   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1309         |
|    total_timesteps       | 980992       |
| train/                   |              |
|    approx_kl             | 0.0015686182 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 4.13         |
|    cost_values           | 1.85         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.77         |
|    n_updates             | 4780         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.635        |
|    value_loss            | 7.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.39827672  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1344         |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0030870873 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 0.1          |
|    cost_values           | 1.94         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.28         |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -3.43e-05    |
|    std                   | 0.634        |
|    value_loss            | 6.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.7418573   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1379         |
|    total_timesteps       | 985088       |
| train/                   |              |
|    approx_kl             | 0.0022418452 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 0.639        |
|    cost_values           | 1.5          |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 4800         |
|    policy_gradient_loss  | -3.79e-05    |
|    std                   | 0.634        |
|    value_loss            | 28.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.5821265   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1413         |
|    total_timesteps       | 987136       |
| train/                   |              |
|    approx_kl             | 5.853499e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 8.68         |
|    cost_values           | 1.4          |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.27         |
|    n_updates             | 4810         |
|    policy_gradient_loss  | 2.66e-05     |
|    std                   | 0.634        |
|    value_loss            | 6.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5809595  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1448        |
|    total_timesteps       | 989184      |
| train/                   |             |
|    approx_kl             | 0.003240922 |
|    clip_fraction         | 0.00244     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 0.282       |
|    cost_values           | 1.49        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 4820        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.634       |
|    value_loss            | 26.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.8735775   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1483         |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0034262293 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 1.17         |
|    cost_values           | 1.26         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.5          |
|    n_updates             | 4830         |
|    policy_gradient_loss  | -0.000787    |
|    std                   | 0.635        |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.58168465  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1519         |
|    total_timesteps       | 993280       |
| train/                   |              |
|    approx_kl             | 0.0029610537 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 3.32         |
|    cost_values           | 1.28         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.77         |
|    n_updates             | 4840         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.635        |
|    value_loss            | 8.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.47182193  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1554         |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0034470793 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 1.83         |
|    cost_values           | 1.48         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.000486    |
|    std                   | 0.634        |
|    value_loss            | 20.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.706741    |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1589         |
|    total_timesteps       | 997376       |
| train/                   |              |
|    approx_kl             | 0.0042579127 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 1.41         |
|    cost_values           | 1.49         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.65         |
|    n_updates             | 4860         |
|    policy_gradient_loss  | -0.000315    |
|    std                   | 0.634        |
|    value_loss            | 4.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.98084426  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1624         |
|    total_timesteps       | 999424       |
| train/                   |              |
|    approx_kl             | 0.0022280375 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 2.56         |
|    cost_values           | 1.52         |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.86         |
|    n_updates             | 4870         |
|    policy_gradient_loss  | 0.000118     |
|    std                   | 0.631        |
|    value_loss            | 5.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7028643  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1658        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.003992738 |
|    clip_fraction         | 0.0233      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 2.6         |
|    cost_values           | 1.61        |
|    entropy               | -1.91       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.77        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.63        |
|    value_loss            | 13.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1403502   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1693         |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0041077775 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.84         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 1.71         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.629        |
|    value_loss            | 15.5         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.04       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.04       |
| reward             | -0.7861686 |
| rollout/           |            |
|    ep_len_mean     | 967        |
|    ep_rew_mean     | -716       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1005568    |
-----------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1493694  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 1007616     |
| train/                   |             |
|    approx_kl             | 0.003458329 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.54        |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 4910        |
|    policy_gradient_loss  | -0.00144    |
|    std                   | 0.621       |
|    value_loss            | 11.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.65095115  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1009664      |
| train/                   |              |
|    approx_kl             | 0.0045336485 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 1.36         |
|    cost_values           | 2.78         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.32         |
|    n_updates             | 4920         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.621        |
|    value_loss            | 13.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.374        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.374        |
| reward                   | -0.51475704  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 1011712      |
| train/                   |              |
|    approx_kl             | 0.0036716312 |
|    clip_fraction         | 0.0061       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 2.53         |
|    entropy               | -1.89        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.38         |
|    n_updates             | 4930         |
|    policy_gradient_loss  | -0.000989    |
|    std                   | 0.621        |
|    value_loss            | 17.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.53         |
| reward                   | -0.65327066  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 1013760      |
| train/                   |              |
|    approx_kl             | 0.0029461468 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 3.45         |
|    cost_values           | 2.58         |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.65         |
|    n_updates             | 4940         |
|    policy_gradient_loss  | -0.000238    |
|    std                   | 0.623        |
|    value_loss            | 12.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.73         |
| reward                   | -0.9075284   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 199          |
|    total_timesteps       | 1015808      |
| train/                   |              |
|    approx_kl             | 0.0041520423 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 0.195        |
|    cost_values           | 2.57         |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 4950         |
|    policy_gradient_loss  | -0.000937    |
|    std                   | 0.622        |
|    value_loss            | 21.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.34406623  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -732         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 234          |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0016501918 |
|    clip_fraction         | 0.0431       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 2.36         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.37         |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.62         |
|    value_loss            | 15.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.45745704 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 8           |
|    time_elapsed          | 269         |
|    total_timesteps       | 1019904     |
| train/                   |             |
|    approx_kl             | 0.00332567  |
|    clip_fraction         | 0.0501      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.8         |
|    cost_value_loss       | 9.59        |
|    cost_values           | 2.56        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 4970        |
|    policy_gradient_loss  | 0.000424    |
|    std                   | 0.62        |
|    value_loss            | 17.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7637561   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0025159987 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.38         |
|    cost_value_loss       | 5.87         |
|    cost_values           | 2.79         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.11         |
|    n_updates             | 4980         |
|    policy_gradient_loss  | -8.75e-05    |
|    std                   | 0.62         |
|    value_loss            | 9.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.9512111  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 338         |
|    total_timesteps       | 1024000     |
| train/                   |             |
|    approx_kl             | 0.016665615 |
|    clip_fraction         | 0.0675      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 3.62        |
|    cost_values           | 2.97        |
|    entropy               | -1.87       |
|    entropy_loss          | -1.88       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.000979    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.45        |
|    n_updates             | 4990        |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 0.617       |
|    value_loss            | 21.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87793005  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 373          |
|    total_timesteps       | 1026048      |
| train/                   |              |
|    approx_kl             | 0.0029131982 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 0.978        |
|    cost_values           | 2.85         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.44         |
|    n_updates             | 5000         |
|    policy_gradient_loss  | 0.000921     |
|    std                   | 0.614        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.8405443   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 408          |
|    total_timesteps       | 1028096      |
| train/                   |              |
|    approx_kl             | 0.0013859053 |
|    clip_fraction         | 0.00264      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 1.64         |
|    cost_values           | 2.56         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.18         |
|    n_updates             | 5010         |
|    policy_gradient_loss  | 0.000571     |
|    std                   | 0.614        |
|    value_loss            | 7.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.16559     |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 442          |
|    total_timesteps       | 1030144      |
| train/                   |              |
|    approx_kl             | 0.0061785257 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 7.92         |
|    cost_values           | 2.55         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 5020         |
|    policy_gradient_loss  | 0.000624     |
|    std                   | 0.615        |
|    value_loss            | 14.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.48550913 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 477         |
|    total_timesteps       | 1032192     |
| train/                   |             |
|    approx_kl             | 0.004368153 |
|    clip_fraction         | 0.00391     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.26        |
|    cost_value_loss       | 0.236       |
|    cost_values           | 2.68        |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 5030        |
|    policy_gradient_loss  | -0.000138   |
|    std                   | 0.616       |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.9968573   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 1034240      |
| train/                   |              |
|    approx_kl             | 0.0010683108 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 3.15         |
|    cost_values           | 2.38         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.63         |
|    n_updates             | 5040         |
|    policy_gradient_loss  | -0.000185    |
|    std                   | 0.615        |
|    value_loss            | 9.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9132276  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 545         |
|    total_timesteps       | 1036288     |
| train/                   |             |
|    approx_kl             | 0.003177911 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 0.375       |
|    cost_values           | 2.36        |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.83        |
|    n_updates             | 5050        |
|    policy_gradient_loss  | -0.000369   |
|    std                   | 0.614       |
|    value_loss            | 5.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2728335  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 17          |
|    time_elapsed          | 580         |
|    total_timesteps       | 1038336     |
| train/                   |             |
|    approx_kl             | 0.006819499 |
|    clip_fraction         | 0.0457      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.31        |
|    cost_value_loss       | 3.43        |
|    cost_values           | 2.13        |
|    entropy               | -1.85       |
|    entropy_loss          | -1.86       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.75        |
|    n_updates             | 5060        |
|    policy_gradient_loss  | -0.00229    |
|    std                   | 0.611       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.89571846  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 615          |
|    total_timesteps       | 1040384      |
| train/                   |              |
|    approx_kl             | 0.0057526673 |
|    clip_fraction         | 0.0512       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.81         |
|    cost_value_loss       | 4.9          |
|    cost_values           | 2.31         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 5070         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 0.609        |
|    value_loss            | 18.2         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.91       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.91       |
| reward                   | -1.0840822 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -749       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 19         |
|    time_elapsed          | 649        |
|    total_timesteps       | 1042432    |
| train/                   |            |
|    approx_kl             | 0.00793061 |
|    clip_fraction         | 0.0267     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.55       |
|    cost_value_loss       | 7.02       |
|    cost_values           | 2.59       |
|    entropy               | -1.85      |
|    entropy_loss          | -1.85      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 11.4       |
|    n_updates             | 5080       |
|    policy_gradient_loss  | -0.0033    |
|    std                   | 0.609      |
|    value_loss            | 17.6       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.477993    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 683          |
|    total_timesteps       | 1044480      |
| train/                   |              |
|    approx_kl             | 0.0016394546 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 0.608        |
|    cost_values           | 2.53         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.48         |
|    n_updates             | 5090         |
|    policy_gradient_loss  | -0.000416    |
|    std                   | 0.608        |
|    value_loss            | 5.94         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.11          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.11          |
| reward                   | -0.5002444    |
| rollout/                 |               |
|    ep_len_mean           | 980           |
|    ep_rew_mean           | -745          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 21            |
|    time_elapsed          | 718           |
|    total_timesteps       | 1046528       |
| train/                   |               |
|    approx_kl             | 0.00041902185 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.94          |
|    cost_value_loss       | 5.94          |
|    cost_values           | 2.3           |
|    entropy               | -1.84         |
|    entropy_loss          | -1.84         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.4          |
|    n_updates             | 5100          |
|    policy_gradient_loss  | 3.2e-05       |
|    std                   | 0.608         |
|    value_loss            | 15            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 6.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.09         |
| reward                   | -0.7540749   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 752          |
|    total_timesteps       | 1048576      |
| train/                   |              |
|    approx_kl             | 0.0056193024 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.75         |
|    cost_value_loss       | 4.96         |
|    cost_values           | 2.38         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.9         |
|    n_updates             | 5110         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.608        |
|    value_loss            | 49.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.81588835 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -750        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 787         |
|    total_timesteps       | 1050624     |
| train/                   |             |
|    approx_kl             | 0.005198473 |
|    clip_fraction         | 0.0085      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.37        |
|    cost_value_loss       | 2.16        |
|    cost_values           | 2.39        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.87        |
|    n_updates             | 5120        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.607       |
|    value_loss            | 21.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.71581686 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -740        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 821         |
|    total_timesteps       | 1052672     |
| train/                   |             |
|    approx_kl             | 0.003753535 |
|    clip_fraction         | 0.00781     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.26        |
|    cost_value_loss       | 1.96        |
|    cost_values           | 2.15        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 5130        |
|    policy_gradient_loss  | -0.000848   |
|    std                   | 0.607       |
|    value_loss            | 9.64        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.95          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.95          |
| reward                   | -1.1111015    |
| rollout/                 |               |
|    ep_len_mean           | 973           |
|    ep_rew_mean           | -744          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 25            |
|    time_elapsed          | 856           |
|    total_timesteps       | 1054720       |
| train/                   |               |
|    approx_kl             | 0.00027473073 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.53          |
|    cost_value_loss       | 3.82          |
|    cost_values           | 1.99          |
|    entropy               | -1.84         |
|    entropy_loss          | -1.84         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 17.3          |
|    n_updates             | 5140          |
|    policy_gradient_loss  | 0.000114      |
|    std                   | 0.607         |
|    value_loss            | 40.4          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.8           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.8           |
| reward                   | -1.0716883    |
| rollout/                 |               |
|    ep_len_mean           | 973           |
|    ep_rew_mean           | -745          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 26            |
|    time_elapsed          | 890           |
|    total_timesteps       | 1056768       |
| train/                   |               |
|    approx_kl             | 0.00083407573 |
|    clip_fraction         | 0.0108        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.71          |
|    cost_value_loss       | 0.362         |
|    cost_values           | 1.77          |
|    entropy               | -1.83         |
|    entropy_loss          | -1.84         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 2.93          |
|    n_updates             | 5150          |
|    policy_gradient_loss  | -0.000216     |
|    std                   | 0.605         |
|    value_loss            | 5.61          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.6          |
| reward                   | -0.5842039   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 924          |
|    total_timesteps       | 1058816      |
| train/                   |              |
|    approx_kl             | 0.0023595314 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 1.23         |
|    cost_values           | 1.54         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.19         |
|    n_updates             | 5160         |
|    policy_gradient_loss  | -0.000303    |
|    std                   | 0.604        |
|    value_loss            | 11.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.24        |
| reward                   | -0.67607945 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -757        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 959         |
|    total_timesteps       | 1060864     |
| train/                   |             |
|    approx_kl             | 0.004417956 |
|    clip_fraction         | 0.0185      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 1.83        |
|    cost_values           | 1.39        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.28        |
|    n_updates             | 5170        |
|    policy_gradient_loss  | -0.00184    |
|    std                   | 0.6         |
|    value_loss            | 18.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.71         |
| reward                   | -0.53722715  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 994          |
|    total_timesteps       | 1062912      |
| train/                   |              |
|    approx_kl             | 0.0031894105 |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 5.06         |
|    cost_values           | 1.45         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 5180         |
|    policy_gradient_loss  | 0.000667     |
|    std                   | 0.599        |
|    value_loss            | 20.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.33         |
| reward                   | -0.78472614  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1029         |
|    total_timesteps       | 1064960      |
| train/                   |              |
|    approx_kl             | 0.0028715814 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 2.75         |
|    cost_values           | 1.43         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.97         |
|    n_updates             | 5190         |
|    policy_gradient_loss  | -0.000325    |
|    std                   | 0.6          |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3394344   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 1067008      |
| train/                   |              |
|    approx_kl             | 0.0001353925 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 2.55         |
|    cost_values           | 1.49         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.46         |
|    n_updates             | 5200         |
|    policy_gradient_loss  | 0.000314     |
|    std                   | 0.599        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.69176173  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1098         |
|    total_timesteps       | 1069056      |
| train/                   |              |
|    approx_kl             | 0.0044708904 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 1.35         |
|    cost_values           | 1.54         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 5210         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.599        |
|    value_loss            | 25.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7256109   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1132         |
|    total_timesteps       | 1071104      |
| train/                   |              |
|    approx_kl             | 0.0025836658 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 12           |
|    cost_values           | 1.45         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 5220         |
|    policy_gradient_loss  | -0.000827    |
|    std                   | 0.599        |
|    value_loss            | 14.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1877768   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1167         |
|    total_timesteps       | 1073152      |
| train/                   |              |
|    approx_kl             | 0.0042344965 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 7.41         |
|    cost_values           | 1.63         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.76         |
|    n_updates             | 5230         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.598        |
|    value_loss            | 9.2          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.99          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.99          |
| reward                   | -0.90928596   |
| rollout/                 |               |
|    ep_len_mean           | 991           |
|    ep_rew_mean           | -772          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 35            |
|    time_elapsed          | 1202          |
|    total_timesteps       | 1075200       |
| train/                   |               |
|    approx_kl             | 0.00031715713 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.49          |
|    cost_value_loss       | 20            |
|    cost_values           | 1.89          |
|    entropy               | -1.81         |
|    entropy_loss          | -1.81         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 14.5          |
|    n_updates             | 5240          |
|    policy_gradient_loss  | -8.14e-05     |
|    std                   | 0.598         |
|    value_loss            | 10.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.74830836  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1237         |
|    total_timesteps       | 1077248      |
| train/                   |              |
|    approx_kl             | 0.0010227861 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.67         |
|    cost_value_loss       | 5.55         |
|    cost_values           | 2.16         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 5250         |
|    policy_gradient_loss  | -0.000273    |
|    std                   | 0.598        |
|    value_loss            | 36.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6486851   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 1079296      |
| train/                   |              |
|    approx_kl             | 0.0049151033 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 0.191        |
|    cost_values           | 1.94         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.45         |
|    n_updates             | 5260         |
|    policy_gradient_loss  | 0.000296     |
|    std                   | 0.594        |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46740097  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1306         |
|    total_timesteps       | 1081344      |
| train/                   |              |
|    approx_kl             | 0.0033784811 |
|    clip_fraction         | 0.0278       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 2.6          |
|    cost_values           | 1.65         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.44         |
|    n_updates             | 5270         |
|    policy_gradient_loss  | -0.000525    |
|    std                   | 0.593        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.53828853  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1341         |
|    total_timesteps       | 1083392      |
| train/                   |              |
|    approx_kl             | 0.0042666085 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 6.68         |
|    cost_values           | 1.49         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 5280         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.593        |
|    value_loss            | 15.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7491899  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -761        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1375        |
|    total_timesteps       | 1085440     |
| train/                   |             |
|    approx_kl             | 0.004441589 |
|    clip_fraction         | 0.00684     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 0.0677      |
|    cost_values           | 1.35        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.68        |
|    n_updates             | 5290        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.593       |
|    value_loss            | 9.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.42859322 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -759        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1410        |
|    total_timesteps       | 1087488     |
| train/                   |             |
|    approx_kl             | 0.00377979  |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 1.55        |
|    cost_values           | 1.2         |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.1         |
|    n_updates             | 5300        |
|    policy_gradient_loss  | -0.000991   |
|    std                   | 0.594       |
|    value_loss            | 17.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.6269355   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1445         |
|    total_timesteps       | 1089536      |
| train/                   |              |
|    approx_kl             | 0.0064755566 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.151        |
|    cost_values           | 1.17         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.05         |
|    n_updates             | 5310         |
|    policy_gradient_loss  | -0.000391    |
|    std                   | 0.596        |
|    value_loss            | 6.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.07163     |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1479         |
|    total_timesteps       | 1091584      |
| train/                   |              |
|    approx_kl             | 0.0010615019 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 2.02         |
|    cost_values           | 1            |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.08         |
|    n_updates             | 5320         |
|    policy_gradient_loss  | -0.000109    |
|    std                   | 0.596        |
|    value_loss            | 5.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.77948946  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1514         |
|    total_timesteps       | 1093632      |
| train/                   |              |
|    approx_kl             | 0.0021398494 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.833        |
|    cost_value_loss       | 0.0284       |
|    cost_values           | 0.965        |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 5330         |
|    policy_gradient_loss  | -0.000639    |
|    std                   | 0.596        |
|    value_loss            | 13.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.97586644   |
| rollout/                 |               |
|    ep_len_mean           | 991           |
|    ep_rew_mean           | -763          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 45            |
|    time_elapsed          | 1548          |
|    total_timesteps       | 1095680       |
| train/                   |               |
|    approx_kl             | 0.00072479644 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.791         |
|    cost_value_loss       | 0.052         |
|    cost_values           | 0.885         |
|    entropy               | -1.8          |
|    entropy_loss          | -1.8          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.17          |
|    n_updates             | 5340          |
|    policy_gradient_loss  | -0.000102     |
|    std                   | 0.596         |
|    value_loss            | 5.55          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.1144589   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1583         |
|    total_timesteps       | 1097728      |
| train/                   |              |
|    approx_kl             | 0.0027728227 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.828        |
|    cost_value_loss       | 0.442        |
|    cost_values           | 0.822        |
|    entropy               | -1.8         |
|    entropy_loss          | -1.81        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.944        |
|    n_updates             | 5350         |
|    policy_gradient_loss  | -0.00043     |
|    std                   | 0.595        |
|    value_loss            | 1.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.1034948   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1617         |
|    total_timesteps       | 1099776      |
| train/                   |              |
|    approx_kl             | 0.0023449515 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.889        |
|    cost_value_loss       | 0.321        |
|    cost_values           | 0.838        |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.56         |
|    n_updates             | 5360         |
|    policy_gradient_loss  | -2.88e-05    |
|    std                   | 0.595        |
|    value_loss            | 6.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.9240483   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1652         |
|    total_timesteps       | 1101824      |
| train/                   |              |
|    approx_kl             | 0.0046323314 |
|    clip_fraction         | 0.0522       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.79         |
|    cost_value_loss       | 0.155        |
|    cost_values           | 0.797        |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 5370         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.595        |
|    value_loss            | 6.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.02         |
| reward                   | -0.8217257   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1687         |
|    total_timesteps       | 1103872      |
| train/                   |              |
|    approx_kl             | 0.0005408075 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.984        |
|    cost_value_loss       | 2.1          |
|    cost_values           | 0.89         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.7          |
|    n_updates             | 5380         |
|    policy_gradient_loss  | -4.49e-05    |
|    std                   | 0.595        |
|    value_loss            | 3.58         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
------------------------------------
| avg_speed          | 5.69        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 5.69        |
| reward             | -0.92031443 |
| rollout/           |             |
|    ep_len_mean     | 991         |
|    ep_rew_mean     | -768        |
| time/              |             |
|    fps             | 82          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1105920     |
------------------------------------
-------------------------------------------
| avg_speed                | 6.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.77         |
| reward                   | -0.8531263   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1107968      |
| train/                   |              |
|    approx_kl             | 0.0036663755 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.14         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 1.2          |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 5400         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.596        |
|    value_loss            | 19.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8055635  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 94          |
|    total_timesteps       | 1110016     |
| train/                   |             |
|    approx_kl             | 0.001561305 |
|    clip_fraction         | 4.88e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.04        |
|    cost_value_loss       | 4.63        |
|    cost_values           | 1.59        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.22        |
|    n_updates             | 5410        |
|    policy_gradient_loss  | -0.000488   |
|    std                   | 0.596       |
|    value_loss            | 4.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.3878015  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -767        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 129         |
|    total_timesteps       | 1112064     |
| train/                   |             |
|    approx_kl             | 0.004127192 |
|    clip_fraction         | 0.00376     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 9.77        |
|    cost_values           | 1.75        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.78        |
|    n_updates             | 5420        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.596       |
|    value_loss            | 7.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.9539506   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 1114112      |
| train/                   |              |
|    approx_kl             | 0.0033320053 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 0.969        |
|    cost_values           | 1.83         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.62         |
|    n_updates             | 5430         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.596        |
|    value_loss            | 14.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8693092   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1116160      |
| train/                   |              |
|    approx_kl             | 0.0044162394 |
|    clip_fraction         | 0.00713      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.88         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 1.73         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 5440         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.596        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.46351352  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 233          |
|    total_timesteps       | 1118208      |
| train/                   |              |
|    approx_kl             | 0.0066480604 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 1.91         |
|    cost_values           | 1.84         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 5450         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.596        |
|    value_loss            | 39           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78180337  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 1120256      |
| train/                   |              |
|    approx_kl             | 0.0046773963 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 2.97         |
|    cost_values           | 1.85         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.53         |
|    n_updates             | 5460         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.597        |
|    value_loss            | 8.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.0984809   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 1122304      |
| train/                   |              |
|    approx_kl             | 0.0023294867 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 0.101        |
|    cost_values           | 1.87         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.06         |
|    n_updates             | 5470         |
|    policy_gradient_loss  | -0.000461    |
|    std                   | 0.597        |
|    value_loss            | 6.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.56912434  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 1124352      |
| train/                   |              |
|    approx_kl             | 0.0042081093 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 0.0363       |
|    cost_values           | 1.42         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.7         |
|    n_updates             | 5480         |
|    policy_gradient_loss  | -0.000933    |
|    std                   | 0.597        |
|    value_loss            | 44.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0605817  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 371         |
|    total_timesteps       | 1126400     |
| train/                   |             |
|    approx_kl             | 0.002986598 |
|    clip_fraction         | 0.00161     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 10.4        |
|    cost_values           | 1.37        |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 5490        |
|    policy_gradient_loss  | -0.000592   |
|    std                   | 0.597       |
|    value_loss            | 21.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9066035   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 1128448      |
| train/                   |              |
|    approx_kl             | 0.0030004918 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 2.98         |
|    cost_values           | 1.71         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.2         |
|    n_updates             | 5500         |
|    policy_gradient_loss  | -0.000358    |
|    std                   | 0.598        |
|    value_loss            | 43           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.236        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.236        |
| reward                   | -0.84137326  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 1130496      |
| train/                   |              |
|    approx_kl             | 0.0006979793 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 0.078        |
|    cost_values           | 1.58         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.9          |
|    n_updates             | 5510         |
|    policy_gradient_loss  | -0.000443    |
|    std                   | 0.597        |
|    value_loss            | 6.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.69         |
| reward                   | -0.81444156  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1132544      |
| train/                   |              |
|    approx_kl             | 0.0016086455 |
|    clip_fraction         | 0.0439       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 3.82         |
|    cost_values           | 1.31         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.61         |
|    n_updates             | 5520         |
|    policy_gradient_loss  | 0.00263      |
|    std                   | 0.596        |
|    value_loss            | 16           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.8           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.8           |
| reward                   | -0.7712598    |
| rollout/                 |               |
|    ep_len_mean           | 988           |
|    ep_rew_mean           | -754          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 15            |
|    time_elapsed          | 509           |
|    total_timesteps       | 1134592       |
| train/                   |               |
|    approx_kl             | 0.00044146954 |
|    clip_fraction         | 0.0187        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.1           |
|    cost_value_loss       | 0.141         |
|    cost_values           | 1.11          |
|    entropy               | -1.8          |
|    entropy_loss          | -1.8          |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.79          |
|    n_updates             | 5530          |
|    policy_gradient_loss  | -0.000561     |
|    std                   | 0.595         |
|    value_loss            | 3.61          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.63272727  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 544          |
|    total_timesteps       | 1136640      |
| train/                   |              |
|    approx_kl             | 0.0058418876 |
|    clip_fraction         | 0.0377       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.29         |
|    cost_values           | 1.04         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.64         |
|    n_updates             | 5540         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.596        |
|    value_loss            | 6.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.9056993   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 578          |
|    total_timesteps       | 1138688      |
| train/                   |              |
|    approx_kl             | 0.0045371316 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 3.02         |
|    cost_values           | 1.02         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 5550         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.596        |
|    value_loss            | 22.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.71323454  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 612          |
|    total_timesteps       | 1140736      |
| train/                   |              |
|    approx_kl             | 0.0015903874 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.564        |
|    cost_values           | 0.998        |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.47         |
|    n_updates             | 5560         |
|    policy_gradient_loss  | -0.0002      |
|    std                   | 0.596        |
|    value_loss            | 5.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -1.0146106   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 647          |
|    total_timesteps       | 1142784      |
| train/                   |              |
|    approx_kl             | 0.0021021145 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 1.22         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 5570         |
|    policy_gradient_loss  | -0.000293    |
|    std                   | 0.596        |
|    value_loss            | 27.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.047236    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 1144832      |
| train/                   |              |
|    approx_kl             | 0.0056984783 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 0.413        |
|    cost_values           | 1.47         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.85         |
|    n_updates             | 5580         |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.594        |
|    value_loss            | 7.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.6973634   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 717          |
|    total_timesteps       | 1146880      |
| train/                   |              |
|    approx_kl             | 0.0030823052 |
|    clip_fraction         | 0.0446       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 5.77         |
|    cost_values           | 1.35         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.8         |
|    n_updates             | 5590         |
|    policy_gradient_loss  | -0.000691    |
|    std                   | 0.594        |
|    value_loss            | 32.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.48629153 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 752         |
|    total_timesteps       | 1148928     |
| train/                   |             |
|    approx_kl             | 0.004365419 |
|    clip_fraction         | 0.0126      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 8.36        |
|    cost_values           | 1.58        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.44        |
|    n_updates             | 5600        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.594       |
|    value_loss            | 12.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0190691   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 787          |
|    total_timesteps       | 1150976      |
| train/                   |              |
|    approx_kl             | 0.0047513265 |
|    clip_fraction         | 0.00776      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 0.984        |
|    cost_values           | 1.8          |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.19         |
|    n_updates             | 5610         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.593        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.7421566   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 823          |
|    total_timesteps       | 1153024      |
| train/                   |              |
|    approx_kl             | 0.0013607382 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 8.75         |
|    cost_values           | 1.7          |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.58         |
|    n_updates             | 5620         |
|    policy_gradient_loss  | -0.000459    |
|    std                   | 0.593        |
|    value_loss            | 9.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.0068111   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 858          |
|    total_timesteps       | 1155072      |
| train/                   |              |
|    approx_kl             | 0.0036802958 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 7.52         |
|    cost_values           | 2            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.53         |
|    n_updates             | 5630         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.593        |
|    value_loss            | 6.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1388856   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 893          |
|    total_timesteps       | 1157120      |
| train/                   |              |
|    approx_kl             | 0.0016052313 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 0.483        |
|    cost_values           | 2.16         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.85         |
|    n_updates             | 5640         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.592        |
|    value_loss            | 5.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53140765  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 928          |
|    total_timesteps       | 1159168      |
| train/                   |              |
|    approx_kl             | 0.0018287166 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 3.44         |
|    cost_values           | 1.85         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.72         |
|    n_updates             | 5650         |
|    policy_gradient_loss  | 0.00282      |
|    std                   | 0.592        |
|    value_loss            | 8.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.64875007 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 963         |
|    total_timesteps       | 1161216     |
| train/                   |             |
|    approx_kl             | 0.006259518 |
|    clip_fraction         | 0.0467      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.56        |
|    cost_value_loss       | 6.69        |
|    cost_values           | 1.83        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.9        |
|    n_updates             | 5660        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.591       |
|    value_loss            | 46.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.96658105 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -751        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 997         |
|    total_timesteps       | 1163264     |
| train/                   |             |
|    approx_kl             | 0.003614965 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 5.78        |
|    cost_values           | 2.14        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.25        |
|    n_updates             | 5670        |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 0.591       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3798968   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1031         |
|    total_timesteps       | 1165312      |
| train/                   |              |
|    approx_kl             | 0.0010553601 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 0.267        |
|    cost_values           | 2.34         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.88         |
|    n_updates             | 5680         |
|    policy_gradient_loss  | -0.000694    |
|    std                   | 0.59         |
|    value_loss            | 20.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.41647685   |
| rollout/                 |               |
|    ep_len_mean           | 992           |
|    ep_rew_mean           | -746          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 31            |
|    time_elapsed          | 1066          |
|    total_timesteps       | 1167360       |
| train/                   |               |
|    approx_kl             | 0.00030914973 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.17          |
|    cost_value_loss       | 8.32          |
|    cost_values           | 2.14          |
|    entropy               | -1.78         |
|    entropy_loss          | -1.78         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.76          |
|    n_updates             | 5690          |
|    policy_gradient_loss  | 3.97e-05      |
|    std                   | 0.59          |
|    value_loss            | 12.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.9435679   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1100         |
|    total_timesteps       | 1169408      |
| train/                   |              |
|    approx_kl             | 0.0028791612 |
|    clip_fraction         | 0.00674      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 3.06         |
|    cost_values           | 2.2          |
|    entropy               | -1.8         |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.96         |
|    n_updates             | 5700         |
|    policy_gradient_loss  | -0.000669    |
|    std                   | 0.594        |
|    value_loss            | 9.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.44054005  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1134         |
|    total_timesteps       | 1171456      |
| train/                   |              |
|    approx_kl             | 0.0050451485 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 2.46         |
|    cost_values           | 2.2          |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 5710         |
|    policy_gradient_loss  | -0.00076     |
|    std                   | 0.594        |
|    value_loss            | 20.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9178806   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1169         |
|    total_timesteps       | 1173504      |
| train/                   |              |
|    approx_kl             | 0.0029212174 |
|    clip_fraction         | 0.00308      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 0.113        |
|    cost_values           | 2.09         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 5720         |
|    policy_gradient_loss  | -0.000283    |
|    std                   | 0.594        |
|    value_loss            | 15.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.6542715  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -743        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1203        |
|    total_timesteps       | 1175552     |
| train/                   |             |
|    approx_kl             | 0.004913492 |
|    clip_fraction         | 0.00796     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 0.521       |
|    cost_values           | 1.62        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.83        |
|    n_updates             | 5730        |
|    policy_gradient_loss  | -3.74e-06   |
|    std                   | 0.596       |
|    value_loss            | 7.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5087377   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1237         |
|    total_timesteps       | 1177600      |
| train/                   |              |
|    approx_kl             | 0.0014672556 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 2.7          |
|    cost_values           | 1.6          |
|    entropy               | -1.79        |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 5740         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.594        |
|    value_loss            | 11.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.95574695  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 1179648      |
| train/                   |              |
|    approx_kl             | 0.0039752754 |
|    clip_fraction         | 0.00752      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.67         |
|    cost_value_loss       | 4.84         |
|    cost_values           | 1.8          |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.64         |
|    n_updates             | 5750         |
|    policy_gradient_loss  | -0.000886    |
|    std                   | 0.592        |
|    value_loss            | 17.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.96          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.96          |
| reward                   | -1.3014       |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -742          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1308          |
|    total_timesteps       | 1181696       |
| train/                   |               |
|    approx_kl             | 0.00040574223 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.51          |
|    cost_value_loss       | 0.0782        |
|    cost_values           | 1.68          |
|    entropy               | -1.79         |
|    entropy_loss          | -1.79         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.53          |
|    n_updates             | 5760          |
|    policy_gradient_loss  | -7.6e-05      |
|    std                   | 0.593         |
|    value_loss            | 4.58          |
--------------------------------------------
------------------------------------------
| avg_speed                | 3.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.17        |
| reward                   | -0.66415185 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1343        |
|    total_timesteps       | 1183744     |
| train/                   |             |
|    approx_kl             | 0.004809904 |
|    clip_fraction         | 0.0864      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.49        |
|    cost_value_loss       | 9.27        |
|    cost_values           | 1.43        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.8        |
|    n_updates             | 5770        |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.593       |
|    value_loss            | 54.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.9634021  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -747        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1378        |
|    total_timesteps       | 1185792     |
| train/                   |             |
|    approx_kl             | 0.004334422 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 0.051       |
|    cost_values           | 1.37        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.22        |
|    n_updates             | 5780        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.592       |
|    value_loss            | 15.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.634162   |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1414        |
|    total_timesteps       | 1187840     |
| train/                   |             |
|    approx_kl             | 0.001336602 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 3.99        |
|    cost_value_loss       | 18.2        |
|    cost_values           | 1.25        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 5790        |
|    policy_gradient_loss  | -0.000613   |
|    std                   | 0.592       |
|    value_loss            | 16.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.6017799  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1449        |
|    total_timesteps       | 1189888     |
| train/                   |             |
|    approx_kl             | 0.003115338 |
|    clip_fraction         | 0.0233      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 6.03        |
|    cost_values           | 1.59        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.66        |
|    n_updates             | 5800        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.591       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.6612527   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1484         |
|    total_timesteps       | 1191936      |
| train/                   |              |
|    approx_kl             | 0.0011176413 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 0.473        |
|    cost_values           | 1.73         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 5810         |
|    policy_gradient_loss  | 4.39e-05     |
|    std                   | 0.59         |
|    value_loss            | 9.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.85917974  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1519         |
|    total_timesteps       | 1193984      |
| train/                   |              |
|    approx_kl             | 0.0010093116 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 2.23         |
|    cost_values           | 1.48         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.57         |
|    n_updates             | 5820         |
|    policy_gradient_loss  | -0.000119    |
|    std                   | 0.589        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.84516513  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1554         |
|    total_timesteps       | 1196032      |
| train/                   |              |
|    approx_kl             | 0.0038997466 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 3.32         |
|    cost_values           | 1.58         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.92         |
|    n_updates             | 5830         |
|    policy_gradient_loss  | -0.000792    |
|    std                   | 0.589        |
|    value_loss            | 5.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.063911    |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1588         |
|    total_timesteps       | 1198080      |
| train/                   |              |
|    approx_kl             | 0.0052953917 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 5.1          |
|    cost_values           | 1.87         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22           |
|    n_updates             | 5840         |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.589        |
|    value_loss            | 43.6         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.96       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.96       |
| reward                   | -1.3820583 |
| rollout/                 |            |
|    ep_len_mean           | 987        |
|    ep_rew_mean           | -737       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 47         |
|    time_elapsed          | 1623       |
|    total_timesteps       | 1200128    |
| train/                   |            |
|    approx_kl             | 0.00210774 |
|    clip_fraction         | 0.000146   |
|    clip_range            | 0.2        |
|    cost_returns          | 1.67       |
|    cost_value_loss       | 0.573      |
|    cost_values           | 1.75       |
|    entropy               | -1.78      |
|    entropy_loss          | -1.78      |
|    explained_variance    | 1.19e-07   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.53       |
|    n_updates             | 5850       |
|    policy_gradient_loss  | -0.00028   |
|    std                   | 0.589      |
|    value_loss            | 11.6       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6768638  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1658        |
|    total_timesteps       | 1202176     |
| train/                   |             |
|    approx_kl             | 0.005080627 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 0.202       |
|    cost_values           | 1.43        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.31        |
|    n_updates             | 5860        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.588       |
|    value_loss            | 15.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.63784915  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1693         |
|    total_timesteps       | 1204224      |
| train/                   |              |
|    approx_kl             | 0.0040886253 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 10.5         |
|    cost_values           | 1.35         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.6         |
|    n_updates             | 5870         |
|    policy_gradient_loss  | -0.00089     |
|    std                   | 0.589        |
|    value_loss            | 31.5         |
-------------------------------------------
----------------------------------
| avg_speed          | 8.02      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 8.02      |
| reward             | -0.907655 |
| rollout/           |           |
|    ep_len_mean     | 987       |
|    ep_rew_mean     | -742      |
| time/              |           |
|    fps             | 82        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 1206272   |
----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7997755   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1208320      |
| train/                   |              |
|    approx_kl             | 0.0059105307 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 1.28         |
|    cost_values           | 1.73         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.81         |
|    n_updates             | 5890         |
|    policy_gradient_loss  | 2.03e-06     |
|    std                   | 0.583        |
|    value_loss            | 9.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.90579605  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 1210368      |
| train/                   |              |
|    approx_kl             | 0.0021785698 |
|    clip_fraction         | 0.0922       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 0.0961       |
|    cost_values           | 1.58         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.72         |
|    n_updates             | 5900         |
|    policy_gradient_loss  | -7.85e-05    |
|    std                   | 0.583        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.51767576  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 1212416      |
| train/                   |              |
|    approx_kl             | 0.0038317682 |
|    clip_fraction         | 0.0439       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 0.487        |
|    cost_values           | 1.29         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.87         |
|    n_updates             | 5910         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.581        |
|    value_loss            | 37.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.262831    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1214464      |
| train/                   |              |
|    approx_kl             | 0.0016845145 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 2.38         |
|    cost_values           | 1.2          |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.6          |
|    n_updates             | 5920         |
|    policy_gradient_loss  | 7.58e-05     |
|    std                   | 0.581        |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.69487095  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1216512      |
| train/                   |              |
|    approx_kl             | 0.0025202606 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 3.14         |
|    cost_values           | 1.22         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.75         |
|    n_updates             | 5930         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.582        |
|    value_loss            | 9.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.69        |
| reward                   | -0.62373394 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -745        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 232         |
|    total_timesteps       | 1218560     |
| train/                   |             |
|    approx_kl             | 0.00220118  |
|    clip_fraction         | 0.00083     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.77        |
|    cost_value_loss       | 2.54        |
|    cost_values           | 1.45        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 5940        |
|    policy_gradient_loss  | 9.63e-05    |
|    std                   | 0.583       |
|    value_loss            | 20.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.45         |
| reward                   | -0.88233364  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 1220608      |
| train/                   |              |
|    approx_kl             | 0.0046453793 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 0.773        |
|    cost_values           | 1.42         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 5950         |
|    policy_gradient_loss  | -0.000519    |
|    std                   | 0.583        |
|    value_loss            | 42           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.7557096    |
| rollout/                 |               |
|    ep_len_mean           | 977           |
|    ep_rew_mean           | -732          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 9             |
|    time_elapsed          | 302           |
|    total_timesteps       | 1222656       |
| train/                   |               |
|    approx_kl             | 0.00070363865 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.6           |
|    cost_value_loss       | 7.08          |
|    cost_values           | 1.32          |
|    entropy               | -1.76         |
|    entropy_loss          | -1.76         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.3          |
|    n_updates             | 5960          |
|    policy_gradient_loss  | -0.000209     |
|    std                   | 0.582         |
|    value_loss            | 14.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0900136   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 1224704      |
| train/                   |              |
|    approx_kl             | 0.0017785493 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.41         |
|    cost_value_loss       | 12           |
|    cost_values           | 1.46         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 5970         |
|    policy_gradient_loss  | -0.000564    |
|    std                   | 0.582        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.98557234  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 1226752      |
| train/                   |              |
|    approx_kl             | 0.0039505223 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 6.53         |
|    cost_values           | 1.78         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 5980         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.582        |
|    value_loss            | 44.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.27918422  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 406          |
|    total_timesteps       | 1228800      |
| train/                   |              |
|    approx_kl             | 0.0022122082 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 3.73         |
|    cost_values           | 1.91         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 5990         |
|    policy_gradient_loss  | -0.000733    |
|    std                   | 0.582        |
|    value_loss            | 27.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6693726  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 440         |
|    total_timesteps       | 1230848     |
| train/                   |             |
|    approx_kl             | 0.005840147 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 10.4        |
|    cost_values           | 2.03        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 6000        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.583       |
|    value_loss            | 9.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.13003226  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 475          |
|    total_timesteps       | 1232896      |
| train/                   |              |
|    approx_kl             | 0.0033201305 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 0.192        |
|    cost_values           | 2.17         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.8          |
|    n_updates             | 6010         |
|    policy_gradient_loss  | -0.00024     |
|    std                   | 0.582        |
|    value_loss            | 11.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.44227427 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 510         |
|    total_timesteps       | 1234944     |
| train/                   |             |
|    approx_kl             | 0.004504077 |
|    clip_fraction         | 0.0332      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 4.82        |
|    cost_values           | 1.87        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.43        |
|    n_updates             | 6020        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.582       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0215346   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 544          |
|    total_timesteps       | 1236992      |
| train/                   |              |
|    approx_kl             | 0.0067831073 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 1.89         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 6030         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.582        |
|    value_loss            | 38.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 1.99          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.99          |
| reward                   | -0.6668163    |
| rollout/                 |               |
|    ep_len_mean           | 975           |
|    ep_rew_mean           | -739          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 17            |
|    time_elapsed          | 578           |
|    total_timesteps       | 1239040       |
| train/                   |               |
|    approx_kl             | 0.00022481492 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.83          |
|    cost_value_loss       | 1.69          |
|    cost_values           | 1.71          |
|    entropy               | -1.75         |
|    entropy_loss          | -1.75         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.98          |
|    n_updates             | 6040          |
|    policy_gradient_loss  | -0.000142     |
|    std                   | 0.581         |
|    value_loss            | 21.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -0.7218438   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 613          |
|    total_timesteps       | 1241088      |
| train/                   |              |
|    approx_kl             | 0.0019900831 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.152        |
|    cost_values           | 1.44         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.9         |
|    n_updates             | 6050         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.581        |
|    value_loss            | 36.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9131105  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -736        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 647         |
|    total_timesteps       | 1243136     |
| train/                   |             |
|    approx_kl             | 0.005385072 |
|    clip_fraction         | 0.0514      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 1.59        |
|    cost_values           | 1.24        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.54        |
|    n_updates             | 6060        |
|    policy_gradient_loss  | -0.00435    |
|    std                   | 0.585       |
|    value_loss            | 5.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.80487436  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 1245184      |
| train/                   |              |
|    approx_kl             | 0.0041470323 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 3.82         |
|    cost_values           | 1.48         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.75         |
|    n_updates             | 6070         |
|    policy_gradient_loss  | -0.000884    |
|    std                   | 0.588        |
|    value_loss            | 8.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9781463   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 717          |
|    total_timesteps       | 1247232      |
| train/                   |              |
|    approx_kl             | 0.0033306093 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 0.567        |
|    cost_values           | 1.68         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.6         |
|    n_updates             | 6080         |
|    policy_gradient_loss  | 0.000309     |
|    std                   | 0.589        |
|    value_loss            | 33.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.62085766  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 751          |
|    total_timesteps       | 1249280      |
| train/                   |              |
|    approx_kl             | 0.0016275259 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 9.3          |
|    cost_values           | 1.68         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.1         |
|    n_updates             | 6090         |
|    policy_gradient_loss  | -0.000381    |
|    std                   | 0.589        |
|    value_loss            | 54.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80450535 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 786         |
|    total_timesteps       | 1251328     |
| train/                   |             |
|    approx_kl             | 0.005065512 |
|    clip_fraction         | 0.00991     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 0.217       |
|    cost_values           | 1.87        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.2         |
|    n_updates             | 6100        |
|    policy_gradient_loss  | -0.000677   |
|    std                   | 0.587       |
|    value_loss            | 16.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.4695307  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -750        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 820         |
|    total_timesteps       | 1253376     |
| train/                   |             |
|    approx_kl             | 0.004459936 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 4.44        |
|    cost_values           | 1.6         |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.55        |
|    n_updates             | 6110        |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.586       |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.79286665  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 855          |
|    total_timesteps       | 1255424      |
| train/                   |              |
|    approx_kl             | 0.0029811973 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 2.23         |
|    cost_values           | 1.55         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 6120         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.585        |
|    value_loss            | 24.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.36531687  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 889          |
|    total_timesteps       | 1257472      |
| train/                   |              |
|    approx_kl             | 0.0037734117 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.27         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 1.55         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 6130         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.584        |
|    value_loss            | 12.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.870532    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 924          |
|    total_timesteps       | 1259520      |
| train/                   |              |
|    approx_kl             | 0.0030716741 |
|    clip_fraction         | 0.00244      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 0.36         |
|    cost_values           | 1.58         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 6140         |
|    policy_gradient_loss  | -0.000673    |
|    std                   | 0.584        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.87263554  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 1261568      |
| train/                   |              |
|    approx_kl             | 0.0045063486 |
|    clip_fraction         | 0.00645      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 7.3          |
|    cost_values           | 1.52         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.76        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.44         |
|    n_updates             | 6150         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.586        |
|    value_loss            | 11.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6464186  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 993         |
|    total_timesteps       | 1263616     |
| train/                   |             |
|    approx_kl             | 0.004475994 |
|    clip_fraction         | 0.0203      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 7.45        |
|    cost_values           | 1.92        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 6160        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.586       |
|    value_loss            | 11.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6667961  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1028        |
|    total_timesteps       | 1265664     |
| train/                   |             |
|    approx_kl             | 0.001773657 |
|    clip_fraction         | 0.000293    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.6         |
|    cost_value_loss       | 9.58        |
|    cost_values           | 2.4         |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.05        |
|    n_updates             | 6170        |
|    policy_gradient_loss  | -0.000222   |
|    std                   | 0.586       |
|    value_loss            | 7.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.5926752  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -745        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1062        |
|    total_timesteps       | 1267712     |
| train/                   |             |
|    approx_kl             | 0.007648468 |
|    clip_fraction         | 0.0297      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 4.25        |
|    cost_values           | 2.73        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 6180        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.586       |
|    value_loss            | 6.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9093662   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1097         |
|    total_timesteps       | 1269760      |
| train/                   |              |
|    approx_kl             | 0.0051091267 |
|    clip_fraction         | 0.01         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.84         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 2.61         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.28         |
|    n_updates             | 6190         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.586        |
|    value_loss            | 8.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6588712   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1132         |
|    total_timesteps       | 1271808      |
| train/                   |              |
|    approx_kl             | 0.0015964916 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.18         |
|    cost_value_loss       | 8.95         |
|    cost_values           | 2.62         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.44         |
|    n_updates             | 6200         |
|    policy_gradient_loss  | -0.000317    |
|    std                   | 0.587        |
|    value_loss            | 8.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.88671607  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1167         |
|    total_timesteps       | 1273856      |
| train/                   |              |
|    approx_kl             | 0.0059935916 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 4.43         |
|    cost_values           | 2.96         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.77        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 6210         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.584        |
|    value_loss            | 19.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1719275   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1202         |
|    total_timesteps       | 1275904      |
| train/                   |              |
|    approx_kl             | 0.0040146955 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.12         |
|    cost_value_loss       | 7.77         |
|    cost_values           | 3            |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00246      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.77         |
|    n_updates             | 6220         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.584        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.69119185  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1236         |
|    total_timesteps       | 1277952      |
| train/                   |              |
|    approx_kl             | 0.0012497557 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 0.396        |
|    cost_values           | 2.89         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.45         |
|    n_updates             | 6230         |
|    policy_gradient_loss  | 7.66e-05     |
|    std                   | 0.584        |
|    value_loss            | 12.5         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 3.25       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.25       |
| reward                   | -0.8732751 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -754       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 37         |
|    time_elapsed          | 1271       |
|    total_timesteps       | 1280000    |
| train/                   |            |
|    approx_kl             | 0.00487981 |
|    clip_fraction         | 0.0346     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.43       |
|    cost_value_loss       | 0.511      |
|    cost_values           | 2.52       |
|    entropy               | -1.76      |
|    entropy_loss          | -1.76      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 3.71       |
|    n_updates             | 6240       |
|    policy_gradient_loss  | -0.00208   |
|    std                   | 0.582      |
|    value_loss            | 7.35       |
-----------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.49153203   |
| rollout/                 |               |
|    ep_len_mean           | 983           |
|    ep_rew_mean           | -759          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1305          |
|    total_timesteps       | 1282048       |
| train/                   |               |
|    approx_kl             | 0.00042807794 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.91          |
|    cost_value_loss       | 0.135         |
|    cost_values           | 2.19          |
|    entropy               | -1.75         |
|    entropy_loss          | -1.75         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.77          |
|    n_updates             | 6250          |
|    policy_gradient_loss  | -7.84e-05     |
|    std                   | 0.582         |
|    value_loss            | 22            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6760758   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1340         |
|    total_timesteps       | 1284096      |
| train/                   |              |
|    approx_kl             | 0.0020055375 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 2.3          |
|    cost_values           | 1.88         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.5         |
|    n_updates             | 6260         |
|    policy_gradient_loss  | -0.00096     |
|    std                   | 0.582        |
|    value_loss            | 48.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0298271   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1375         |
|    total_timesteps       | 1286144      |
| train/                   |              |
|    approx_kl             | 0.0026137568 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 8.52         |
|    cost_values           | 1.74         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.35         |
|    n_updates             | 6270         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.582        |
|    value_loss            | 12.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.68367946  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1409         |
|    total_timesteps       | 1288192      |
| train/                   |              |
|    approx_kl             | 0.0011974166 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 0.652        |
|    cost_values           | 1.71         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 6280         |
|    policy_gradient_loss  | -0.000322    |
|    std                   | 0.582        |
|    value_loss            | 24.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.119809    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1444         |
|    total_timesteps       | 1290240      |
| train/                   |              |
|    approx_kl             | 0.0070239822 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.0793       |
|    cost_values           | 1.42         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 6290         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.582        |
|    value_loss            | 25.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.4574193    |
| rollout/                 |               |
|    ep_len_mean           | 983           |
|    ep_rew_mean           | -775          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 43            |
|    time_elapsed          | 1478          |
|    total_timesteps       | 1292288       |
| train/                   |               |
|    approx_kl             | 0.00016527768 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.15          |
|    cost_value_loss       | 0.305         |
|    cost_values           | 1.12          |
|    entropy               | -1.75         |
|    entropy_loss          | -1.75         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.9          |
|    n_updates             | 6300          |
|    policy_gradient_loss  | 4.06e-05      |
|    std                   | 0.582         |
|    value_loss            | 28            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7160913   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1514         |
|    total_timesteps       | 1294336      |
| train/                   |              |
|    approx_kl             | 0.0031218575 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 6.61         |
|    cost_values           | 1.17         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 6310         |
|    policy_gradient_loss  | -0.000329    |
|    std                   | 0.581        |
|    value_loss            | 23.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.87825996  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1548         |
|    total_timesteps       | 1296384      |
| train/                   |              |
|    approx_kl             | 0.0008922494 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.93         |
|    cost_value_loss       | 8.6          |
|    cost_values           | 1.55         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.8          |
|    n_updates             | 6320         |
|    policy_gradient_loss  | -0.00032     |
|    std                   | 0.58         |
|    value_loss            | 13.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.4596471   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -780         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1583         |
|    total_timesteps       | 1298432      |
| train/                   |              |
|    approx_kl             | 0.0014635661 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 1.53         |
|    cost_values           | 1.58         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 6330         |
|    policy_gradient_loss  | -0.000162    |
|    std                   | 0.579        |
|    value_loss            | 6.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.65126884  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -774         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1617         |
|    total_timesteps       | 1300480      |
| train/                   |              |
|    approx_kl             | 0.0048348396 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 1.56         |
|    cost_values           | 1.4          |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.45         |
|    n_updates             | 6340         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.578        |
|    value_loss            | 18.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7967531   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1652         |
|    total_timesteps       | 1302528      |
| train/                   |              |
|    approx_kl             | 0.0026400208 |
|    clip_fraction         | 0.00718      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 1.99         |
|    cost_values           | 1.3          |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.29         |
|    n_updates             | 6350         |
|    policy_gradient_loss  | -0.00093     |
|    std                   | 0.577        |
|    value_loss            | 6.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1138656  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -778        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1686        |
|    total_timesteps       | 1304576     |
| train/                   |             |
|    approx_kl             | 0.003719188 |
|    clip_fraction         | 0.00786     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 0.0442      |
|    cost_values           | 1.25        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.88        |
|    n_updates             | 6360        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.577       |
|    value_loss            | 15.4        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -1.3132349 |
| rollout/           |            |
|    ep_len_mean     | 984        |
|    ep_rew_mean     | -778       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1306624    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0574664   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1308672      |
| train/                   |              |
|    approx_kl             | 0.0045936513 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.479        |
|    cost_values           | 1.16         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 6380         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.576        |
|    value_loss            | 29.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5989115   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -790         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1310720      |
| train/                   |              |
|    approx_kl             | 0.0011822851 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 4.05         |
|    cost_values           | 1.01         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 6390         |
|    policy_gradient_loss  | -0.000188    |
|    std                   | 0.576        |
|    value_loss            | 39.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.57850426  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1312768      |
| train/                   |              |
|    approx_kl             | 0.0049438514 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 5.29         |
|    cost_values           | 1.18         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.73        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.83         |
|    n_updates             | 6400         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.577        |
|    value_loss            | 14.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1807708  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -788        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 1314816     |
| train/                   |             |
|    approx_kl             | 0.005613463 |
|    clip_fraction         | 0.0118      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 2.21        |
|    cost_values           | 1.44        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 6410        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.579       |
|    value_loss            | 10.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9765804  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -796        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 1316864     |
| train/                   |             |
|    approx_kl             | 0.003448864 |
|    clip_fraction         | 0.035       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 4.42        |
|    cost_values           | 1.56        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.8        |
|    n_updates             | 6420        |
|    policy_gradient_loss  | -0.00278    |
|    std                   | 0.579       |
|    value_loss            | 20          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.372507    |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1318912      |
| train/                   |              |
|    approx_kl             | 0.0034000464 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 1            |
|    cost_values           | 1.81         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.6         |
|    n_updates             | 6430         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.579        |
|    value_loss            | 46.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.84425414  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -808         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 1320960      |
| train/                   |              |
|    approx_kl             | 0.0003937963 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 1.12         |
|    cost_values           | 1.56         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.9         |
|    n_updates             | 6440         |
|    policy_gradient_loss  | -0.000115    |
|    std                   | 0.578        |
|    value_loss            | 42.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50905824  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 1323008      |
| train/                   |              |
|    approx_kl             | 0.0037283371 |
|    clip_fraction         | 0.00264      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 5.9          |
|    cost_values           | 1.44         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.85         |
|    n_updates             | 6450         |
|    policy_gradient_loss  | -0.000565    |
|    std                   | 0.578        |
|    value_loss            | 14.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.38        |
| reward                   | -0.48589796 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -817        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 1325056     |
| train/                   |             |
|    approx_kl             | 0.003186266 |
|    clip_fraction         | 0.0129      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 3.47        |
|    cost_values           | 1.6         |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 6460        |
|    policy_gradient_loss  | -0.0013     |
|    std                   | 0.579       |
|    value_loss            | 5.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6367525   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -816         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 1327104      |
| train/                   |              |
|    approx_kl             | 0.0064960625 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 2.5          |
|    cost_values           | 1.62         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 6470         |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.579        |
|    value_loss            | 22.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5124687   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -821         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 1329152      |
| train/                   |              |
|    approx_kl             | 0.0040419037 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 4.57         |
|    cost_values           | 1.69         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 6480         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.58         |
|    value_loss            | 18.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.58743507  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -823         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 1331200      |
| train/                   |              |
|    approx_kl             | 0.0035105376 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 0.235        |
|    cost_values           | 1.85         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 6490         |
|    policy_gradient_loss  | -0.000772    |
|    std                   | 0.579        |
|    value_loss            | 22.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.9926262   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -827         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1333248      |
| train/                   |              |
|    approx_kl             | 0.0042976453 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 0.493        |
|    cost_values           | 1.54         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.88         |
|    n_updates             | 6500         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.579        |
|    value_loss            | 13           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.72176445 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -835        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 509         |
|    total_timesteps       | 1335296     |
| train/                   |             |
|    approx_kl             | 0.006614919 |
|    clip_fraction         | 0.0482      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 0.027       |
|    cost_values           | 1.17        |
|    entropy               | -1.73       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 6510        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.573       |
|    value_loss            | 7.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1220924   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -832         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 544          |
|    total_timesteps       | 1337344      |
| train/                   |              |
|    approx_kl             | 0.0021693986 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 2.06         |
|    cost_values           | 1.04         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 6520         |
|    policy_gradient_loss  | 0.000863     |
|    std                   | 0.572        |
|    value_loss            | 37.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3431451   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -828         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 579          |
|    total_timesteps       | 1339392      |
| train/                   |              |
|    approx_kl             | 0.0017348644 |
|    clip_fraction         | 0.00557      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 2.56         |
|    cost_values           | 1.07         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 6530         |
|    policy_gradient_loss  | -0.000259    |
|    std                   | 0.57         |
|    value_loss            | 24.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2417859   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -826         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 614          |
|    total_timesteps       | 1341440      |
| train/                   |              |
|    approx_kl             | 0.0023768228 |
|    clip_fraction         | 0.00601      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 5.5          |
|    cost_values           | 1.36         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.6         |
|    n_updates             | 6540         |
|    policy_gradient_loss  | -0.000226    |
|    std                   | 0.567        |
|    value_loss            | 93.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0201954   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -833         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 649          |
|    total_timesteps       | 1343488      |
| train/                   |              |
|    approx_kl             | 0.0027457485 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 1.63         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.98         |
|    n_updates             | 6550         |
|    policy_gradient_loss  | -0.000617    |
|    std                   | 0.567        |
|    value_loss            | 9.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8855435  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -831        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 684         |
|    total_timesteps       | 1345536     |
| train/                   |             |
|    approx_kl             | 0.001545253 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 0.339       |
|    cost_values           | 1.47        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 6560        |
|    policy_gradient_loss  | -0.000496   |
|    std                   | 0.567       |
|    value_loss            | 27          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.03698     |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -833         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 719          |
|    total_timesteps       | 1347584      |
| train/                   |              |
|    approx_kl             | 0.0024564618 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 1.39         |
|    cost_values           | 1.34         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.71        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.28         |
|    n_updates             | 6570         |
|    policy_gradient_loss  | -0.000576    |
|    std                   | 0.567        |
|    value_loss            | 15.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1919254   |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 753          |
|    total_timesteps       | 1349632      |
| train/                   |              |
|    approx_kl             | 0.0017149169 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 1.36         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.6          |
|    n_updates             | 6580         |
|    policy_gradient_loss  | -0.000706    |
|    std                   | 0.568        |
|    value_loss            | 14.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.883137   |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -835        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 788         |
|    total_timesteps       | 1351680     |
| train/                   |             |
|    approx_kl             | 0.003971791 |
|    clip_fraction         | 0.00498     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 0.357       |
|    cost_values           | 1.28        |
|    entropy               | -1.71       |
|    entropy_loss          | -1.71       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.93        |
|    n_updates             | 6590        |
|    policy_gradient_loss  | -0.000315   |
|    std                   | 0.569       |
|    value_loss            | 14.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.3032424   |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -836         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 822          |
|    total_timesteps       | 1353728      |
| train/                   |              |
|    approx_kl             | 0.0030286037 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 1.69         |
|    cost_values           | 1.16         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.64         |
|    n_updates             | 6600         |
|    policy_gradient_loss  | -0.0001      |
|    std                   | 0.57         |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.91         |
| reward                   | -0.45322073  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 857          |
|    total_timesteps       | 1355776      |
| train/                   |              |
|    approx_kl             | 0.0036969895 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 3.64         |
|    cost_values           | 1.07         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 6610         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.571        |
|    value_loss            | 25.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.6488679    |
| rollout/                 |               |
|    ep_len_mean           | 998           |
|    ep_rew_mean           | -837          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 26            |
|    time_elapsed          | 893           |
|    total_timesteps       | 1357824       |
| train/                   |               |
|    approx_kl             | 7.1404356e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.42          |
|    cost_value_loss       | 7.36          |
|    cost_values           | 1.06          |
|    entropy               | -1.72         |
|    entropy_loss          | -1.72         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.74          |
|    n_updates             | 6620          |
|    policy_gradient_loss  | 1.13e-05      |
|    std                   | 0.571         |
|    value_loss            | 13.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.78053015  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -832         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 927          |
|    total_timesteps       | 1359872      |
| train/                   |              |
|    approx_kl             | 0.0032080265 |
|    clip_fraction         | 0.002        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 8.58         |
|    cost_values           | 1.21         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.13         |
|    n_updates             | 6630         |
|    policy_gradient_loss  | -0.000955    |
|    std                   | 0.571        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.59791327  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -837         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 962          |
|    total_timesteps       | 1361920      |
| train/                   |              |
|    approx_kl             | 0.0006144471 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 1.34         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.61         |
|    n_updates             | 6640         |
|    policy_gradient_loss  | -0.000282    |
|    std                   | 0.571        |
|    value_loss            | 13.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5190342   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -830         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 997          |
|    total_timesteps       | 1363968      |
| train/                   |              |
|    approx_kl             | 0.0036894565 |
|    clip_fraction         | 0.0064       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 0.581        |
|    cost_values           | 1.16         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 6650         |
|    policy_gradient_loss  | -0.000976    |
|    std                   | 0.571        |
|    value_loss            | 24.1         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.333      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.333      |
| reward                   | -0.5205185 |
| rollout/                 |            |
|    ep_len_mean           | 991        |
|    ep_rew_mean           | -836       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 30         |
|    time_elapsed          | 1032       |
|    total_timesteps       | 1366016    |
| train/                   |            |
|    approx_kl             | 6.3232e-05 |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 4.27       |
|    cost_value_loss       | 21.9       |
|    cost_values           | 1.08       |
|    entropy               | -1.71      |
|    entropy_loss          | -1.72      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 34.8       |
|    n_updates             | 6660       |
|    policy_gradient_loss  | -2.08e-05  |
|    std                   | 0.57       |
|    value_loss            | 52.9       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 4.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.53         |
| reward                   | -0.50723475  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1066         |
|    total_timesteps       | 1368064      |
| train/                   |              |
|    approx_kl             | 0.0031409315 |
|    clip_fraction         | 0.00259      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 0.88         |
|    cost_values           | 1.16         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16           |
|    n_updates             | 6670         |
|    policy_gradient_loss  | -0.000862    |
|    std                   | 0.57         |
|    value_loss            | 33.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.78148794   |
| rollout/                 |               |
|    ep_len_mean           | 991           |
|    ep_rew_mean           | -840          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 32            |
|    time_elapsed          | 1101          |
|    total_timesteps       | 1370112       |
| train/                   |               |
|    approx_kl             | 0.00016826135 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.902         |
|    cost_value_loss       | 0.0669        |
|    cost_values           | 0.95          |
|    entropy               | -1.72         |
|    entropy_loss          | -1.71         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.13          |
|    n_updates             | 6680          |
|    policy_gradient_loss  | 6.07e-05      |
|    std                   | 0.571         |
|    value_loss            | 16.3          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.47448072 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -840        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1135        |
|    total_timesteps       | 1372160     |
| train/                   |             |
|    approx_kl             | 0.005513741 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.748       |
|    cost_value_loss       | 0.0232      |
|    cost_values           | 0.835       |
|    entropy               | -1.71       |
|    entropy_loss          | -1.72       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.32        |
|    n_updates             | 6690        |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 0.569       |
|    value_loss            | 15          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5132553  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -838        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1170        |
|    total_timesteps       | 1374208     |
| train/                   |             |
|    approx_kl             | 0.006651678 |
|    clip_fraction         | 0.0341      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 4.16        |
|    cost_values           | 0.874       |
|    entropy               | -1.7        |
|    entropy_loss          | -1.71       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.77        |
|    n_updates             | 6700        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.567       |
|    value_loss            | 14.8        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.82          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.82          |
| reward                   | -0.6258036    |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -833          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 35            |
|    time_elapsed          | 1204          |
|    total_timesteps       | 1376256       |
| train/                   |               |
|    approx_kl             | 0.00049747404 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.1           |
|    cost_value_loss       | 6.71          |
|    cost_values           | 1.09          |
|    entropy               | -1.7          |
|    entropy_loss          | -1.7          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.8          |
|    n_updates             | 6710          |
|    policy_gradient_loss  | -0.000128     |
|    std                   | 0.567         |
|    value_loss            | 17.2          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.754773   |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -832        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1239        |
|    total_timesteps       | 1378304     |
| train/                   |             |
|    approx_kl             | 0.003770824 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 4.44        |
|    cost_values           | 1.28        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.7        |
|    n_updates             | 6720        |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.567       |
|    value_loss            | 46.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.473458    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1274         |
|    total_timesteps       | 1380352      |
| train/                   |              |
|    approx_kl             | 0.0032758107 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 0.822        |
|    cost_values           | 1.41         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.21         |
|    n_updates             | 6730         |
|    policy_gradient_loss  | -0.000982    |
|    std                   | 0.566        |
|    value_loss            | 6.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6763075   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -825         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1309         |
|    total_timesteps       | 1382400      |
| train/                   |              |
|    approx_kl             | 0.0060913768 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.55         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 1.42         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 6740         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.566        |
|    value_loss            | 8.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.0081635  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -827        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1344        |
|    total_timesteps       | 1384448     |
| train/                   |             |
|    approx_kl             | 0.003901879 |
|    clip_fraction         | 0.0286      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.5         |
|    cost_value_loss       | 0.349       |
|    cost_values           | 1.58        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.12        |
|    n_updates             | 6750        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.567       |
|    value_loss            | 5.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8647469   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1379         |
|    total_timesteps       | 1386496      |
| train/                   |              |
|    approx_kl             | 0.0032465141 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.0351       |
|    cost_values           | 1.28         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.55         |
|    n_updates             | 6760         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.569        |
|    value_loss            | 15.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.55303323   |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -807          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1414          |
|    total_timesteps       | 1388544       |
| train/                   |               |
|    approx_kl             | 0.00046838963 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.53          |
|    cost_value_loss       | 3.64          |
|    cost_values           | 1.02          |
|    entropy               | -1.71         |
|    entropy_loss          | -1.71         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 26.1          |
|    n_updates             | 6770          |
|    policy_gradient_loss  | -7.54e-05     |
|    std                   | 0.568         |
|    value_loss            | 41.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.076715    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1448         |
|    total_timesteps       | 1390592      |
| train/                   |              |
|    approx_kl             | 0.0019983319 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 7.67         |
|    cost_values           | 1.19         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 6780         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.566        |
|    value_loss            | 4.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.75         |
| reward                   | -0.41082755  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1484         |
|    total_timesteps       | 1392640      |
| train/                   |              |
|    approx_kl             | 0.0053711277 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 4.36         |
|    cost_values           | 1.51         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.97         |
|    n_updates             | 6790         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.565        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.49         |
| reward                   | -0.64048016  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -803         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1519         |
|    total_timesteps       | 1394688      |
| train/                   |              |
|    approx_kl             | 0.0039018677 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.94         |
|    cost_value_loss       | 9.75         |
|    cost_values           | 1.53         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 6800         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.565        |
|    value_loss            | 13           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66091424  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1554         |
|    total_timesteps       | 1396736      |
| train/                   |              |
|    approx_kl             | 0.0040452667 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 4.85         |
|    cost_values           | 1.62         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.02         |
|    n_updates             | 6810         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.565        |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.63820225  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1589         |
|    total_timesteps       | 1398784      |
| train/                   |              |
|    approx_kl             | 0.0034976378 |
|    clip_fraction         | 0.00225      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.89         |
|    cost_value_loss       | 9.93         |
|    cost_values           | 1.64         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 6820         |
|    policy_gradient_loss  | -0.000654    |
|    std                   | 0.565        |
|    value_loss            | 21.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5935668   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -801         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1623         |
|    total_timesteps       | 1400832      |
| train/                   |              |
|    approx_kl             | 0.0031131716 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 0.115        |
|    cost_values           | 1.67         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 6830         |
|    policy_gradient_loss  | -0.000883    |
|    std                   | 0.566        |
|    value_loss            | 8.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5876632   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -801         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1658         |
|    total_timesteps       | 1402880      |
| train/                   |              |
|    approx_kl             | 0.0027323833 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.0331       |
|    cost_values           | 1.27         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.66         |
|    n_updates             | 6840         |
|    policy_gradient_loss  | -0.000515    |
|    std                   | 0.567        |
|    value_loss            | 9.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.96173537 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -797        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1693        |
|    total_timesteps       | 1404928     |
| train/                   |             |
|    approx_kl             | 0.007337461 |
|    clip_fraction         | 0.0139      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.307       |
|    cost_values           | 1           |
|    entropy               | -1.71       |
|    entropy_loss          | -1.7        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.25        |
|    n_updates             | 6850        |
|    policy_gradient_loss  | -0.000623   |
|    std                   | 0.57        |
|    value_loss            | 12.3        |
------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.5684927 |
| rollout/           |            |
|    ep_len_mean     | 976        |
|    ep_rew_mean     | -798       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1406976    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8138053   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -795         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 1409024      |
| train/                   |              |
|    approx_kl             | 0.0049102204 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.743        |
|    cost_value_loss       | 0.0255       |
|    cost_values           | 0.886        |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 6870         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.566        |
|    value_loss            | 30.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.36514747  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -798         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 95           |
|    total_timesteps       | 1411072      |
| train/                   |              |
|    approx_kl             | 0.0018345584 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 0.987        |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 6880         |
|    policy_gradient_loss  | -0.000656    |
|    std                   | 0.566        |
|    value_loss            | 15.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7307974   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 1413120      |
| train/                   |              |
|    approx_kl             | 0.0032039774 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 6.99         |
|    cost_values           | 1.23         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 6890         |
|    policy_gradient_loss  | -0.000844    |
|    std                   | 0.566        |
|    value_loss            | 15.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.3946941    |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -786          |
| time/                    |               |
|    fps                   | 62            |
|    iterations            | 5             |
|    time_elapsed          | 164           |
|    total_timesteps       | 1415168       |
| train/                   |               |
|    approx_kl             | 0.00048581124 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.7           |
|    cost_value_loss       | 17            |
|    cost_values           | 1.49          |
|    entropy               | -1.7          |
|    entropy_loss          | -1.7          |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 17.8          |
|    n_updates             | 6900          |
|    policy_gradient_loss  | -0.000107     |
|    std                   | 0.566         |
|    value_loss            | 19.5          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7177128  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -777        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 6           |
|    time_elapsed          | 198         |
|    total_timesteps       | 1417216     |
| train/                   |             |
|    approx_kl             | 0.005680261 |
|    clip_fraction         | 0.0175      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 8.59        |
|    cost_values           | 1.72        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.7        |
|    n_updates             | 6910        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.566       |
|    value_loss            | 41          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30860385 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -773        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 234         |
|    total_timesteps       | 1419264     |
| train/                   |             |
|    approx_kl             | 0.003541695 |
|    clip_fraction         | 0.0203      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 4.29        |
|    cost_values           | 2.04        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.53        |
|    n_updates             | 6920        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.565       |
|    value_loss            | 7.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66642666  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 8            |
|    time_elapsed          | 269          |
|    total_timesteps       | 1421312      |
| train/                   |              |
|    approx_kl             | 0.0045062657 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 5.4          |
|    cost_values           | 2.25         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.8         |
|    n_updates             | 6930         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.564        |
|    value_loss            | 35.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8338268  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 303         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.006712541 |
|    clip_fraction         | 0.0111      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 1.03        |
|    cost_values           | 2.38        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.82        |
|    n_updates             | 6940        |
|    policy_gradient_loss  | -0.000194   |
|    std                   | 0.563       |
|    value_loss            | 15.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.89026535  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 1425408      |
| train/                   |              |
|    approx_kl             | 0.0008921939 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 7.07         |
|    cost_values           | 2.32         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.69        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.97         |
|    n_updates             | 6950         |
|    policy_gradient_loss  | -0.000271    |
|    std                   | 0.562        |
|    value_loss            | 5.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0823509  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 372         |
|    total_timesteps       | 1427456     |
| train/                   |             |
|    approx_kl             | 9.77263e-06 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 3.57        |
|    cost_value_loss       | 8.15        |
|    cost_values           | 2.56        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.63        |
|    n_updates             | 6960        |
|    policy_gradient_loss  | 6.26e-06    |
|    std                   | 0.561       |
|    value_loss            | 7.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8133016  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -766        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 407         |
|    total_timesteps       | 1429504     |
| train/                   |             |
|    approx_kl             | 0.004987544 |
|    clip_fraction         | 0.0124      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.27        |
|    cost_value_loss       | 0.236       |
|    cost_values           | 2.57        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.22        |
|    n_updates             | 6970        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.561       |
|    value_loss            | 9.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4736212   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 441          |
|    total_timesteps       | 1431552      |
| train/                   |              |
|    approx_kl             | 0.0054267976 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 0.0949       |
|    cost_values           | 2.16         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.33         |
|    n_updates             | 6980         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.56         |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6881429  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 476         |
|    total_timesteps       | 1433600     |
| train/                   |             |
|    approx_kl             | 0.005805018 |
|    clip_fraction         | 0.0263      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 0.203       |
|    cost_values           | 1.76        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.05        |
|    n_updates             | 6990        |
|    policy_gradient_loss  | -0.00251    |
|    std                   | 0.559       |
|    value_loss            | 7.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8153152  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -750        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 511         |
|    total_timesteps       | 1435648     |
| train/                   |             |
|    approx_kl             | 0.003217965 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.52        |
|    cost_value_loss       | 5.75        |
|    cost_values           | 1.67        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 7000        |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.56        |
|    value_loss            | 5.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.91618687  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 545          |
|    total_timesteps       | 1437696      |
| train/                   |              |
|    approx_kl             | 0.0002546774 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 8.01         |
|    cost_values           | 2.12         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.29         |
|    n_updates             | 7010         |
|    policy_gradient_loss  | -4.27e-05    |
|    std                   | 0.56         |
|    value_loss            | 4.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5810789   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 580          |
|    total_timesteps       | 1439744      |
| train/                   |              |
|    approx_kl             | 0.0049554775 |
|    clip_fraction         | 0.00874      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.06         |
|    cost_value_loss       | 5.66         |
|    cost_values           | 2.49         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 7020         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.56         |
|    value_loss            | 27.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0321645   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 615          |
|    total_timesteps       | 1441792      |
| train/                   |              |
|    approx_kl             | 0.0019105383 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.17         |
|    cost_value_loss       | 6.73         |
|    cost_values           | 2.48         |
|    entropy               | -1.67        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.4         |
|    n_updates             | 7030         |
|    policy_gradient_loss  | -0.000774    |
|    std                   | 0.559        |
|    value_loss            | 80.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.61646515 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -730        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 649         |
|    total_timesteps       | 1443840     |
| train/                   |             |
|    approx_kl             | 0.00407088  |
|    clip_fraction         | 0.00791     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 6.68        |
|    cost_values           | 2.48        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.62        |
|    n_updates             | 7040        |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.559       |
|    value_loss            | 11.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.071885    |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 684          |
|    total_timesteps       | 1445888      |
| train/                   |              |
|    approx_kl             | 0.0016493732 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 3.34         |
|    cost_values           | 2.64         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.24         |
|    n_updates             | 7050         |
|    policy_gradient_loss  | -0.000974    |
|    std                   | 0.559        |
|    value_loss            | 7.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6061991   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 718          |
|    total_timesteps       | 1447936      |
| train/                   |              |
|    approx_kl             | 0.0052104387 |
|    clip_fraction         | 0.156        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.8          |
|    cost_value_loss       | 2.92         |
|    cost_values           | 2.63         |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.9         |
|    n_updates             | 7060         |
|    policy_gradient_loss  | 0.00399      |
|    std                   | 0.559        |
|    value_loss            | 79.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.99          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.99          |
| reward                   | -0.889645     |
| rollout/                 |               |
|    ep_len_mean           | 956           |
|    ep_rew_mean           | -737          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 22            |
|    time_elapsed          | 753           |
|    total_timesteps       | 1449984       |
| train/                   |               |
|    approx_kl             | 0.00013241774 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.29          |
|    cost_value_loss       | 0.915         |
|    cost_values           | 2.36          |
|    entropy               | -1.67         |
|    entropy_loss          | -1.67         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 22.1          |
|    n_updates             | 7070          |
|    policy_gradient_loss  | 0.000145      |
|    std                   | 0.558         |
|    value_loss            | 48.1          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.60367376  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 788          |
|    total_timesteps       | 1452032      |
| train/                   |              |
|    approx_kl             | 0.0010354506 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.56         |
|    cost_value_loss       | 8.22         |
|    cost_values           | 2.15         |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.3         |
|    n_updates             | 7080         |
|    policy_gradient_loss  | -0.000627    |
|    std                   | 0.558        |
|    value_loss            | 43.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1720573  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -742        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 822         |
|    total_timesteps       | 1454080     |
| train/                   |             |
|    approx_kl             | 0.004467214 |
|    clip_fraction         | 0.0113      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.38        |
|    cost_value_loss       | 2.45        |
|    cost_values           | 2.11        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 7090        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.558       |
|    value_loss            | 31          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.284512    |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 857          |
|    total_timesteps       | 1456128      |
| train/                   |              |
|    approx_kl             | 0.0048432453 |
|    clip_fraction         | 0.0483       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 1.16         |
|    cost_values           | 1.98         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.14         |
|    n_updates             | 7100         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.555        |
|    value_loss            | 16.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0505702    |
| rollout/                 |               |
|    ep_len_mean           | 956           |
|    ep_rew_mean           | -746          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 26            |
|    time_elapsed          | 892           |
|    total_timesteps       | 1458176       |
| train/                   |               |
|    approx_kl             | 0.00087242166 |
|    clip_fraction         | 0.0041        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.42          |
|    cost_value_loss       | 4.72          |
|    cost_values           | 2.03          |
|    entropy               | -1.65         |
|    entropy_loss          | -1.66         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.9          |
|    n_updates             | 7110          |
|    policy_gradient_loss  | 1.43e-05      |
|    std                   | 0.553         |
|    value_loss            | 20.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.6170914   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 927          |
|    total_timesteps       | 1460224      |
| train/                   |              |
|    approx_kl             | 0.0023045745 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 0.122        |
|    cost_values           | 2.03         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.43         |
|    n_updates             | 7120         |
|    policy_gradient_loss  | -0.000751    |
|    std                   | 0.553        |
|    value_loss            | 17           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.129576    |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 962          |
|    total_timesteps       | 1462272      |
| train/                   |              |
|    approx_kl             | 0.0013859267 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 0.0798       |
|    cost_values           | 1.62         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.6          |
|    n_updates             | 7130         |
|    policy_gradient_loss  | -0.000702    |
|    std                   | 0.553        |
|    value_loss            | 9.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.68674374  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 997          |
|    total_timesteps       | 1464320      |
| train/                   |              |
|    approx_kl             | 0.0055166623 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.56         |
|    cost_value_loss       | 7.9          |
|    cost_values           | 1.6          |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.6         |
|    n_updates             | 7140         |
|    policy_gradient_loss  | -0.000894    |
|    std                   | 0.554        |
|    value_loss            | 45.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.236984    |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1032         |
|    total_timesteps       | 1466368      |
| train/                   |              |
|    approx_kl             | 0.0082242675 |
|    clip_fraction         | 0.0452       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 0.949        |
|    cost_values           | 1.73         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.66        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 7150         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.553        |
|    value_loss            | 7.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.60342604  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1067         |
|    total_timesteps       | 1468416      |
| train/                   |              |
|    approx_kl             | 0.0063354485 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 5.78         |
|    cost_values           | 1.84         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.95         |
|    n_updates             | 7160         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.551        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75675267  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1102         |
|    total_timesteps       | 1470464      |
| train/                   |              |
|    approx_kl             | 0.0026829536 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 0.555        |
|    cost_values           | 2.06         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.52         |
|    n_updates             | 7170         |
|    policy_gradient_loss  | -0.000605    |
|    std                   | 0.551        |
|    value_loss            | 18           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7055793   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1138         |
|    total_timesteps       | 1472512      |
| train/                   |              |
|    approx_kl             | 0.0014661273 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.19         |
|    cost_value_loss       | 9.77         |
|    cost_values           | 1.89         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.59         |
|    n_updates             | 7180         |
|    policy_gradient_loss  | -0.000367    |
|    std                   | 0.551        |
|    value_loss            | 12.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.56780213   |
| rollout/                 |               |
|    ep_len_mean           | 962           |
|    ep_rew_mean           | -743          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 34            |
|    time_elapsed          | 1173          |
|    total_timesteps       | 1474560       |
| train/                   |               |
|    approx_kl             | 0.00060465926 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 5.29          |
|    cost_value_loss       | 25.7          |
|    cost_values           | 2.07          |
|    entropy               | -1.65         |
|    entropy_loss          | -1.65         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21.4          |
|    n_updates             | 7190          |
|    policy_gradient_loss  | -0.000158     |
|    std                   | 0.551         |
|    value_loss            | 20.1          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7272358   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1207         |
|    total_timesteps       | 1476608      |
| train/                   |              |
|    approx_kl             | 0.0014419885 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.14         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 2.33         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.65         |
|    n_updates             | 7200         |
|    policy_gradient_loss  | -0.000559    |
|    std                   | 0.551        |
|    value_loss            | 8.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.7098708   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1242         |
|    total_timesteps       | 1478656      |
| train/                   |              |
|    approx_kl             | 0.0004524996 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 2.3          |
|    cost_values           | 2.44         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.2         |
|    n_updates             | 7210         |
|    policy_gradient_loss  | -0.00019     |
|    std                   | 0.551        |
|    value_loss            | 40.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9458215  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -726        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1277        |
|    total_timesteps       | 1480704     |
| train/                   |             |
|    approx_kl             | 0.003725558 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.53        |
|    cost_value_loss       | 3.74        |
|    cost_values           | 2.23        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 7220        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.549       |
|    value_loss            | 6.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6734566  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1312        |
|    total_timesteps       | 1482752     |
| train/                   |             |
|    approx_kl             | 0.004476634 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 0.206       |
|    cost_values           | 2.05        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.54        |
|    n_updates             | 7230        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.55        |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8454383  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -735        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1347        |
|    total_timesteps       | 1484800     |
| train/                   |             |
|    approx_kl             | 0.005418051 |
|    clip_fraction         | 0.0409      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 2.59        |
|    cost_values           | 1.84        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.27        |
|    n_updates             | 7240        |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.548       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.035217    |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1382         |
|    total_timesteps       | 1486848      |
| train/                   |              |
|    approx_kl             | 0.0041649016 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 5.78         |
|    cost_values           | 1.94         |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 7250         |
|    policy_gradient_loss  | 0.000806     |
|    std                   | 0.546        |
|    value_loss            | 6.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0384008   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1417         |
|    total_timesteps       | 1488896      |
| train/                   |              |
|    approx_kl             | 0.0003619765 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 2.04         |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 7260         |
|    policy_gradient_loss  | -0.000839    |
|    std                   | 0.547        |
|    value_loss            | 35.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30812365 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -728        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1452        |
|    total_timesteps       | 1490944     |
| train/                   |             |
|    approx_kl             | 0.004249002 |
|    clip_fraction         | 0.0145      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 4.46        |
|    cost_values           | 2.2         |
|    entropy               | -1.62       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.19        |
|    n_updates             | 7270        |
|    policy_gradient_loss  | -0.000742   |
|    std                   | 0.545       |
|    value_loss            | 5.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5992504   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1487         |
|    total_timesteps       | 1492992      |
| train/                   |              |
|    approx_kl             | 0.0027740584 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 2.49         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.93         |
|    n_updates             | 7280         |
|    policy_gradient_loss  | -0.000497    |
|    std                   | 0.544        |
|    value_loss            | 8.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72729117  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1522         |
|    total_timesteps       | 1495040      |
| train/                   |              |
|    approx_kl             | 0.0008232655 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.87         |
|    cost_value_loss       | 23.2         |
|    cost_values           | 2.92         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00618      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.71         |
|    n_updates             | 7290         |
|    policy_gradient_loss  | -0.000349    |
|    std                   | 0.544        |
|    value_loss            | 8.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.7939461  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -716        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1557        |
|    total_timesteps       | 1497088     |
| train/                   |             |
|    approx_kl             | 0.002585968 |
|    clip_fraction         | 0.011       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 15.6        |
|    cost_values           | 3           |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.000993    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.5        |
|    n_updates             | 7300        |
|    policy_gradient_loss  | -0.000429   |
|    std                   | 0.544       |
|    value_loss            | 19.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.71         |
| reward                   | -0.80772555  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1591         |
|    total_timesteps       | 1499136      |
| train/                   |              |
|    approx_kl             | 0.0048814793 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.97         |
|    cost_value_loss       | 1.36         |
|    cost_values           | 2.93         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.03         |
|    n_updates             | 7310         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.544        |
|    value_loss            | 2.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.32         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.32         |
| reward                   | -0.4217268   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1626         |
|    total_timesteps       | 1501184      |
| train/                   |              |
|    approx_kl             | 0.0043325447 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.57         |
|    cost_value_loss       | 9.25         |
|    cost_values           | 2.91         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00739      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.06         |
|    n_updates             | 7320         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.543        |
|    value_loss            | 5.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5749893   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1661         |
|    total_timesteps       | 1503232      |
| train/                   |              |
|    approx_kl             | 0.0021227223 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.44         |
|    cost_value_loss       | 12           |
|    cost_values           | 3            |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00302      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.89         |
|    n_updates             | 7330         |
|    policy_gradient_loss  | -0.000551    |
|    std                   | 0.542        |
|    value_loss            | 9.45         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.7603291 |
| rollout/                 |            |
|    ep_len_mean           | 955        |
|    ep_rew_mean           | -709       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 49         |
|    time_elapsed          | 1696       |
|    total_timesteps       | 1505280    |
| train/                   |            |
|    approx_kl             | 0.0056604  |
|    clip_fraction         | 0.0208     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.34       |
|    cost_value_loss       | 5.35       |
|    cost_values           | 3          |
|    entropy               | -1.61      |
|    entropy_loss          | -1.61      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0.00224    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.57       |
|    n_updates             | 7340       |
|    policy_gradient_loss  | -0.000712  |
|    std                   | 0.54       |
|    value_loss            | 2.75       |
-----------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
----------------------------------
| avg_speed          | 8         |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 8         |
| reward             | -0.727171 |
| rollout/           |           |
|    ep_len_mean     | 955       |
|    ep_rew_mean     | -713      |
| time/              |           |
|    fps             | 82        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 1507328   |
----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7106251   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 1509376      |
| train/                   |              |
|    approx_kl             | 0.0050024465 |
|    clip_fraction         | 0.0248       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.75         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 3            |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0067       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.53         |
|    n_updates             | 7360         |
|    policy_gradient_loss  | -0.00322     |
|    std                   | 0.539        |
|    value_loss            | 16.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.95428956  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1511424      |
| train/                   |              |
|    approx_kl             | 0.0012636441 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 0.43         |
|    cost_values           | 2.85         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 7370         |
|    policy_gradient_loss  | -0.000202    |
|    std                   | 0.539        |
|    value_loss            | 20.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6101209   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1513472      |
| train/                   |              |
|    approx_kl             | 0.0056018033 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 2.62         |
|    cost_values           | 2.58         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.52         |
|    n_updates             | 7380         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.539        |
|    value_loss            | 6.72         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.44909522   |
| rollout/                 |               |
|    ep_len_mean           | 953           |
|    ep_rew_mean           | -714          |
| time/                    |               |
|    fps                   | 62            |
|    iterations            | 5             |
|    time_elapsed          | 162           |
|    total_timesteps       | 1515520       |
| train/                   |               |
|    approx_kl             | 0.00087142346 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.62          |
|    cost_value_loss       | 9.47          |
|    cost_values           | 2.71          |
|    entropy               | -1.6          |
|    entropy_loss          | -1.6          |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 30.8          |
|    n_updates             | 7390          |
|    policy_gradient_loss  | -5.62e-05     |
|    std                   | 0.539         |
|    value_loss            | 34.4          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.7850574    |
| rollout/                 |               |
|    ep_len_mean           | 947           |
|    ep_rew_mean           | -704          |
| time/                    |               |
|    fps                   | 62            |
|    iterations            | 6             |
|    time_elapsed          | 197           |
|    total_timesteps       | 1517568       |
| train/                   |               |
|    approx_kl             | 0.00056741084 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.97          |
|    cost_value_loss       | 7.07          |
|    cost_values           | 2.96          |
|    entropy               | -1.6          |
|    entropy_loss          | -1.6          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00329       |
|    learning_rate         | 0.0003        |
|    loss                  | 5.02          |
|    n_updates             | 7400          |
|    policy_gradient_loss  | -7.16e-05     |
|    std                   | 0.539         |
|    value_loss            | 11.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6762856   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1519616      |
| train/                   |              |
|    approx_kl             | 0.0031729292 |
|    clip_fraction         | 0.00415      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.12         |
|    cost_value_loss       | 7.32         |
|    cost_values           | 3            |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00795      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.22         |
|    n_updates             | 7410         |
|    policy_gradient_loss  | -0.000887    |
|    std                   | 0.539        |
|    value_loss            | 43.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.42961237  |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 1521664      |
| train/                   |              |
|    approx_kl             | 0.0014171463 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.28         |
|    cost_value_loss       | 11.5         |
|    cost_values           | 3            |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 8.46e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 26.9         |
|    n_updates             | 7420         |
|    policy_gradient_loss  | -0.000149    |
|    std                   | 0.539        |
|    value_loss            | 48           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.45387223  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 1523712      |
| train/                   |              |
|    approx_kl             | 0.0010631772 |
|    clip_fraction         | 0.00352      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 0.16         |
|    cost_values           | 2.71         |
|    entropy               | -1.61        |
|    entropy_loss          | -1.6         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.85         |
|    n_updates             | 7430         |
|    policy_gradient_loss  | -0.000149    |
|    std                   | 0.54         |
|    value_loss            | 5.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5320039   |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 1525760      |
| train/                   |              |
|    approx_kl             | 0.0029676515 |
|    clip_fraction         | 0.00273      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.08         |
|    cost_value_loss       | 5.23         |
|    cost_values           | 2.38         |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 7440         |
|    policy_gradient_loss  | -0.000271    |
|    std                   | 0.541        |
|    value_loss            | 36           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.9712326   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 1527808      |
| train/                   |              |
|    approx_kl             | 0.0003090262 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.94         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 2.57         |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 7450         |
|    policy_gradient_loss  | 9.82e-05     |
|    std                   | 0.541        |
|    value_loss            | 30.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7020703  |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 405         |
|    total_timesteps       | 1529856     |
| train/                   |             |
|    approx_kl             | 0.006383811 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 2.94        |
|    cost_values           | 2.94        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.61       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.8        |
|    n_updates             | 7460        |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.543       |
|    value_loss            | 30.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.484403    |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 1531904      |
| train/                   |              |
|    approx_kl             | 0.0016307314 |
|    clip_fraction         | 0.111        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.06         |
|    cost_value_loss       | 3.58         |
|    cost_values           | 2.91         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.04         |
|    n_updates             | 7470         |
|    policy_gradient_loss  | 0.00304      |
|    std                   | 0.543        |
|    value_loss            | 14.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.9          |
| reward                   | -0.28174305  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1533952      |
| train/                   |              |
|    approx_kl             | 0.0017052465 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 0.24         |
|    cost_values           | 2.67         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 7480         |
|    policy_gradient_loss  | -0.000265    |
|    std                   | 0.543        |
|    value_loss            | 32.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0519773  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -694        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 509         |
|    total_timesteps       | 1536000     |
| train/                   |             |
|    approx_kl             | 0.003910477 |
|    clip_fraction         | 0.0285      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 5.36        |
|    cost_values           | 2.52        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.77        |
|    n_updates             | 7490        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.544       |
|    value_loss            | 9.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1253473  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -694        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 543         |
|    total_timesteps       | 1538048     |
| train/                   |             |
|    approx_kl             | 0.005211545 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 0.237       |
|    cost_values           | 2.45        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.5        |
|    n_updates             | 7500        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.543       |
|    value_loss            | 47          |
------------------------------------------
------------------------------------------
| avg_speed                | 3.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.59        |
| reward                   | -0.7042109  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 577         |
|    total_timesteps       | 1540096     |
| train/                   |             |
|    approx_kl             | 0.006381905 |
|    clip_fraction         | 0.066       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 0.0871      |
|    cost_values           | 2.03        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.62       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.65        |
|    n_updates             | 7510        |
|    policy_gradient_loss  | -0.00372    |
|    std                   | 0.542       |
|    value_loss            | 18.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6120914   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 612          |
|    total_timesteps       | 1542144      |
| train/                   |              |
|    approx_kl             | 0.0051072706 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 0.97         |
|    cost_values           | 1.72         |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.28         |
|    n_updates             | 7520         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.542        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.78397596  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 647          |
|    total_timesteps       | 1544192      |
| train/                   |              |
|    approx_kl             | 0.0024042819 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 8.52         |
|    cost_values           | 1.71         |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.46         |
|    n_updates             | 7530         |
|    policy_gradient_loss  | -0.000512    |
|    std                   | 0.542        |
|    value_loss            | 6.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.418738   |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 681         |
|    total_timesteps       | 1546240     |
| train/                   |             |
|    approx_kl             | 0.005152924 |
|    clip_fraction         | 0.00898     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.28        |
|    cost_value_loss       | 2.74        |
|    cost_values           | 2.02        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.77        |
|    n_updates             | 7540        |
|    policy_gradient_loss  | -0.000499   |
|    std                   | 0.542       |
|    value_loss            | 8.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8388225  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -673        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 716         |
|    total_timesteps       | 1548288     |
| train/                   |             |
|    approx_kl             | 0.003722198 |
|    clip_fraction         | 0.00625     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 6.23        |
|    cost_values           | 2.12        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.92        |
|    n_updates             | 7550        |
|    policy_gradient_loss  | -0.00092    |
|    std                   | 0.543       |
|    value_loss            | 5.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8264568   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 750          |
|    total_timesteps       | 1550336      |
| train/                   |              |
|    approx_kl             | 0.0013571901 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 12           |
|    cost_values           | 2.35         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 7560         |
|    policy_gradient_loss  | -0.000217    |
|    std                   | 0.544        |
|    value_loss            | 8.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5566532  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 784         |
|    total_timesteps       | 1552384     |
| train/                   |             |
|    approx_kl             | 0.003463657 |
|    clip_fraction         | 0.014       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 0.239       |
|    cost_values           | 2.3         |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 7570        |
|    policy_gradient_loss  | -0.000657   |
|    std                   | 0.544       |
|    value_loss            | 3.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.8046583  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -664        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 819         |
|    total_timesteps       | 1554432     |
| train/                   |             |
|    approx_kl             | 0.001337884 |
|    clip_fraction         | 0.0145      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 0.127       |
|    cost_values           | 1.8         |
|    entropy               | -1.61       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 7580        |
|    policy_gradient_loss  | -0.000933   |
|    std                   | 0.541       |
|    value_loss            | 9.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5469783   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 854          |
|    total_timesteps       | 1556480      |
| train/                   |              |
|    approx_kl             | 0.0037641283 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 2.49         |
|    cost_values           | 1.69         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.21         |
|    n_updates             | 7590         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.538        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9900808   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 889          |
|    total_timesteps       | 1558528      |
| train/                   |              |
|    approx_kl             | 0.0035099327 |
|    clip_fraction         | 0.00493      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.97         |
|    cost_value_loss       | 7.39         |
|    cost_values           | 1.96         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.7          |
|    n_updates             | 7600         |
|    policy_gradient_loss  | -0.000471    |
|    std                   | 0.537        |
|    value_loss            | 10.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.46477023 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -672        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 923         |
|    total_timesteps       | 1560576     |
| train/                   |             |
|    approx_kl             | 0.004539125 |
|    clip_fraction         | 0.00791     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 7.94        |
|    cost_values           | 2.34        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.49        |
|    n_updates             | 7610        |
|    policy_gradient_loss  | -0.0009     |
|    std                   | 0.537       |
|    value_loss            | 9.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.2080729   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 1562624      |
| train/                   |              |
|    approx_kl             | 0.0010367653 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 0.28         |
|    cost_values           | 2.44         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 7620         |
|    policy_gradient_loss  | -0.000603    |
|    std                   | 0.537        |
|    value_loss            | 40.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0761994   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 993          |
|    total_timesteps       | 1564672      |
| train/                   |              |
|    approx_kl             | 0.0039758054 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 1.78         |
|    cost_values           | 2.22         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.35         |
|    n_updates             | 7630         |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.536        |
|    value_loss            | 15.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5394707   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 1566720      |
| train/                   |              |
|    approx_kl             | 0.0041040014 |
|    clip_fraction         | 0.04         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 6.87         |
|    cost_values           | 2.39         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.2         |
|    n_updates             | 7640         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.536        |
|    value_loss            | 75.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7379315  |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -674        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 1568768     |
| train/                   |             |
|    approx_kl             | 0.003022023 |
|    clip_fraction         | 0.0175      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.49        |
|    cost_value_loss       | 7.18        |
|    cost_values           | 2.83        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 7650        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.535       |
|    value_loss            | 17.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6616926   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1098         |
|    total_timesteps       | 1570816      |
| train/                   |              |
|    approx_kl             | 0.0046933424 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.79         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 3            |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00896      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.46         |
|    n_updates             | 7660         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.535        |
|    value_loss            | 6.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7090125  |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -678        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1132        |
|    total_timesteps       | 1572864     |
| train/                   |             |
|    approx_kl             | 0.001685052 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 3.32        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 2.95        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.8        |
|    n_updates             | 7670        |
|    policy_gradient_loss  | -0.000163   |
|    std                   | 0.533       |
|    value_loss            | 35.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6363712   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1167         |
|    total_timesteps       | 1574912      |
| train/                   |              |
|    approx_kl             | 0.0049854526 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 0.825        |
|    cost_values           | 2.85         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.31         |
|    n_updates             | 7680         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.533        |
|    value_loss            | 6.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8240693   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1201         |
|    total_timesteps       | 1576960      |
| train/                   |              |
|    approx_kl             | 0.0031369482 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.14         |
|    cost_value_loss       | 5.51         |
|    cost_values           | 2.64         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.55         |
|    n_updates             | 7690         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.533        |
|    value_loss            | 9.78         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.57905656 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1237        |
|    total_timesteps       | 1579008     |
| train/                   |             |
|    approx_kl             | 0.00341951  |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 4.38        |
|    cost_values           | 2.84        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 7700        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.534       |
|    value_loss            | 18.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57507753  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 1581056      |
| train/                   |              |
|    approx_kl             | 0.0037266929 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 4.7          |
|    cost_values           | 2.99         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0077       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 7710         |
|    policy_gradient_loss  | -0.000959    |
|    std                   | 0.533        |
|    value_loss            | 5.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9745133   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1306         |
|    total_timesteps       | 1583104      |
| train/                   |              |
|    approx_kl             | 0.0045381165 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.26         |
|    cost_value_loss       | 3.46         |
|    cost_values           | 2.97         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.81         |
|    n_updates             | 7720         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.533        |
|    value_loss            | 13.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.72571623   |
| rollout/                 |               |
|    ep_len_mean           | 945           |
|    ep_rew_mean           | -691          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 39            |
|    time_elapsed          | 1341          |
|    total_timesteps       | 1585152       |
| train/                   |               |
|    approx_kl             | 0.00083053205 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.47          |
|    cost_value_loss       | 0.291         |
|    cost_values           | 2.81          |
|    entropy               | -1.58         |
|    entropy_loss          | -1.58         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10            |
|    n_updates             | 7730          |
|    policy_gradient_loss  | -0.00024      |
|    std                   | 0.532         |
|    value_loss            | 23.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.64407074 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -694        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1375        |
|    total_timesteps       | 1587200     |
| train/                   |             |
|    approx_kl             | 0.009659906 |
|    clip_fraction         | 0.066       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 0.118       |
|    cost_values           | 2.39        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 7740        |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 0.532       |
|    value_loss            | 11.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.84867835  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1411         |
|    total_timesteps       | 1589248      |
| train/                   |              |
|    approx_kl             | 0.0028701818 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 1.69         |
|    cost_values           | 2            |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.18         |
|    n_updates             | 7750         |
|    policy_gradient_loss  | 0.000962     |
|    std                   | 0.533        |
|    value_loss            | 3.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8670177   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1446         |
|    total_timesteps       | 1591296      |
| train/                   |              |
|    approx_kl             | 0.0032051937 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 9.81         |
|    cost_values           | 2.12         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.43         |
|    n_updates             | 7760         |
|    policy_gradient_loss  | -0.000952    |
|    std                   | 0.532        |
|    value_loss            | 8.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8880594   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1481         |
|    total_timesteps       | 1593344      |
| train/                   |              |
|    approx_kl             | 0.0042411652 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 0.524        |
|    cost_values           | 2.22         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 7770         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.53         |
|    value_loss            | 8.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5344255   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1515         |
|    total_timesteps       | 1595392      |
| train/                   |              |
|    approx_kl             | 0.0008386155 |
|    clip_fraction         | 0.00723      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.56         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.08         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 7780         |
|    policy_gradient_loss  | 0.000865     |
|    std                   | 0.529        |
|    value_loss            | 18.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.97321385   |
| rollout/                 |               |
|    ep_len_mean           | 945           |
|    ep_rew_mean           | -694          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 45            |
|    time_elapsed          | 1550          |
|    total_timesteps       | 1597440       |
| train/                   |               |
|    approx_kl             | 1.0175048e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.66          |
|    cost_value_loss       | 4.31          |
|    cost_values           | 2.31          |
|    entropy               | -1.56         |
|    entropy_loss          | -1.56         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.83          |
|    n_updates             | 7790          |
|    policy_gradient_loss  | 8.94e-05      |
|    std                   | 0.528         |
|    value_loss            | 8.12          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.9083287  |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1584        |
|    total_timesteps       | 1599488     |
| train/                   |             |
|    approx_kl             | 0.004202657 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.88        |
|    cost_value_loss       | 0.118       |
|    cost_values           | 2.13        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 7800        |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.528       |
|    value_loss            | 10.2        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.04       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.04       |
| reward                   | -1.2021604 |
| rollout/                 |            |
|    ep_len_mean           | 945        |
|    ep_rew_mean           | -697       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 47         |
|    time_elapsed          | 1619       |
|    total_timesteps       | 1601536    |
| train/                   |            |
|    approx_kl             | 0.00664833 |
|    clip_fraction         | 0.0233     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.17       |
|    cost_value_loss       | 4.27       |
|    cost_values           | 1.98       |
|    entropy               | -1.56      |
|    entropy_loss          | -1.56      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.42       |
|    n_updates             | 7810       |
|    policy_gradient_loss  | -0.00133   |
|    std                   | 0.529      |
|    value_loss            | 10.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 2.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.34         |
| reward                   | -0.5460662   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1654         |
|    total_timesteps       | 1603584      |
| train/                   |              |
|    approx_kl             | 0.0039933515 |
|    clip_fraction         | 0.00532      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 0.138        |
|    cost_values           | 2.01         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 7820         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.528        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.88011956  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1689         |
|    total_timesteps       | 1605632      |
| train/                   |              |
|    approx_kl             | 0.0038332525 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 0.0649       |
|    cost_values           | 1.62         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.41         |
|    n_updates             | 7830         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.525        |
|    value_loss            | 4.91         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.04       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.04       |
| reward             | -0.8921081 |
| rollout/           |            |
|    ep_len_mean     | 947        |
|    ep_rew_mean     | -703       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1607680    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1175585   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1609728      |
| train/                   |              |
|    approx_kl             | 0.0026961186 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 4.1          |
|    cost_values           | 1.25         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.58         |
|    n_updates             | 7850         |
|    policy_gradient_loss  | -0.00031     |
|    std                   | 0.527        |
|    value_loss            | 4.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.52489835 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -718        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1611776     |
| train/                   |             |
|    approx_kl             | 0.004309936 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 1.52        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 7860        |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.527       |
|    value_loss            | 18.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1948501  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -721        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 1613824     |
| train/                   |             |
|    approx_kl             | 0.004894212 |
|    clip_fraction         | 0.00864     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.68        |
|    cost_value_loss       | 7.74        |
|    cost_values           | 1.92        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 7870        |
|    policy_gradient_loss  | -0.000921   |
|    std                   | 0.527       |
|    value_loss            | 16.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67500365  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1615872      |
| train/                   |              |
|    approx_kl             | 0.0020805164 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 2.01         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 7880         |
|    policy_gradient_loss  | -0.000897    |
|    std                   | 0.526        |
|    value_loss            | 22.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.1640885   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1617920      |
| train/                   |              |
|    approx_kl             | 0.0012626911 |
|    clip_fraction         | 0.00498      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.36         |
|    cost_value_loss       | 3.06         |
|    cost_values           | 1.95         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.21         |
|    n_updates             | 7890         |
|    policy_gradient_loss  | -0.000649    |
|    std                   | 0.525        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.55568016  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -732         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1619968      |
| train/                   |              |
|    approx_kl             | 0.0019603746 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 2.47         |
|    cost_values           | 2.16         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.94         |
|    n_updates             | 7900         |
|    policy_gradient_loss  | -0.000787    |
|    std                   | 0.521        |
|    value_loss            | 11.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.09        |
| reward                   | -0.5305349  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -738        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 267         |
|    total_timesteps       | 1622016     |
| train/                   |             |
|    approx_kl             | 0.004831136 |
|    clip_fraction         | 0.00786     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 2.15        |
|    cost_values           | 2.09        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.07        |
|    n_updates             | 7910        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.519       |
|    value_loss            | 7.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.02         |
| reward                   | -0.725052    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 1624064      |
| train/                   |              |
|    approx_kl             | 0.0027150551 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.91         |
|    cost_value_loss       | 21.4         |
|    cost_values           | 2.07         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 7920         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.519        |
|    value_loss            | 16.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.68829256  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 1626112      |
| train/                   |              |
|    approx_kl             | 0.0060241045 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.01         |
|    cost_value_loss       | 8.43         |
|    cost_values           | 2.27         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.25         |
|    n_updates             | 7930         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.519        |
|    value_loss            | 10.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39540243 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -734        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 371         |
|    total_timesteps       | 1628160     |
| train/                   |             |
|    approx_kl             | 0.00465166  |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 0.463       |
|    cost_values           | 2.14        |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.54        |
|    n_updates             | 7940        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.519       |
|    value_loss            | 7.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.98791695  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 406          |
|    total_timesteps       | 1630208      |
| train/                   |              |
|    approx_kl             | 0.0032330253 |
|    clip_fraction         | 0.00894      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 1.59         |
|    cost_values           | 1.81         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.41         |
|    n_updates             | 7950         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.52         |
|    value_loss            | 3.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8161237   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 1632256      |
| train/                   |              |
|    approx_kl             | 0.0023990143 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.89         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 1.87         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 7960         |
|    policy_gradient_loss  | -0.00042     |
|    std                   | 0.521        |
|    value_loss            | 26.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.65013117  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 475          |
|    total_timesteps       | 1634304      |
| train/                   |              |
|    approx_kl             | 0.0039481493 |
|    clip_fraction         | 0.0445       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.01         |
|    cost_value_loss       | 8.66         |
|    cost_values           | 2.2          |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 7970         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.521        |
|    value_loss            | 24.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8502733   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 510          |
|    total_timesteps       | 1636352      |
| train/                   |              |
|    approx_kl             | 0.0037404445 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 3.21         |
|    cost_values           | 2.45         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 7980         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.52         |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.048202    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 545          |
|    total_timesteps       | 1638400      |
| train/                   |              |
|    approx_kl             | 0.0027391855 |
|    clip_fraction         | 0.00615      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.05         |
|    cost_value_loss       | 14.2         |
|    cost_values           | 2.55         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 7990         |
|    policy_gradient_loss  | -0.000104    |
|    std                   | 0.52         |
|    value_loss            | 31.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.2478284   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 579          |
|    total_timesteps       | 1640448      |
| train/                   |              |
|    approx_kl             | 0.0015201259 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 4.96         |
|    cost_values           | 2.82         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 8000         |
|    policy_gradient_loss  | -0.000882    |
|    std                   | 0.52         |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -1.0590545  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -740        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 614         |
|    total_timesteps       | 1642496     |
| train/                   |             |
|    approx_kl             | 0.007784643 |
|    clip_fraction         | 0.0562      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.83        |
|    cost_value_loss       | 3.95        |
|    cost_values           | 2.75        |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.66        |
|    n_updates             | 8010        |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.517       |
|    value_loss            | 9.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5586481  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -745        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 648         |
|    total_timesteps       | 1644544     |
| train/                   |             |
|    approx_kl             | 0.004170263 |
|    clip_fraction         | 0.0471      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.55        |
|    cost_value_loss       | 6.27        |
|    cost_values           | 2.82        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.9        |
|    n_updates             | 8020        |
|    policy_gradient_loss  | 0.000412    |
|    std                   | 0.516       |
|    value_loss            | 34          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.47886133  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 683          |
|    total_timesteps       | 1646592      |
| train/                   |              |
|    approx_kl             | 0.0052636466 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 2.78         |
|    cost_values           | 2.98         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00344      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.59         |
|    n_updates             | 8030         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.515        |
|    value_loss            | 11.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6224985   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 718          |
|    total_timesteps       | 1648640      |
| train/                   |              |
|    approx_kl             | 0.0020837758 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.06         |
|    cost_value_loss       | 3.58         |
|    cost_values           | 2.9          |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.12         |
|    n_updates             | 8040         |
|    policy_gradient_loss  | -0.000298    |
|    std                   | 0.514        |
|    value_loss            | 7.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.80138874  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 753          |
|    total_timesteps       | 1650688      |
| train/                   |              |
|    approx_kl             | 0.0032027857 |
|    clip_fraction         | 0.00718      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.54         |
|    cost_value_loss       | 8.26         |
|    cost_values           | 2.81         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 8050         |
|    policy_gradient_loss  | -0.000714    |
|    std                   | 0.516        |
|    value_loss            | 7.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.70092624  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 787          |
|    total_timesteps       | 1652736      |
| train/                   |              |
|    approx_kl             | 0.0040155407 |
|    clip_fraction         | 0.0542       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 2.43         |
|    cost_values           | 2.92         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.29         |
|    n_updates             | 8060         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.517        |
|    value_loss            | 3.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.46818444  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 822          |
|    total_timesteps       | 1654784      |
| train/                   |              |
|    approx_kl             | 0.0037847585 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 7.77         |
|    cost_values           | 2.85         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.22         |
|    n_updates             | 8070         |
|    policy_gradient_loss  | -0.000669    |
|    std                   | 0.517        |
|    value_loss            | 6.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.62180156  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 857          |
|    total_timesteps       | 1656832      |
| train/                   |              |
|    approx_kl             | 0.0038230675 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.52         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 2.98         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00828      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.74         |
|    n_updates             | 8080         |
|    policy_gradient_loss  | -0.000422    |
|    std                   | 0.517        |
|    value_loss            | 12.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.64526063  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 892          |
|    total_timesteps       | 1658880      |
| train/                   |              |
|    approx_kl             | 0.0011532599 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 9.74         |
|    cost_values           | 2.99         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00446      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 8090         |
|    policy_gradient_loss  | -0.000393    |
|    std                   | 0.516        |
|    value_loss            | 8.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.5205146  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -738        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 926         |
|    total_timesteps       | 1660928     |
| train/                   |             |
|    approx_kl             | 0.003037268 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 5.77        |
|    cost_values           | 3           |
|    entropy               | -1.51       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00354     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 8100        |
|    policy_gradient_loss  | -0.000825   |
|    std                   | 0.516       |
|    value_loss            | 6.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.49413824  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 961          |
|    total_timesteps       | 1662976      |
| train/                   |              |
|    approx_kl             | 0.0034296873 |
|    clip_fraction         | 0.00659      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.94         |
|    cost_value_loss       | 2.87         |
|    cost_values           | 2.87         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.22         |
|    n_updates             | 8110         |
|    policy_gradient_loss  | -0.000963    |
|    std                   | 0.516        |
|    value_loss            | 4.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.668508   |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -741        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 996         |
|    total_timesteps       | 1665024     |
| train/                   |             |
|    approx_kl             | 0.004730189 |
|    clip_fraction         | 0.00996     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.52        |
|    cost_value_loss       | 6.88        |
|    cost_values           | 2.74        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.5        |
|    n_updates             | 8120        |
|    policy_gradient_loss  | -0.000681   |
|    std                   | 0.516       |
|    value_loss            | 31.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3379601   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1031         |
|    total_timesteps       | 1667072      |
| train/                   |              |
|    approx_kl             | 0.0048875506 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 0.577        |
|    cost_values           | 2.73         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 8130         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.516        |
|    value_loss            | 20.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.9325813    |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -741          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 31            |
|    time_elapsed          | 1066          |
|    total_timesteps       | 1669120       |
| train/                   |               |
|    approx_kl             | 0.00069870695 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.25          |
|    cost_value_loss       | 9.58          |
|    cost_values           | 2.52          |
|    entropy               | -1.51         |
|    entropy_loss          | -1.51         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.1          |
|    n_updates             | 8140          |
|    policy_gradient_loss  | -0.000384     |
|    std                   | 0.516         |
|    value_loss            | 14.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.7387261   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1101         |
|    total_timesteps       | 1671168      |
| train/                   |              |
|    approx_kl             | 0.0046973675 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 3.2          |
|    cost_values           | 2.68         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 8150         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.516        |
|    value_loss            | 7.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48280835  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1135         |
|    total_timesteps       | 1673216      |
| train/                   |              |
|    approx_kl             | 0.0036845193 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 5.03         |
|    cost_values           | 2.9          |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.2          |
|    n_updates             | 8160         |
|    policy_gradient_loss  | -0.00076     |
|    std                   | 0.514        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.83665127 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -741        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1170        |
|    total_timesteps       | 1675264     |
| train/                   |             |
|    approx_kl             | 0.003115977 |
|    clip_fraction         | 0.00225     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.49        |
|    cost_value_loss       | 4.63        |
|    cost_values           | 2.94        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.9        |
|    n_updates             | 8170        |
|    policy_gradient_loss  | 0.000589    |
|    std                   | 0.514       |
|    value_loss            | 28.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.8975534   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1205         |
|    total_timesteps       | 1677312      |
| train/                   |              |
|    approx_kl             | 0.0056405053 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.39         |
|    cost_value_loss       | 4.94         |
|    cost_values           | 2.99         |
|    entropy               | -1.5         |
|    entropy_loss          | -1.51        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00208      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 8180         |
|    policy_gradient_loss  | -0.000737    |
|    std                   | 0.513        |
|    value_loss            | 4.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.46409842  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1239         |
|    total_timesteps       | 1679360      |
| train/                   |              |
|    approx_kl             | 0.0025713672 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 9.41         |
|    cost_values           | 3            |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00324      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 8190         |
|    policy_gradient_loss  | -0.000303    |
|    std                   | 0.512        |
|    value_loss            | 4.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1023916   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1273         |
|    total_timesteps       | 1681408      |
| train/                   |              |
|    approx_kl             | 0.0029873634 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.69         |
|    cost_value_loss       | 1.12         |
|    cost_values           | 2.81         |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 8200         |
|    policy_gradient_loss  | -0.000431    |
|    std                   | 0.511        |
|    value_loss            | 9.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5109719   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1308         |
|    total_timesteps       | 1683456      |
| train/                   |              |
|    approx_kl             | 0.0057920683 |
|    clip_fraction         | 0.0529       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.67         |
|    cost_value_loss       | 3.21         |
|    cost_values           | 2.61         |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.87         |
|    n_updates             | 8210         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.514        |
|    value_loss            | 4.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0287668   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1343         |
|    total_timesteps       | 1685504      |
| train/                   |              |
|    approx_kl             | 0.0013156639 |
|    clip_fraction         | 0.00552      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.84         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 2.65         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.5         |
|    n_updates             | 8220         |
|    policy_gradient_loss  | 0.00151      |
|    std                   | 0.514        |
|    value_loss            | 65.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.9755204   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1377         |
|    total_timesteps       | 1687552      |
| train/                   |              |
|    approx_kl             | 0.0026732306 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 1.47         |
|    cost_values           | 2.61         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.79         |
|    n_updates             | 8230         |
|    policy_gradient_loss  | -0.000436    |
|    std                   | 0.515        |
|    value_loss            | 6.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0120828   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1412         |
|    total_timesteps       | 1689600      |
| train/                   |              |
|    approx_kl             | 0.0024932944 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 2.36         |
|    cost_values           | 2.4          |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.57         |
|    n_updates             | 8240         |
|    policy_gradient_loss  | -0.000782    |
|    std                   | 0.515        |
|    value_loss            | 9.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.788022    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1446         |
|    total_timesteps       | 1691648      |
| train/                   |              |
|    approx_kl             | 0.0047723893 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 0.16         |
|    cost_values           | 2.14         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.5          |
|    n_updates             | 8250         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.514        |
|    value_loss            | 4.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.88800067  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1481         |
|    total_timesteps       | 1693696      |
| train/                   |              |
|    approx_kl             | 0.0028671306 |
|    clip_fraction         | 0.00645      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 0.106        |
|    cost_values           | 1.65         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.5         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.61         |
|    n_updates             | 8260         |
|    policy_gradient_loss  | -0.00028     |
|    std                   | 0.51         |
|    value_loss            | 3.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.67394316  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1516         |
|    total_timesteps       | 1695744      |
| train/                   |              |
|    approx_kl             | 0.0027901665 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.5          |
|    cost_value_loss       | 15           |
|    cost_values           | 1.53         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.7         |
|    n_updates             | 8270         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.51         |
|    value_loss            | 41.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.83364546  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1550         |
|    total_timesteps       | 1697792      |
| train/                   |              |
|    approx_kl             | 0.0050374167 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 0.0531       |
|    cost_values           | 1.37         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.23         |
|    n_updates             | 8280         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.51         |
|    value_loss            | 4.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.7709269  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1585        |
|    total_timesteps       | 1699840     |
| train/                   |             |
|    approx_kl             | 0.004161878 |
|    clip_fraction         | 0.0372      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.16        |
|    cost_value_loss       | 6.27        |
|    cost_values           | 1.36        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.03        |
|    n_updates             | 8290        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.51        |
|    value_loss            | 3.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.5844569   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1620         |
|    total_timesteps       | 1701888      |
| train/                   |              |
|    approx_kl             | 0.0064819986 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 0.179        |
|    cost_values           | 1.49         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.52         |
|    n_updates             | 8300         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.508        |
|    value_loss            | 4.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.804755   |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1655        |
|    total_timesteps       | 1703936     |
| train/                   |             |
|    approx_kl             | 0.002799534 |
|    clip_fraction         | 0.0203      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.0245      |
|    cost_values           | 1.12        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 8310        |
|    policy_gradient_loss  | 0.00015     |
|    std                   | 0.506       |
|    value_loss            | 8.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.79466754 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1689        |
|    total_timesteps       | 1705984     |
| train/                   |             |
|    approx_kl             | 0.004245948 |
|    clip_fraction         | 0.00698     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.929       |
|    cost_value_loss       | 0.251       |
|    cost_values           | 0.97        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.85        |
|    n_updates             | 8320        |
|    policy_gradient_loss  | -0.000415   |
|    std                   | 0.505       |
|    value_loss            | 4.75        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
-----------------------------------
| avg_speed          | 8.02       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.02       |
| reward             | -0.8640044 |
| rollout/           |            |
|    ep_len_mean     | 966        |
|    ep_rew_mean     | -703       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1708032    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5447527  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 1710080     |
| train/                   |             |
|    approx_kl             | 0.004645746 |
|    clip_fraction         | 0.0498      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.822       |
|    cost_value_loss       | 0.133       |
|    cost_values           | 0.875       |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.4        |
|    n_updates             | 8340        |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.504       |
|    value_loss            | 36.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.54345495  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 1712128      |
| train/                   |              |
|    approx_kl             | 0.0067650843 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.708        |
|    cost_value_loss       | 0.092        |
|    cost_values           | 0.77         |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 8350         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.503        |
|    value_loss            | 9.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.8874899  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 129         |
|    total_timesteps       | 1714176     |
| train/                   |             |
|    approx_kl             | 0.003665712 |
|    clip_fraction         | 0.0254      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 4.8         |
|    cost_values           | 0.807       |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.79        |
|    n_updates             | 8360        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.503       |
|    value_loss            | 5.87        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.68619406  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1716224      |
| train/                   |              |
|    approx_kl             | 0.0008224178 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.784        |
|    cost_value_loss       | 0.0429       |
|    cost_values           | 0.977        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.43         |
|    n_updates             | 8370         |
|    policy_gradient_loss  | -0.000185    |
|    std                   | 0.503        |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.23425458 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 6           |
|    time_elapsed          | 198         |
|    total_timesteps       | 1718272     |
| train/                   |             |
|    approx_kl             | 0.004543946 |
|    clip_fraction         | 0.0285      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.771       |
|    cost_value_loss       | 0.0165      |
|    cost_values           | 0.867       |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.76        |
|    n_updates             | 8380        |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.503       |
|    value_loss            | 6.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.71594614 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 233         |
|    total_timesteps       | 1720320     |
| train/                   |             |
|    approx_kl             | 0.00075463  |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 0.951       |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.64        |
|    n_updates             | 8390        |
|    policy_gradient_loss  | 0.00015     |
|    std                   | 0.503       |
|    value_loss            | 10.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.56145227  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 1722368      |
| train/                   |              |
|    approx_kl             | 0.0038449224 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 8.38         |
|    cost_values           | 1.29         |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.76         |
|    n_updates             | 8400         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.503        |
|    value_loss            | 9.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.2543439   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 1724416      |
| train/                   |              |
|    approx_kl             | 0.0021206124 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.266        |
|    cost_values           | 1.33         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.44         |
|    n_updates             | 8410         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.504        |
|    value_loss            | 2.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9821228   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 1726464      |
| train/                   |              |
|    approx_kl             | 0.0007910547 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 9.29         |
|    cost_values           | 1.39         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 8420         |
|    policy_gradient_loss  | 0.000451     |
|    std                   | 0.505        |
|    value_loss            | 18.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.34680524  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 372          |
|    total_timesteps       | 1728512      |
| train/                   |              |
|    approx_kl             | 0.0026267266 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 9.04         |
|    cost_values           | 1.74         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 8430         |
|    policy_gradient_loss  | -0.000451    |
|    std                   | 0.505        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.5033338   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 408          |
|    total_timesteps       | 1730560      |
| train/                   |              |
|    approx_kl             | 0.0023818929 |
|    clip_fraction         | 0.00156      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 2.14         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 8440         |
|    policy_gradient_loss  | -0.000479    |
|    std                   | 0.506        |
|    value_loss            | 8.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.38         |
| reward                   | -0.49437606  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1732608      |
| train/                   |              |
|    approx_kl             | 0.0031505693 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 5.67         |
|    cost_values           | 2.61         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 8450         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.505        |
|    value_loss            | 2.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.78         |
| reward                   | -0.5630496   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 14           |
|    time_elapsed          | 478          |
|    total_timesteps       | 1734656      |
| train/                   |              |
|    approx_kl             | 0.0042943927 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.62         |
|    cost_value_loss       | 8.51         |
|    cost_values           | 2.9          |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.19         |
|    n_updates             | 8460         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.504        |
|    value_loss            | 5.88         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.6379121  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 15          |
|    time_elapsed          | 513         |
|    total_timesteps       | 1736704     |
| train/                   |             |
|    approx_kl             | 0.006386705 |
|    clip_fraction         | 0.0128      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.55        |
|    cost_value_loss       | 7.64        |
|    cost_values           | 3           |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.00339     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 8470        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.504       |
|    value_loss            | 3.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.86804175  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 548          |
|    total_timesteps       | 1738752      |
| train/                   |              |
|    approx_kl             | 0.0012046263 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 0.192        |
|    cost_values           | 2.81         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 8480         |
|    policy_gradient_loss  | -0.000408    |
|    std                   | 0.504        |
|    value_loss            | 8.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8525905   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 584          |
|    total_timesteps       | 1740800      |
| train/                   |              |
|    approx_kl             | 0.0027487155 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 1.71         |
|    cost_values           | 2.46         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.54         |
|    n_updates             | 8490         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.506        |
|    value_loss            | 5.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.55195844 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 619         |
|    total_timesteps       | 1742848     |
| train/                   |             |
|    approx_kl             | 0.002589315 |
|    clip_fraction         | 0.00122     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 30.2        |
|    cost_values           | 2.66        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.1        |
|    n_updates             | 8500        |
|    policy_gradient_loss  | -0.000115   |
|    std                   | 0.507       |
|    value_loss            | 6.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7442361   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 654          |
|    total_timesteps       | 1744896      |
| train/                   |              |
|    approx_kl             | 0.0046393913 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 0.228        |
|    cost_values           | 2.79         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.4          |
|    n_updates             | 8510         |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.508        |
|    value_loss            | 6.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.72949964  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 689          |
|    total_timesteps       | 1746944      |
| train/                   |              |
|    approx_kl             | 0.0031194615 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.38         |
|    cost_value_loss       | 6.21         |
|    cost_values           | 2.53         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 8520         |
|    policy_gradient_loss  | -0.000769    |
|    std                   | 0.509        |
|    value_loss            | 2.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8490347   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 724          |
|    total_timesteps       | 1748992      |
| train/                   |              |
|    approx_kl             | 0.0027660304 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 1.62         |
|    cost_values           | 2.65         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.37         |
|    n_updates             | 8530         |
|    policy_gradient_loss  | -0.000658    |
|    std                   | 0.509        |
|    value_loss            | 1.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.32359186 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 759         |
|    total_timesteps       | 1751040     |
| train/                   |             |
|    approx_kl             | 0.003375953 |
|    clip_fraction         | 0.00322     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 5.54        |
|    cost_values           | 2.48        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.91        |
|    n_updates             | 8540        |
|    policy_gradient_loss  | -0.000998   |
|    std                   | 0.509       |
|    value_loss            | 6.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8299375  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -680        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 795         |
|    total_timesteps       | 1753088     |
| train/                   |             |
|    approx_kl             | 0.000644902 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 29.8        |
|    cost_values           | 2.66        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0155      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.06        |
|    n_updates             | 8550        |
|    policy_gradient_loss  | -0.00044    |
|    std                   | 0.509       |
|    value_loss            | 13.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7584214   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 830          |
|    total_timesteps       | 1755136      |
| train/                   |              |
|    approx_kl             | 0.0016588068 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.66         |
|    cost_value_loss       | 3.4          |
|    cost_values           | 3            |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00192      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.8          |
|    n_updates             | 8560         |
|    policy_gradient_loss  | -0.000309    |
|    std                   | 0.51         |
|    value_loss            | 5.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.74290633  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 865          |
|    total_timesteps       | 1757184      |
| train/                   |              |
|    approx_kl             | 0.0035967059 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 2.06         |
|    cost_values           | 2.9          |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.28         |
|    n_updates             | 8570         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.509        |
|    value_loss            | 3.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.59866214  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 900          |
|    total_timesteps       | 1759232      |
| train/                   |              |
|    approx_kl             | 0.0034646618 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.75         |
|    cost_value_loss       | 1.81         |
|    cost_values           | 2.73         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.36         |
|    n_updates             | 8580         |
|    policy_gradient_loss  | -0.000884    |
|    std                   | 0.509        |
|    value_loss            | 6.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.9688973   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 935          |
|    total_timesteps       | 1761280      |
| train/                   |              |
|    approx_kl             | 0.0051777516 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 2            |
|    cost_values           | 2.6          |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.04         |
|    n_updates             | 8590         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.51         |
|    value_loss            | 6.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.6962276   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 970          |
|    total_timesteps       | 1763328      |
| train/                   |              |
|    approx_kl             | 0.0044264467 |
|    clip_fraction         | 0.00713      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 0.153        |
|    cost_values           | 2.4          |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 8600         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.51         |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.79951936 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -688        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 1005        |
|    total_timesteps       | 1765376     |
| train/                   |             |
|    approx_kl             | 0.00343733  |
|    clip_fraction         | 0.0558      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.65        |
|    cost_value_loss       | 5.97        |
|    cost_values           | 2.29        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.2        |
|    n_updates             | 8610        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.51        |
|    value_loss            | 27          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.7995265   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1040         |
|    total_timesteps       | 1767424      |
| train/                   |              |
|    approx_kl             | 0.0035632323 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.51         |
|    cost_value_loss       | 25.6         |
|    cost_values           | 2.65         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 8620         |
|    policy_gradient_loss  | -0.000209    |
|    std                   | 0.51         |
|    value_loss            | 4.65         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7654246  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1074        |
|    total_timesteps       | 1769472     |
| train/                   |             |
|    approx_kl             | 0.002124905 |
|    clip_fraction         | 0.000439    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 0.325       |
|    cost_values           | 2.85        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.12        |
|    n_updates             | 8630        |
|    policy_gradient_loss  | -0.000902   |
|    std                   | 0.51        |
|    value_loss            | 7.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.86229604 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1109        |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.003550612 |
|    clip_fraction         | 0.00308     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.73        |
|    cost_value_loss       | 1.53        |
|    cost_values           | 2.56        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.54        |
|    n_updates             | 8640        |
|    policy_gradient_loss  | -0.000488   |
|    std                   | 0.51        |
|    value_loss            | 3.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5942992   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1144         |
|    total_timesteps       | 1773568      |
| train/                   |              |
|    approx_kl             | 0.0046219365 |
|    clip_fraction         | 0.035        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 0.116        |
|    cost_values           | 2.28         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.557        |
|    n_updates             | 8650         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.51         |
|    value_loss            | 1.41         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.560407  |
| rollout/                 |            |
|    ep_len_mean           | 972        |
|    ep_rew_mean           | -680       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 34         |
|    time_elapsed          | 1178       |
|    total_timesteps       | 1775616    |
| train/                   |            |
|    approx_kl             | 0.00501921 |
|    clip_fraction         | 0.0105     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.35       |
|    cost_value_loss       | 30.8       |
|    cost_values           | 2.08       |
|    entropy               | -1.49      |
|    entropy_loss          | -1.49      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 19.7       |
|    n_updates             | 8660       |
|    policy_gradient_loss  | -0.00314   |
|    std                   | 0.51       |
|    value_loss            | 10.5       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.46853852  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1213         |
|    total_timesteps       | 1777664      |
| train/                   |              |
|    approx_kl             | 0.0046263835 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.68         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 2.37         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.18         |
|    n_updates             | 8670         |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.51         |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.52873385  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1248         |
|    total_timesteps       | 1779712      |
| train/                   |              |
|    approx_kl             | 0.0046600914 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 1.09         |
|    cost_values           | 2.36         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.1          |
|    n_updates             | 8680         |
|    policy_gradient_loss  | -0.00032     |
|    std                   | 0.509        |
|    value_loss            | 5.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49446592  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1283         |
|    total_timesteps       | 1781760      |
| train/                   |              |
|    approx_kl             | 0.0032122408 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 6.33         |
|    cost_values           | 2.32         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.52         |
|    n_updates             | 8690         |
|    policy_gradient_loss  | -0.000229    |
|    std                   | 0.508        |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.74257755 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -682        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1318        |
|    total_timesteps       | 1783808     |
| train/                   |             |
|    approx_kl             | 0.004250561 |
|    clip_fraction         | 0.00547     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.98        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.64        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.8         |
|    n_updates             | 8700        |
|    policy_gradient_loss  | -0.000867   |
|    std                   | 0.509       |
|    value_loss            | 3.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.81448567  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1352         |
|    total_timesteps       | 1785856      |
| train/                   |              |
|    approx_kl             | 0.0047477265 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 3.29         |
|    cost_values           | 2.78         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 8710         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.506        |
|    value_loss            | 4.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.44         |
| reward                   | -0.67146695  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1387         |
|    total_timesteps       | 1787904      |
| train/                   |              |
|    approx_kl             | 0.0021934498 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 0.196        |
|    cost_values           | 2.58         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.18         |
|    n_updates             | 8720         |
|    policy_gradient_loss  | 1.88e-05     |
|    std                   | 0.505        |
|    value_loss            | 6.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.87917316  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 41           |
|    time_elapsed          | 1423         |
|    total_timesteps       | 1789952      |
| train/                   |              |
|    approx_kl             | 0.0023017265 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.58         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 2.43         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.94         |
|    n_updates             | 8730         |
|    policy_gradient_loss  | -0.000304    |
|    std                   | 0.506        |
|    value_loss            | 2.98         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.71179205   |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -681          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 42            |
|    time_elapsed          | 1457          |
|    total_timesteps       | 1792000       |
| train/                   |               |
|    approx_kl             | 0.00014668552 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 5.02          |
|    cost_value_loss       | 20.2          |
|    cost_values           | 2.83          |
|    entropy               | -1.47         |
|    entropy_loss          | -1.47         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 14            |
|    n_updates             | 8740          |
|    policy_gradient_loss  | 0.000419      |
|    std                   | 0.506         |
|    value_loss            | 9.22          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.66420174 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -678        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 43          |
|    time_elapsed          | 1492        |
|    total_timesteps       | 1794048     |
| train/                   |             |
|    approx_kl             | 0.00412832  |
|    clip_fraction         | 0.00459     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.45        |
|    cost_value_loss       | 0.239       |
|    cost_values           | 2.87        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.49        |
|    n_updates             | 8750        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.506       |
|    value_loss            | 15.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8706983   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 44           |
|    time_elapsed          | 1527         |
|    total_timesteps       | 1796096      |
| train/                   |              |
|    approx_kl             | 0.0026573348 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.96         |
|    cost_value_loss       | 3.69         |
|    cost_values           | 2.57         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.54         |
|    n_updates             | 8760         |
|    policy_gradient_loss  | -0.000423    |
|    std                   | 0.506        |
|    value_loss            | 4.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.0041943   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 45           |
|    time_elapsed          | 1562         |
|    total_timesteps       | 1798144      |
| train/                   |              |
|    approx_kl             | 0.0023242547 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 0.113        |
|    cost_values           | 2.28         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.971        |
|    n_updates             | 8770         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.508        |
|    value_loss            | 1.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5179371   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 46           |
|    time_elapsed          | 1597         |
|    total_timesteps       | 1800192      |
| train/                   |              |
|    approx_kl             | 0.0030849644 |
|    clip_fraction         | 0.0726       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 0.0866       |
|    cost_values           | 1.88         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 8780         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.509        |
|    value_loss            | 12.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.51519185 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -673        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 47          |
|    time_elapsed          | 1632        |
|    total_timesteps       | 1802240     |
| train/                   |             |
|    approx_kl             | 0.002755498 |
|    clip_fraction         | 0.00176     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 0.0413      |
|    cost_values           | 1.48        |
|    entropy               | -1.5        |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 8790        |
|    policy_gradient_loss  | -9.13e-05   |
|    std                   | 0.511       |
|    value_loss            | 8.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72860247  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 48           |
|    time_elapsed          | 1668         |
|    total_timesteps       | 1804288      |
| train/                   |              |
|    approx_kl             | 0.0015583672 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.44         |
|    cost_value_loss       | 30.1         |
|    cost_values           | 1.41         |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 8800         |
|    policy_gradient_loss  | -0.00068     |
|    std                   | 0.511        |
|    value_loss            | 38.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.542522     |
| rollout/                 |               |
|    ep_len_mean           | 986           |
|    ep_rew_mean           | -671          |
| time/                    |               |
|    fps                   | 58            |
|    iterations            | 49            |
|    time_elapsed          | 1702          |
|    total_timesteps       | 1806336       |
| train/                   |               |
|    approx_kl             | 0.00051244843 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.59          |
|    cost_value_loss       | 20.2          |
|    cost_values           | 1.59          |
|    entropy               | -1.5          |
|    entropy_loss          | -1.5          |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 28.1          |
|    n_updates             | 8810          |
|    policy_gradient_loss  | -0.000396     |
|    std                   | 0.512         |
|    value_loss            | 35.3          |
--------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.58731717 |
| rollout/           |             |
|    ep_len_mean     | 986         |
|    ep_rew_mean     | -670        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1808384     |
------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.8736053    |
| rollout/                 |               |
|    ep_len_mean           | 986           |
|    ep_rew_mean           | -674          |
| time/                    |               |
|    fps                   | 69            |
|    iterations            | 2             |
|    time_elapsed          | 59            |
|    total_timesteps       | 1810432       |
| train/                   |               |
|    approx_kl             | 0.00016758687 |
|    clip_fraction         | 0.00308       |
|    clip_range            | 0.2           |
|    cost_returns          | 1.06          |
|    cost_value_loss       | 0.053         |
|    cost_values           | 1.15          |
|    entropy               | -1.48         |
|    entropy_loss          | -1.48         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.46          |
|    n_updates             | 8830          |
|    policy_gradient_loss  | 0.00123       |
|    std                   | 0.508         |
|    value_loss            | 9.72          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41169012  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1812480      |
| train/                   |              |
|    approx_kl             | 0.0043335455 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.819        |
|    cost_value_loss       | 0.0194       |
|    cost_values           | 0.931        |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.26         |
|    n_updates             | 8840         |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 0.508        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.7160874   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -663         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1814528      |
| train/                   |              |
|    approx_kl             | 0.0032929862 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.719        |
|    cost_value_loss       | 0.0126       |
|    cost_values           | 0.794        |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.58         |
|    n_updates             | 8850         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.508        |
|    value_loss            | 11           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7525166  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -664        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 1816576     |
| train/                   |             |
|    approx_kl             | 0.008002571 |
|    clip_fraction         | 0.0344      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.46        |
|    cost_value_loss       | 5.21        |
|    cost_values           | 0.818       |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.21        |
|    n_updates             | 8860        |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.508       |
|    value_loss            | 30.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.61202365  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1818624      |
| train/                   |              |
|    approx_kl             | 0.0057200193 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.925        |
|    cost_value_loss       | 0.315        |
|    cost_values           | 0.95         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.02         |
|    n_updates             | 8870         |
|    policy_gradient_loss  | -0.000677    |
|    std                   | 0.505        |
|    value_loss            | 1.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.74         |
| reward                   | -0.58806074  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1820672      |
| train/                   |              |
|    approx_kl             | 0.0038824226 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.975        |
|    cost_value_loss       | 0.53         |
|    cost_values           | 0.951        |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.66         |
|    n_updates             | 8880         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.503        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.7954356   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -661         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 1822720      |
| train/                   |              |
|    approx_kl             | 0.0037558016 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.29         |
|    cost_values           | 1.05         |
|    entropy               | -1.45        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.31         |
|    n_updates             | 8890         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.5          |
|    value_loss            | 3.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.570621   |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -662        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 300         |
|    total_timesteps       | 1824768     |
| train/                   |             |
|    approx_kl             | 0.002749247 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 0.45        |
|    cost_values           | 1.04        |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.3         |
|    n_updates             | 8900        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.497       |
|    value_loss            | 6.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6683893   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 335          |
|    total_timesteps       | 1826816      |
| train/                   |              |
|    approx_kl             | 0.0035650749 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.854        |
|    cost_value_loss       | 0.0146       |
|    cost_values           | 0.902        |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.04         |
|    n_updates             | 8910         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.497        |
|    value_loss            | 4.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7544116   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -662         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 1828864      |
| train/                   |              |
|    approx_kl             | 0.0045749648 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 6.08         |
|    cost_values           | 1.13         |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.9         |
|    n_updates             | 8920         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.497        |
|    value_loss            | 32.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.522575     |
| rollout/                 |               |
|    ep_len_mean           | 979           |
|    ep_rew_mean           | -663          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 12            |
|    time_elapsed          | 404           |
|    total_timesteps       | 1830912       |
| train/                   |               |
|    approx_kl             | 0.00010201431 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.19          |
|    cost_value_loss       | 0.0958        |
|    cost_values           | 1.37          |
|    entropy               | -1.44         |
|    entropy_loss          | -1.44         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.33          |
|    n_updates             | 8930          |
|    policy_gradient_loss  | 6.13e-05      |
|    std                   | 0.497         |
|    value_loss            | 9.91          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6228358   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -662         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 1832960      |
| train/                   |              |
|    approx_kl             | 0.0045986655 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.0304       |
|    cost_values           | 1.03         |
|    entropy               | -1.45        |
|    entropy_loss          | -1.44        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.21         |
|    n_updates             | 8940         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.499        |
|    value_loss            | 4.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.5127681  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -659        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 474         |
|    total_timesteps       | 1835008     |
| train/                   |             |
|    approx_kl             | 0.004113596 |
|    clip_fraction         | 0.00435     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.924       |
|    cost_value_loss       | 0.149       |
|    cost_values           | 0.959       |
|    entropy               | -1.45       |
|    entropy_loss          | -1.45       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.832       |
|    n_updates             | 8950        |
|    policy_gradient_loss  | -0.000269   |
|    std                   | 0.5         |
|    value_loss            | 1.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.94297564  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -659         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1837056      |
| train/                   |              |
|    approx_kl             | 0.0045097754 |
|    clip_fraction         | 0.00811      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.947        |
|    cost_value_loss       | 0.837        |
|    cost_values           | 0.924        |
|    entropy               | -1.45        |
|    entropy_loss          | -1.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.09         |
|    n_updates             | 8960         |
|    policy_gradient_loss  | -8.43e-05    |
|    std                   | 0.5          |
|    value_loss            | 4.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.872637    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 1839104      |
| train/                   |              |
|    approx_kl             | 0.0037750397 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.761        |
|    cost_value_loss       | 0.0306       |
|    cost_values           | 0.919        |
|    entropy               | -1.45        |
|    entropy_loss          | -1.45        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.23         |
|    n_updates             | 8970         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.5          |
|    value_loss            | 8.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.88766545 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -659        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 577         |
|    total_timesteps       | 1841152     |
| train/                   |             |
|    approx_kl             | 0.002770226 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.76        |
|    cost_values           | 1.02        |
|    entropy               | -1.45       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 8980        |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 0.499       |
|    value_loss            | 18.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.57499284 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -660        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 613         |
|    total_timesteps       | 1843200     |
| train/                   |             |
|    approx_kl             | 0.002253836 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 1.02        |
|    cost_values           | 1.1         |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.81        |
|    n_updates             | 8990        |
|    policy_gradient_loss  | -0.0025     |
|    std                   | 0.497       |
|    value_loss            | 4.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8824906  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -658        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 648         |
|    total_timesteps       | 1845248     |
| train/                   |             |
|    approx_kl             | 0.004523159 |
|    clip_fraction         | 0.0155      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 28.1        |
|    cost_values           | 1.31        |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.8        |
|    n_updates             | 9000        |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.497       |
|    value_loss            | 7.69        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3910178 |
| rollout/                 |            |
|    ep_len_mean           | 979        |
|    ep_rew_mean           | -662       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 20         |
|    time_elapsed          | 683        |
|    total_timesteps       | 1847296    |
| train/                   |            |
|    approx_kl             | 2.6611e-05 |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 3.53       |
|    cost_value_loss       | 15.1       |
|    cost_values           | 1.89       |
|    entropy               | -1.44      |
|    entropy_loss          | -1.44      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.82       |
|    n_updates             | 9010       |
|    policy_gradient_loss  | -1.2e-05   |
|    std                   | 0.497      |
|    value_loss            | 3.7        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1257848   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -662         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 717          |
|    total_timesteps       | 1849344      |
| train/                   |              |
|    approx_kl             | 0.0031443066 |
|    clip_fraction         | 0.00137      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 0.107        |
|    cost_values           | 2.02         |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 9020         |
|    policy_gradient_loss  | -8.86e-05    |
|    std                   | 0.497        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49608395  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 752          |
|    total_timesteps       | 1851392      |
| train/                   |              |
|    approx_kl             | 0.0004998511 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 0.0497       |
|    cost_values           | 1.55         |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.94         |
|    n_updates             | 9030         |
|    policy_gradient_loss  | -6.09e-05    |
|    std                   | 0.497        |
|    value_loss            | 18.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5330185    |
| rollout/                 |               |
|    ep_len_mean           | 979           |
|    ep_rew_mean           | -663          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 23            |
|    time_elapsed          | 787           |
|    total_timesteps       | 1853440       |
| train/                   |               |
|    approx_kl             | 0.00041615593 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.58          |
|    cost_value_loss       | 6.62          |
|    cost_values           | 1.45          |
|    entropy               | -1.44         |
|    entropy_loss          | -1.44         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.67          |
|    n_updates             | 9040          |
|    policy_gradient_loss  | -0.000201     |
|    std                   | 0.497         |
|    value_loss            | 5.36          |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.873       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.873       |
| reward                   | -0.55134195 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -664        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 822         |
|    total_timesteps       | 1855488     |
| train/                   |             |
|    approx_kl             | 0.004657995 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 0.467       |
|    cost_values           | 1.52        |
|    entropy               | -1.43       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.4         |
|    n_updates             | 9050        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.495       |
|    value_loss            | 2.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8255991   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 857          |
|    total_timesteps       | 1857536      |
| train/                   |              |
|    approx_kl             | 0.0046658833 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 0.0443       |
|    cost_values           | 1.27         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.49         |
|    n_updates             | 9060         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.493        |
|    value_loss            | 6.51         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.8536445    |
| rollout/                 |               |
|    ep_len_mean           | 979           |
|    ep_rew_mean           | -659          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 26            |
|    time_elapsed          | 892           |
|    total_timesteps       | 1859584       |
| train/                   |               |
|    approx_kl             | 0.00057065196 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.56          |
|    cost_value_loss       | 14.4          |
|    cost_values           | 1.14          |
|    entropy               | -1.42         |
|    entropy_loss          | -1.42         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.96          |
|    n_updates             | 9070          |
|    policy_gradient_loss  | -0.00026      |
|    std                   | 0.493         |
|    value_loss            | 4.01          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5591272   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 927          |
|    total_timesteps       | 1861632      |
| train/                   |              |
|    approx_kl             | 0.0012664847 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.47         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 1.5          |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 9080         |
|    policy_gradient_loss  | -0.000512    |
|    std                   | 0.493        |
|    value_loss            | 2.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9043894   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 962          |
|    total_timesteps       | 1863680      |
| train/                   |              |
|    approx_kl             | 0.0027512023 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 1.97         |
|    cost_values           | 1.84         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.58         |
|    n_updates             | 9090         |
|    policy_gradient_loss  | -0.000313    |
|    std                   | 0.493        |
|    value_loss            | 3.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6082972   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 996          |
|    total_timesteps       | 1865728      |
| train/                   |              |
|    approx_kl             | 0.0020631035 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 6.8          |
|    cost_values           | 1.88         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 9100         |
|    policy_gradient_loss  | -0.000145    |
|    std                   | 0.493        |
|    value_loss            | 5.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8145071   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1031         |
|    total_timesteps       | 1867776      |
| train/                   |              |
|    approx_kl             | 0.0008052004 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 0.121        |
|    cost_values           | 1.96         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.9          |
|    n_updates             | 9110         |
|    policy_gradient_loss  | -0.000499    |
|    std                   | 0.493        |
|    value_loss            | 18           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.46502107 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1066        |
|    total_timesteps       | 1869824     |
| train/                   |             |
|    approx_kl             | 0.00526715  |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 2.54        |
|    cost_values           | 1.74        |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.85        |
|    n_updates             | 9120        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.493       |
|    value_loss            | 4.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8390488   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1100         |
|    total_timesteps       | 1871872      |
| train/                   |              |
|    approx_kl             | 0.0037714154 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 0.293        |
|    cost_values           | 1.67         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.82         |
|    n_updates             | 9130         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.492        |
|    value_loss            | 8.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.82724243 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -672        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1135        |
|    total_timesteps       | 1873920     |
| train/                   |             |
|    approx_kl             | 0.003911762 |
|    clip_fraction         | 0.00571     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.88        |
|    cost_value_loss       | 2.25        |
|    cost_values           | 1.48        |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.17        |
|    n_updates             | 9140        |
|    policy_gradient_loss  | -0.000701   |
|    std                   | 0.492       |
|    value_loss            | 11.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48669612  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1170         |
|    total_timesteps       | 1875968      |
| train/                   |              |
|    approx_kl             | 0.0019198046 |
|    clip_fraction         | 0.00937      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 1.13         |
|    cost_values           | 1.49         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.96         |
|    n_updates             | 9150         |
|    policy_gradient_loss  | -0.000444    |
|    std                   | 0.491        |
|    value_loss            | 4.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.79790795  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1205         |
|    total_timesteps       | 1878016      |
| train/                   |              |
|    approx_kl             | 0.0045169303 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 6.23         |
|    cost_values           | 1.72         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.8          |
|    n_updates             | 9160         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.49         |
|    value_loss            | 6.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.70049465  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1240         |
|    total_timesteps       | 1880064      |
| train/                   |              |
|    approx_kl             | 0.0036512814 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 5.75         |
|    cost_values           | 2.06         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.53         |
|    n_updates             | 9170         |
|    policy_gradient_loss  | -0.000703    |
|    std                   | 0.49         |
|    value_loss            | 4.41         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0149436    |
| rollout/                 |               |
|    ep_len_mean           | 986           |
|    ep_rew_mean           | -678          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 37            |
|    time_elapsed          | 1275          |
|    total_timesteps       | 1882112       |
| train/                   |               |
|    approx_kl             | 0.00085920433 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.96          |
|    cost_value_loss       | 16.9          |
|    cost_values           | 2.15          |
|    entropy               | -1.41         |
|    entropy_loss          | -1.41         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.9          |
|    n_updates             | 9180          |
|    policy_gradient_loss  | -0.000111     |
|    std                   | 0.49          |
|    value_loss            | 10.3          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.74420696 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -678        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1311        |
|    total_timesteps       | 1884160     |
| train/                   |             |
|    approx_kl             | 0.003228391 |
|    clip_fraction         | 0.012       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.34        |
|    cost_value_loss       | 1.7         |
|    cost_values           | 2.28        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.72        |
|    n_updates             | 9190        |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.489       |
|    value_loss            | 5.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.36245617  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1346         |
|    total_timesteps       | 1886208      |
| train/                   |              |
|    approx_kl             | 0.0017214732 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 14.2         |
|    cost_values           | 2.28         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 9200         |
|    policy_gradient_loss  | -0.000261    |
|    std                   | 0.489        |
|    value_loss            | 16.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5201789   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1381         |
|    total_timesteps       | 1888256      |
| train/                   |              |
|    approx_kl             | 0.0035807723 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.49         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.6          |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.86         |
|    n_updates             | 9210         |
|    policy_gradient_loss  | -0.000721    |
|    std                   | 0.49         |
|    value_loss            | 3.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9515501  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -673        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1416        |
|    total_timesteps       | 1890304     |
| train/                   |             |
|    approx_kl             | 0.005882786 |
|    clip_fraction         | 0.0215      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 2.22        |
|    cost_values           | 2.77        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 9220        |
|    policy_gradient_loss  | -0.000525   |
|    std                   | 0.486       |
|    value_loss            | 9.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0826887  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1451        |
|    total_timesteps       | 1892352     |
| train/                   |             |
|    approx_kl             | 0.002210588 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 2.91        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00576     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.53        |
|    n_updates             | 9230        |
|    policy_gradient_loss  | -0.000893   |
|    std                   | 0.485       |
|    value_loss            | 14          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9618428   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1485         |
|    total_timesteps       | 1894400      |
| train/                   |              |
|    approx_kl             | 0.0059063844 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 0.198        |
|    cost_values           | 2.82         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.61         |
|    n_updates             | 9240         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.485        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.866565   |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1520        |
|    total_timesteps       | 1896448     |
| train/                   |             |
|    approx_kl             | 0.005111395 |
|    clip_fraction         | 0.046       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.47        |
|    cost_value_loss       | 1.26        |
|    cost_values           | 2.42        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.2        |
|    n_updates             | 9250        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.487       |
|    value_loss            | 41.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67367554  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1555         |
|    total_timesteps       | 1898496      |
| train/                   |              |
|    approx_kl             | 0.0012854035 |
|    clip_fraction         | 0.0446       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 0.771        |
|    cost_values           | 2.29         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.62         |
|    n_updates             | 9260         |
|    policy_gradient_loss  | 0.000139     |
|    std                   | 0.487        |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.80043477 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1590        |
|    total_timesteps       | 1900544     |
| train/                   |             |
|    approx_kl             | 0.003282817 |
|    clip_fraction         | 0.0382      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 2.71        |
|    cost_values           | 2.21        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.67        |
|    n_updates             | 9270        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.486       |
|    value_loss            | 1.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6977185   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1625         |
|    total_timesteps       | 1902592      |
| train/                   |              |
|    approx_kl             | 0.0035843896 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.17         |
|    cost_value_loss       | 5.42         |
|    cost_values           | 2.51         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.72         |
|    n_updates             | 9280         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.485        |
|    value_loss            | 2.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.34180212  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1660         |
|    total_timesteps       | 1904640      |
| train/                   |              |
|    approx_kl             | 0.0023927474 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.94         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 2.82         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0144       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.45         |
|    n_updates             | 9290         |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.485        |
|    value_loss            | 2.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49957302  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1695         |
|    total_timesteps       | 1906688      |
| train/                   |              |
|    approx_kl             | 0.0045677954 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.28         |
|    cost_value_loss       | 17.5         |
|    cost_values           | 2.99         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00464      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 9300         |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.485        |
|    value_loss            | 9.39         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.39380744 |
| rollout/           |             |
|    ep_len_mean     | 989         |
|    ep_rew_mean     | -688        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1908736     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0106833   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 1910784      |
| train/                   |              |
|    approx_kl             | 0.0037937446 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 0.213        |
|    cost_values           | 2.85         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.89         |
|    n_updates             | 9320         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.485        |
|    value_loss            | 5.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8666419   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1912832      |
| train/                   |              |
|    approx_kl             | 0.0032369674 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 0.122        |
|    cost_values           | 2.42         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 9330         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.486        |
|    value_loss            | 15.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.71581715  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1914880      |
| train/                   |              |
|    approx_kl             | 0.0038762274 |
|    clip_fraction         | 0.00776      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.81         |
|    cost_value_loss       | 4.12         |
|    cost_values           | 2.14         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.4         |
|    n_updates             | 9340         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.486        |
|    value_loss            | 38.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6636563   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1916928      |
| train/                   |              |
|    approx_kl             | 0.0061158263 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 0.669        |
|    cost_values           | 1.99         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.66         |
|    n_updates             | 9350         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.485        |
|    value_loss            | 6.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3837469   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1918976      |
| train/                   |              |
|    approx_kl             | 0.0020847914 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.78         |
|    cost_value_loss       | 9.22         |
|    cost_values           | 2.06         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 9360         |
|    policy_gradient_loss  | 0.000154     |
|    std                   | 0.484        |
|    value_loss            | 8.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.91799563 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -689        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 232         |
|    total_timesteps       | 1921024     |
| train/                   |             |
|    approx_kl             | 0.005044516 |
|    clip_fraction         | 0.0114      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.9         |
|    cost_value_loss       | 0.165       |
|    cost_values           | 2.25        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 9370        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.485       |
|    value_loss            | 5.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6939122   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 1923072      |
| train/                   |              |
|    approx_kl             | 0.0045777163 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 6.48         |
|    cost_values           | 2.01         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.58         |
|    n_updates             | 9380         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.485        |
|    value_loss            | 11.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7293638  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 302         |
|    total_timesteps       | 1925120     |
| train/                   |             |
|    approx_kl             | 0.005144556 |
|    clip_fraction         | 0.0122      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.5         |
|    cost_value_loss       | 3.57        |
|    cost_values           | 2.19        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.46        |
|    n_updates             | 9390        |
|    policy_gradient_loss  | -0.000546   |
|    std                   | 0.485       |
|    value_loss            | 3.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48936725  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 1927168      |
| train/                   |              |
|    approx_kl             | 0.0034536486 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.01         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 2.63         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.82         |
|    n_updates             | 9400         |
|    policy_gradient_loss  | -2.55e-05    |
|    std                   | 0.484        |
|    value_loss            | 1.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7943792   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 372          |
|    total_timesteps       | 1929216      |
| train/                   |              |
|    approx_kl             | 0.0035658656 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.58         |
|    cost_value_loss       | 6.54         |
|    cost_values           | 2.94         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 9410         |
|    policy_gradient_loss  | -0.000899    |
|    std                   | 0.484        |
|    value_loss            | 9.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7965086  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -687        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 407         |
|    total_timesteps       | 1931264     |
| train/                   |             |
|    approx_kl             | 0.005234169 |
|    clip_fraction         | 0.0204      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 17.7        |
|    cost_values           | 2.98        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.65        |
|    n_updates             | 9420        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.483       |
|    value_loss            | 4.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40874422  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 441          |
|    total_timesteps       | 1933312      |
| train/                   |              |
|    approx_kl             | 0.0019695698 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 0.209        |
|    cost_values           | 2.79         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.66         |
|    n_updates             | 9430         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.483        |
|    value_loss            | 9.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.80429965  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 1935360      |
| train/                   |              |
|    approx_kl             | 0.0058952663 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.12         |
|    cost_value_loss       | 4.49         |
|    cost_values           | 2.56         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 9440         |
|    policy_gradient_loss  | -0.00061     |
|    std                   | 0.484        |
|    value_loss            | 28.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.558945   |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 511         |
|    total_timesteps       | 1937408     |
| train/                   |             |
|    approx_kl             | 0.004381331 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 4.92        |
|    cost_values           | 2.88        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 9450        |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.484       |
|    value_loss            | 20.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.65026426  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 545          |
|    total_timesteps       | 1939456      |
| train/                   |              |
|    approx_kl             | 0.0020674118 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 0.339        |
|    cost_values           | 2.88         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.12         |
|    n_updates             | 9460         |
|    policy_gradient_loss  | -0.000395    |
|    std                   | 0.484        |
|    value_loss            | 9.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5794396   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 580          |
|    total_timesteps       | 1941504      |
| train/                   |              |
|    approx_kl             | 0.0011306466 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 0.426        |
|    cost_values           | 2.4          |
|    entropy               | -1.4         |
|    entropy_loss          | -1.39        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.91         |
|    n_updates             | 9470         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.488        |
|    value_loss            | 5.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0257132   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 615          |
|    total_timesteps       | 1943552      |
| train/                   |              |
|    approx_kl             | 0.0057066926 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 15           |
|    cost_values           | 2.39         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 9480         |
|    policy_gradient_loss  | -0.000878    |
|    std                   | 0.489        |
|    value_loss            | 13.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.3522178    |
| rollout/                 |               |
|    ep_len_mean           | 987           |
|    ep_rew_mean           | -696          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 19            |
|    time_elapsed          | 649           |
|    total_timesteps       | 1945600       |
| train/                   |               |
|    approx_kl             | 0.00031425606 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.93          |
|    cost_value_loss       | 11            |
|    cost_values           | 2.83          |
|    entropy               | -1.41         |
|    entropy_loss          | -1.41         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0.00116       |
|    learning_rate         | 0.0003        |
|    loss                  | 6.24          |
|    n_updates             | 9490          |
|    policy_gradient_loss  | 0.000112      |
|    std                   | 0.489         |
|    value_loss            | 6.64          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4840446   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 684          |
|    total_timesteps       | 1947648      |
| train/                   |              |
|    approx_kl             | 0.0011720725 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 4.91         |
|    cost_values           | 2.93         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 9500         |
|    policy_gradient_loss  | -0.000271    |
|    std                   | 0.488        |
|    value_loss            | 20.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9073675  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 719         |
|    total_timesteps       | 1949696     |
| train/                   |             |
|    approx_kl             | 0.002472313 |
|    clip_fraction         | 0.0284      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 3.65        |
|    cost_values           | 2.83        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 9510        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.487       |
|    value_loss            | 5.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7835489   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 754          |
|    total_timesteps       | 1951744      |
| train/                   |              |
|    approx_kl             | 0.0028758564 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 0.766        |
|    cost_values           | 2.77         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.4         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 9520         |
|    policy_gradient_loss  | -0.0005      |
|    std                   | 0.486        |
|    value_loss            | 8.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48701146  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 789          |
|    total_timesteps       | 1953792      |
| train/                   |              |
|    approx_kl             | 0.0052410644 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 1.66         |
|    cost_values           | 2.5          |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25           |
|    n_updates             | 9530         |
|    policy_gradient_loss  | -0.000516    |
|    std                   | 0.486        |
|    value_loss            | 31.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.31694672  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 823          |
|    total_timesteps       | 1955840      |
| train/                   |              |
|    approx_kl             | 0.0058307704 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.58         |
|    cost_value_loss       | 8.31         |
|    cost_values           | 2.58         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.63         |
|    n_updates             | 9540         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.485        |
|    value_loss            | 7.1          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.58681864 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -689        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 858         |
|    total_timesteps       | 1957888     |
| train/                   |             |
|    approx_kl             | 0.003052208 |
|    clip_fraction         | 0.0219      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.61        |
|    cost_value_loss       | 1.86        |
|    cost_values           | 2.73        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.28        |
|    n_updates             | 9550        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.482       |
|    value_loss            | 9.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.62496966 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -687        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 893         |
|    total_timesteps       | 1959936     |
| train/                   |             |
|    approx_kl             | 0.001790841 |
|    clip_fraction         | 0.000195    |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 18.7        |
|    cost_values           | 2.58        |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.5        |
|    n_updates             | 9560        |
|    policy_gradient_loss  | -0.00039    |
|    std                   | 0.481       |
|    value_loss            | 11.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.557511    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 928          |
|    total_timesteps       | 1961984      |
| train/                   |              |
|    approx_kl             | 0.0072559025 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 8.55         |
|    cost_values           | 2.85         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.6          |
|    n_updates             | 9570         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.482        |
|    value_loss            | 4.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4628772   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 964          |
|    total_timesteps       | 1964032      |
| train/                   |              |
|    approx_kl             | 0.0067129144 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.2          |
|    cost_value_loss       | 17.6         |
|    cost_values           | 3            |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00684      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.36         |
|    n_updates             | 9580         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.481        |
|    value_loss            | 1.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9050438  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -680        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 1000        |
|    total_timesteps       | 1966080     |
| train/                   |             |
|    approx_kl             | 0.003949424 |
|    clip_fraction         | 0.00415     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 3           |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00399     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 9590        |
|    policy_gradient_loss  | -0.000499   |
|    std                   | 0.481       |
|    value_loss            | 7.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.46678954  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1036         |
|    total_timesteps       | 1968128      |
| train/                   |              |
|    approx_kl             | 0.0043624043 |
|    clip_fraction         | 0.00479      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 1.14         |
|    cost_values           | 2.87         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.13         |
|    n_updates             | 9600         |
|    policy_gradient_loss  | -0.000697    |
|    std                   | 0.483        |
|    value_loss            | 7.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9959283   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1072         |
|    total_timesteps       | 1970176      |
| train/                   |              |
|    approx_kl             | 0.0017945702 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 0.371        |
|    cost_values           | 2.55         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 9610         |
|    policy_gradient_loss  | -9.23e-05    |
|    std                   | 0.483        |
|    value_loss            | 25.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5516661   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1107         |
|    total_timesteps       | 1972224      |
| train/                   |              |
|    approx_kl             | 0.0052407067 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.01         |
|    cost_value_loss       | 5.83         |
|    cost_values           | 2.43         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.44         |
|    n_updates             | 9620         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.483        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7846919   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1143         |
|    total_timesteps       | 1974272      |
| train/                   |              |
|    approx_kl             | 0.0042907717 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 0.321        |
|    cost_values           | 2.33         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.08         |
|    n_updates             | 9630         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.479        |
|    value_loss            | 9.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0024455   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1178         |
|    total_timesteps       | 1976320      |
| train/                   |              |
|    approx_kl             | 0.0016894694 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 0.361        |
|    cost_values           | 1.86         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.59         |
|    n_updates             | 9640         |
|    policy_gradient_loss  | -0.000393    |
|    std                   | 0.478        |
|    value_loss            | 4.46         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4306761  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -682        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1213        |
|    total_timesteps       | 1978368     |
| train/                   |             |
|    approx_kl             | 0.007785779 |
|    clip_fraction         | 0.0112      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 0.0544      |
|    cost_values           | 1.55        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.08        |
|    n_updates             | 9650        |
|    policy_gradient_loss  | 0.000406    |
|    std                   | 0.478       |
|    value_loss            | 10          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89873135  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1248         |
|    total_timesteps       | 1980416      |
| train/                   |              |
|    approx_kl             | 0.0039720936 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 0.576        |
|    cost_values           | 1.26         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.8          |
|    n_updates             | 9660         |
|    policy_gradient_loss  | -0.000702    |
|    std                   | 0.478        |
|    value_loss            | 16.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.81246984   |
| rollout/                 |               |
|    ep_len_mean           | 982           |
|    ep_rew_mean           | -684          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 37            |
|    time_elapsed          | 1283          |
|    total_timesteps       | 1982464       |
| train/                   |               |
|    approx_kl             | 0.00079247897 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.04          |
|    cost_value_loss       | 4.69          |
|    cost_values           | 1.31          |
|    entropy               | -1.36         |
|    entropy_loss          | -1.36         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.95          |
|    n_updates             | 9670          |
|    policy_gradient_loss  | 8.73e-05      |
|    std                   | 0.478         |
|    value_loss            | 8.55          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.9556067    |
| rollout/                 |               |
|    ep_len_mean           | 982           |
|    ep_rew_mean           | -686          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1318          |
|    total_timesteps       | 1984512       |
| train/                   |               |
|    approx_kl             | 0.00013837879 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.11          |
|    cost_value_loss       | 0.0421        |
|    cost_values           | 1.27          |
|    entropy               | -1.36         |
|    entropy_loss          | -1.36         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.8           |
|    n_updates             | 9680          |
|    policy_gradient_loss  | -6.21e-05     |
|    std                   | 0.478         |
|    value_loss            | 9.79          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.83850986  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1353         |
|    total_timesteps       | 1986560      |
| train/                   |              |
|    approx_kl             | 0.0037839492 |
|    clip_fraction         | 0.00396      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 1.2          |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8            |
|    n_updates             | 9690         |
|    policy_gradient_loss  | -0.000787    |
|    std                   | 0.479        |
|    value_loss            | 5.27         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.7599833 |
| rollout/                 |            |
|    ep_len_mean           | 982        |
|    ep_rew_mean           | -691       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 40         |
|    time_elapsed          | 1388       |
|    total_timesteps       | 1988608    |
| train/                   |            |
|    approx_kl             | 0.00432323 |
|    clip_fraction         | 0.00645    |
|    clip_range            | 0.2        |
|    cost_returns          | 3.07       |
|    cost_value_loss       | 10.7       |
|    cost_values           | 1.6        |
|    entropy               | -1.36      |
|    entropy_loss          | -1.36      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.53       |
|    n_updates             | 9700       |
|    policy_gradient_loss  | -0.00101   |
|    std                   | 0.478      |
|    value_loss            | 7.04       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.83004117  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1422         |
|    total_timesteps       | 1990656      |
| train/                   |              |
|    approx_kl             | 0.0053036525 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.24         |
|    cost_value_loss       | 9.3          |
|    cost_values           | 2.09         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 9710         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.478        |
|    value_loss            | 3.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8117136   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1457         |
|    total_timesteps       | 1992704      |
| train/                   |              |
|    approx_kl             | 0.0018043255 |
|    clip_fraction         | 0.042        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 0.719        |
|    cost_values           | 2.25         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.71         |
|    n_updates             | 9720         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.479        |
|    value_loss            | 6.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.46         |
| reward                   | -0.6030122   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 43           |
|    time_elapsed          | 1492         |
|    total_timesteps       | 1994752      |
| train/                   |              |
|    approx_kl             | 0.0055298526 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 2.41         |
|    cost_values           | 2.04         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 9730         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.48         |
|    value_loss            | 5.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7323979   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 44           |
|    time_elapsed          | 1528         |
|    total_timesteps       | 1996800      |
| train/                   |              |
|    approx_kl             | 0.0025472618 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 0.355        |
|    cost_values           | 1.99         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.75         |
|    n_updates             | 9740         |
|    policy_gradient_loss  | 0.000268     |
|    std                   | 0.48         |
|    value_loss            | 8.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.862898    |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 45           |
|    time_elapsed          | 1562         |
|    total_timesteps       | 1998848      |
| train/                   |              |
|    approx_kl             | 0.0032205388 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.79         |
|    cost_value_loss       | 19.3         |
|    cost_values           | 1.93         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 9750         |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.48         |
|    value_loss            | 5.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57541895  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 46           |
|    time_elapsed          | 1598         |
|    total_timesteps       | 2000896      |
| train/                   |              |
|    approx_kl             | 0.0025910349 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 0.134        |
|    cost_values           | 2.05         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.27         |
|    n_updates             | 9760         |
|    policy_gradient_loss  | -0.000596    |
|    std                   | 0.48         |
|    value_loss            | 5.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5186156   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 47           |
|    time_elapsed          | 1633         |
|    total_timesteps       | 2002944      |
| train/                   |              |
|    approx_kl             | 0.0018459021 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 1.96         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.16         |
|    n_updates             | 9770         |
|    policy_gradient_loss  | -0.000413    |
|    std                   | 0.481        |
|    value_loss            | 3.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78357315  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 48           |
|    time_elapsed          | 1669         |
|    total_timesteps       | 2004992      |
| train/                   |              |
|    approx_kl             | 0.0010133458 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 2.48         |
|    cost_values           | 2.21         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 9780         |
|    policy_gradient_loss  | -0.000234    |
|    std                   | 0.481        |
|    value_loss            | 30.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.59744954  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 49           |
|    time_elapsed          | 1704         |
|    total_timesteps       | 2007040      |
| train/                   |              |
|    approx_kl             | 0.0025283417 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.75         |
|    cost_value_loss       | 9.73         |
|    cost_values           | 2.2          |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.4         |
|    n_updates             | 9790         |
|    policy_gradient_loss  | -0.000948    |
|    std                   | 0.48         |
|    value_loss            | 26.2         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.4617314 |
| rollout/           |            |
|    ep_len_mean     | 975        |
|    ep_rew_mean     | -676       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2009088    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1836947   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2011136      |
| train/                   |              |
|    approx_kl             | 0.0046901796 |
|    clip_fraction         | 0.0515       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 0.63         |
|    cost_values           | 2.39         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.1          |
|    n_updates             | 9810         |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 0.48         |
|    value_loss            | 9.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89354706  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 2013184      |
| train/                   |              |
|    approx_kl             | 0.0035803905 |
|    clip_fraction         | 0.00264      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 0.918        |
|    cost_values           | 2.07         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.27         |
|    n_updates             | 9820         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.48         |
|    value_loss            | 17.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4820052   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2015232      |
| train/                   |              |
|    approx_kl             | 0.0013934126 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 0.0688       |
|    cost_values           | 1.77         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 9830         |
|    policy_gradient_loss  | -0.000654    |
|    std                   | 0.481        |
|    value_loss            | 25.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7688353   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 2017280      |
| train/                   |              |
|    approx_kl             | 0.0038058306 |
|    clip_fraction         | 0.00527      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 4.58         |
|    cost_values           | 1.57         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.99         |
|    n_updates             | 9840         |
|    policy_gradient_loss  | -0.000557    |
|    std                   | 0.48         |
|    value_loss            | 6.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7085746   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 2019328      |
| train/                   |              |
|    approx_kl             | 0.0048393295 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 3.85         |
|    cost_values           | 1.57         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.97         |
|    n_updates             | 9850         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.479        |
|    value_loss            | 6.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.71733874  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 233          |
|    total_timesteps       | 2021376      |
| train/                   |              |
|    approx_kl             | 0.0027226114 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.94         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 1.73         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.98         |
|    n_updates             | 9860         |
|    policy_gradient_loss  | -0.000617    |
|    std                   | 0.479        |
|    value_loss            | 4.29         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.7042776 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -683       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 8          |
|    time_elapsed          | 268        |
|    total_timesteps       | 2023424    |
| train/                   |            |
|    approx_kl             | 0.00359788 |
|    clip_fraction         | 0.00356    |
|    clip_range            | 0.2        |
|    cost_returns          | 4.44       |
|    cost_value_loss       | 17.6       |
|    cost_values           | 2.23       |
|    entropy               | -1.37      |
|    entropy_loss          | -1.37      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 11.5       |
|    n_updates             | 9870       |
|    policy_gradient_loss  | -0.00052   |
|    std                   | 0.479      |
|    value_loss            | 6.9        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0835264   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 2025472      |
| train/                   |              |
|    approx_kl             | 0.0023224354 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 10.3         |
|    cost_values           | 2.75         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0063       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.29         |
|    n_updates             | 9880         |
|    policy_gradient_loss  | -0.000447    |
|    std                   | 0.478        |
|    value_loss            | 5.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0327802   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 2027520      |
| train/                   |              |
|    approx_kl             | 0.0064320657 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 0.306        |
|    cost_values           | 2.9          |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.59         |
|    n_updates             | 9890         |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.477        |
|    value_loss            | 14.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.552188    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 372          |
|    total_timesteps       | 2029568      |
| train/                   |              |
|    approx_kl             | 0.0011819039 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 0.306        |
|    cost_values           | 2.56         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.98         |
|    n_updates             | 9900         |
|    policy_gradient_loss  | -0.000191    |
|    std                   | 0.478        |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.52130616  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 407          |
|    total_timesteps       | 2031616      |
| train/                   |              |
|    approx_kl             | 0.0011921994 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.4          |
|    cost_value_loss       | 8.77         |
|    cost_values           | 2.37         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.01         |
|    n_updates             | 9910         |
|    policy_gradient_loss  | -0.000191    |
|    std                   | 0.478        |
|    value_loss            | 9.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.13        |
| reward                   | -0.5240931  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 441         |
|    total_timesteps       | 2033664     |
| train/                   |             |
|    approx_kl             | 0.001983635 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.29        |
|    cost_value_loss       | 1.03        |
|    cost_values           | 2.36        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.88        |
|    n_updates             | 9920        |
|    policy_gradient_loss  | -0.000397   |
|    std                   | 0.478       |
|    value_loss            | 11.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6952317   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 2035712      |
| train/                   |              |
|    approx_kl             | 0.0049058436 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 0.0953       |
|    cost_values           | 2.07         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.71         |
|    n_updates             | 9930         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.478        |
|    value_loss            | 8.96         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0023452    |
| rollout/                 |               |
|    ep_len_mean           | 984           |
|    ep_rew_mean           | -700          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 15            |
|    time_elapsed          | 511           |
|    total_timesteps       | 2037760       |
| train/                   |               |
|    approx_kl             | 0.00020765938 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.95          |
|    cost_value_loss       | 12.5          |
|    cost_values           | 1.88          |
|    entropy               | -1.36         |
|    entropy_loss          | -1.36         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13.6          |
|    n_updates             | 9940          |
|    policy_gradient_loss  | 0.000169      |
|    std                   | 0.478         |
|    value_loss            | 15.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7351139   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 546          |
|    total_timesteps       | 2039808      |
| train/                   |              |
|    approx_kl             | 0.0019763412 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 0.109        |
|    cost_values           | 1.89         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.1         |
|    n_updates             | 9950         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.478        |
|    value_loss            | 49.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6561571   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 582          |
|    total_timesteps       | 2041856      |
| train/                   |              |
|    approx_kl             | 0.0007674462 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 0.158        |
|    cost_values           | 1.61         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.47         |
|    n_updates             | 9960         |
|    policy_gradient_loss  | 3.84e-05     |
|    std                   | 0.478        |
|    value_loss            | 16.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.46378863 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 617         |
|    total_timesteps       | 2043904     |
| train/                   |             |
|    approx_kl             | 0.005349407 |
|    clip_fraction         | 0.0217      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 19.9        |
|    cost_values           | 1.55        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18          |
|    n_updates             | 9970        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.478       |
|    value_loss            | 16.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5453007   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 652          |
|    total_timesteps       | 2045952      |
| train/                   |              |
|    approx_kl             | 0.0037338967 |
|    clip_fraction         | 0.00688      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 6.4          |
|    cost_values           | 1.86         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.74         |
|    n_updates             | 9980         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.477        |
|    value_loss            | 8.61         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.45788914 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 687         |
|    total_timesteps       | 2048000     |
| train/                   |             |
|    approx_kl             | 0.004832607 |
|    clip_fraction         | 0.0157      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.37        |
|    cost_value_loss       | 3.39        |
|    cost_values           | 2.03        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.48        |
|    n_updates             | 9990        |
|    policy_gradient_loss  | -0.000205   |
|    std                   | 0.476       |
|    value_loss            | 8.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6491046   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 722          |
|    total_timesteps       | 2050048      |
| train/                   |              |
|    approx_kl             | 0.0030733042 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.03         |
|    cost_value_loss       | 24.2         |
|    cost_values           | 2.34         |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 10000        |
|    policy_gradient_loss  | -0.000123    |
|    std                   | 0.476        |
|    value_loss            | 12.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80017436 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -702        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 757         |
|    total_timesteps       | 2052096     |
| train/                   |             |
|    approx_kl             | 0.004018477 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.71        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.79        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.0035      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.46        |
|    n_updates             | 10010       |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.477       |
|    value_loss            | 15.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3066321   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 792          |
|    total_timesteps       | 2054144      |
| train/                   |              |
|    approx_kl             | 0.0044126436 |
|    clip_fraction         | 0.00479      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.75         |
|    cost_value_loss       | 1.03         |
|    cost_values           | 2.86         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.06         |
|    n_updates             | 10020        |
|    policy_gradient_loss  | -0.000701    |
|    std                   | 0.477        |
|    value_loss            | 11.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.88618004 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 827         |
|    total_timesteps       | 2056192     |
| train/                   |             |
|    approx_kl             | 0.00518445  |
|    clip_fraction         | 0.0379      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.33        |
|    cost_value_loss       | 12          |
|    cost_values           | 2.76        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 10030       |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.477       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5854106   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 862          |
|    total_timesteps       | 2058240      |
| train/                   |              |
|    approx_kl             | 0.0043312437 |
|    clip_fraction         | 0.0567       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.98         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0049       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.01         |
|    n_updates             | 10040        |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 0.477        |
|    value_loss            | 7.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.08         |
| reward                   | -0.652418    |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 897          |
|    total_timesteps       | 2060288      |
| train/                   |              |
|    approx_kl             | 0.0012549988 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.01         |
|    cost_value_loss       | 8.25         |
|    cost_values           | 3            |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0.00368      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.32         |
|    n_updates             | 10050        |
|    policy_gradient_loss  | -0.000207    |
|    std                   | 0.478        |
|    value_loss            | 5.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66970235  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 931          |
|    total_timesteps       | 2062336      |
| train/                   |              |
|    approx_kl             | 0.0067632813 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 5.39         |
|    cost_values           | 2.99         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00224      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.17         |
|    n_updates             | 10060        |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.478        |
|    value_loss            | 29.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5520539  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -706        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 966         |
|    total_timesteps       | 2064384     |
| train/                   |             |
|    approx_kl             | 0.005051854 |
|    clip_fraction         | 0.0287      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 0.182       |
|    cost_values           | 2.79        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.55        |
|    n_updates             | 10070       |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.477       |
|    value_loss            | 3.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4882045   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 1002         |
|    total_timesteps       | 2066432      |
| train/                   |              |
|    approx_kl             | 0.0030619274 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 0.0952       |
|    cost_values           | 2.17         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.19         |
|    n_updates             | 10080        |
|    policy_gradient_loss  | -0.000466    |
|    std                   | 0.471        |
|    value_loss            | 4.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78768784  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1036         |
|    total_timesteps       | 2068480      |
| train/                   |              |
|    approx_kl             | 0.0032769633 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.23         |
|    cost_value_loss       | 16           |
|    cost_values           | 2.11         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 10090        |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.47         |
|    value_loss            | 15           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9271116  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1071        |
|    total_timesteps       | 2070528     |
| train/                   |             |
|    approx_kl             | 0.006031436 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.88        |
|    cost_value_loss       | 0.114       |
|    cost_values           | 2.12        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.15        |
|    n_updates             | 10100       |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.469       |
|    value_loss            | 2.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.97807515  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1106         |
|    total_timesteps       | 2072576      |
| train/                   |              |
|    approx_kl             | 0.0019050721 |
|    clip_fraction         | 0.0574       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 0.0543       |
|    cost_values           | 1.64         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 10110        |
|    policy_gradient_loss  | 0.00131      |
|    std                   | 0.469        |
|    value_loss            | 16.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.61016625 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1141        |
|    total_timesteps       | 2074624     |
| train/                   |             |
|    approx_kl             | 0.005657263 |
|    clip_fraction         | 0.0189      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 0.0346      |
|    cost_values           | 1.34        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 10120       |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.469       |
|    value_loss            | 9.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8244418   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1175         |
|    total_timesteps       | 2076672      |
| train/                   |              |
|    approx_kl             | 0.0036617876 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.36         |
|    cost_value_loss       | 7.17         |
|    cost_values           | 1.29         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.66         |
|    n_updates             | 10130        |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.469        |
|    value_loss            | 9.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.51459944  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1210         |
|    total_timesteps       | 2078720      |
| train/                   |              |
|    approx_kl             | 0.0048899427 |
|    clip_fraction         | 0.0295       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 4.16         |
|    cost_values           | 1.75         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.32         |
|    n_updates             | 10140        |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.469        |
|    value_loss            | 4.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7329262   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1246         |
|    total_timesteps       | 2080768      |
| train/                   |              |
|    approx_kl             | 0.0004901566 |
|    clip_fraction         | 0.00947      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 0.903        |
|    cost_values           | 1.87         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.49         |
|    n_updates             | 10150        |
|    policy_gradient_loss  | -0.000441    |
|    std                   | 0.469        |
|    value_loss            | 3.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7721561   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1281         |
|    total_timesteps       | 2082816      |
| train/                   |              |
|    approx_kl             | 0.0003001694 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 1.81         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.5         |
|    n_updates             | 10160        |
|    policy_gradient_loss  | 0.000829     |
|    std                   | 0.469        |
|    value_loss            | 32.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8399646   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1316         |
|    total_timesteps       | 2084864      |
| train/                   |              |
|    approx_kl             | 0.0040500746 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 2.94         |
|    cost_values           | 1.9          |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.68         |
|    n_updates             | 10170        |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.468        |
|    value_loss            | 6.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8603867  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1350        |
|    total_timesteps       | 2086912     |
| train/                   |             |
|    approx_kl             | 0.000525853 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 5.58        |
|    cost_values           | 2.04        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 10180       |
|    policy_gradient_loss  | 0.000122    |
|    std                   | 0.467       |
|    value_loss            | 5.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75938684  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1385         |
|    total_timesteps       | 2088960      |
| train/                   |              |
|    approx_kl             | 0.0036735795 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 0.172        |
|    cost_values           | 2.21         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 10190        |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.468        |
|    value_loss            | 22.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.76        |
| reward                   | -0.6660329  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1420        |
|    total_timesteps       | 2091008     |
| train/                   |             |
|    approx_kl             | 0.004737194 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.68        |
|    cost_value_loss       | 4.9         |
|    cost_values           | 2.16        |
|    entropy               | -1.31       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 10200       |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.467       |
|    value_loss            | 4.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47182482  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1454         |
|    total_timesteps       | 2093056      |
| train/                   |              |
|    approx_kl             | 0.0010510283 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 7.88         |
|    cost_values           | 2.43         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.44         |
|    n_updates             | 10210        |
|    policy_gradient_loss  | 0.000587     |
|    std                   | 0.466        |
|    value_loss            | 7.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41518512  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1489         |
|    total_timesteps       | 2095104      |
| train/                   |              |
|    approx_kl             | 0.0027308199 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 2.43         |
|    cost_values           | 2.46         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.89         |
|    n_updates             | 10220        |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.461        |
|    value_loss            | 3.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.45953503 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1524        |
|    total_timesteps       | 2097152     |
| train/                   |             |
|    approx_kl             | 0.00524158  |
|    clip_fraction         | 0.0122      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.28        |
|    cost_value_loss       | 8.9         |
|    cost_values           | 2.52        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.45        |
|    n_updates             | 10230       |
|    policy_gradient_loss  | -0.000481   |
|    std                   | 0.46        |
|    value_loss            | 6.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.23428217  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1559         |
|    total_timesteps       | 2099200      |
| train/                   |              |
|    approx_kl             | 0.0023406781 |
|    clip_fraction         | 0.0427       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 0.131        |
|    cost_values           | 2.37         |
|    entropy               | -1.28        |
|    entropy_loss          | -1.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.52         |
|    n_updates             | 10240        |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.46         |
|    value_loss            | 6.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9806322  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -710        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1594        |
|    total_timesteps       | 2101248     |
| train/                   |             |
|    approx_kl             | 0.004086254 |
|    clip_fraction         | 0.0498      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.28        |
|    cost_value_loss       | 8.37        |
|    cost_values           | 2.15        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.44        |
|    n_updates             | 10250       |
|    policy_gradient_loss  | -0.000933   |
|    std                   | 0.459       |
|    value_loss            | 4.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.81527007  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1629         |
|    total_timesteps       | 2103296      |
| train/                   |              |
|    approx_kl             | 0.0046379515 |
|    clip_fraction         | 0.00796      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.52         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 2.5          |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.7         |
|    n_updates             | 10260        |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.459        |
|    value_loss            | 16.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.42671528 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1664        |
|    total_timesteps       | 2105344     |
| train/                   |             |
|    approx_kl             | 0.007678987 |
|    clip_fraction         | 0.0505      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.48        |
|    cost_value_loss       | 5.08        |
|    cost_values           | 2.7         |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 10270       |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.459       |
|    value_loss            | 5.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.58986455  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1699         |
|    total_timesteps       | 2107392      |
| train/                   |              |
|    approx_kl             | 0.0004352289 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.17         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 2.86         |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0113       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.13         |
|    n_updates             | 10280        |
|    policy_gradient_loss  | -0.000121    |
|    std                   | 0.459        |
|    value_loss            | 30.1         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
----------------------------------
| avg_speed          | 8         |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 8         |
| reward             | -0.880813 |
| rollout/           |           |
|    ep_len_mean     | 993       |
|    ep_rew_mean     | -719      |
| time/              |           |
|    fps             | 83        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 2109440   |
----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45710966  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2111488      |
| train/                   |              |
|    approx_kl             | 0.0018747007 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 0.379        |
|    cost_values           | 2.65         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.74         |
|    n_updates             | 10300        |
|    policy_gradient_loss  | -0.000845    |
|    std                   | 0.464        |
|    value_loss            | 3.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7631911   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 2113536      |
| train/                   |              |
|    approx_kl             | 0.0047131553 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.63         |
|    cost_value_loss       | 2.57         |
|    cost_values           | 2.32         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6            |
|    n_updates             | 10310        |
|    policy_gradient_loss  | -0.000832    |
|    std                   | 0.464        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.79934055  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2115584      |
| train/                   |              |
|    approx_kl             | 0.0036025573 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 0.518        |
|    cost_values           | 2.13         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.44         |
|    n_updates             | 10320        |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.464        |
|    value_loss            | 9.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.91270715  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 2117632      |
| train/                   |              |
|    approx_kl             | 0.0027666832 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 5.52         |
|    cost_values           | 2.04         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 10330        |
|    policy_gradient_loss  | -0.000929    |
|    std                   | 0.464        |
|    value_loss            | 28           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87463814  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 2119680      |
| train/                   |              |
|    approx_kl             | 0.0019632473 |
|    clip_fraction         | 0.00571      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.91         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 2.42         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 10340        |
|    policy_gradient_loss  | -0.000376    |
|    std                   | 0.464        |
|    value_loss            | 8.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8350767  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 233         |
|    total_timesteps       | 2121728     |
| train/                   |             |
|    approx_kl             | 0.009045753 |
|    clip_fraction         | 0.0588      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 4.86        |
|    cost_values           | 2.72        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.58        |
|    n_updates             | 10350       |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.463       |
|    value_loss            | 5.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6525814   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 268          |
|    total_timesteps       | 2123776      |
| train/                   |              |
|    approx_kl             | 0.0016554161 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.77         |
|    cost_value_loss       | 2.45         |
|    cost_values           | 2.7          |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.78         |
|    n_updates             | 10360        |
|    policy_gradient_loss  | -0.000804    |
|    std                   | 0.463        |
|    value_loss            | 7.46         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.94426954 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -703        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 303         |
|    total_timesteps       | 2125824     |
| train/                   |             |
|    approx_kl             | 0.005307086 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 0.146       |
|    cost_values           | 2.5         |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 10370       |
|    policy_gradient_loss  | -0.000707   |
|    std                   | 0.465       |
|    value_loss            | 4.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1902399   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 2127872      |
| train/                   |              |
|    approx_kl             | 0.0029196837 |
|    clip_fraction         | 0.0022       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.19         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 10380        |
|    policy_gradient_loss  | -0.000986    |
|    std                   | 0.465        |
|    value_loss            | 37.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72224826  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 372          |
|    total_timesteps       | 2129920      |
| train/                   |              |
|    approx_kl             | 0.0011477317 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 0.17         |
|    cost_values           | 2.17         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.2          |
|    n_updates             | 10390        |
|    policy_gradient_loss  | -0.000329    |
|    std                   | 0.465        |
|    value_loss            | 14.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.62347424  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 407          |
|    total_timesteps       | 2131968      |
| train/                   |              |
|    approx_kl             | 0.0010494846 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 0.0942       |
|    cost_values           | 1.84         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.94         |
|    n_updates             | 10400        |
|    policy_gradient_loss  | -7.79e-05    |
|    std                   | 0.465        |
|    value_loss            | 15.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73581564  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 442          |
|    total_timesteps       | 2134016      |
| train/                   |              |
|    approx_kl             | 0.0033839245 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 8.8          |
|    cost_values           | 1.71         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 10410        |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.466        |
|    value_loss            | 18           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.61         |
| reward                   | -0.77321786  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 14           |
|    time_elapsed          | 477          |
|    total_timesteps       | 2136064      |
| train/                   |              |
|    approx_kl             | 0.0039589917 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 5.65         |
|    cost_values           | 1.99         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.62         |
|    n_updates             | 10420        |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.466        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.61336076  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 15           |
|    time_elapsed          | 512          |
|    total_timesteps       | 2138112      |
| train/                   |              |
|    approx_kl             | 0.0030527893 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.54         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.23         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.53         |
|    n_updates             | 10430        |
|    policy_gradient_loss  | -0.000765    |
|    std                   | 0.466        |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42833674 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -702        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 16          |
|    time_elapsed          | 547         |
|    total_timesteps       | 2140160     |
| train/                   |             |
|    approx_kl             | 0.003555811 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 0.614       |
|    cost_values           | 2.38        |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 10440       |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.465       |
|    value_loss            | 3.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.40400636  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 582          |
|    total_timesteps       | 2142208      |
| train/                   |              |
|    approx_kl             | 0.0044523585 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 0.181        |
|    cost_values           | 1.96         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.49         |
|    n_updates             | 10450        |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.462        |
|    value_loss            | 6.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.49082813 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -703        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 617         |
|    total_timesteps       | 2144256     |
| train/                   |             |
|    approx_kl             | 0.004524188 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.46        |
|    cost_value_loss       | 6.11        |
|    cost_values           | 1.91        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.95        |
|    n_updates             | 10460       |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.461       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34417245 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 652         |
|    total_timesteps       | 2146304     |
| train/                   |             |
|    approx_kl             | 0.000198044 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 4.03        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.27        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.79        |
|    n_updates             | 10470       |
|    policy_gradient_loss  | 4.31e-05    |
|    std                   | 0.461       |
|    value_loss            | 7.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3901125  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 687         |
|    total_timesteps       | 2148352     |
| train/                   |             |
|    approx_kl             | 0.004215843 |
|    clip_fraction         | 0.00469     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.58        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.21        |
|    n_updates             | 10480       |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.461       |
|    value_loss            | 7.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.9850507  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -703        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 722         |
|    total_timesteps       | 2150400     |
| train/                   |             |
|    approx_kl             | 0.001427886 |
|    clip_fraction         | 0.000244    |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.9         |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.0076      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 10490       |
|    policy_gradient_loss  | -4.08e-05   |
|    std                   | 0.461       |
|    value_loss            | 8.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.8300141   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 757          |
|    total_timesteps       | 2152448      |
| train/                   |              |
|    approx_kl             | 0.0006047719 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 7.99         |
|    cost_values           | 3            |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00859      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 10500        |
|    policy_gradient_loss  | -0.000182    |
|    std                   | 0.461        |
|    value_loss            | 7.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4033248   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 793          |
|    total_timesteps       | 2154496      |
| train/                   |              |
|    approx_kl             | 0.0016976867 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.04         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 3            |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00938      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 10510        |
|    policy_gradient_loss  | -0.000178    |
|    std                   | 0.461        |
|    value_loss            | 35.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7050861   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 828          |
|    total_timesteps       | 2156544      |
| train/                   |              |
|    approx_kl             | 0.0053708726 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.41         |
|    cost_value_loss       | 3.83         |
|    cost_values           | 2.95         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.44         |
|    n_updates             | 10520        |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.461        |
|    value_loss            | 17.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8091542   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 864          |
|    total_timesteps       | 2158592      |
| train/                   |              |
|    approx_kl             | 0.0035026895 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.88         |
|    cost_value_loss       | 7.41         |
|    cost_values           | 2.93         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00103      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.51         |
|    n_updates             | 10530        |
|    policy_gradient_loss  | -0.000947    |
|    std                   | 0.461        |
|    value_loss            | 6.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40070498  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 899          |
|    total_timesteps       | 2160640      |
| train/                   |              |
|    approx_kl             | 0.0044906638 |
|    clip_fraction         | 0.00791      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 3            |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.00712      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.97         |
|    n_updates             | 10540        |
|    policy_gradient_loss  | -0.000904    |
|    std                   | 0.46         |
|    value_loss            | 7.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.70581126  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 934          |
|    total_timesteps       | 2162688      |
| train/                   |              |
|    approx_kl             | 0.0032804322 |
|    clip_fraction         | 0.00269      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 0.206        |
|    cost_values           | 2.83         |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.67         |
|    n_updates             | 10550        |
|    policy_gradient_loss  | -0.00055     |
|    std                   | 0.46         |
|    value_loss            | 9.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.0925729   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 970          |
|    total_timesteps       | 2164736      |
| train/                   |              |
|    approx_kl             | 0.0011761708 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.02         |
|    cost_value_loss       | 4.16         |
|    cost_values           | 2.51         |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.17         |
|    n_updates             | 10560        |
|    policy_gradient_loss  | -0.000105    |
|    std                   | 0.459        |
|    value_loss            | 7.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.13112    |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 1005        |
|    total_timesteps       | 2166784     |
| train/                   |             |
|    approx_kl             | 0.003946582 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.06        |
|    cost_value_loss       | 5.67        |
|    cost_values           | 2.59        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.8        |
|    n_updates             | 10570       |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.46        |
|    value_loss            | 33.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.61935586  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1040         |
|    total_timesteps       | 2168832      |
| train/                   |              |
|    approx_kl             | 0.0030547932 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 4.03         |
|    cost_values           | 2.8          |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 10580        |
|    policy_gradient_loss  | -0.000548    |
|    std                   | 0.46         |
|    value_loss            | 20.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5412673   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 31           |
|    time_elapsed          | 1076         |
|    total_timesteps       | 2170880      |
| train/                   |              |
|    approx_kl             | 0.0015089007 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 4.52         |
|    cost_values           | 2.69         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 10590        |
|    policy_gradient_loss  | -0.000417    |
|    std                   | 0.461        |
|    value_loss            | 23.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7215741  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 32          |
|    time_elapsed          | 1111        |
|    total_timesteps       | 2172928     |
| train/                   |             |
|    approx_kl             | 0.002089225 |
|    clip_fraction         | 0.000537    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.47        |
|    cost_value_loss       | 6           |
|    cost_values           | 2.59        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.15        |
|    n_updates             | 10600       |
|    policy_gradient_loss  | -0.000548   |
|    std                   | 0.461       |
|    value_loss            | 9.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.179808    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 33           |
|    time_elapsed          | 1146         |
|    total_timesteps       | 2174976      |
| train/                   |              |
|    approx_kl             | 0.0040645353 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 2.13         |
|    cost_values           | 2.68         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 10610        |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.46         |
|    value_loss            | 5.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.58727825  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 34           |
|    time_elapsed          | 1181         |
|    total_timesteps       | 2177024      |
| train/                   |              |
|    approx_kl             | 0.0063732467 |
|    clip_fraction         | 0.0716       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 2.57         |
|    cost_values           | 2.84         |
|    entropy               | -1.28        |
|    entropy_loss          | -1.29        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21           |
|    n_updates             | 10620        |
|    policy_gradient_loss  | -0.00448     |
|    std                   | 0.46         |
|    value_loss            | 40.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.59769255  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 35           |
|    time_elapsed          | 1216         |
|    total_timesteps       | 2179072      |
| train/                   |              |
|    approx_kl             | 0.0017344875 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 0.508        |
|    cost_values           | 2.68         |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.11         |
|    n_updates             | 10630        |
|    policy_gradient_loss  | -9.47e-05    |
|    std                   | 0.459        |
|    value_loss            | 16.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3007294   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 36           |
|    time_elapsed          | 1252         |
|    total_timesteps       | 2181120      |
| train/                   |              |
|    approx_kl             | 0.0030991798 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.7          |
|    cost_value_loss       | 14.9         |
|    cost_values           | 2.51         |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 10640        |
|    policy_gradient_loss  | -0.000871    |
|    std                   | 0.459        |
|    value_loss            | 12.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.35092562  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 37           |
|    time_elapsed          | 1286         |
|    total_timesteps       | 2183168      |
| train/                   |              |
|    approx_kl             | 0.0016788172 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 4.63         |
|    cost_values           | 2.71         |
|    entropy               | -1.28        |
|    entropy_loss          | -1.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.76         |
|    n_updates             | 10650        |
|    policy_gradient_loss  | 1.51e-05     |
|    std                   | 0.458        |
|    value_loss            | 15.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5433801  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 38          |
|    time_elapsed          | 1321        |
|    total_timesteps       | 2185216     |
| train/                   |             |
|    approx_kl             | 0.004065651 |
|    clip_fraction         | 0.0064      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.44        |
|    cost_value_loss       | 0.383       |
|    cost_values           | 2.8         |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.1        |
|    n_updates             | 10660       |
|    policy_gradient_loss  | -0.000819   |
|    std                   | 0.457       |
|    value_loss            | 31.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.80093914  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 39           |
|    time_elapsed          | 1356         |
|    total_timesteps       | 2187264      |
| train/                   |              |
|    approx_kl             | 0.0028503207 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.99         |
|    cost_value_loss       | 8.15         |
|    cost_values           | 2.6          |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 10670        |
|    policy_gradient_loss  | -0.00094     |
|    std                   | 0.456        |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4153468   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 40           |
|    time_elapsed          | 1391         |
|    total_timesteps       | 2189312      |
| train/                   |              |
|    approx_kl             | 0.0032465672 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.75         |
|    cost_value_loss       | 7.91         |
|    cost_values           | 2.78         |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0129       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.73         |
|    n_updates             | 10680        |
|    policy_gradient_loss  | -0.000643    |
|    std                   | 0.457        |
|    value_loss            | 9.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9229682   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 41           |
|    time_elapsed          | 1426         |
|    total_timesteps       | 2191360      |
| train/                   |              |
|    approx_kl             | 0.0017175428 |
|    clip_fraction         | 0.00601      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 0.176        |
|    cost_values           | 2.74         |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.93         |
|    n_updates             | 10690        |
|    policy_gradient_loss  | -0.000557    |
|    std                   | 0.457        |
|    value_loss            | 3.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.75577736  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 42           |
|    time_elapsed          | 1461         |
|    total_timesteps       | 2193408      |
| train/                   |              |
|    approx_kl             | 0.0031563495 |
|    clip_fraction         | 0.0336       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.57         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 2.42         |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 10700        |
|    policy_gradient_loss  | -0.000196    |
|    std                   | 0.456        |
|    value_loss            | 12.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7755671   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 43           |
|    time_elapsed          | 1497         |
|    total_timesteps       | 2195456      |
| train/                   |              |
|    approx_kl             | 0.0004935359 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 0.192        |
|    cost_values           | 2.42         |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.9          |
|    n_updates             | 10710        |
|    policy_gradient_loss  | 8.98e-05     |
|    std                   | 0.456        |
|    value_loss            | 9.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.79        |
| reward                   | -0.80230874 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 44          |
|    time_elapsed          | 1532        |
|    total_timesteps       | 2197504     |
| train/                   |             |
|    approx_kl             | 0.00552999  |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 3.7         |
|    cost_values           | 2.19        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.85        |
|    n_updates             | 10720       |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.457       |
|    value_loss            | 5.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5575222   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 45           |
|    time_elapsed          | 1567         |
|    total_timesteps       | 2199552      |
| train/                   |              |
|    approx_kl             | 0.0021427642 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 1.8          |
|    cost_values           | 2.34         |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.11         |
|    n_updates             | 10730        |
|    policy_gradient_loss  | -0.000813    |
|    std                   | 0.456        |
|    value_loss            | 4.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.67717284 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 46          |
|    time_elapsed          | 1602        |
|    total_timesteps       | 2201600     |
| train/                   |             |
|    approx_kl             | 0.003494035 |
|    clip_fraction         | 0.00229     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 4.04        |
|    cost_values           | 2.16        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.72        |
|    n_updates             | 10740       |
|    policy_gradient_loss  | -0.000467   |
|    std                   | 0.456       |
|    value_loss            | 17.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73516655  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 47           |
|    time_elapsed          | 1637         |
|    total_timesteps       | 2203648      |
| train/                   |              |
|    approx_kl             | 0.0027572862 |
|    clip_fraction         | 0.0021       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 0.985        |
|    cost_values           | 2.07         |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 10750        |
|    policy_gradient_loss  | -0.000755    |
|    std                   | 0.456        |
|    value_loss            | 24.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8378236  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -687        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 48          |
|    time_elapsed          | 1672        |
|    total_timesteps       | 2205696     |
| train/                   |             |
|    approx_kl             | 0.004612555 |
|    clip_fraction         | 0.0084      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 7.3         |
|    cost_values           | 1.9         |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.8        |
|    n_updates             | 10760       |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.456       |
|    value_loss            | 35.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6568602   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 49           |
|    time_elapsed          | 1707         |
|    total_timesteps       | 2207744      |
| train/                   |              |
|    approx_kl             | 0.0035217288 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 0.642        |
|    cost_values           | 1.81         |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.47         |
|    n_updates             | 10770        |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.457        |
|    value_loss            | 13.3         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.5570834 |
| rollout/           |            |
|    ep_len_mean     | 966        |
|    ep_rew_mean     | -686       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2209792    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89104825  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2211840      |
| train/                   |              |
|    approx_kl             | 0.0023439713 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 3.07         |
|    cost_values           | 2.12         |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 10790        |
|    policy_gradient_loss  | -0.000612    |
|    std                   | 0.457        |
|    value_loss            | 30.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.056013   |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 3           |
|    time_elapsed          | 94          |
|    total_timesteps       | 2213888     |
| train/                   |             |
|    approx_kl             | 0.003473877 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 5.93        |
|    cost_values           | 2.09        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.9         |
|    n_updates             | 10800       |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.457       |
|    value_loss            | 8.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.92684346  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 4            |
|    time_elapsed          | 130          |
|    total_timesteps       | 2215936      |
| train/                   |              |
|    approx_kl             | 0.0009795376 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 0.607        |
|    cost_values           | 2.07         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.71         |
|    n_updates             | 10810        |
|    policy_gradient_loss  | -0.000279    |
|    std                   | 0.453        |
|    value_loss            | 6.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.69352645 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 5           |
|    time_elapsed          | 165         |
|    total_timesteps       | 2217984     |
| train/                   |             |
|    approx_kl             | 0.002436815 |
|    clip_fraction         | 0.00195     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.28        |
|    cost_value_loss       | 8.91        |
|    cost_values           | 2.1         |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.84        |
|    n_updates             | 10820       |
|    policy_gradient_loss  | -0.000259   |
|    std                   | 0.452       |
|    value_loss            | 10.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3684222   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 200          |
|    total_timesteps       | 2220032      |
| train/                   |              |
|    approx_kl             | 0.0039370125 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 3.71         |
|    cost_values           | 2.41         |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.14         |
|    n_updates             | 10830        |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.452        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.14449     |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 7            |
|    time_elapsed          | 235          |
|    total_timesteps       | 2222080      |
| train/                   |              |
|    approx_kl             | 0.0022413123 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 0.33         |
|    cost_values           | 2.21         |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.48         |
|    n_updates             | 10840        |
|    policy_gradient_loss  | -0.0005      |
|    std                   | 0.451        |
|    value_loss            | 5.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6998208  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 8           |
|    time_elapsed          | 270         |
|    total_timesteps       | 2224128     |
| train/                   |             |
|    approx_kl             | 0.003903516 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 0.899       |
|    cost_values           | 1.86        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 10850       |
|    policy_gradient_loss  | -0.000262   |
|    std                   | 0.45        |
|    value_loss            | 8.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5233862   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 305          |
|    total_timesteps       | 2226176      |
| train/                   |              |
|    approx_kl             | 0.0053102947 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 3.41         |
|    cost_values           | 1.8          |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.02         |
|    n_updates             | 10860        |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.451        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.58640903  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 340          |
|    total_timesteps       | 2228224      |
| train/                   |              |
|    approx_kl             | 0.0035967943 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.99         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 2.04         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.8         |
|    n_updates             | 10870        |
|    policy_gradient_loss  | -0.000457    |
|    std                   | 0.451        |
|    value_loss            | 29           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9283684   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 11           |
|    time_elapsed          | 375          |
|    total_timesteps       | 2230272      |
| train/                   |              |
|    approx_kl             | 0.0005528376 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 23.9         |
|    cost_values           | 2.37         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 10880        |
|    policy_gradient_loss  | -0.000249    |
|    std                   | 0.451        |
|    value_loss            | 7.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7752974   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 12           |
|    time_elapsed          | 410          |
|    total_timesteps       | 2232320      |
| train/                   |              |
|    approx_kl             | 0.0037788157 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.11         |
|    cost_value_loss       | 8.98         |
|    cost_values           | 2.8          |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0.0065       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.65         |
|    n_updates             | 10890        |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.45         |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.758157    |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 13           |
|    time_elapsed          | 445          |
|    total_timesteps       | 2234368      |
| train/                   |              |
|    approx_kl             | 0.0033917197 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 1.4          |
|    cost_values           | 2.9          |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.83         |
|    n_updates             | 10900        |
|    policy_gradient_loss  | -0.000895    |
|    std                   | 0.45         |
|    value_loss            | 12.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7309683   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 14           |
|    time_elapsed          | 480          |
|    total_timesteps       | 2236416      |
| train/                   |              |
|    approx_kl             | 0.0047758017 |
|    clip_fraction         | 0.041        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.24         |
|    cost_value_loss       | 6.51         |
|    cost_values           | 2.72         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 10910        |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.451        |
|    value_loss            | 38.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.8129824  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -666        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 15          |
|    time_elapsed          | 516         |
|    total_timesteps       | 2238464     |
| train/                   |             |
|    approx_kl             | 0.003050474 |
|    clip_fraction         | 0.0128      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.47        |
|    cost_value_loss       | 4.49        |
|    cost_values           | 2.79        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.62        |
|    n_updates             | 10920       |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.45        |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.35808396  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 551          |
|    total_timesteps       | 2240512      |
| train/                   |              |
|    approx_kl             | 0.0074694706 |
|    clip_fraction         | 0.079        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 2.88         |
|    cost_values           | 2.93         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 10930        |
|    policy_gradient_loss  | -0.00448     |
|    std                   | 0.449        |
|    value_loss            | 41.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.95763165  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -663         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 587          |
|    total_timesteps       | 2242560      |
| train/                   |              |
|    approx_kl             | 0.0011519259 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.3          |
|    cost_value_loss       | 4.01         |
|    cost_values           | 2.91         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.55         |
|    n_updates             | 10940        |
|    policy_gradient_loss  | 0.00056      |
|    std                   | 0.448        |
|    value_loss            | 9.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8250674  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -663        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 621         |
|    total_timesteps       | 2244608     |
| train/                   |             |
|    approx_kl             | 0.005334155 |
|    clip_fraction         | 0.0457      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 2.51        |
|    cost_values           | 2.86        |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.46        |
|    n_updates             | 10950       |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.447       |
|    value_loss            | 8.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5708706   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 656          |
|    total_timesteps       | 2246656      |
| train/                   |              |
|    approx_kl             | 0.0009435413 |
|    clip_fraction         | 0.00356      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 4.25         |
|    cost_values           | 2.87         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.39         |
|    n_updates             | 10960        |
|    policy_gradient_loss  | 0.000267     |
|    std                   | 0.446        |
|    value_loss            | 10.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.79691166 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 691         |
|    total_timesteps       | 2248704     |
| train/                   |             |
|    approx_kl             | 0.00552593  |
|    clip_fraction         | 0.0711      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 4.56        |
|    cost_values           | 2.96        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.29        |
|    n_updates             | 10970       |
|    policy_gradient_loss  | -0.00524    |
|    std                   | 0.446       |
|    value_loss            | 4.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5650119  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -671        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 21          |
|    time_elapsed          | 725         |
|    total_timesteps       | 2250752     |
| train/                   |             |
|    approx_kl             | 0.004107719 |
|    clip_fraction         | 0.00693     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.71        |
|    cost_value_loss       | 1.37        |
|    cost_values           | 2.89        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.54        |
|    n_updates             | 10980       |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.446       |
|    value_loss            | 15.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44458184  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 760          |
|    total_timesteps       | 2252800      |
| train/                   |              |
|    approx_kl             | 0.0014201449 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 2.59         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.75         |
|    n_updates             | 10990        |
|    policy_gradient_loss  | -0.000251    |
|    std                   | 0.446        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.41524422  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 795          |
|    total_timesteps       | 2254848      |
| train/                   |              |
|    approx_kl             | 0.0049295286 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 1.47         |
|    cost_values           | 2.33         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 11000        |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.446        |
|    value_loss            | 30.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40275264 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -676        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 831         |
|    total_timesteps       | 2256896     |
| train/                   |             |
|    approx_kl             | 0.003798185 |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 3.47        |
|    cost_values           | 2.3         |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.35        |
|    n_updates             | 11010       |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 0.445       |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5039324   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 867          |
|    total_timesteps       | 2258944      |
| train/                   |              |
|    approx_kl             | 0.0042202887 |
|    clip_fraction         | 0.00605      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.73         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.3          |
|    n_updates             | 11020        |
|    policy_gradient_loss  | -0.000518    |
|    std                   | 0.445        |
|    value_loss            | 7.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.666282    |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 26           |
|    time_elapsed          | 903          |
|    total_timesteps       | 2260992      |
| train/                   |              |
|    approx_kl             | 0.0048044436 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.42         |
|    cost_value_loss       | 4.51         |
|    cost_values           | 2.99         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 11030        |
|    policy_gradient_loss  | -0.000806    |
|    std                   | 0.445        |
|    value_loss            | 6.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0979799   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 27           |
|    time_elapsed          | 938          |
|    total_timesteps       | 2263040      |
| train/                   |              |
|    approx_kl             | 0.0037160895 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.01         |
|    cost_value_loss       | 2.44         |
|    cost_values           | 2.96         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.82         |
|    n_updates             | 11040        |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.439        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.71739584  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 28           |
|    time_elapsed          | 972          |
|    total_timesteps       | 2265088      |
| train/                   |              |
|    approx_kl             | 0.0045982487 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 5.05         |
|    cost_values           | 2.94         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.35         |
|    n_updates             | 11050        |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.439        |
|    value_loss            | 11.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.58179045 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -677        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 29          |
|    time_elapsed          | 1007        |
|    total_timesteps       | 2267136     |
| train/                   |             |
|    approx_kl             | 0.005471247 |
|    clip_fraction         | 0.00996     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.25        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.99        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00185     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.24        |
|    n_updates             | 11060       |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.438       |
|    value_loss            | 7.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8100068   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 30           |
|    time_elapsed          | 1042         |
|    total_timesteps       | 2269184      |
| train/                   |              |
|    approx_kl             | 0.0013918437 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.75         |
|    cost_value_loss       | 7.35         |
|    cost_values           | 3            |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00568      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 11070        |
|    policy_gradient_loss  | -0.000104    |
|    std                   | 0.437        |
|    value_loss            | 5.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.47922924 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 31          |
|    time_elapsed          | 1077        |
|    total_timesteps       | 2271232     |
| train/                   |             |
|    approx_kl             | 0.001407619 |
|    clip_fraction         | 0.00669     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 2.89        |
|    cost_values           | 2.97        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.36        |
|    n_updates             | 11080       |
|    policy_gradient_loss  | 1.83e-05    |
|    std                   | 0.438       |
|    value_loss            | 2.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0572538   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 32           |
|    time_elapsed          | 1112         |
|    total_timesteps       | 2273280      |
| train/                   |              |
|    approx_kl             | 0.0054166783 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.42         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 3            |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0.00764      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.5          |
|    n_updates             | 11090        |
|    policy_gradient_loss  | -0.000885    |
|    std                   | 0.439        |
|    value_loss            | 9.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.98305875  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 33           |
|    time_elapsed          | 1147         |
|    total_timesteps       | 2275328      |
| train/                   |              |
|    approx_kl             | 0.0066046948 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.58         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 3            |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 11100        |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.439        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0659579  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 34          |
|    time_elapsed          | 1182        |
|    total_timesteps       | 2277376     |
| train/                   |             |
|    approx_kl             | 0.005213922 |
|    clip_fraction         | 0.012       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 3.58        |
|    cost_values           | 2.93        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.11        |
|    n_updates             | 11110       |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.438       |
|    value_loss            | 13.4        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.85821366   |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -687          |
| time/                    |               |
|    fps                   | 58            |
|    iterations            | 35            |
|    time_elapsed          | 1217          |
|    total_timesteps       | 2279424       |
| train/                   |               |
|    approx_kl             | 8.0834114e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.63          |
|    cost_value_loss       | 1.44          |
|    cost_values           | 2.76          |
|    entropy               | -1.19         |
|    entropy_loss          | -1.19         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.7           |
|    n_updates             | 11120         |
|    policy_gradient_loss  | 6.89e-05      |
|    std                   | 0.438         |
|    value_loss            | 16.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 1.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.42        |
| reward                   | -0.6175359  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 36          |
|    time_elapsed          | 1252        |
|    total_timesteps       | 2281472     |
| train/                   |             |
|    approx_kl             | 0.004138984 |
|    clip_fraction         | 0.00425     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.45        |
|    cost_value_loss       | 1.87        |
|    cost_values           | 2.48        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 11130       |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.438       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.77965134  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 37           |
|    time_elapsed          | 1287         |
|    total_timesteps       | 2283520      |
| train/                   |              |
|    approx_kl             | 0.0012051602 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.81         |
|    cost_value_loss       | 5.22         |
|    cost_values           | 2.26         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 11140        |
|    policy_gradient_loss  | -0.000339    |
|    std                   | 0.438        |
|    value_loss            | 28.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9156522   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 38           |
|    time_elapsed          | 1323         |
|    total_timesteps       | 2285568      |
| train/                   |              |
|    approx_kl             | 0.0020241085 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.66         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.32         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 11150        |
|    policy_gradient_loss  | -0.000373    |
|    std                   | 0.438        |
|    value_loss            | 14.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.1381164  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 39          |
|    time_elapsed          | 1358        |
|    total_timesteps       | 2287616     |
| train/                   |             |
|    approx_kl             | 0.005922775 |
|    clip_fraction         | 0.0203      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 2.56        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.34        |
|    n_updates             | 11160       |
|    policy_gradient_loss  | -0.00163    |
|    std                   | 0.438       |
|    value_loss            | 9.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.73031956 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 40          |
|    time_elapsed          | 1393        |
|    total_timesteps       | 2289664     |
| train/                   |             |
|    approx_kl             | 0.006083913 |
|    clip_fraction         | 0.0471      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 4.22        |
|    cost_values           | 2.54        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 11170       |
|    policy_gradient_loss  | -0.00302    |
|    std                   | 0.438       |
|    value_loss            | 3.68        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.33599517  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 41           |
|    time_elapsed          | 1429         |
|    total_timesteps       | 2291712      |
| train/                   |              |
|    approx_kl             | 0.0020057722 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 3.07         |
|    cost_values           | 2.54         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.25         |
|    n_updates             | 11180        |
|    policy_gradient_loss  | -0.00029     |
|    std                   | 0.438        |
|    value_loss            | 9.86         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5537285  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 42          |
|    time_elapsed          | 1464        |
|    total_timesteps       | 2293760     |
| train/                   |             |
|    approx_kl             | 0.004374871 |
|    clip_fraction         | 0.0151      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 2.64        |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.5        |
|    n_updates             | 11190       |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.437       |
|    value_loss            | 16.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46800494  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 43           |
|    time_elapsed          | 1499         |
|    total_timesteps       | 2295808      |
| train/                   |              |
|    approx_kl             | 0.0022495044 |
|    clip_fraction         | 0.01         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.02         |
|    cost_value_loss       | 2.38         |
|    cost_values           | 2.95         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 11200        |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.438        |
|    value_loss            | 20.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5739503  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -702        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 44          |
|    time_elapsed          | 1534        |
|    total_timesteps       | 2297856     |
| train/                   |             |
|    approx_kl             | 0.004047486 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.7         |
|    cost_value_loss       | 6.67        |
|    cost_values           | 2.96        |
|    entropy               | -1.18       |
|    entropy_loss          | -1.19       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.00942     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.15        |
|    n_updates             | 11210       |
|    policy_gradient_loss  | -0.001      |
|    std                   | 0.437       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.014023    |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 45           |
|    time_elapsed          | 1569         |
|    total_timesteps       | 2299904      |
| train/                   |              |
|    approx_kl             | 0.0039943345 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.64         |
|    cost_value_loss       | 0.497        |
|    cost_values           | 2.77         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.1          |
|    n_updates             | 11220        |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.437        |
|    value_loss            | 8.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7674896   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 46           |
|    time_elapsed          | 1604         |
|    total_timesteps       | 2301952      |
| train/                   |              |
|    approx_kl             | 0.0050197016 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 1.25         |
|    cost_values           | 2.41         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 11230        |
|    policy_gradient_loss  | -1.35e-05    |
|    std                   | 0.436        |
|    value_loss            | 7.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2114351   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 47           |
|    time_elapsed          | 1639         |
|    total_timesteps       | 2304000      |
| train/                   |              |
|    approx_kl             | 0.0062940326 |
|    clip_fraction         | 0.124        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.04         |
|    cost_value_loss       | 5.39         |
|    cost_values           | 2.33         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.8         |
|    n_updates             | 11240        |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 0.435        |
|    value_loss            | 74.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.94647014  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 48           |
|    time_elapsed          | 1674         |
|    total_timesteps       | 2306048      |
| train/                   |              |
|    approx_kl             | 0.0057225847 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 0.134        |
|    cost_values           | 2.22         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.77         |
|    n_updates             | 11250        |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.435        |
|    value_loss            | 22.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55024177  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 49           |
|    time_elapsed          | 1708         |
|    total_timesteps       | 2308096      |
| train/                   |              |
|    approx_kl             | 0.0038089682 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 8.56         |
|    cost_values           | 2.14         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 11260        |
|    policy_gradient_loss  | -0.000803    |
|    std                   | 0.435        |
|    value_loss            | 20.6         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
-----------------------------------
| avg_speed          | 8.01       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.01       |
| reward             | -0.7978384 |
| rollout/           |            |
|    ep_len_mean     | 970        |
|    ep_rew_mean     | -720       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2310144    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7092095   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2312192      |
| train/                   |              |
|    approx_kl             | 0.0017175121 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 0.344        |
|    cost_values           | 1.97         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.7          |
|    n_updates             | 11280        |
|    policy_gradient_loss  | -0.000424    |
|    std                   | 0.436        |
|    value_loss            | 17           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8735863   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 2314240      |
| train/                   |              |
|    approx_kl             | 0.0018731854 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 0.311        |
|    cost_values           | 1.63         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.33         |
|    n_updates             | 11290        |
|    policy_gradient_loss  | -0.000547    |
|    std                   | 0.437        |
|    value_loss            | 4.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6074995   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 2316288      |
| train/                   |              |
|    approx_kl             | 0.0021989376 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.75         |
|    cost_value_loss       | 7.33         |
|    cost_values           | 1.5          |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.3          |
|    n_updates             | 11300        |
|    policy_gradient_loss  | -5.27e-05    |
|    std                   | 0.438        |
|    value_loss            | 6.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8324409   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 2318336      |
| train/                   |              |
|    approx_kl             | 0.0028178955 |
|    clip_fraction         | 0.00518      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.42         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 1.72         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 11310        |
|    policy_gradient_loss  | -0.000634    |
|    std                   | 0.438        |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8304655   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 2320384      |
| train/                   |              |
|    approx_kl             | 0.0056861583 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 5.74         |
|    cost_values           | 2.06         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.35         |
|    n_updates             | 11320        |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.437        |
|    value_loss            | 8.84         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.1319625    |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -718          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 7             |
|    time_elapsed          | 233           |
|    total_timesteps       | 2322432       |
| train/                   |               |
|    approx_kl             | 0.00064646057 |
|    clip_fraction         | 0.0113        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.19          |
|    cost_value_loss       | 1.38          |
|    cost_values           | 2.2           |
|    entropy               | -1.16         |
|    entropy_loss          | -1.17         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 2.73          |
|    n_updates             | 11330         |
|    policy_gradient_loss  | -9.41e-05     |
|    std                   | 0.431         |
|    value_loss            | 4.33          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2265617  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -728        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 268         |
|    total_timesteps       | 2324480     |
| train/                   |             |
|    approx_kl             | 0.003901625 |
|    clip_fraction         | 0.0206      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 6.17        |
|    cost_values           | 2.29        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.04        |
|    n_updates             | 11340       |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.43        |
|    value_loss            | 8.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.96        |
| reward                   | -0.48450157 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 303         |
|    total_timesteps       | 2326528     |
| train/                   |             |
|    approx_kl             | 0.005628206 |
|    clip_fraction         | 0.0199      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 0.34        |
|    cost_values           | 2.47        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.12        |
|    n_updates             | 11350       |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.43        |
|    value_loss            | 19.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.39611894  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 2328576      |
| train/                   |              |
|    approx_kl             | 0.0048265983 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 0.292        |
|    cost_values           | 2.14         |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 11360        |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.43         |
|    value_loss            | 11.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9011512   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 373          |
|    total_timesteps       | 2330624      |
| train/                   |              |
|    approx_kl             | 0.0010659999 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 14.7         |
|    cost_values           | 1.96         |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.3         |
|    n_updates             | 11370        |
|    policy_gradient_loss  | -0.000317    |
|    std                   | 0.43         |
|    value_loss            | 42.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0644759  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 407         |
|    total_timesteps       | 2332672     |
| train/                   |             |
|    approx_kl             | 0.003525145 |
|    clip_fraction         | 0.0155      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.34        |
|    cost_value_loss       | 2.19        |
|    cost_values           | 2.08        |
|    entropy               | -1.14       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.89        |
|    n_updates             | 11380       |
|    policy_gradient_loss  | -0.00093    |
|    std                   | 0.429       |
|    value_loss            | 3.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.33        |
| reward                   | -0.3950436  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -733        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 442         |
|    total_timesteps       | 2334720     |
| train/                   |             |
|    approx_kl             | 0.004082447 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.88        |
|    cost_value_loss       | 0.227       |
|    cost_values           | 2.06        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.9        |
|    n_updates             | 11390       |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.429       |
|    value_loss            | 38.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.17         |
| reward                   | -0.8939539   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 477          |
|    total_timesteps       | 2336768      |
| train/                   |              |
|    approx_kl             | 0.0039652097 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 0.0894       |
|    cost_values           | 1.68         |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.79         |
|    n_updates             | 11400        |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 0.43         |
|    value_loss            | 6.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6739874   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 2338816      |
| train/                   |              |
|    approx_kl             | 0.0031267349 |
|    clip_fraction         | 0.00264      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.883        |
|    cost_values           | 1.4          |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.3          |
|    n_updates             | 11410        |
|    policy_gradient_loss  | -0.000582    |
|    std                   | 0.43         |
|    value_loss            | 19.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.49070203  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 546          |
|    total_timesteps       | 2340864      |
| train/                   |              |
|    approx_kl             | 0.0045369826 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 1.33         |
|    cost_values           | 1.28         |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.5         |
|    n_updates             | 11420        |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.43         |
|    value_loss            | 38.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.83404666  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 581          |
|    total_timesteps       | 2342912      |
| train/                   |              |
|    approx_kl             | 0.0057424973 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 1.1          |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 11430        |
|    policy_gradient_loss  | -0.00382     |
|    std                   | 0.43         |
|    value_loss            | 28.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57571733  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 616          |
|    total_timesteps       | 2344960      |
| train/                   |              |
|    approx_kl             | 0.0050428454 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 5.71         |
|    cost_values           | 1.03         |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.59         |
|    n_updates             | 11440        |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.429        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.71832764 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -756        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 652         |
|    total_timesteps       | 2347008     |
| train/                   |             |
|    approx_kl             | 0.002588736 |
|    clip_fraction         | 0.00449     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 2.41        |
|    cost_values           | 1.14        |
|    entropy               | -1.14       |
|    entropy_loss          | -1.14       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 11450       |
|    policy_gradient_loss  | 0.000255    |
|    std                   | 0.428       |
|    value_loss            | 19.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.52675337  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 687          |
|    total_timesteps       | 2349056      |
| train/                   |              |
|    approx_kl             | 0.0052246926 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 9.81         |
|    cost_values           | 1.3          |
|    entropy               | -1.14        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 11460        |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.427        |
|    value_loss            | 11.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.81670773  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 722          |
|    total_timesteps       | 2351104      |
| train/                   |              |
|    approx_kl             | 0.0031454274 |
|    clip_fraction         | 0.00186      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 6.22         |
|    cost_values           | 1.51         |
|    entropy               | -1.13        |
|    entropy_loss          | -1.14        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.56         |
|    n_updates             | 11470        |
|    policy_gradient_loss  | -0.000673    |
|    std                   | 0.427        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.88279784  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 757          |
|    total_timesteps       | 2353152      |
| train/                   |              |
|    approx_kl             | 0.0022405344 |
|    clip_fraction         | 0.00645      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 3.41         |
|    cost_values           | 1.68         |
|    entropy               | -1.14        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.51         |
|    n_updates             | 11480        |
|    policy_gradient_loss  | -0.000632    |
|    std                   | 0.427        |
|    value_loss            | 16.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75157076  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 792          |
|    total_timesteps       | 2355200      |
| train/                   |              |
|    approx_kl             | 0.0044642724 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.35         |
|    cost_value_loss       | 8.4          |
|    cost_values           | 2.01         |
|    entropy               | -1.14        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.3          |
|    n_updates             | 11490        |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 0.427        |
|    value_loss            | 8.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.879719    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 827          |
|    total_timesteps       | 2357248      |
| train/                   |              |
|    approx_kl             | 0.0037674583 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 6.54         |
|    cost_values           | 2.39         |
|    entropy               | -1.14        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.26         |
|    n_updates             | 11500        |
|    policy_gradient_loss  | -0.00026     |
|    std                   | 0.427        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52588725  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 862          |
|    total_timesteps       | 2359296      |
| train/                   |              |
|    approx_kl             | 0.0016755548 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.32         |
|    cost_value_loss       | 6.44         |
|    cost_values           | 2.84         |
|    entropy               | -1.13        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.42         |
|    n_updates             | 11510        |
|    policy_gradient_loss  | -0.00038     |
|    std                   | 0.427        |
|    value_loss            | 5.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.81173897  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 897          |
|    total_timesteps       | 2361344      |
| train/                   |              |
|    approx_kl             | 0.0042930776 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.68         |
|    cost_value_loss       | 4.82         |
|    cost_values           | 2.91         |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.3         |
|    n_updates             | 11520        |
|    policy_gradient_loss  | -0.00097     |
|    std                   | 0.426        |
|    value_loss            | 36.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8338131  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 932         |
|    total_timesteps       | 2363392     |
| train/                   |             |
|    approx_kl             | 0.004344861 |
|    clip_fraction         | 0.00405     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.45        |
|    cost_value_loss       | 5.04        |
|    cost_values           | 2.92        |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.26        |
|    n_updates             | 11530       |
|    policy_gradient_loss  | -0.000378   |
|    std                   | 0.425       |
|    value_loss            | 12.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6499821   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 967          |
|    total_timesteps       | 2365440      |
| train/                   |              |
|    approx_kl             | 0.0051487563 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.63         |
|    cost_value_loss       | 0.424        |
|    cost_values           | 2.9          |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.84         |
|    n_updates             | 11540        |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.425        |
|    value_loss            | 17.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5585833  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -761        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 1002        |
|    total_timesteps       | 2367488     |
| train/                   |             |
|    approx_kl             | 0.005060192 |
|    clip_fraction         | 0.0394      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.8         |
|    cost_value_loss       | 2.85        |
|    cost_values           | 2.62        |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.8         |
|    n_updates             | 11550       |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 0.425       |
|    value_loss            | 17.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2451347  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -760        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1037        |
|    total_timesteps       | 2369536     |
| train/                   |             |
|    approx_kl             | 0.004762622 |
|    clip_fraction         | 0.0064      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 5.14        |
|    cost_values           | 2.65        |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.7        |
|    n_updates             | 11560       |
|    policy_gradient_loss  | -0.000139   |
|    std                   | 0.425       |
|    value_loss            | 54.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2566543   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1072         |
|    total_timesteps       | 2371584      |
| train/                   |              |
|    approx_kl             | 0.0065501174 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.4          |
|    cost_value_loss       | 4.16         |
|    cost_values           | 2.97         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 11570        |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.424        |
|    value_loss            | 17.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0629758   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1107         |
|    total_timesteps       | 2373632      |
| train/                   |              |
|    approx_kl             | 0.0056539583 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 0.872        |
|    cost_values           | 2.82         |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.5          |
|    n_updates             | 11580        |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.421        |
|    value_loss            | 8.41         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.96        |
| reward                   | -0.42063904 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -761        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1142        |
|    total_timesteps       | 2375680     |
| train/                   |             |
|    approx_kl             | 0.004545184 |
|    clip_fraction         | 0.0369      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.26        |
|    cost_value_loss       | 0.283       |
|    cost_values           | 2.52        |
|    entropy               | -1.1        |
|    entropy_loss          | -1.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.78        |
|    n_updates             | 11590       |
|    policy_gradient_loss  | 0.000139    |
|    std                   | 0.419       |
|    value_loss            | 13.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.58090985  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1176         |
|    total_timesteps       | 2377728      |
| train/                   |              |
|    approx_kl             | 0.0052655293 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 0.596        |
|    cost_values           | 2.15         |
|    entropy               | -1.1         |
|    entropy_loss          | -1.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 11600        |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.419        |
|    value_loss            | 8.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.81939435  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1211         |
|    total_timesteps       | 2379776      |
| train/                   |              |
|    approx_kl             | 0.0042014904 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 5.06         |
|    cost_values           | 1.96         |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 11610        |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.418        |
|    value_loss            | 18.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.46566644 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -760        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1246        |
|    total_timesteps       | 2381824     |
| train/                   |             |
|    approx_kl             | 0.004689007 |
|    clip_fraction         | 0.0298      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 1.25        |
|    cost_values           | 1.96        |
|    entropy               | -1.09       |
|    entropy_loss          | -1.09       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.29        |
|    n_updates             | 11620       |
|    policy_gradient_loss  | -0.00267    |
|    std                   | 0.418       |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6871825   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1281         |
|    total_timesteps       | 2383872      |
| train/                   |              |
|    approx_kl             | 0.0049822554 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 0.916        |
|    cost_values           | 1.71         |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.42         |
|    n_updates             | 11630        |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.417        |
|    value_loss            | 16.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.56113577  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1316         |
|    total_timesteps       | 2385920      |
| train/                   |              |
|    approx_kl             | 0.0011899234 |
|    clip_fraction         | 0.0141       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 2.74         |
|    cost_values           | 1.58         |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.01         |
|    n_updates             | 11640        |
|    policy_gradient_loss  | -0.000959    |
|    std                   | 0.417        |
|    value_loss            | 7.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7378955   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1351         |
|    total_timesteps       | 2387968      |
| train/                   |              |
|    approx_kl             | 0.0028378002 |
|    clip_fraction         | 0.00479      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 2.97         |
|    cost_values           | 1.59         |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.95         |
|    n_updates             | 11650        |
|    policy_gradient_loss  | -0.000281    |
|    std                   | 0.417        |
|    value_loss            | 17           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.058593   |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1385        |
|    total_timesteps       | 2390016     |
| train/                   |             |
|    approx_kl             | 0.004952585 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 3.39        |
|    cost_values           | 1.62        |
|    entropy               | -1.09       |
|    entropy_loss          | -1.09       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 11660       |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.417       |
|    value_loss            | 23.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.76419955  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1420         |
|    total_timesteps       | 2392064      |
| train/                   |              |
|    approx_kl             | 0.0054849656 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 5.18         |
|    cost_values           | 1.76         |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 11670        |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 0.415        |
|    value_loss            | 24.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.81616795  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1455         |
|    total_timesteps       | 2394112      |
| train/                   |              |
|    approx_kl             | 0.0031363128 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 1.48         |
|    cost_values           | 1.97         |
|    entropy               | -1.07        |
|    entropy_loss          | -1.08        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.42         |
|    n_updates             | 11680        |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.414        |
|    value_loss            | 20           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.0090628    |
| rollout/                 |               |
|    ep_len_mean           | 972           |
|    ep_rew_mean           | -762          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 43            |
|    time_elapsed          | 1490          |
|    total_timesteps       | 2396160       |
| train/                   |               |
|    approx_kl             | 0.00045791967 |
|    clip_fraction         | 0.0151        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.54          |
|    cost_value_loss       | 0.053         |
|    cost_values           | 1.59          |
|    entropy               | -1.08         |
|    entropy_loss          | -1.08         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.62          |
|    n_updates             | 11690         |
|    policy_gradient_loss  | 0.000277      |
|    std                   | 0.416         |
|    value_loss            | 7.27          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6249319   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1524         |
|    total_timesteps       | 2398208      |
| train/                   |              |
|    approx_kl             | 0.0024319403 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 1.39         |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.95         |
|    n_updates             | 11700        |
|    policy_gradient_loss  | -0.000857    |
|    std                   | 0.416        |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.7775799  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -771        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1559        |
|    total_timesteps       | 2400256     |
| train/                   |             |
|    approx_kl             | 0.001189111 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 1.48        |
|    cost_values           | 1.36        |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.64        |
|    n_updates             | 11710       |
|    policy_gradient_loss  | -0.000625   |
|    std                   | 0.416       |
|    value_loss            | 15.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.91209847  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1594         |
|    total_timesteps       | 2402304      |
| train/                   |              |
|    approx_kl             | 0.0034020203 |
|    clip_fraction         | 0.0875       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 4.56         |
|    cost_values           | 1.48         |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.81         |
|    n_updates             | 11720        |
|    policy_gradient_loss  | -0.000271    |
|    std                   | 0.416        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53520644  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1629         |
|    total_timesteps       | 2404352      |
| train/                   |              |
|    approx_kl             | 0.0050614565 |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 3.69         |
|    cost_values           | 1.62         |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.51         |
|    n_updates             | 11730        |
|    policy_gradient_loss  | -0.00367     |
|    std                   | 0.415        |
|    value_loss            | 5.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0737985   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1665         |
|    total_timesteps       | 2406400      |
| train/                   |              |
|    approx_kl             | 0.0058549107 |
|    clip_fraction         | 0.0589       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 0.533        |
|    cost_values           | 1.73         |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 11740        |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 0.415        |
|    value_loss            | 8.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0219761   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1700         |
|    total_timesteps       | 2408448      |
| train/                   |              |
|    approx_kl             | 0.0031611738 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.62         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 1.74         |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 11750        |
|    policy_gradient_loss  | -0.000553    |
|    std                   | 0.416        |
|    value_loss            | 14.5         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.02       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 8.02       |
| reward             | -0.3148369 |
| rollout/           |            |
|    ep_len_mean     | 982        |
|    ep_rew_mean     | -765       |
| time/              |            |
|    fps             | 81         |
|    iterations      | 1          |
|    time_elapsed    | 25         |
|    total_timesteps | 2410496    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8729264  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -762        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 2           |
|    time_elapsed          | 60          |
|    total_timesteps       | 2412544     |
| train/                   |             |
|    approx_kl             | 0.006203604 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 2.74        |
|    cost_values           | 1.88        |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.69        |
|    n_updates             | 11770       |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.416       |
|    value_loss            | 12.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.007992    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 3            |
|    time_elapsed          | 96           |
|    total_timesteps       | 2414592      |
| train/                   |              |
|    approx_kl             | 0.0049963347 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 7.14         |
|    cost_values           | 1.99         |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 11780        |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.416        |
|    value_loss            | 19.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.1519326    |
| rollout/                 |               |
|    ep_len_mean           | 982           |
|    ep_rew_mean           | -769          |
| time/                    |               |
|    fps                   | 62            |
|    iterations            | 4             |
|    time_elapsed          | 130           |
|    total_timesteps       | 2416640       |
| train/                   |               |
|    approx_kl             | 0.00066140975 |
|    clip_fraction         | 0.0173        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.61          |
|    cost_value_loss       | 3.26          |
|    cost_values           | 2.41          |
|    entropy               | -1.09         |
|    entropy_loss          | -1.08         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.15          |
|    n_updates             | 11790         |
|    policy_gradient_loss  | -0.00077      |
|    std                   | 0.417         |
|    value_loss            | 8.8           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2421342   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 5            |
|    time_elapsed          | 165          |
|    total_timesteps       | 2418688      |
| train/                   |              |
|    approx_kl             | 0.0046082274 |
|    clip_fraction         | 0.0494       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 2.66         |
|    cost_values           | 2.5          |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.84         |
|    n_updates             | 11800        |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 0.418        |
|    value_loss            | 8.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.95         |
| reward                   | -0.6993867   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 200          |
|    total_timesteps       | 2420736      |
| train/                   |              |
|    approx_kl             | 0.0041746423 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 0.208        |
|    cost_values           | 2.23         |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 11810        |
|    policy_gradient_loss  | -0.000138    |
|    std                   | 0.418        |
|    value_loss            | 8.65         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.3671174    |
| rollout/                 |               |
|    ep_len_mean           | 975           |
|    ep_rew_mean           | -763          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 7             |
|    time_elapsed          | 235           |
|    total_timesteps       | 2422784       |
| train/                   |               |
|    approx_kl             | 0.00016792274 |
|    clip_fraction         | 0.00308       |
|    clip_range            | 0.2           |
|    cost_returns          | 2             |
|    cost_value_loss       | 0.932         |
|    cost_values           | 1.87          |
|    entropy               | -1.09         |
|    entropy_loss          | -1.09         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.37          |
|    n_updates             | 11820         |
|    policy_gradient_loss  | 0.000851      |
|    std                   | 0.417         |
|    value_loss            | 15.2          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6703255  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 8           |
|    time_elapsed          | 271         |
|    total_timesteps       | 2424832     |
| train/                   |             |
|    approx_kl             | 0.004363384 |
|    clip_fraction         | 0.00571     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 9.99        |
|    cost_values           | 1.87        |
|    entropy               | -1.09       |
|    entropy_loss          | -1.09       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.3        |
|    n_updates             | 11830       |
|    policy_gradient_loss  | -0.000908   |
|    std                   | 0.417       |
|    value_loss            | 58          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7616671   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 306          |
|    total_timesteps       | 2426880      |
| train/                   |              |
|    approx_kl             | 0.0045384364 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 0.157        |
|    cost_values           | 1.93         |
|    entropy               | -1.07        |
|    entropy_loss          | -1.08        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 11840        |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 0.414        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9961681   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 10           |
|    time_elapsed          | 341          |
|    total_timesteps       | 2428928      |
| train/                   |              |
|    approx_kl             | 0.0031430544 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 0.0917       |
|    cost_values           | 1.5          |
|    entropy               | -1.07        |
|    entropy_loss          | -1.07        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.28         |
|    n_updates             | 11850        |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.413        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.532456   |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 11          |
|    time_elapsed          | 376         |
|    total_timesteps       | 2430976     |
| train/                   |             |
|    approx_kl             | 0.003363451 |
|    clip_fraction         | 0.00308     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.43        |
|    cost_value_loss       | 6           |
|    cost_values           | 1.41        |
|    entropy               | -1.06       |
|    entropy_loss          | -1.07       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.4        |
|    n_updates             | 11860       |
|    policy_gradient_loss  | -0.000189   |
|    std                   | 0.412       |
|    value_loss            | 40.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.7309388  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -772        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 12          |
|    time_elapsed          | 411         |
|    total_timesteps       | 2433024     |
| train/                   |             |
|    approx_kl             | 0.004687092 |
|    clip_fraction         | 0.0491      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 7.69        |
|    cost_values           | 1.8         |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.27        |
|    n_updates             | 11870       |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.412       |
|    value_loss            | 7.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6768351   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 13           |
|    time_elapsed          | 446          |
|    total_timesteps       | 2435072      |
| train/                   |              |
|    approx_kl             | 0.0030056345 |
|    clip_fraction         | 0.0021       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 7.79         |
|    cost_values           | 2.18         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 11880        |
|    policy_gradient_loss  | -0.00026     |
|    std                   | 0.412        |
|    value_loss            | 7.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.8329692   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 14           |
|    time_elapsed          | 481          |
|    total_timesteps       | 2437120      |
| train/                   |              |
|    approx_kl             | 0.0026850817 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 0.208        |
|    cost_values           | 2.13         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.77         |
|    n_updates             | 11890        |
|    policy_gradient_loss  | -0.000459    |
|    std                   | 0.411        |
|    value_loss            | 5.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0376832   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 15           |
|    time_elapsed          | 516          |
|    total_timesteps       | 2439168      |
| train/                   |              |
|    approx_kl             | 0.0005634195 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 4.31         |
|    cost_values           | 1.87         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.8         |
|    n_updates             | 11900        |
|    policy_gradient_loss  | 0.0011       |
|    std                   | 0.411        |
|    value_loss            | 38.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0885429   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 551          |
|    total_timesteps       | 2441216      |
| train/                   |              |
|    approx_kl             | 0.0008419168 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 0.339        |
|    cost_values           | 1.78         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 11910        |
|    policy_gradient_loss  | 6.18e-05     |
|    std                   | 0.411        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42202872  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 586          |
|    total_timesteps       | 2443264      |
| train/                   |              |
|    approx_kl             | 0.0034077163 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 2.4          |
|    cost_values           | 1.6          |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 11920        |
|    policy_gradient_loss  | -0.000987    |
|    std                   | 0.411        |
|    value_loss            | 24.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.66645527 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -764        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 621         |
|    total_timesteps       | 2445312     |
| train/                   |             |
|    approx_kl             | 0.004586571 |
|    clip_fraction         | 0.0296      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 0.545       |
|    cost_values           | 1.6         |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.12        |
|    n_updates             | 11930       |
|    policy_gradient_loss  | -0.00293    |
|    std                   | 0.41        |
|    value_loss            | 13          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7880636   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 656          |
|    total_timesteps       | 2447360      |
| train/                   |              |
|    approx_kl             | 0.0020196212 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 1.58         |
|    cost_values           | 1.35         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.4          |
|    n_updates             | 11940        |
|    policy_gradient_loss  | -3.81e-05    |
|    std                   | 0.41         |
|    value_loss            | 3.67         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.8570113 |
| rollout/                 |            |
|    ep_len_mean           | 974        |
|    ep_rew_mean           | -756       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 20         |
|    time_elapsed          | 691        |
|    total_timesteps       | 2449408    |
| train/                   |            |
|    approx_kl             | 0.00506827 |
|    clip_fraction         | 0.0446     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.67       |
|    cost_value_loss       | 8.27       |
|    cost_values           | 1.27       |
|    entropy               | -1.05      |
|    entropy_loss          | -1.06      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 28.1       |
|    n_updates             | 11950      |
|    policy_gradient_loss  | -0.00273   |
|    std                   | 0.41       |
|    value_loss            | 38.1       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3075251   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 726          |
|    total_timesteps       | 2451456      |
| train/                   |              |
|    approx_kl             | 0.0041399356 |
|    clip_fraction         | 0.00601      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.14         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 1.38         |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 11960        |
|    policy_gradient_loss  | -0.000948    |
|    std                   | 0.41         |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6275373   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 761          |
|    total_timesteps       | 2453504      |
| train/                   |              |
|    approx_kl             | 0.0046999347 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 3.98         |
|    cost_values           | 1.64         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 11970        |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.411        |
|    value_loss            | 17.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.99311715  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 796          |
|    total_timesteps       | 2455552      |
| train/                   |              |
|    approx_kl             | 0.0024190194 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 2.76         |
|    cost_values           | 1.92         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 11980        |
|    policy_gradient_loss  | -0.000155    |
|    std                   | 0.412        |
|    value_loss            | 8.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.5935552   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 830          |
|    total_timesteps       | 2457600      |
| train/                   |              |
|    approx_kl             | 0.0056552133 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 1.55         |
|    cost_values           | 1.94         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 11990        |
|    policy_gradient_loss  | -0.000907    |
|    std                   | 0.411        |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.8097158   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 865          |
|    total_timesteps       | 2459648      |
| train/                   |              |
|    approx_kl             | 0.0046800375 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 1.73         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.82         |
|    n_updates             | 12000        |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.411        |
|    value_loss            | 8.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7716904  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 900         |
|    total_timesteps       | 2461696     |
| train/                   |             |
|    approx_kl             | 0.005716823 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 6.16        |
|    cost_values           | 1.78        |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.16        |
|    n_updates             | 12010       |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.41        |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.84848315 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 935         |
|    total_timesteps       | 2463744     |
| train/                   |             |
|    approx_kl             | 0.004660453 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.2         |
|    cost_value_loss       | 15.2        |
|    cost_values           | 2.17        |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 12020       |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.41        |
|    value_loss            | 12.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.1007361   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 970          |
|    total_timesteps       | 2465792      |
| train/                   |              |
|    approx_kl             | 0.0051188897 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 2.64         |
|    cost_values           | 2.37         |
|    entropy               | -1.05        |
|    entropy_loss          | -1.06        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 12030        |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.41         |
|    value_loss            | 18.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1136647  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 1005        |
|    total_timesteps       | 2467840     |
| train/                   |             |
|    approx_kl             | 0.003630305 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.51        |
|    cost_value_loss       | 8.96        |
|    cost_values           | 2.56        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.65        |
|    n_updates             | 12040       |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.409       |
|    value_loss            | 7.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.630591    |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1040         |
|    total_timesteps       | 2469888      |
| train/                   |              |
|    approx_kl             | 0.0062447297 |
|    clip_fraction         | 0.0432       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.68         |
|    cost_value_loss       | 6.25         |
|    cost_values           | 2.96         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.3         |
|    n_updates             | 12050        |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.408        |
|    value_loss            | 40.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5841532   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1075         |
|    total_timesteps       | 2471936      |
| train/                   |              |
|    approx_kl             | 0.0034046692 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.02         |
|    cost_value_loss       | 2.19         |
|    cost_values           | 2.96         |
|    entropy               | -1.03        |
|    entropy_loss          | -1.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 12060        |
|    policy_gradient_loss  | -0.000196    |
|    std                   | 0.404        |
|    value_loss            | 34           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.97785556  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1110         |
|    total_timesteps       | 2473984      |
| train/                   |              |
|    approx_kl             | 0.0036228234 |
|    clip_fraction         | 0.0656       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.09         |
|    cost_value_loss       | 6.81         |
|    cost_values           | 2.95         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.8         |
|    n_updates             | 12070        |
|    policy_gradient_loss  | -3.06e-05    |
|    std                   | 0.403        |
|    value_loss            | 37.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7893831   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 33           |
|    time_elapsed          | 1145         |
|    total_timesteps       | 2476032      |
| train/                   |              |
|    approx_kl             | 0.0025095532 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 1.61         |
|    cost_values           | 2.82         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.91         |
|    n_updates             | 12080        |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 0.403        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5924643   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 34           |
|    time_elapsed          | 1180         |
|    total_timesteps       | 2478080      |
| train/                   |              |
|    approx_kl             | 0.0050958386 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 1.96         |
|    cost_values           | 2.6          |
|    entropy               | -1.01        |
|    entropy_loss          | -1.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.84         |
|    n_updates             | 12090        |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.402        |
|    value_loss            | 7.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6519872   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 35           |
|    time_elapsed          | 1215         |
|    total_timesteps       | 2480128      |
| train/                   |              |
|    approx_kl             | 0.0032065636 |
|    clip_fraction         | 0.0379       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 2.23         |
|    cost_values           | 2.46         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.42         |
|    n_updates             | 12100        |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.402        |
|    value_loss            | 14.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.46286583  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 36           |
|    time_elapsed          | 1251         |
|    total_timesteps       | 2482176      |
| train/                   |              |
|    approx_kl             | 0.0005176271 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 9.68         |
|    cost_values           | 2.37         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.8          |
|    n_updates             | 12110        |
|    policy_gradient_loss  | 0.00121      |
|    std                   | 0.402        |
|    value_loss            | 9.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.71985734  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 37           |
|    time_elapsed          | 1286         |
|    total_timesteps       | 2484224      |
| train/                   |              |
|    approx_kl             | 0.0033713684 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 3.63         |
|    cost_values           | 2.59         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 12120        |
|    policy_gradient_loss  | -0.000268    |
|    std                   | 0.4          |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0268867  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -728        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 38          |
|    time_elapsed          | 1320        |
|    total_timesteps       | 2486272     |
| train/                   |             |
|    approx_kl             | 0.006010282 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.72        |
|    cost_value_loss       | 1.01        |
|    cost_values           | 2.64        |
|    entropy               | -1          |
|    entropy_loss          | -1          |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3           |
|    n_updates             | 12130       |
|    policy_gradient_loss  | -0.000675   |
|    std                   | 0.399       |
|    value_loss            | 6.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.77175236 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 39          |
|    time_elapsed          | 1354        |
|    total_timesteps       | 2488320     |
| train/                   |             |
|    approx_kl             | 0.004143609 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.07        |
|    cost_value_loss       | 0.123       |
|    cost_values           | 2.3         |
|    entropy               | -0.996      |
|    entropy_loss          | -0.999      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.05        |
|    n_updates             | 12140       |
|    policy_gradient_loss  | -0.00203    |
|    std                   | 0.398       |
|    value_loss            | 16.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4233136   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 40           |
|    time_elapsed          | 1389         |
|    total_timesteps       | 2490368      |
| train/                   |              |
|    approx_kl             | 0.0018036187 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 0.833        |
|    cost_values           | 1.85         |
|    entropy               | -0.994       |
|    entropy_loss          | -0.995       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.59         |
|    n_updates             | 12150        |
|    policy_gradient_loss  | -2.92e-05    |
|    std                   | 0.398        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3596948  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 41          |
|    time_elapsed          | 1424        |
|    total_timesteps       | 2492416     |
| train/                   |             |
|    approx_kl             | 0.010663911 |
|    clip_fraction         | 0.0451      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.99        |
|    cost_value_loss       | 2.08        |
|    cost_values           | 1.81        |
|    entropy               | -0.995      |
|    entropy_loss          | -0.994      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.82        |
|    n_updates             | 12160       |
|    policy_gradient_loss  | -0.000769   |
|    std                   | 0.398       |
|    value_loss            | 6.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.93        |
| reward                   | -0.5564358  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -730        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 42          |
|    time_elapsed          | 1459        |
|    total_timesteps       | 2494464     |
| train/                   |             |
|    approx_kl             | 0.002725508 |
|    clip_fraction         | 0.0505      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 1.83        |
|    cost_values           | 1.94        |
|    entropy               | -0.999      |
|    entropy_loss          | -0.996      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.36        |
|    n_updates             | 12170       |
|    policy_gradient_loss  | 0.000191    |
|    std                   | 0.399       |
|    value_loss            | 18.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.11        |
| reward                   | -0.8871466  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 43          |
|    time_elapsed          | 1494        |
|    total_timesteps       | 2496512     |
| train/                   |             |
|    approx_kl             | 0.003911066 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.76        |
|    cost_value_loss       | 6.79        |
|    cost_values           | 2.08        |
|    entropy               | -1          |
|    entropy_loss          | -1          |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.88        |
|    n_updates             | 12180       |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.399       |
|    value_loss            | 14.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.05         |
| reward                   | -0.6968181   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 44           |
|    time_elapsed          | 1528         |
|    total_timesteps       | 2498560      |
| train/                   |              |
|    approx_kl             | 0.0045679277 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 4.28         |
|    cost_values           | 2.37         |
|    entropy               | -0.998       |
|    entropy_loss          | -1           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.49         |
|    n_updates             | 12190        |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.398        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50230294  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 45           |
|    time_elapsed          | 1563         |
|    total_timesteps       | 2500608      |
| train/                   |              |
|    approx_kl             | 0.0037041898 |
|    clip_fraction         | 0.00937      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 0.17         |
|    cost_values           | 2.32         |
|    entropy               | -0.994       |
|    entropy_loss          | -0.995       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 12200        |
|    policy_gradient_loss  | -0.000742    |
|    std                   | 0.398        |
|    value_loss            | 9.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.7726326  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 46          |
|    time_elapsed          | 1598        |
|    total_timesteps       | 2502656     |
| train/                   |             |
|    approx_kl             | 0.007041658 |
|    clip_fraction         | 0.0158      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 6.14        |
|    cost_values           | 2.08        |
|    entropy               | -0.995      |
|    entropy_loss          | -0.995      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 12210       |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 0.398       |
|    value_loss            | 41.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.58886796  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 47           |
|    time_elapsed          | 1634         |
|    total_timesteps       | 2504704      |
| train/                   |              |
|    approx_kl             | 0.0020118547 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 6.84         |
|    cost_values           | 2.08         |
|    entropy               | -0.995       |
|    entropy_loss          | -0.995       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.84         |
|    n_updates             | 12220        |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.398        |
|    value_loss            | 5.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.1183336   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 48           |
|    time_elapsed          | 1668         |
|    total_timesteps       | 2506752      |
| train/                   |              |
|    approx_kl             | 0.0046562473 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 5.9          |
|    cost_values           | 2.34         |
|    entropy               | -0.994       |
|    entropy_loss          | -0.995       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.8         |
|    n_updates             | 12230        |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.398        |
|    value_loss            | 33.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5761334   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 49           |
|    time_elapsed          | 1704         |
|    total_timesteps       | 2508800      |
| train/                   |              |
|    approx_kl             | 0.0060479287 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 1.27         |
|    cost_values           | 2.52         |
|    entropy               | -0.99        |
|    entropy_loss          | -0.993       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.5          |
|    n_updates             | 12240        |
|    policy_gradient_loss  | -0.000741    |
|    std                   | 0.397        |
|    value_loss            | 10           |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/cvnfd1ju
-----------------------------------
| avg_speed          | 8.03       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.03       |
| reward             | -1.1602608 |
| rollout/           |            |
|    ep_len_mean     | 965        |
|    ep_rew_mean     | -725       |
| time/              |            |
|    fps             | 80         |
|    iterations      | 1          |
|    time_elapsed    | 25         |
|    total_timesteps | 2510848    |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.2147491   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 2512896      |
| train/                   |              |
|    approx_kl             | 0.0027422777 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.74         |
|    cost_value_loss       | 9.49         |
|    cost_values           | 2.57         |
|    entropy               | -0.981       |
|    entropy_loss          | -0.981       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 12260        |
|    policy_gradient_loss  | -0.000287    |
|    std                   | 0.395        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.86334527  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 2514944      |
| train/                   |              |
|    approx_kl             | 0.0035022455 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 0.32         |
|    cost_values           | 2.65         |
|    entropy               | -0.98        |
|    entropy_loss          | -0.98        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.54         |
|    n_updates             | 12270        |
|    policy_gradient_loss  | -0.000475    |
|    std                   | 0.395        |
|    value_loss            | 18.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3409801   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 2516992      |
| train/                   |              |
|    approx_kl             | 0.0021495332 |
|    clip_fraction         | 0.0623       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 1.61         |
|    cost_values           | 2.38         |
|    entropy               | -0.985       |
|    entropy_loss          | -0.982       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.61         |
|    n_updates             | 12280        |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 0.396        |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6519336   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 2519040      |
| train/                   |              |
|    approx_kl             | 0.0021378878 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 0.795        |
|    cost_values           | 2.2          |
|    entropy               | -0.987       |
|    entropy_loss          | -0.987       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.18         |
|    n_updates             | 12290        |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.396        |
|    value_loss            | 13.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.98136204 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 6           |
|    time_elapsed          | 199         |
|    total_timesteps       | 2521088     |
| train/                   |             |
|    approx_kl             | 0.007406703 |
|    clip_fraction         | 0.072       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 18.5        |
|    cost_values           | 2.01        |
|    entropy               | -0.985      |
|    entropy_loss          | -0.985      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 12300       |
|    policy_gradient_loss  | -0.00491    |
|    std                   | 0.396       |
|    value_loss            | 20.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.5232304   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 234          |
|    total_timesteps       | 2523136      |
| train/                   |              |
|    approx_kl             | 0.0036420133 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 3.88         |
|    cost_values           | 2.14         |
|    entropy               | -0.984       |
|    entropy_loss          | -0.984       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.97         |
|    n_updates             | 12310        |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.396        |
|    value_loss            | 6.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.32107484  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 8            |
|    time_elapsed          | 269          |
|    total_timesteps       | 2525184      |
| train/                   |              |
|    approx_kl             | 0.0028780831 |
|    clip_fraction         | 0.00327      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.36         |
|    cost_value_loss       | 8.56         |
|    cost_values           | 2.3          |
|    entropy               | -0.983       |
|    entropy_loss          | -0.983       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.84         |
|    n_updates             | 12320        |
|    policy_gradient_loss  | 1.3e-05      |
|    std                   | 0.396        |
|    value_loss            | 11.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0724       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0724       |
| reward                   | -0.6221332   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 304          |
|    total_timesteps       | 2527232      |
| train/                   |              |
|    approx_kl             | 0.0038656686 |
|    clip_fraction         | 0.00488      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.5          |
|    cost_value_loss       | 6.85         |
|    cost_values           | 2.4          |
|    entropy               | -0.983       |
|    entropy_loss          | -0.983       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.68         |
|    n_updates             | 12330        |
|    policy_gradient_loss  | -0.000527    |
|    std                   | 0.396        |
|    value_loss            | 6.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.64         |
| reward                   | -0.7454226   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 2529280      |
| train/                   |              |
|    approx_kl             | 0.0053084674 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 0.539        |
|    cost_values           | 2.39         |
|    entropy               | -0.983       |
|    entropy_loss          | -0.984       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.08         |
|    n_updates             | 12340        |
|    policy_gradient_loss  | -0.000325    |
|    std                   | 0.396        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.79         |
| reward                   | -0.45235324  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 373          |
|    total_timesteps       | 2531328      |
| train/                   |              |
|    approx_kl             | 0.0018481488 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 0.0696       |
|    cost_values           | 1.87         |
|    entropy               | -0.975       |
|    entropy_loss          | -0.979       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 12350        |
|    policy_gradient_loss  | 0.000378     |
|    std                   | 0.394        |
|    value_loss            | 17           |
-------------------------------------------
slurmstepd: error: *** STEP 141853.0 ON airl.ist.berkeley.edu CANCELLED AT 2024-02-22T15:22:32 ***
slurmstepd: error: *** JOB 141853 ON airl.ist.berkeley.edu CANCELLED AT 2024-02-22T15:22:32 ***
