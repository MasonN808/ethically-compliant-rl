Steps	update/episode	update/cum_cost	train/reward	train/cost	train/length	loss/kl	loss/entropy	loss/rew_loss	loss/cost_loss	loss/optim_A	loss/optim_B	loss/optim_C	loss/optim_Q	loss/optim_R	loss/optim_S	loss/optim_lam	loss/optim_nu	loss/optim_case	loss/step_size	loss/vf0	loss/vf1	loss/vf_total	update/gradient_steps	test/reward	test/cost	test/length	update/duration	update/test_time	update/test_speed	update/train_collector_time	update/train_model_time	update/train_speed	update/remaining_epoch	update/env_step
20000	20.0	1745.0	-1.2366270302391826	87.25	1000.0	0.006676580756902695	1.8397140502929688	-0.0017223277174402973	87.24362373352051	0.0270174709148705	-594344.802734375	77.24362373352051	-0.011607968132011592	0.03275523137199343	-0.02250784181524068	0.00042788102291524405	1.2304621040821075	0.25	0.13325876409380738	0.18205589801073074	13.789791107177734	13.97184705734253	4.0	-24.309953988953648	13.0	1000.0	30.87208867073059	6.699560165405273	298.5270600788783	14.09614610671997	10.076382398605347	827.3855172243942	9.0	20000.0
40000	10.0	40.0	5302.0	0.26874923167019443	177.85	1000.0	0.0059498995542526245	1.839155673980713	-0.0013233701287163058	177.84417724609375	-0.0012526118662208319	-1523080.6875	167.84417724609375	-0.015936564188450575	-0.0035738999758905265	0.0041306710336357355	0.0	0.3558509349822998	0.25	0.13156347713421318	0.1376064009964466	23.428543090820312	23.566149711608887	8.0	-14.72465688918252	0.0	1000.0	59.725301027297974	12.543949365615845	318.87883818826464	27.936092615127563	19.245259046554565	847.7925831125692	8.0	40000.0
